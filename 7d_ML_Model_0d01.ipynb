{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b137a905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\Users\\\\user\\\\anaconda3\\\\lib\\\\site-packages\\\\config']\n",
      "2.12.0-dev20221107\n",
      "2.12.0\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import glob\n",
    "import xlwings as xw\n",
    "import math\n",
    "from pathlib import Path\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "from matplotlib import cm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mclr\n",
    "import plotly.express as px\n",
    "import statsmodels.api as sm\n",
    "import pylab as py\n",
    "import os, cv2, glob, tempfile\n",
    "import joblib\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "import sklearn\n",
    "from sklearn import datasets\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "make_scorer = sklearn.metrics.make_scorer\n",
    "f1 = make_scorer(f1_score, pos_label=1, average=\"binary\")\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate, KFold\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import BatchNormalization, Conv2D, MaxPooling2D, Activation, Dropout, Flatten, Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras import utils as np_utils\n",
    "from keras import models\n",
    "import keras_tuner as kt\n",
    "from scipy import signal\n",
    "\n",
    "import config as config\n",
    "print(config.__path__)\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import to_categorical\n",
    "from keras import backend as K\n",
    "\n",
    "import argparse\n",
    "# from sklearn.utils import class_weight\n",
    "print(tf.__version__)\n",
    "print(keras.__version__)\n",
    "\n",
    "import shutil\n",
    "import xlwings as xw\n",
    "\n",
    "%matplotlib inline\n",
    "mpl.use(\"Agg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5c8a718",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build XGBoost Model\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statsmodels.graphics.tsaplots import plot_acf,plot_pacf\n",
    "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV,train_test_split\n",
    "from skopt import BayesSearchCV\n",
    "from sklearn.metrics import accuracy_score,f1_score,roc_auc_score,confusion_matrix,roc_curve\n",
    "import xgboost as xgb\n",
    "import time\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30868f12",
   "metadata": {},
   "source": [
    "# 1. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "daf38283",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDEFSDf = pd.read_csv(r\"H:\\\\3_output_raMSIn\\\\3_3_Output_raMSIn_HKU_Ingested4ALL\\\\XGB_ALL\\\\df_train_cbMSIn0d014nonInDI_norm.csv\")\n",
    "diDEFSDf = pd.read_csv(r\"H:\\\\3_output_raMSIn\\\\3_3_Output_raMSIn_HKU_Ingested4ALL\\\\XGB_ALL\\\\df_nonInDI_cbMSIn0d014nonInDI_norm.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36740c29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel_id</th>\n",
       "      <th>311.165</th>\n",
       "      <th>269.245</th>\n",
       "      <th>215.03</th>\n",
       "      <th>295.225</th>\n",
       "      <th>883.53</th>\n",
       "      <th>309.165</th>\n",
       "      <th>738.505</th>\n",
       "      <th>435.295</th>\n",
       "      <th>280.235</th>\n",
       "      <th>241.215</th>\n",
       "      <th>311.225</th>\n",
       "      <th>339.2</th>\n",
       "      <th>353.205</th>\n",
       "      <th>325.185</th>\n",
       "      <th>250.145</th>\n",
       "      <th>514.285</th>\n",
       "      <th>265.15</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HKULiver_Post29wk_HCCAMCLiver_Left_Mice03_Slid...</td>\n",
       "      <td>0.318680</td>\n",
       "      <td>0.158874</td>\n",
       "      <td>-0.119558</td>\n",
       "      <td>-0.067045</td>\n",
       "      <td>-0.066287</td>\n",
       "      <td>0.379941</td>\n",
       "      <td>-0.143222</td>\n",
       "      <td>0.118146</td>\n",
       "      <td>-0.082902</td>\n",
       "      <td>0.226590</td>\n",
       "      <td>-0.001528</td>\n",
       "      <td>0.230682</td>\n",
       "      <td>0.259711</td>\n",
       "      <td>0.293665</td>\n",
       "      <td>0.126028</td>\n",
       "      <td>-0.040504</td>\n",
       "      <td>0.322887</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HKULiver_Post29wk_HCCAMCLiver_Left_Mice03_Slid...</td>\n",
       "      <td>0.440770</td>\n",
       "      <td>0.416132</td>\n",
       "      <td>-0.038726</td>\n",
       "      <td>-0.067045</td>\n",
       "      <td>-0.016995</td>\n",
       "      <td>0.474342</td>\n",
       "      <td>-0.160202</td>\n",
       "      <td>0.058245</td>\n",
       "      <td>-0.102754</td>\n",
       "      <td>0.292241</td>\n",
       "      <td>-0.001528</td>\n",
       "      <td>0.312409</td>\n",
       "      <td>0.331336</td>\n",
       "      <td>0.399209</td>\n",
       "      <td>0.300340</td>\n",
       "      <td>-0.040504</td>\n",
       "      <td>0.392676</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HKULiver_Post29wk_HCCAMCLiver_Left_Mice03_Slid...</td>\n",
       "      <td>0.297775</td>\n",
       "      <td>0.175596</td>\n",
       "      <td>-0.084135</td>\n",
       "      <td>-0.067045</td>\n",
       "      <td>-0.008095</td>\n",
       "      <td>0.313386</td>\n",
       "      <td>-0.150604</td>\n",
       "      <td>-0.029436</td>\n",
       "      <td>-0.088450</td>\n",
       "      <td>0.210586</td>\n",
       "      <td>-0.001528</td>\n",
       "      <td>0.229602</td>\n",
       "      <td>0.246386</td>\n",
       "      <td>0.267796</td>\n",
       "      <td>0.208663</td>\n",
       "      <td>-0.040504</td>\n",
       "      <td>0.315222</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HKULiver_Post29wk_HCCAMCLiver_Left_Mice03_Slid...</td>\n",
       "      <td>0.276239</td>\n",
       "      <td>0.121844</td>\n",
       "      <td>-0.042891</td>\n",
       "      <td>-0.067045</td>\n",
       "      <td>-0.020798</td>\n",
       "      <td>0.305273</td>\n",
       "      <td>-0.142973</td>\n",
       "      <td>-0.018069</td>\n",
       "      <td>-0.107063</td>\n",
       "      <td>0.272800</td>\n",
       "      <td>-0.001528</td>\n",
       "      <td>0.220945</td>\n",
       "      <td>0.199128</td>\n",
       "      <td>0.247302</td>\n",
       "      <td>0.200047</td>\n",
       "      <td>-0.040504</td>\n",
       "      <td>0.303789</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HKULiver_Post29wk_HCCAMCLiver_Left_Mice03_Slid...</td>\n",
       "      <td>0.172550</td>\n",
       "      <td>0.211353</td>\n",
       "      <td>-0.132357</td>\n",
       "      <td>-0.067045</td>\n",
       "      <td>0.002602</td>\n",
       "      <td>0.216593</td>\n",
       "      <td>-0.145999</td>\n",
       "      <td>0.140062</td>\n",
       "      <td>-0.064755</td>\n",
       "      <td>0.166787</td>\n",
       "      <td>-0.001528</td>\n",
       "      <td>0.138834</td>\n",
       "      <td>0.185411</td>\n",
       "      <td>0.151390</td>\n",
       "      <td>0.094654</td>\n",
       "      <td>-0.040504</td>\n",
       "      <td>0.219720</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90955</th>\n",
       "      <td>HKULiver_Post29wk_HCCLiver_Left_Mice12_Slide4F...</td>\n",
       "      <td>0.035410</td>\n",
       "      <td>-0.286289</td>\n",
       "      <td>0.003710</td>\n",
       "      <td>-0.067045</td>\n",
       "      <td>0.003306</td>\n",
       "      <td>0.062085</td>\n",
       "      <td>-0.200224</td>\n",
       "      <td>0.242741</td>\n",
       "      <td>-0.173988</td>\n",
       "      <td>-0.248716</td>\n",
       "      <td>-0.001528</td>\n",
       "      <td>0.042742</td>\n",
       "      <td>0.062754</td>\n",
       "      <td>0.035213</td>\n",
       "      <td>0.038039</td>\n",
       "      <td>0.212815</td>\n",
       "      <td>0.036007</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90956</th>\n",
       "      <td>HKULiver_Post29wk_HCCLiver_Left_Mice12_Slide4F...</td>\n",
       "      <td>0.021744</td>\n",
       "      <td>-0.286289</td>\n",
       "      <td>-0.091689</td>\n",
       "      <td>-0.067045</td>\n",
       "      <td>0.004163</td>\n",
       "      <td>0.073295</td>\n",
       "      <td>-0.191613</td>\n",
       "      <td>0.300480</td>\n",
       "      <td>-0.195427</td>\n",
       "      <td>0.152716</td>\n",
       "      <td>-0.001528</td>\n",
       "      <td>0.050250</td>\n",
       "      <td>0.066487</td>\n",
       "      <td>0.037005</td>\n",
       "      <td>0.210493</td>\n",
       "      <td>-0.040504</td>\n",
       "      <td>0.018545</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90957</th>\n",
       "      <td>HKULiver_Post29wk_HCCLiver_Left_Mice12_Slide4F...</td>\n",
       "      <td>0.030824</td>\n",
       "      <td>0.350751</td>\n",
       "      <td>-0.093844</td>\n",
       "      <td>-0.067045</td>\n",
       "      <td>-0.011962</td>\n",
       "      <td>0.043894</td>\n",
       "      <td>-0.114121</td>\n",
       "      <td>0.195788</td>\n",
       "      <td>-0.114261</td>\n",
       "      <td>-0.248716</td>\n",
       "      <td>-0.001528</td>\n",
       "      <td>0.046723</td>\n",
       "      <td>0.097950</td>\n",
       "      <td>0.037395</td>\n",
       "      <td>0.143166</td>\n",
       "      <td>-0.040504</td>\n",
       "      <td>-0.052600</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90958</th>\n",
       "      <td>HKULiver_Post29wk_HCCLiver_Left_Mice12_Slide4F...</td>\n",
       "      <td>0.045441</td>\n",
       "      <td>-0.286289</td>\n",
       "      <td>-0.123126</td>\n",
       "      <td>-0.067045</td>\n",
       "      <td>-0.002699</td>\n",
       "      <td>0.059139</td>\n",
       "      <td>-0.138327</td>\n",
       "      <td>0.149666</td>\n",
       "      <td>-0.163355</td>\n",
       "      <td>-0.248716</td>\n",
       "      <td>-0.001528</td>\n",
       "      <td>0.033817</td>\n",
       "      <td>-0.065876</td>\n",
       "      <td>0.036375</td>\n",
       "      <td>0.188902</td>\n",
       "      <td>-0.040504</td>\n",
       "      <td>0.047997</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90959</th>\n",
       "      <td>HKULiver_Post29wk_HCCLiver_Left_Mice12_Slide4F...</td>\n",
       "      <td>0.017762</td>\n",
       "      <td>-0.286289</td>\n",
       "      <td>-0.121358</td>\n",
       "      <td>-0.067045</td>\n",
       "      <td>-0.056177</td>\n",
       "      <td>0.048773</td>\n",
       "      <td>-0.112228</td>\n",
       "      <td>0.101821</td>\n",
       "      <td>-0.231541</td>\n",
       "      <td>-0.248716</td>\n",
       "      <td>-0.001528</td>\n",
       "      <td>0.041683</td>\n",
       "      <td>-0.065876</td>\n",
       "      <td>0.028752</td>\n",
       "      <td>0.177535</td>\n",
       "      <td>-0.040504</td>\n",
       "      <td>0.035222</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90960 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                pixel_id   311.165   269.245  \\\n",
       "0      HKULiver_Post29wk_HCCAMCLiver_Left_Mice03_Slid...  0.318680  0.158874   \n",
       "1      HKULiver_Post29wk_HCCAMCLiver_Left_Mice03_Slid...  0.440770  0.416132   \n",
       "2      HKULiver_Post29wk_HCCAMCLiver_Left_Mice03_Slid...  0.297775  0.175596   \n",
       "3      HKULiver_Post29wk_HCCAMCLiver_Left_Mice03_Slid...  0.276239  0.121844   \n",
       "4      HKULiver_Post29wk_HCCAMCLiver_Left_Mice03_Slid...  0.172550  0.211353   \n",
       "...                                                  ...       ...       ...   \n",
       "90955  HKULiver_Post29wk_HCCLiver_Left_Mice12_Slide4F...  0.035410 -0.286289   \n",
       "90956  HKULiver_Post29wk_HCCLiver_Left_Mice12_Slide4F...  0.021744 -0.286289   \n",
       "90957  HKULiver_Post29wk_HCCLiver_Left_Mice12_Slide4F...  0.030824  0.350751   \n",
       "90958  HKULiver_Post29wk_HCCLiver_Left_Mice12_Slide4F...  0.045441 -0.286289   \n",
       "90959  HKULiver_Post29wk_HCCLiver_Left_Mice12_Slide4F...  0.017762 -0.286289   \n",
       "\n",
       "         215.03   295.225    883.53   309.165   738.505   435.295   280.235  \\\n",
       "0     -0.119558 -0.067045 -0.066287  0.379941 -0.143222  0.118146 -0.082902   \n",
       "1     -0.038726 -0.067045 -0.016995  0.474342 -0.160202  0.058245 -0.102754   \n",
       "2     -0.084135 -0.067045 -0.008095  0.313386 -0.150604 -0.029436 -0.088450   \n",
       "3     -0.042891 -0.067045 -0.020798  0.305273 -0.142973 -0.018069 -0.107063   \n",
       "4     -0.132357 -0.067045  0.002602  0.216593 -0.145999  0.140062 -0.064755   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "90955  0.003710 -0.067045  0.003306  0.062085 -0.200224  0.242741 -0.173988   \n",
       "90956 -0.091689 -0.067045  0.004163  0.073295 -0.191613  0.300480 -0.195427   \n",
       "90957 -0.093844 -0.067045 -0.011962  0.043894 -0.114121  0.195788 -0.114261   \n",
       "90958 -0.123126 -0.067045 -0.002699  0.059139 -0.138327  0.149666 -0.163355   \n",
       "90959 -0.121358 -0.067045 -0.056177  0.048773 -0.112228  0.101821 -0.231541   \n",
       "\n",
       "        241.215   311.225     339.2   353.205   325.185   250.145   514.285  \\\n",
       "0      0.226590 -0.001528  0.230682  0.259711  0.293665  0.126028 -0.040504   \n",
       "1      0.292241 -0.001528  0.312409  0.331336  0.399209  0.300340 -0.040504   \n",
       "2      0.210586 -0.001528  0.229602  0.246386  0.267796  0.208663 -0.040504   \n",
       "3      0.272800 -0.001528  0.220945  0.199128  0.247302  0.200047 -0.040504   \n",
       "4      0.166787 -0.001528  0.138834  0.185411  0.151390  0.094654 -0.040504   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "90955 -0.248716 -0.001528  0.042742  0.062754  0.035213  0.038039  0.212815   \n",
       "90956  0.152716 -0.001528  0.050250  0.066487  0.037005  0.210493 -0.040504   \n",
       "90957 -0.248716 -0.001528  0.046723  0.097950  0.037395  0.143166 -0.040504   \n",
       "90958 -0.248716 -0.001528  0.033817 -0.065876  0.036375  0.188902 -0.040504   \n",
       "90959 -0.248716 -0.001528  0.041683 -0.065876  0.028752  0.177535 -0.040504   \n",
       "\n",
       "         265.15  type  \n",
       "0      0.322887     0  \n",
       "1      0.392676     0  \n",
       "2      0.315222     0  \n",
       "3      0.303789     0  \n",
       "4      0.219720     0  \n",
       "...         ...   ...  \n",
       "90955  0.036007     1  \n",
       "90956  0.018545     1  \n",
       "90957 -0.052600     1  \n",
       "90958  0.047997     1  \n",
       "90959  0.035222     1  \n",
       "\n",
       "[90960 rows x 19 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDEFSDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "558c10c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "can = []\n",
    "for i in list(range(0,9)) + list(range(15,17)) + [len(list(trainDEFSDf.columns))-1]:\n",
    "    can.append(list(trainDEFSDf.columns)[i])\n",
    "\n",
    "dican = []\n",
    "for i in list(range(0,9)) + list(range(15,17)) + [len(list(diDEFSDf.columns))-1]:\n",
    "    dican.append(list(diDEFSDf.columns)[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85c654ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pixel_id',\n",
       " '311.165',\n",
       " '269.245',\n",
       " '215.03',\n",
       " '295.225',\n",
       " '883.53',\n",
       " '309.165',\n",
       " '738.505',\n",
       " '435.295',\n",
       " '250.145',\n",
       " '514.285',\n",
       " 'type']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "can"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c5daef9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pixel_id',\n",
       " '311.16',\n",
       " '269.24',\n",
       " '215.03',\n",
       " '295.23',\n",
       " '883.54',\n",
       " '309.18',\n",
       " '738.51',\n",
       " '435.3',\n",
       " '250.14',\n",
       " '514.28',\n",
       " 'type']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dican"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d2530f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## input training set ## 90960 x 20 df\n",
    "trainDEFSDf = pd.read_csv(r\"H:\\\\3_output_raMSIn\\\\3_3_Output_raMSIn_HKU_Ingested4ALL\\\\XGB_ALL\\\\df_train_cbMSIn0d014nonInDI_norm.csv\")\n",
    "#trainDEFSDf[trainDEFSDf.type .== 1, :]\n",
    "## calculate weight ## 0: 47449, 1: 43511\n",
    "trainDEFSDf = trainDEFSDf[can]\n",
    "Yy_train = trainDEFSDf[\"type\"]  # 0.9585; 1.0453\n",
    "sampleW = []\n",
    "for w in Yy_train:\n",
    "    if w == 0:\n",
    "        sampleW.append(0.9585)\n",
    "    elif w == 1:\n",
    "        sampleW.append(1.0453) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26f6b926",
   "metadata": {},
   "outputs": [],
   "source": [
    "## input ext val set ## 6075 x 20 df\n",
    "extDEFSDf = pd.read_csv(r\"H:\\\\3_output_raMSIn\\\\3_3_Output_raMSIn_HKU_Ingested4ALL\\\\XGB_ALL\\\\df_ext_cbMSIn0d014nonInDI_norm.csv\")\n",
    "#extDEFSDf[extDEFSDf.type .== 1, :]\n",
    "## calculate weight ## 0: 2943, 1: 3132\n",
    "extDEFSDf = extDEFSDf[can]\n",
    "Yy_ext = extDEFSDf[\"type\"]  # 1.0321; 0.9698\n",
    "sampleExtW = []\n",
    "for w in Yy_ext:\n",
    "    if w == 0:\n",
    "        sampleExtW.append(1.0321)\n",
    "    elif w == 1:\n",
    "        sampleExtW.append(0.9698) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f13b3818",
   "metadata": {},
   "outputs": [],
   "source": [
    "## input ingested set ## 97035 x 20 df\n",
    "ingestedDEFSDf = pd.read_csv(r\"H:\\\\3_output_raMSIn\\\\3_3_Output_raMSIn_HKU_Ingested4ALL\\\\XGB_ALL\\\\df_ingested_cbMSIn0d014nonInDI_norm.csv\")\n",
    "#ingestedDEFSDf[extDEFSDf.type .== 1, :]\n",
    "## calculate weight ## 0: 50392, 1: 46643\n",
    "ingestedDEFSDf = ingestedDEFSDf[can]\n",
    "Yy_ingested = ingestedDEFSDf[\"type\"]  # 0.9628; 1.0402\n",
    "sampleIngestedW = []\n",
    "for w in Yy_ingested:\n",
    "    if w == 0:\n",
    "        sampleIngestedW.append(0.9628)\n",
    "    elif w == 1:\n",
    "        sampleIngestedW.append(1.0402)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a884cb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "## input FNA set ## 88701 x 20 df\n",
    "fnaDEFSDf = pd.read_csv(r\"H:\\\\3_output_raMSIn\\\\3_3_Output_raMSIn_HKU_Ingested4ALL\\\\XGB_ALL\\\\df_FNA_cbMSIn0d014nonInDI_norm.csv\")\n",
    "#fnaDEFSDf[fnaDEFSDf.type .== 1, :]\n",
    "## calculate weight ##  0: 44540, 1: 44161\n",
    "fnaDEFSDf = fnaDEFSDf[can]\n",
    "Yy_FNA = fnaDEFSDf[\"type\"]  # 0.9957; 1.0043\n",
    "sampleFNAW = []\n",
    "for w in Yy_FNA:\n",
    "    if w == 0:\n",
    "        sampleFNAW.append(0.9957)\n",
    "    elif w == 1:\n",
    "        sampleFNAW.append(1.0043)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b2cfbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## input DirectIn set ## 88701 x 20 df\n",
    "diDEFSDf = pd.read_csv(r\"H:\\\\3_output_raMSIn\\\\3_3_Output_raMSIn_HKU_Ingested4ALL\\\\XGB_ALL\\\\df_nonInDI_cbMSIn0d014nonInDI_norm.csv\")\n",
    "#diDEFSDf[diDEFSDf.type .== 1, :]\n",
    "## calculate weight ## 0: 3027, 1: 3030\n",
    "diDEFSDf = diDEFSDf[dican]\n",
    "diDEFSDf = diDEFSDf.rename(columns={\"311.16\":\"311.165\", \"269.24\":\"269.245\", \"295.23\":\"295.225\", \"883.54\":\"883.53\", \n",
    "                                    \"309.18\":\"309.165\", \"738.51\":\"738.505\", \"435.3\":\"435.295\", \"280.24\":\"280.235\", \n",
    "                                    \"241.22\":\"241.215\", \"311.23\":\"311.225\", \"353.19\":\"353.205\", \"325.18\":\"325.185\", \n",
    "                                    \"250.14\":\"250.145\", \"514.28\":\"514.285\", \"265.14\":\"265.15\"})\n",
    "Yy_DI = diDEFSDf[\"type\"]  # 1.0005; 0.9995\n",
    "sampleDiW = []\n",
    "for w in Yy_DI:\n",
    "    if w == 0:\n",
    "        sampleDiW.append(1.0005)\n",
    "    elif w == 1:\n",
    "        sampleDiW.append(0.9995)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "95558b9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel_id</th>\n",
       "      <th>311.165</th>\n",
       "      <th>269.245</th>\n",
       "      <th>215.03</th>\n",
       "      <th>295.225</th>\n",
       "      <th>883.53</th>\n",
       "      <th>309.165</th>\n",
       "      <th>738.505</th>\n",
       "      <th>435.295</th>\n",
       "      <th>250.145</th>\n",
       "      <th>514.285</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HKULiver_Post29wk_HCCAMCLiver_DirectIn_MiceNL_...</td>\n",
       "      <td>0.005209</td>\n",
       "      <td>0.142200</td>\n",
       "      <td>0.055132</td>\n",
       "      <td>0.003688</td>\n",
       "      <td>0.077996</td>\n",
       "      <td>0.211143</td>\n",
       "      <td>0.061852</td>\n",
       "      <td>0.125846</td>\n",
       "      <td>0.465556</td>\n",
       "      <td>0.036498</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HKULiver_Post29wk_HCCAMCLiver_DirectIn_MiceNL_...</td>\n",
       "      <td>0.089567</td>\n",
       "      <td>0.156323</td>\n",
       "      <td>0.173760</td>\n",
       "      <td>0.001074</td>\n",
       "      <td>0.167022</td>\n",
       "      <td>0.317430</td>\n",
       "      <td>0.127993</td>\n",
       "      <td>0.145506</td>\n",
       "      <td>0.581512</td>\n",
       "      <td>0.099618</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HKULiver_Post29wk_HCCAMCLiver_DirectIn_MiceNL_...</td>\n",
       "      <td>0.032961</td>\n",
       "      <td>0.134117</td>\n",
       "      <td>0.033342</td>\n",
       "      <td>-0.069846</td>\n",
       "      <td>0.121979</td>\n",
       "      <td>0.212942</td>\n",
       "      <td>0.028980</td>\n",
       "      <td>0.076804</td>\n",
       "      <td>0.463399</td>\n",
       "      <td>0.056825</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HKULiver_Post29wk_HCCAMCLiver_DirectIn_MiceNL_...</td>\n",
       "      <td>0.080976</td>\n",
       "      <td>0.235063</td>\n",
       "      <td>0.080277</td>\n",
       "      <td>0.057323</td>\n",
       "      <td>0.129092</td>\n",
       "      <td>0.303446</td>\n",
       "      <td>0.108110</td>\n",
       "      <td>0.192986</td>\n",
       "      <td>0.548904</td>\n",
       "      <td>0.090339</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HKULiver_Post29wk_HCCAMCLiver_DirectIn_MiceNL_...</td>\n",
       "      <td>0.132523</td>\n",
       "      <td>0.236850</td>\n",
       "      <td>0.151528</td>\n",
       "      <td>0.080082</td>\n",
       "      <td>0.239269</td>\n",
       "      <td>0.394202</td>\n",
       "      <td>0.236241</td>\n",
       "      <td>0.204536</td>\n",
       "      <td>0.643706</td>\n",
       "      <td>0.147333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6052</th>\n",
       "      <td>HKULiver_Post29wk_HCCLiver_DirectIn_MiceHCC_S1...</td>\n",
       "      <td>-0.002071</td>\n",
       "      <td>-0.209544</td>\n",
       "      <td>0.151144</td>\n",
       "      <td>-0.039347</td>\n",
       "      <td>-0.042523</td>\n",
       "      <td>-0.056643</td>\n",
       "      <td>0.023261</td>\n",
       "      <td>0.147144</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.163267</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6053</th>\n",
       "      <td>HKULiver_Post29wk_HCCLiver_DirectIn_MiceHCC_S1...</td>\n",
       "      <td>-0.311749</td>\n",
       "      <td>-0.218071</td>\n",
       "      <td>-0.309877</td>\n",
       "      <td>-0.299480</td>\n",
       "      <td>-0.273013</td>\n",
       "      <td>-0.303035</td>\n",
       "      <td>-0.280535</td>\n",
       "      <td>-0.277867</td>\n",
       "      <td>-0.027025</td>\n",
       "      <td>-0.251944</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6054</th>\n",
       "      <td>HKULiver_Post29wk_HCCLiver_DirectIn_MiceHCC_S1...</td>\n",
       "      <td>-0.155841</td>\n",
       "      <td>-0.037302</td>\n",
       "      <td>-0.001820</td>\n",
       "      <td>-0.048717</td>\n",
       "      <td>-0.045113</td>\n",
       "      <td>-0.153138</td>\n",
       "      <td>-0.084896</td>\n",
       "      <td>-0.039435</td>\n",
       "      <td>-0.091159</td>\n",
       "      <td>0.091528</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6055</th>\n",
       "      <td>HKULiver_Post29wk_HCCLiver_DirectIn_MiceHCC_S1...</td>\n",
       "      <td>-0.130135</td>\n",
       "      <td>-0.100402</td>\n",
       "      <td>0.064682</td>\n",
       "      <td>-0.108138</td>\n",
       "      <td>-0.006814</td>\n",
       "      <td>-0.127244</td>\n",
       "      <td>-0.068984</td>\n",
       "      <td>-0.070669</td>\n",
       "      <td>-0.003682</td>\n",
       "      <td>-0.018040</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6056</th>\n",
       "      <td>HKULiver_Post29wk_HCCLiver_DirectIn_MiceHCC_S1...</td>\n",
       "      <td>-0.375077</td>\n",
       "      <td>-0.421285</td>\n",
       "      <td>-0.309877</td>\n",
       "      <td>-0.383148</td>\n",
       "      <td>-0.273013</td>\n",
       "      <td>-0.362302</td>\n",
       "      <td>-0.280535</td>\n",
       "      <td>-0.277867</td>\n",
       "      <td>-0.027551</td>\n",
       "      <td>-0.312439</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6057 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               pixel_id   311.165   269.245  \\\n",
       "0     HKULiver_Post29wk_HCCAMCLiver_DirectIn_MiceNL_...  0.005209  0.142200   \n",
       "1     HKULiver_Post29wk_HCCAMCLiver_DirectIn_MiceNL_...  0.089567  0.156323   \n",
       "2     HKULiver_Post29wk_HCCAMCLiver_DirectIn_MiceNL_...  0.032961  0.134117   \n",
       "3     HKULiver_Post29wk_HCCAMCLiver_DirectIn_MiceNL_...  0.080976  0.235063   \n",
       "4     HKULiver_Post29wk_HCCAMCLiver_DirectIn_MiceNL_...  0.132523  0.236850   \n",
       "...                                                 ...       ...       ...   \n",
       "6052  HKULiver_Post29wk_HCCLiver_DirectIn_MiceHCC_S1... -0.002071 -0.209544   \n",
       "6053  HKULiver_Post29wk_HCCLiver_DirectIn_MiceHCC_S1... -0.311749 -0.218071   \n",
       "6054  HKULiver_Post29wk_HCCLiver_DirectIn_MiceHCC_S1... -0.155841 -0.037302   \n",
       "6055  HKULiver_Post29wk_HCCLiver_DirectIn_MiceHCC_S1... -0.130135 -0.100402   \n",
       "6056  HKULiver_Post29wk_HCCLiver_DirectIn_MiceHCC_S1... -0.375077 -0.421285   \n",
       "\n",
       "        215.03   295.225    883.53   309.165   738.505   435.295   250.145  \\\n",
       "0     0.055132  0.003688  0.077996  0.211143  0.061852  0.125846  0.465556   \n",
       "1     0.173760  0.001074  0.167022  0.317430  0.127993  0.145506  0.581512   \n",
       "2     0.033342 -0.069846  0.121979  0.212942  0.028980  0.076804  0.463399   \n",
       "3     0.080277  0.057323  0.129092  0.303446  0.108110  0.192986  0.548904   \n",
       "4     0.151528  0.080082  0.239269  0.394202  0.236241  0.204536  0.643706   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "6052  0.151144 -0.039347 -0.042523 -0.056643  0.023261  0.147144  0.000700   \n",
       "6053 -0.309877 -0.299480 -0.273013 -0.303035 -0.280535 -0.277867 -0.027025   \n",
       "6054 -0.001820 -0.048717 -0.045113 -0.153138 -0.084896 -0.039435 -0.091159   \n",
       "6055  0.064682 -0.108138 -0.006814 -0.127244 -0.068984 -0.070669 -0.003682   \n",
       "6056 -0.309877 -0.383148 -0.273013 -0.362302 -0.280535 -0.277867 -0.027551   \n",
       "\n",
       "       514.285  type  \n",
       "0     0.036498     0  \n",
       "1     0.099618     0  \n",
       "2     0.056825     0  \n",
       "3     0.090339     0  \n",
       "4     0.147333     0  \n",
       "...        ...   ...  \n",
       "6052  0.163267     1  \n",
       "6053 -0.251944     1  \n",
       "6054  0.091528     1  \n",
       "6055 -0.018040     1  \n",
       "6056 -0.312439     1  \n",
       "\n",
       "[6057 rows x 12 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diDEFSDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ca171d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "## define functions for performace evaluation ##\n",
    "\n",
    "# Average score\n",
    "def avgScore(arrAcc, cv):\n",
    "    sumAcc = 0\n",
    "    for acc in arrAcc:\n",
    "        sumAcc += acc\n",
    "    return sumAcc / cv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9ccef0bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>311.165</th>\n",
       "      <th>269.245</th>\n",
       "      <th>215.03</th>\n",
       "      <th>295.225</th>\n",
       "      <th>883.53</th>\n",
       "      <th>309.165</th>\n",
       "      <th>738.505</th>\n",
       "      <th>435.295</th>\n",
       "      <th>250.145</th>\n",
       "      <th>514.285</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.318680</td>\n",
       "      <td>0.158874</td>\n",
       "      <td>-0.119558</td>\n",
       "      <td>-0.067045</td>\n",
       "      <td>-0.066287</td>\n",
       "      <td>0.379941</td>\n",
       "      <td>-0.143222</td>\n",
       "      <td>0.118146</td>\n",
       "      <td>0.126028</td>\n",
       "      <td>-0.040504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.440770</td>\n",
       "      <td>0.416132</td>\n",
       "      <td>-0.038726</td>\n",
       "      <td>-0.067045</td>\n",
       "      <td>-0.016995</td>\n",
       "      <td>0.474342</td>\n",
       "      <td>-0.160202</td>\n",
       "      <td>0.058245</td>\n",
       "      <td>0.300340</td>\n",
       "      <td>-0.040504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.297775</td>\n",
       "      <td>0.175596</td>\n",
       "      <td>-0.084135</td>\n",
       "      <td>-0.067045</td>\n",
       "      <td>-0.008095</td>\n",
       "      <td>0.313386</td>\n",
       "      <td>-0.150604</td>\n",
       "      <td>-0.029436</td>\n",
       "      <td>0.208663</td>\n",
       "      <td>-0.040504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.276239</td>\n",
       "      <td>0.121844</td>\n",
       "      <td>-0.042891</td>\n",
       "      <td>-0.067045</td>\n",
       "      <td>-0.020798</td>\n",
       "      <td>0.305273</td>\n",
       "      <td>-0.142973</td>\n",
       "      <td>-0.018069</td>\n",
       "      <td>0.200047</td>\n",
       "      <td>-0.040504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.172550</td>\n",
       "      <td>0.211353</td>\n",
       "      <td>-0.132357</td>\n",
       "      <td>-0.067045</td>\n",
       "      <td>0.002602</td>\n",
       "      <td>0.216593</td>\n",
       "      <td>-0.145999</td>\n",
       "      <td>0.140062</td>\n",
       "      <td>0.094654</td>\n",
       "      <td>-0.040504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90955</th>\n",
       "      <td>0.035410</td>\n",
       "      <td>-0.286289</td>\n",
       "      <td>0.003710</td>\n",
       "      <td>-0.067045</td>\n",
       "      <td>0.003306</td>\n",
       "      <td>0.062085</td>\n",
       "      <td>-0.200224</td>\n",
       "      <td>0.242741</td>\n",
       "      <td>0.038039</td>\n",
       "      <td>0.212815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90956</th>\n",
       "      <td>0.021744</td>\n",
       "      <td>-0.286289</td>\n",
       "      <td>-0.091689</td>\n",
       "      <td>-0.067045</td>\n",
       "      <td>0.004163</td>\n",
       "      <td>0.073295</td>\n",
       "      <td>-0.191613</td>\n",
       "      <td>0.300480</td>\n",
       "      <td>0.210493</td>\n",
       "      <td>-0.040504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90957</th>\n",
       "      <td>0.030824</td>\n",
       "      <td>0.350751</td>\n",
       "      <td>-0.093844</td>\n",
       "      <td>-0.067045</td>\n",
       "      <td>-0.011962</td>\n",
       "      <td>0.043894</td>\n",
       "      <td>-0.114121</td>\n",
       "      <td>0.195788</td>\n",
       "      <td>0.143166</td>\n",
       "      <td>-0.040504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90958</th>\n",
       "      <td>0.045441</td>\n",
       "      <td>-0.286289</td>\n",
       "      <td>-0.123126</td>\n",
       "      <td>-0.067045</td>\n",
       "      <td>-0.002699</td>\n",
       "      <td>0.059139</td>\n",
       "      <td>-0.138327</td>\n",
       "      <td>0.149666</td>\n",
       "      <td>0.188902</td>\n",
       "      <td>-0.040504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90959</th>\n",
       "      <td>0.017762</td>\n",
       "      <td>-0.286289</td>\n",
       "      <td>-0.121358</td>\n",
       "      <td>-0.067045</td>\n",
       "      <td>-0.056177</td>\n",
       "      <td>0.048773</td>\n",
       "      <td>-0.112228</td>\n",
       "      <td>0.101821</td>\n",
       "      <td>0.177535</td>\n",
       "      <td>-0.040504</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90960 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        311.165   269.245    215.03   295.225    883.53   309.165   738.505  \\\n",
       "0      0.318680  0.158874 -0.119558 -0.067045 -0.066287  0.379941 -0.143222   \n",
       "1      0.440770  0.416132 -0.038726 -0.067045 -0.016995  0.474342 -0.160202   \n",
       "2      0.297775  0.175596 -0.084135 -0.067045 -0.008095  0.313386 -0.150604   \n",
       "3      0.276239  0.121844 -0.042891 -0.067045 -0.020798  0.305273 -0.142973   \n",
       "4      0.172550  0.211353 -0.132357 -0.067045  0.002602  0.216593 -0.145999   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "90955  0.035410 -0.286289  0.003710 -0.067045  0.003306  0.062085 -0.200224   \n",
       "90956  0.021744 -0.286289 -0.091689 -0.067045  0.004163  0.073295 -0.191613   \n",
       "90957  0.030824  0.350751 -0.093844 -0.067045 -0.011962  0.043894 -0.114121   \n",
       "90958  0.045441 -0.286289 -0.123126 -0.067045 -0.002699  0.059139 -0.138327   \n",
       "90959  0.017762 -0.286289 -0.121358 -0.067045 -0.056177  0.048773 -0.112228   \n",
       "\n",
       "        435.295   250.145   514.285  \n",
       "0      0.118146  0.126028 -0.040504  \n",
       "1      0.058245  0.300340 -0.040504  \n",
       "2     -0.029436  0.208663 -0.040504  \n",
       "3     -0.018069  0.200047 -0.040504  \n",
       "4      0.140062  0.094654 -0.040504  \n",
       "...         ...       ...       ...  \n",
       "90955  0.242741  0.038039  0.212815  \n",
       "90956  0.300480  0.210493 -0.040504  \n",
       "90957  0.195788  0.143166 -0.040504  \n",
       "90958  0.149666  0.188902 -0.040504  \n",
       "90959  0.101821  0.177535 -0.040504  \n",
       "\n",
       "[90960 rows x 10 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDEFSDf[trainDEFSDf.columns[1:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ff9f9ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c56eae",
   "metadata": {},
   "source": [
    "# 2. Unsupervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8049959",
   "metadata": {},
   "source": [
    "## 2.1. Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "56926254",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 720x720 with 0 Axes>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from matplotlib.pyplot import figure\n",
    "plt.rcParams['figure.figsize'] = [10, 10]\n",
    "plt.grid(visible=None)\n",
    "plt.close()\n",
    "figure(figsize=(10, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "62a3d9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ROI_for_ML_Opti = pd.concat([trainDEFSDf, extDEFSDf, fnaDEFSDf, diDEFSDf]).set_index('pixel_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e9061d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ROI_for_ML_Opti_ingested = ingestedDEFSDf.set_index('pixel_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7d1ef236",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ROI_for_ML_Opti_train = trainDEFSDf.set_index('pixel_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f9f05550",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ROI_for_ML_Opti_ext = extDEFSDf.set_index('pixel_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0dfe922b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ROI_for_ML_Opti_FNA = fnaDEFSDf.set_index('pixel_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f17e49c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ROI_for_ML_Opti_di = diDEFSDf.set_index('pixel_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9c15f5e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>311.165</th>\n",
       "      <th>269.245</th>\n",
       "      <th>215.03</th>\n",
       "      <th>295.225</th>\n",
       "      <th>883.53</th>\n",
       "      <th>309.165</th>\n",
       "      <th>738.505</th>\n",
       "      <th>435.295</th>\n",
       "      <th>250.145</th>\n",
       "      <th>514.285</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6.057000e+03</td>\n",
       "      <td>6.057000e+03</td>\n",
       "      <td>6.057000e+03</td>\n",
       "      <td>6.057000e+03</td>\n",
       "      <td>6.057000e+03</td>\n",
       "      <td>6.057000e+03</td>\n",
       "      <td>6.057000e+03</td>\n",
       "      <td>6.057000e+03</td>\n",
       "      <td>6.057000e+03</td>\n",
       "      <td>6.057000e+03</td>\n",
       "      <td>6057.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-3.546775e-17</td>\n",
       "      <td>7.707591e-17</td>\n",
       "      <td>3.379059e-17</td>\n",
       "      <td>-4.492582e-17</td>\n",
       "      <td>-5.146581e-16</td>\n",
       "      <td>-3.770396e-17</td>\n",
       "      <td>5.544700e-17</td>\n",
       "      <td>1.021416e-15</td>\n",
       "      <td>-3.240616e-15</td>\n",
       "      <td>-7.857894e-17</td>\n",
       "      <td>0.500248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.259227e-01</td>\n",
       "      <td>1.439520e-01</td>\n",
       "      <td>1.664150e-01</td>\n",
       "      <td>1.354574e-01</td>\n",
       "      <td>1.815312e-01</td>\n",
       "      <td>1.711844e-01</td>\n",
       "      <td>1.276838e-01</td>\n",
       "      <td>2.073627e-01</td>\n",
       "      <td>1.914439e-01</td>\n",
       "      <td>1.330110e-01</td>\n",
       "      <td>0.500041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-3.937219e-01</td>\n",
       "      <td>-4.212849e-01</td>\n",
       "      <td>-3.098770e-01</td>\n",
       "      <td>-4.546975e-01</td>\n",
       "      <td>-2.730134e-01</td>\n",
       "      <td>-3.623015e-01</td>\n",
       "      <td>-2.805354e-01</td>\n",
       "      <td>-2.778670e-01</td>\n",
       "      <td>-9.115937e-02</td>\n",
       "      <td>-3.327803e-01</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-7.675099e-02</td>\n",
       "      <td>-6.813025e-02</td>\n",
       "      <td>-9.681857e-02</td>\n",
       "      <td>-6.200655e-02</td>\n",
       "      <td>-1.070219e-01</td>\n",
       "      <td>-8.983767e-02</td>\n",
       "      <td>-5.995209e-02</td>\n",
       "      <td>-2.778670e-01</td>\n",
       "      <td>-9.115937e-02</td>\n",
       "      <td>-6.633725e-02</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.528046e-03</td>\n",
       "      <td>-7.047522e-03</td>\n",
       "      <td>1.586049e-02</td>\n",
       "      <td>1.806138e-02</td>\n",
       "      <td>3.089123e-02</td>\n",
       "      <td>-3.333062e-02</td>\n",
       "      <td>1.460550e-02</td>\n",
       "      <td>6.081606e-03</td>\n",
       "      <td>-9.115937e-02</td>\n",
       "      <td>-1.853303e-02</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.998001e-02</td>\n",
       "      <td>5.956024e-02</td>\n",
       "      <td>1.123595e-01</td>\n",
       "      <td>7.459108e-02</td>\n",
       "      <td>1.304366e-01</td>\n",
       "      <td>3.545101e-02</td>\n",
       "      <td>6.956954e-02</td>\n",
       "      <td>1.665530e-01</td>\n",
       "      <td>1.938726e-04</td>\n",
       "      <td>8.938771e-02</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.062781e-01</td>\n",
       "      <td>5.787151e-01</td>\n",
       "      <td>6.901230e-01</td>\n",
       "      <td>5.453025e-01</td>\n",
       "      <td>7.269866e-01</td>\n",
       "      <td>6.376985e-01</td>\n",
       "      <td>7.194646e-01</td>\n",
       "      <td>7.221330e-01</td>\n",
       "      <td>9.088406e-01</td>\n",
       "      <td>6.672197e-01</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            311.165       269.245        215.03       295.225        883.53  \\\n",
       "count  6.057000e+03  6.057000e+03  6.057000e+03  6.057000e+03  6.057000e+03   \n",
       "mean  -3.546775e-17  7.707591e-17  3.379059e-17 -4.492582e-17 -5.146581e-16   \n",
       "std    1.259227e-01  1.439520e-01  1.664150e-01  1.354574e-01  1.815312e-01   \n",
       "min   -3.937219e-01 -4.212849e-01 -3.098770e-01 -4.546975e-01 -2.730134e-01   \n",
       "25%   -7.675099e-02 -6.813025e-02 -9.681857e-02 -6.200655e-02 -1.070219e-01   \n",
       "50%    9.528046e-03 -7.047522e-03  1.586049e-02  1.806138e-02  3.089123e-02   \n",
       "75%    8.998001e-02  5.956024e-02  1.123595e-01  7.459108e-02  1.304366e-01   \n",
       "max    6.062781e-01  5.787151e-01  6.901230e-01  5.453025e-01  7.269866e-01   \n",
       "\n",
       "            309.165       738.505       435.295       250.145       514.285  \\\n",
       "count  6.057000e+03  6.057000e+03  6.057000e+03  6.057000e+03  6.057000e+03   \n",
       "mean  -3.770396e-17  5.544700e-17  1.021416e-15 -3.240616e-15 -7.857894e-17   \n",
       "std    1.711844e-01  1.276838e-01  2.073627e-01  1.914439e-01  1.330110e-01   \n",
       "min   -3.623015e-01 -2.805354e-01 -2.778670e-01 -9.115937e-02 -3.327803e-01   \n",
       "25%   -8.983767e-02 -5.995209e-02 -2.778670e-01 -9.115937e-02 -6.633725e-02   \n",
       "50%   -3.333062e-02  1.460550e-02  6.081606e-03 -9.115937e-02 -1.853303e-02   \n",
       "75%    3.545101e-02  6.956954e-02  1.665530e-01  1.938726e-04  8.938771e-02   \n",
       "max    6.376985e-01  7.194646e-01  7.221330e-01  9.088406e-01  6.672197e-01   \n",
       "\n",
       "              type  \n",
       "count  6057.000000  \n",
       "mean      0.500248  \n",
       "std       0.500041  \n",
       "min       0.000000  \n",
       "25%       0.000000  \n",
       "50%       1.000000  \n",
       "75%       1.000000  \n",
       "max       1.000000  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ROI_for_ML_Opti_di.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c25aab6",
   "metadata": {},
   "source": [
    "## 2.2. PCA Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e9735181",
   "metadata": {},
   "outputs": [],
   "source": [
    "## PCA Analysis\n",
    "\n",
    "def pca_visual(df=df_ROI_for_ML_Opti_di):\n",
    "\n",
    "    pca = PCA(n_components=3)\n",
    "    raMSI_ML_mz_df = df.drop(\"type\", axis = 1)\n",
    "    pca.fit(raMSI_ML_mz_df)\n",
    "    result = pd.DataFrame(pca.transform(raMSI_ML_mz_df), columns=['PCA%i' % i for i in range(3)], index=df_ROI_for_ML_Opti_di.index)\n",
    "    \n",
    "    plt.subplots(dpi = 300)\n",
    "    plt.scatter(result['PCA1'], result['PCA2'], c = df['type'], s=1)\n",
    "    plt.xlabel('PC1', size=20)\n",
    "    plt.ylabel('PC2', size=20)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    plt.savefig(r\"H:/3_output_raMSIn/3_3_Output_raMSIn_HKU_Ingested4ALL/XGB_ALL/afterModelSelection/cbMSIn_0d01/PCA_di.tif\", bbox_inches = 'tight')\n",
    "\n",
    "    components = pca.fit_transform(raMSI_ML_mz_df)\n",
    "    total_var = pca.explained_variance_ratio_.sum() * 100\n",
    "    fig = px.scatter_3d(\n",
    "        components, x=0, y=1, z=2, color=df['type'],\n",
    "        title = f'Total Explained Variance: {total_var:.2f}%',\n",
    "        labels = {'0': 'PC 1', '1': 'PC 2', '2': 'PC 3'}\n",
    "    )\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe05a48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_visual()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a0c5f5",
   "metadata": {},
   "source": [
    "# 3. Supervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cdf76b0",
   "metadata": {},
   "source": [
    "## 3.1. Preparation of training and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a9518fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(df=df_ROI_for_ML_Opti_ingested):\n",
    "    raMSI_ML_NoType = df.drop(\"type\", axis = 1)\n",
    "    raMSI_ML_Type=df[['type']]\n",
    "    X_train,X_test,y_train,y_test=train_test_split(raMSI_ML_NoType,raMSI_ML_Type,test_size=0.2,random_state=42)\n",
    "    return X_train,X_test,y_train,y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7a5146",
   "metadata": {},
   "source": [
    "X_train,X_test,y_train,y_test=split_dataset(df=df_ROI_for_ML_Opti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "92b9ff22",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ingested = df_ROI_for_ML_Opti_ingested[df_ROI_for_ML_Opti_ingested.columns[:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "071b9d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ingested = df_ROI_for_ML_Opti_ingested[df_ROI_for_ML_Opti_ingested.columns[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "78235c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_ROI_for_ML_Opti_train[df_ROI_for_ML_Opti_train.columns[:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "226a001d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_ROI_for_ML_Opti_train[df_ROI_for_ML_Opti_train.columns[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "21066a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = df_ROI_for_ML_Opti_ext[df_ROI_for_ML_Opti_ext.columns[:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "375fd7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val = df_ROI_for_ML_Opti_ext[df_ROI_for_ML_Opti_ext.columns[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "460faa79",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_FNA = df_ROI_for_ML_Opti_FNA[df_ROI_for_ML_Opti_FNA.columns[:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dd2eede7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_FNA = df_ROI_for_ML_Opti_FNA[df_ROI_for_ML_Opti_FNA.columns[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c1e0ca85",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_di = df_ROI_for_ML_Opti_di[df_ROI_for_ML_Opti_di.columns[:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3529c5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_di = df_ROI_for_ML_Opti_di[df_ROI_for_ML_Opti_di.columns[-1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02cd4f6d",
   "metadata": {},
   "source": [
    "## 3.2 Machine Learning Modeling: Model 1+2 (Train 10:10, Val 4:4, Test 3:3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6d458bee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 720x720 with 0 Axes>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from matplotlib.pyplot import figure\n",
    "plt.rcParams['figure.figsize'] = [10, 10]\n",
    "plt.grid(visible=None)\n",
    "plt.close()\n",
    "figure(figsize=(10, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462143af",
   "metadata": {},
   "source": [
    "### 3.2.1. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2bdf27e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build Logistic Regression Model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def LogisticRegression_func(XTrain=X_ingested, XVal=X_val, XTest=X_FNA, yTrain=y_ingested, yVal=y_val, yTest=y_FNA):\n",
    "    model_lr = LogisticRegression(C=0.001, penalty='l1', solver=\"liblinear\", max_iter=5000, random_state=42, class_weight={0:0.9628, 1:1.0402})  # max_iter=100\n",
    "    model_lr.fit(XTrain,yTrain)\n",
    "    \n",
    "    # Training Set\n",
    "    #plt.rcParams[\"figure.figsize\"] = (3,3)\n",
    "    X_train_predictions = model_lr.predict(X_train)\n",
    "    print(\"Training Set F1:\", f1_score(y_train, model_lr.predict(X_train), sample_weight=sampleW))\n",
    "    print(\"Training Set MCC:\", matthews_corrcoef(y_train, model_lr.predict(X_train), sample_weight=sampleW))\n",
    "    print(\"Training Set Accuracy:\", metrics.accuracy_score(y_train, X_train_predictions))\n",
    "    print(classification_report(y_train, X_train_predictions))\n",
    "    print(confusion_matrix(y_train, X_train_predictions))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr, tpr, _ = metrics.roc_curve(y_train, X_train_predictions)\n",
    "    plt.plot(fpr,tpr)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_train.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    # Val set\n",
    "    predictions_val  = model_lr.predict(XVal)\n",
    "    print(\"Ext Val Set F1:\", f1_score(yVal, model_lr.predict(XVal), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set MCC:\", matthews_corrcoef(yVal, model_lr.predict(XVal), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set Accuracy:\", metrics.accuracy_score(yVal, predictions_val))\n",
    "    print(classification_report(yVal, predictions_val))\n",
    "    print(confusion_matrix(yVal, predictions_val))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_val, tpr_val, _ = metrics.roc_curve(yVal, predictions_val)\n",
    "    plt.plot(fpr_val,tpr_val)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_test.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    f1_5_train = cross_val_score(model_lr, XTrain, yTrain, cv = 5, scoring=\"f1\")\n",
    "    print(\"5F-CV:\", avgScore(f1_5_train, 5))\n",
    "    \n",
    "    # Test set\n",
    "    predictions_FNA = model_lr.predict(XTest)\n",
    "    print(\"FNA Set F1:\", f1_score(yTest, model_lr.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set MCC:\", matthews_corrcoef(yTest, model_lr.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set Recall:\", recall_score(yTest, model_lr.predict(XTest)))\n",
    "    print(\"FNA Test Set Accuracy:\", metrics.accuracy_score(yTest, predictions_FNA))\n",
    "    print(classification_report(yTest, predictions_FNA))\n",
    "    print(confusion_matrix(yTest, predictions_FNA))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_FNA, tpr_FNA, _ = metrics.roc_curve(yTest, predictions_FNA)\n",
    "    plt.plot(fpr_FNA,tpr_FNA)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"G:/raMSIn/XGB_Importance2/XGB2_ROC_FNAtest2.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    # Visualize the importantance of the features\n",
    "    feature_imp = pd.Series(model_lr.coef_[0], index=XTrain.columns).sort_values(ascending=False)\n",
    "    x=feature_imp\n",
    "    y=feature_imp.index\n",
    "    \n",
    "    plt.subplots(dpi = 300)\n",
    "    #plt.rcParams[\"figure.figsize\"] = [4, 6]\n",
    "    #plt.rcParams[\"font.family\"] = \"Arial\"\n",
    "    #plt.rcParams.update({'font.size': 6})\n",
    "    plt.xlabel('Feature Importance Score', fontproperties='Arial', fontsize=17)\n",
    "    plt.ylabel('Features', fontproperties='Arial', fontsize=17)\n",
    "    plt.xticks(fontsize=15)\n",
    "    plt.yticks(fontsize=15)\n",
    "    plt.title(\"Important Molecular Features\", fontproperties='Arial', fontsize=20)\n",
    "    sns.barplot(x=feature_imp, y=feature_imp.index)\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_TopFeatures.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    #feature_importances = model_lr.coef_[0]\n",
    "    #feature_df=pd.DataFrame({'m/z':XTrain.columns,'coef':feature_importances})\n",
    "\n",
    "    #fig = px.bar(feature_df, x='coef', y='m/z')\n",
    "    #fig.show()\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e4810838",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set F1: 0.8398883587999828\n",
      "Training Set MCC: 0.6803641493172349\n",
      "Training Set Accuracy: 0.840259454705365\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.84      0.85     47449\n",
      "           1       0.83      0.84      0.83     43511\n",
      "\n",
      "    accuracy                           0.84     90960\n",
      "   macro avg       0.84      0.84      0.84     90960\n",
      "weighted avg       0.84      0.84      0.84     90960\n",
      "\n",
      "[[39953  7496]\n",
      " [ 7034 36477]]\n",
      "Ext Val Set F1: 0.8096924523246609\n",
      "Ext Val Set MCC: 0.5912991355373542\n",
      "Ext Val Set Accuracy: 0.7911111111111111\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.67      0.76      2943\n",
      "           1       0.75      0.90      0.82      3132\n",
      "\n",
      "    accuracy                           0.79      6075\n",
      "   macro avg       0.81      0.79      0.79      6075\n",
      "weighted avg       0.80      0.79      0.79      6075\n",
      "\n",
      "[[1974  969]\n",
      " [ 300 2832]]\n",
      "5F-CV: 0.6281101346140516\n",
      "FNA Set F1: 0.75055036328328\n",
      "FNA Set MCC: 0.501087968506394\n",
      "FNA Set Recall: 0.7505491270578112\n",
      "FNA Test Set Accuracy: 0.7505439623003123\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.75      0.75     44540\n",
      "           1       0.75      0.75      0.75     44161\n",
      "\n",
      "    accuracy                           0.75     88701\n",
      "   macro avg       0.75      0.75      0.75     88701\n",
      "weighted avg       0.75      0.75      0.75     88701\n",
      "\n",
      "[[33429 11111]\n",
      " [11016 33145]]\n"
     ]
    }
   ],
   "source": [
    "coeff_LogReg, TOPfeatures_LogReg = LogisticRegression_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b7a08c",
   "metadata": {},
   "source": [
    "### 3.2.2. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "aab84224",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build LinearSVC Model\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "def LinearSVC_func(XTrain=X_ingested, XVal=X_val, XTest=X_FNA, yTrain=y_ingested, yVal=y_val, yTest=y_FNA):\n",
    "    model_svm = LinearSVC(penalty='l2', loss=\"squared_hinge\", C=461, random_state=42, class_weight={0:0.9628, 1:1.0402})\n",
    "    model_svm.fit(XTrain,yTrain)\n",
    "    \n",
    "    # Training Set\n",
    "    #plt.rcParams[\"figure.figsize\"] = (3,3)\n",
    "    X_train_predictions = model_svm.predict(X_train)\n",
    "    print(\"Training Set F1:\", f1_score(y_train, model_svm.predict(X_train), sample_weight=sampleW))\n",
    "    print(\"Training Set MCC:\", matthews_corrcoef(y_train, model_svm.predict(X_train), sample_weight=sampleW))\n",
    "    print(\"Training Set Accuracy:\", metrics.accuracy_score(y_train, X_train_predictions))\n",
    "    print(classification_report(y_train, X_train_predictions))\n",
    "    print(confusion_matrix(y_train, X_train_predictions))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr, tpr, _ = metrics.roc_curve(y_train, X_train_predictions)\n",
    "    plt.plot(fpr,tpr)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_train.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    # Val set\n",
    "    predictions_val  = model_svm.predict(XVal)\n",
    "    print(\"Ext Val Set F1:\", f1_score(yVal, model_svm.predict(XVal), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set MCC:\", matthews_corrcoef(yVal, model_svm.predict(XVal), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set Accuracy:\", metrics.accuracy_score(yVal, predictions_val))\n",
    "    print(classification_report(yVal, predictions_val))\n",
    "    print(confusion_matrix(yVal, predictions_val))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_val, tpr_val, _ = metrics.roc_curve(yVal, predictions_val)\n",
    "    plt.plot(fpr_val,tpr_val)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_test.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    f1_5_train = cross_val_score(model_svm, XTrain, yTrain, cv = 5, scoring=\"f1\")\n",
    "    print(\"5F-CV:\", avgScore(f1_5_train, 5))\n",
    "    \n",
    "    # Test set\n",
    "    predictions_FNA = model_svm.predict(XTest)\n",
    "    print(\"FNA Set F1:\", f1_score(yTest, model_svm.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set MCC:\", matthews_corrcoef(yTest, model_svm.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set Recall:\", recall_score(yTest, model_svm.predict(XTest)))\n",
    "    print(\"FNA Test Set Accuracy:\", metrics.accuracy_score(yTest, predictions_FNA))\n",
    "    print(classification_report(yTest, predictions_FNA))\n",
    "    print(confusion_matrix(yTest, predictions_FNA))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_FNA, tpr_FNA, _ = metrics.roc_curve(yTest, predictions_FNA)\n",
    "    plt.plot(fpr_FNA,tpr_FNA)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"G:/raMSIn/XGB_Importance2/XGB2_ROC_FNAtest2.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    # Visualize the importantance of the features\n",
    "    feature_imp = pd.Series(model_svm.coef_[0], index=XTrain.columns).sort_values(ascending=False)\n",
    "    x=feature_imp\n",
    "    y=feature_imp.index\n",
    "    \n",
    "    plt.subplots(dpi = 300)\n",
    "    #plt.rcParams[\"figure.figsize\"] = [4, 6]\n",
    "    #plt.rcParams[\"font.family\"] = \"Arial\"\n",
    "    #plt.rcParams.update({'font.size': 6})\n",
    "    plt.xlabel('Feature Importance Score', fontproperties='Arial', fontsize=17)\n",
    "    plt.ylabel('Features', fontproperties='Arial', fontsize=17)\n",
    "    plt.xticks(fontsize=15)\n",
    "    plt.yticks(fontsize=15)\n",
    "    plt.title(\"Important Molecular Features\", fontproperties='Arial', fontsize=20)\n",
    "    sns.barplot(x=feature_imp, y=feature_imp.index)\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_TopFeatures.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    #feature_importances = model_svm.coef_[0]\n",
    "    #feature_df=pd.DataFrame({'m/z':XTrain.columns,'coef':feature_importances})\n",
    "\n",
    "    #fig = px.bar(feature_df, x='coef', y='m/z')\n",
    "    #fig.show()\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "78a85b62",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set F1: 0.8824230288660423\n",
      "Training Set MCC: 0.7609477596760243\n",
      "Training Set Accuracy: 0.8793865435356201\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.86      0.88     47449\n",
      "           1       0.86      0.90      0.88     43511\n",
      "\n",
      "    accuracy                           0.88     90960\n",
      "   macro avg       0.88      0.88      0.88     90960\n",
      "weighted avg       0.88      0.88      0.88     90960\n",
      "\n",
      "[[40870  6579]\n",
      " [ 4392 39119]]\n",
      "Ext Val Set F1: 0.7225673652373401\n",
      "Ext Val Set MCC: 0.4176800020778394\n",
      "Ext Val Set Accuracy: 0.7093004115226338\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.65      0.69      2943\n",
      "           1       0.70      0.76      0.73      3132\n",
      "\n",
      "    accuracy                           0.71      6075\n",
      "   macro avg       0.71      0.71      0.71      6075\n",
      "weighted avg       0.71      0.71      0.71      6075\n",
      "\n",
      "[[1924 1019]\n",
      " [ 747 2385]]\n",
      "5F-CV: 0.8968381695072141\n",
      "FNA Set F1: 0.6569488379340425\n",
      "FNA Set MCC: 0.25975826188406576\n",
      "FNA Set Recall: 0.7123253549512013\n",
      "FNA Test Set Accuracy: 0.6276592146649982\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.54      0.59     44540\n",
      "           1       0.61      0.71      0.66     44161\n",
      "\n",
      "    accuracy                           0.63     88701\n",
      "   macro avg       0.63      0.63      0.63     88701\n",
      "weighted avg       0.63      0.63      0.63     88701\n",
      "\n",
      "[[24217 20323]\n",
      " [12704 31457]]\n"
     ]
    }
   ],
   "source": [
    "coeff_SVM, TOPfeatures_SVM = LinearSVC_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e84218",
   "metadata": {},
   "source": [
    "### 3.2.3. GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "44b76c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build GBM Model\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "def GBM_func(XTrain=X_ingested, XVal=X_val, XTest=X_FNA, yTrain=y_ingested, yVal=y_val, yTest=y_FNA):\n",
    "    model_gbm = GradientBoostingClassifier(learning_rate=4, n_estimators=50, max_depth=7, min_samples_leaf=4, min_samples_split=30, n_iter_no_change=5, random_state=42)\n",
    "    model_gbm.fit(XTrain,yTrain)\n",
    "    \n",
    "    # Training Set\n",
    "    #plt.rcParams[\"figure.figsize\"] = (3,3)\n",
    "    X_train_predictions = model_gbm.predict(X_train)\n",
    "    print(\"Training Set F1:\", f1_score(y_train, model_gbm.predict(X_train), sample_weight=sampleW))\n",
    "    print(\"Training Set MCC:\", matthews_corrcoef(y_train, model_gbm.predict(X_train), sample_weight=sampleW))\n",
    "    print(\"Training Set Accuracy:\", metrics.accuracy_score(y_train, X_train_predictions))\n",
    "    print(classification_report(y_train, X_train_predictions))\n",
    "    print(confusion_matrix(y_train, X_train_predictions))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr, tpr, _ = metrics.roc_curve(y_train, X_train_predictions)\n",
    "    plt.plot(fpr,tpr)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_train.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    # Val set\n",
    "    predictions_val  = model_gbm.predict(XVal)\n",
    "    print(\"Ext Val Set F1:\", f1_score(yVal, model_gbm.predict(XVal), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set MCC:\", matthews_corrcoef(yVal, model_gbm.predict(XVal), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set Accuracy:\", metrics.accuracy_score(yVal, predictions_val))\n",
    "    print(classification_report(yVal, predictions_val))\n",
    "    print(confusion_matrix(yVal, predictions_val))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_val, tpr_val, _ = metrics.roc_curve(yVal, predictions_val)\n",
    "    plt.plot(fpr_val,tpr_val)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_test.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    f1_5_train = cross_val_score(model_gbm, XTrain, yTrain, cv = 5, scoring=\"f1\")\n",
    "    print(\"5F-CV:\", avgScore(f1_5_train, 5))\n",
    "    \n",
    "    # Test set\n",
    "    predictions_FNA = model_gbm.predict(XTest)\n",
    "    print(\"FNA Set F1:\", f1_score(yTest, model_gbm.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set MCC:\", matthews_corrcoef(yTest, model_gbm.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set Recall:\", recall_score(yTest, model_gbm.predict(XTest)))\n",
    "    print(\"FNA Test Set Accuracy:\", metrics.accuracy_score(yTest, predictions_FNA))\n",
    "    print(classification_report(yTest, predictions_FNA))\n",
    "    print(confusion_matrix(yTest, predictions_FNA))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_FNA, tpr_FNA, _ = metrics.roc_curve(yTest, predictions_FNA)\n",
    "    plt.plot(fpr_FNA,tpr_FNA)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"G:/raMSIn/XGB_Importance2/XGB2_ROC_FNAtest2.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    # Visualize the importantance of the features\n",
    "    feature_imp = pd.Series(model_gbm.feature_importances_, index=XTrain.columns).sort_values(ascending=False)\n",
    "    x=feature_imp\n",
    "    y=feature_imp.index\n",
    "    \n",
    "    plt.subplots(dpi = 300)\n",
    "    #plt.rcParams[\"figure.figsize\"] = [4, 6]\n",
    "    #plt.rcParams[\"font.family\"] = \"Arial\"\n",
    "    #plt.rcParams.update({'font.size': 6})\n",
    "    plt.xlabel('Feature Importance Score', fontproperties='Arial', fontsize=17)\n",
    "    plt.ylabel('Features', fontproperties='Arial', fontsize=17)\n",
    "    plt.xticks(fontsize=15)\n",
    "    plt.yticks(fontsize=15)\n",
    "    plt.title(\"Important Molecular Features\", fontproperties='Arial', fontsize=20)\n",
    "    sns.barplot(x=feature_imp, y=feature_imp.index)\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/XGB_TopFeatures.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    # Visualize the boxplot of the important features between the two groups\n",
    "    #fig = px.box(data_frame = df_ROI_for_ML_Opti, x = feature_imp[:10].index,color= 'type')\n",
    "    #fig.show()\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2dcef352",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set F1: 0.5830799381104731\n",
      "Training Set MCC: 0.16677743970600323\n",
      "Training Set Accuracy: 0.5834212840809146\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.58      0.59     47449\n",
      "           1       0.56      0.58      0.57     43511\n",
      "\n",
      "    accuracy                           0.58     90960\n",
      "   macro avg       0.58      0.58      0.58     90960\n",
      "weighted avg       0.58      0.58      0.58     90960\n",
      "\n",
      "[[27717 19732]\n",
      " [18160 25351]]\n",
      "Ext Val Set F1: 0.4568231853268396\n",
      "Ext Val Set MCC: 0.07960053123303563\n",
      "Ext Val Set Accuracy: 0.5333333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.69      0.59      2943\n",
      "           1       0.57      0.39      0.46      3132\n",
      "\n",
      "    accuracy                           0.53      6075\n",
      "   macro avg       0.54      0.54      0.52      6075\n",
      "weighted avg       0.54      0.53      0.52      6075\n",
      "\n",
      "[[2023  920]\n",
      " [1915 1217]]\n",
      "5F-CV: 0.5844956694661804\n",
      "FNA Set F1: 0.3718241757386939\n",
      "FNA Set MCC: -0.2659717613669517\n",
      "FNA Set Recall: 0.37465184212314034\n",
      "FNA Test Set Accuracy: 0.36699698988737445\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.36      0.36     44540\n",
      "           1       0.37      0.37      0.37     44161\n",
      "\n",
      "    accuracy                           0.37     88701\n",
      "   macro avg       0.37      0.37      0.37     88701\n",
      "weighted avg       0.37      0.37      0.37     88701\n",
      "\n",
      "[[16008 28532]\n",
      " [27616 16545]]\n"
     ]
    }
   ],
   "source": [
    "coeff_GBM, TOPfeatures_GBM = GBM_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98e2c8c",
   "metadata": {},
   "source": [
    "### 3.2.4. Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "79af839d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StackingRegressor():\n",
    "    \n",
    "    def __init__(self, learners):\n",
    "        self.level_sizes = []\n",
    "        self.learners = []\n",
    "        \n",
    "        for learning_level in learners:\n",
    "            self.level_sizes.append(len(learning_level))\n",
    "            level_learners = []\n",
    "            \n",
    "            for learner in learning_level:\n",
    "                level_learners.append(deepcopy(learner))\n",
    "            self.learners.append(level_learners)\n",
    "            \n",
    "            \n",
    "    def fit(self, x, y):\n",
    "        \n",
    "        meta_data = [x,x,x]\n",
    "        meta_targets = [y,y,y]\n",
    "        \n",
    "        for i in range(len(self.learners)):\n",
    "            level_size = self.level_sizes[i]\n",
    "            \n",
    "            data_z = np.zeros((level_size, len(x)))\n",
    "            target_z = np.zeros(len(x))\n",
    "            \n",
    "            train_x = meta_data[i]\n",
    "            train_y = meta_targets[i]\n",
    "            \n",
    "            # Define number of folds\n",
    "            num_folds = 5\n",
    "            \n",
    "            # Create the k-fold cross-validation object\n",
    "            KF = KFold(n_splits=num_folds)\n",
    "            m = 0\n",
    "\n",
    "            # Loop over each fold of the cross-validation\n",
    "            for train_indices, test_indices in KF.split(x):\n",
    "                \n",
    "                for j in range(len(self.learners[i])):\n",
    "                    train_x = pd.DataFrame(train_x)\n",
    "                    train_y = pd.DataFrame(train_y)\n",
    "\n",
    "                    learner = self.learners[i][j]\n",
    "                    learner.fit(train_x.iloc[train_indices], train_y.iloc[train_indices])\n",
    "                    p = learner.predict(train_x.iloc[test_indices])\n",
    "                    data_z[j][m: m+len(test_indices) ] = p\n",
    "\n",
    "\n",
    "                train_y = pd.DataFrame(train_y)\n",
    "                train_y_array = (np.array(train_y)).reshape(-1,)\n",
    "                zty_ind = (np.array(train_y.iloc[test_indices])).reshape(-1,)\n",
    "                target_z[m: m+len(test_indices)] = train_y_array[zty_ind]\n",
    "                m += len(test_indices)\n",
    "                \n",
    "\n",
    "            data_z = data_z.transpose()\n",
    "            meta_data.append(data_z)\n",
    "            meta_targets.append(target_z)\n",
    "            \n",
    "            \n",
    "            for learner in self.learners[i]:\n",
    "                train_x = pd.DataFrame(train_x)\n",
    "                train_y = pd.DataFrame(train_y)\n",
    "                learner.fit(train_x, train_y)\n",
    "                \n",
    "                \n",
    "    def predict(self, x):\n",
    "        \n",
    "        meta_data = [x,x,x]\n",
    "        for i in range(len(self.learners)):\n",
    "            \n",
    "            level_size = self.level_sizes[i]\n",
    "            \n",
    "            data_z = np.zeros((level_size, len(x)))\n",
    "            \n",
    "            test_x = meta_data[i]\n",
    "            \n",
    "            for j in range(len(self.learners[i])):\n",
    "                \n",
    "                learner = self.learners[i][j]\n",
    "                predictions = learner.predict(test_x)\n",
    "                data_z[j] = predictions\n",
    "                \n",
    "            \n",
    "            data_z = data_z.transpose()\n",
    "            meta_data.append(data_z)\n",
    "            \n",
    "        return meta_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3fb1ee36",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build stacking Model\n",
    "\n",
    "def Stacking_func(XTrain=X_ingested, XVal=X_val, XTest=X_FNA, XTest2=X_di, yTrain=y_ingested, yVal=y_val, yTest=y_FNA, yTest2=y_di):\n",
    "\n",
    "    base_learners = []\n",
    "\n",
    "    # Define models to use in stacking ensemble\n",
    "    m1 = LogisticRegression(C=0.001, penalty='l1', solver=\"liblinear\", max_iter=5000, random_state=42, class_weight={0:0.9628, 1:1.0402})\n",
    "    base_learners.append(m1)\n",
    "\n",
    "    m2 = LinearSVC(penalty='l2', loss=\"squared_hinge\", C=461, random_state=42, class_weight={0:0.9628, 1:1.0402})\n",
    "    base_learners.append(m2)\n",
    "\n",
    "    m3 = GradientBoostingClassifier(learning_rate=4, n_estimators=50, max_depth=7, min_samples_leaf=4, min_samples_split=30, n_iter_no_change=5, random_state=42)\n",
    "    base_learners.append(m3)\n",
    "\n",
    "    # Define the meta-classifier to use for stacking\n",
    "    #meta_learner = LinearDiscriminantAnalysis()  # 0.90,0.80; 0.75,0.51; 0.65,0.27; 0.64,0.26\n",
    "    #meta_learner = QuadraticDiscriminantAnalysis()  # 0.93,0.86; 0.67,0.39; 0.67,0.15; 0.68,0.20\n",
    "    \n",
    "    #meta_learner = LogisticRegression()  # 0.90,0.79; 0.82,0.65; 0.64,0.24; 0.64;0.27\n",
    "    #meta_learner = LogisticRegression(C=1, penalty='l1', solver=\"liblinear\", max_iter=5000, random_state=42)\n",
    "    ## C=1: 0.90,0.79; 0.82,0.65; 0.65,0.25; 0.65;0.27\n",
    "    #meta_learner = LogisticRegression(C=0.1, penalty='l1', solver=\"liblinear\", max_iter=5000, random_state=42)\n",
    "    ## C=0.1: 0.90,0.79; 0.82,0.65; 0.65,0.25; 0.65;0.28\n",
    "    #meta_learner = LogisticRegression(C=0.01, penalty='l1', solver=\"liblinear\", max_iter=5000, random_state=42)\n",
    "    ## C=0.01: 0.89,0.78; 0.81,0.63; 0.63,0.22; 0.65;0.29\n",
    "    #meta_learner = LogisticRegression(C=0.0075, penalty='l1', solver=\"liblinear\", max_iter=5000, random_state=42)\n",
    "    ## C=0.0075: 0.89,0.77; 0.81,0.63; 0.62,0.20; 0.65;0.29\n",
    "    #meta_learner = LogisticRegression(C=0.005, penalty='l1', solver=\"liblinear\", max_iter=5000, random_state=42)\n",
    "    ## C=0.005: 0.88,0.76; 0.82,0.64; 0.60,0.17; 0.66;0.31\n",
    "    #meta_learner = LogisticRegression(C=0.0025, penalty='l1', solver=\"liblinear\", max_iter=5000, random_state=42)\n",
    "    ## C=0.0025: 0.86,0.72; 0.83,0.66; 0.53,0.02; 0.64;0.31\n",
    "    #meta_learner = LogisticRegression(C=0.0015, penalty='l1', solver=\"liblinear\", max_iter=5000, random_state=42)\n",
    "    ## C=0.0015: 0.85,0.70; 0.80,0.60; 0.55,0.09; 0.64;0.30\n",
    "    #meta_learner = LogisticRegression(C=0.0013, penalty='l1', solver=\"liblinear\", max_iter=5000, random_state=42)\n",
    "    ## C=0.0013: 0.85,0.70; 0.78,0.56; 0.58,0.16; 0.63;0.29\n",
    "    #meta_learner = LogisticRegression(C=0.0012, penalty='l1', solver=\"liblinear\", max_iter=5000, random_state=42)\n",
    "    ## C=0.0012: 0.85,0.69; 0.77,0.52; 0.60,0.22; 0.63;0.27\n",
    "    meta_learner = LogisticRegression(C=0.0011, penalty='l1', solver=\"liblinear\", max_iter=5000, random_state=42)\n",
    "    ## C=0.0011: 0.85,0.69; 0.77,0.51; 0.64,0.30; 0.62;0.25\n",
    "    #meta_learner = LogisticRegression(C=0.001, penalty='l1', solver=\"liblinear\", max_iter=5000, random_state=42)\n",
    "    ## C=0.001: 0.84,0.68; 0.76,0.49; 0.68,0.38; 0.61;0.22\n",
    "    #meta_learner = LogisticRegression(C=0.0005, penalty='l1', solver=\"liblinear\", max_iter=5000, random_state=42)\n",
    "    ## C=0.0005: 0.83,0.66; 0.74,0.45; 0.65,0.37; 0.60;0.18\n",
    "    \n",
    "    #meta_learner = LinearSVC()  # 0.90,0.80; 0.82,0.65; 0.64,0.24; 0.65,0.27\n",
    "    #meta_learner = KNeighborsClassifier()  # 0.98,0.96; 0.65,0.30; 0.68,0.21; 0.52,-0.05\n",
    "    #meta_learner = DecisionTreeClassifier()  # 0.94,0.87; 0.54,0.15; 0.66,0.11; 0.46,-0.11\n",
    "    #meta_learner = RandomForestClassifier()  # 0.98,0.95; 0.54,0.20; 0.66,0.11; 0.49;-0.01\n",
    "    #meta_learner = GradientBoostingClassifier()  # 0.97,0.94; 0.56,0.27; 0.66,0.13; 0.48,-0.09\n",
    "    #meta_learner = AdaBoostClassifier()  # 0.96,0.93; 0.69,0.42; 0.62,0.10; 0.54,0.11\n",
    "    #meta_learner = xgb.XGBClassifier()  # 0.98,0.95; 0.59,0.30; 0.66,0.10; 0.44,-0.12\n",
    "\n",
    "    model_sc = StackingRegressor([[m1, m2, m3], [meta_learner]])\n",
    "    model_sc.fit(XTrain, yTrain)\n",
    "    \n",
    "    #=======================================\n",
    "    \n",
    "    # Training Set\n",
    "    #plt.rcParams[\"figure.figsize\"] = (3,3)\n",
    "    X_train_predictions = model_sc.predict(X_train)[-1]\n",
    "    print(\"Training Set F1:\", f1_score(y_train, model_sc.predict(X_train)[-1], sample_weight=sampleW))\n",
    "    print(\"Training Set MCC:\", matthews_corrcoef(y_train, model_sc.predict(X_train)[-1], sample_weight=sampleW))\n",
    "    print(\"Training Set Accuracy:\", metrics.accuracy_score(y_train, X_train_predictions))\n",
    "    print(classification_report(y_train, X_train_predictions))\n",
    "    print(confusion_matrix(y_train, X_train_predictions))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr, tpr, _ = metrics.roc_curve(y_train, X_train_predictions)\n",
    "    plt.plot(fpr,tpr)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_train.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    # Val set\n",
    "    predictions_val  = model_sc.predict(XVal)[-1]\n",
    "    print(\"Ext Val Set F1:\", f1_score(yVal, model_sc.predict(XVal)[-1], sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set MCC:\", matthews_corrcoef(yVal, model_sc.predict(XVal)[-1], sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set Accuracy:\", metrics.accuracy_score(yVal, predictions_val))\n",
    "    print(classification_report(yVal, predictions_val))\n",
    "    print(confusion_matrix(yVal, predictions_val))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_val, tpr_val, _ = metrics.roc_curve(yVal, predictions_val)\n",
    "    plt.plot(fpr_val,tpr_val)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_test.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    #f1_5_train = cross_val_score(model_sc, XTrain, yTrain, cv = 5, scoring=\"f1\")\n",
    "    #print(\"5F-CV:\", avgScore(f1_5_train, 5))\n",
    "    \n",
    "    # Test set\n",
    "    predictions_FNA = model_sc.predict(XTest)[-1]\n",
    "    print(\"FNA Set F1:\", f1_score(yTest, model_sc.predict(XTest)[-1], sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set MCC:\", matthews_corrcoef(yTest, model_sc.predict(XTest)[-1], sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set Recall:\", recall_score(yTest, model_sc.predict(XTest)[-1]))\n",
    "    print(\"FNA Test Set Accuracy:\", metrics.accuracy_score(yTest, predictions_FNA))\n",
    "    print(classification_report(yTest, predictions_FNA))\n",
    "    print(confusion_matrix(yTest, predictions_FNA))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_FNA, tpr_FNA, _ = metrics.roc_curve(yTest, predictions_FNA)\n",
    "    plt.plot(fpr_FNA,tpr_FNA)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"G:/raMSIn/XGB_Importance2/XGB2_ROC_FNAtest2.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    # Test2 set\n",
    "    predictions_di = model_sc.predict(XTest2)[-1]\n",
    "    print(\"DirectIn Set F1:\", f1_score(yTest2, model_sc.predict(XTest2)[-1], sample_weight=sampleDiW))\n",
    "    print(\"DirectIn Set MCC:\", matthews_corrcoef(yTest2, model_sc.predict(XTest2)[-1], sample_weight=sampleDiW))\n",
    "    print(\"DirectIn Set Recall:\", recall_score(yTest2, model_sc.predict(XTest2)[-1]))\n",
    "    print(\"DirectIn Test Set Accuracy:\", metrics.accuracy_score(yTest2, predictions_di))\n",
    "    print(classification_report(yTest2, predictions_di))\n",
    "    print(confusion_matrix(yTest2, predictions_di))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_di, tpr_di, _ = metrics.roc_curve(yTest2, predictions_di)\n",
    "    plt.plot(fpr_di,tpr_di)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"G:/raMSIn/XGB_Importance2/XGB2_ROC_FNAtest2.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e01c13ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set F1: 0.8412662791207246\n",
      "Training Set MCC: 0.6829904665340507\n",
      "Training Set Accuracy: 0.84155672823219\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.84      0.85     47449\n",
      "           1       0.83      0.84      0.84     43511\n",
      "\n",
      "    accuracy                           0.84     90960\n",
      "   macro avg       0.84      0.84      0.84     90960\n",
      "weighted avg       0.84      0.84      0.84     90960\n",
      "\n",
      "[[39997  7452]\n",
      " [ 6960 36551]]\n",
      "Ext Val Set F1: 0.8260800967064671\n",
      "Ext Val Set MCC: 0.6295614757794611\n",
      "Ext Val Set Accuracy: 0.8108641975308643\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.70      0.78      2943\n",
      "           1       0.76      0.91      0.83      3132\n",
      "\n",
      "    accuracy                           0.81      6075\n",
      "   macro avg       0.82      0.81      0.81      6075\n",
      "weighted avg       0.82      0.81      0.81      6075\n",
      "\n",
      "[[2063  880]\n",
      " [ 269 2863]]\n",
      "FNA Set F1: 0.7129494854515345\n",
      "FNA Set MCC: 0.4441278085524699\n",
      "FNA Set Recall: 0.6913113380584679\n",
      "FNA Test Set Accuracy: 0.7217844218216255\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.75      0.73     44540\n",
      "           1       0.73      0.69      0.71     44161\n",
      "\n",
      "    accuracy                           0.72     88701\n",
      "   macro avg       0.72      0.72      0.72     88701\n",
      "weighted avg       0.72      0.72      0.72     88701\n",
      "\n",
      "[[33494 11046]\n",
      " [13632 30529]]\n",
      "DirectIn Set F1: 0.672681802620277\n",
      "DirectIn Set MCC: 0.35291791530590516\n",
      "DirectIn Set Recall: 0.665016501650165\n",
      "DirectIn Test Set Accuracy: 0.6764074624401519\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.69      0.68      3027\n",
      "           1       0.68      0.67      0.67      3030\n",
      "\n",
      "    accuracy                           0.68      6057\n",
      "   macro avg       0.68      0.68      0.68      6057\n",
      "weighted avg       0.68      0.68      0.68      6057\n",
      "\n",
      "[[2082  945]\n",
      " [1015 2015]]\n"
     ]
    }
   ],
   "source": [
    "Stacking_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235227fc",
   "metadata": {},
   "source": [
    "### 3.2.5. Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "84be5513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a voting ensemble of models\n",
    "def get_voting():\n",
    "    models = list()\n",
    "    # Define the base models\n",
    "    models.append((\"m1\", LogisticRegression(C=0.001, penalty='l1', solver=\"liblinear\", max_iter=5000, random_state=42, class_weight={0:0.9628, 1:1.0402})))\n",
    "    models.append((\"m2\", LinearSVC(penalty='l2', loss=\"squared_hinge\", C=461, random_state=42, class_weight={0:0.9628, 1:1.0402})))\n",
    "    models.append((\"m3\", GradientBoostingClassifier(learning_rate=4, n_estimators=50, max_depth=7, min_samples_leaf=4, min_samples_split=30, n_iter_no_change=5, random_state=42)))\n",
    "\n",
    "    # define the voting ensemble\n",
    "    ensemble = VotingClassifier(estimators=models, voting='hard')\n",
    "    return ensemble\n",
    "\n",
    "# get a list of models to evaluate\n",
    "def get_models():\n",
    "    models = dict()\n",
    "    models['m1'] = LogisticRegression(C=0.001, penalty='l1', solver=\"liblinear\", max_iter=5000, random_state=42, class_weight={0:0.9628, 1:1.0402})\n",
    "    models['m2'] = LinearSVC(penalty='l2', loss=\"squared_hinge\", C=461, random_state=42, class_weight={0:0.9628, 1:1.0402})\n",
    "    models['m3'] = GradientBoostingClassifier(learning_rate=4, n_estimators=50, max_depth=7, min_samples_leaf=4, min_samples_split=30, n_iter_no_change=5, random_state=42)\n",
    "    models['hard_voting'] = get_voting()\n",
    "    return models\n",
    "\n",
    "\n",
    "# evaluate a give model using cross-validation\n",
    "def evaluate_model(model, XX, yy):\n",
    "    cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=10, random_state=42)\n",
    "    scores = cross_val_score(model, XX, yy, scoring='f1', cv=cv, n_jobs=-1, error_score='raise')\n",
    "    return scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2c7985bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 720x720 with 0 Axes>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from matplotlib.pyplot import figure\n",
    "plt.rcParams['figure.figsize'] = [10, 10]\n",
    "plt.close()\n",
    "figure(figsize=(10, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fab33d50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">m1 0.811 (0.003)\n",
      ">m2 0.933 (0.011)\n",
      ">m3 0.697 (0.127)\n",
      ">hard_voting 0.904 (0.021)\n"
     ]
    }
   ],
   "source": [
    "# get the models to evaluate\n",
    "models = get_models()\n",
    "\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "    scores = evaluate_model(model, XX=X_ingested, yy=y_ingested)\n",
    "    results.append(scores)\n",
    "    names.append(name)\n",
    "    print('>%s %.3f (%.3f)' % (name, np.mean(scores), np.std(scores)))\n",
    "    \n",
    "# plot model performance for comparison\n",
    "plt.subplots(dpi = 600)\n",
    "plt.boxplot(results, labels=names, showmeans=True)\n",
    "plt.ylabel('F1 score')\n",
    "plt.xlabel('Predictive Models')\n",
    "plt.savefig(r\"H:/3_output_raMSIn/3_3_Output_raMSIn_HKU_Ingested4ALL/XGB_ALL/afterModelSelection/cbMSIn_0d01/voting.jpg\", bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6832284f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Voting_func(XTrain=X_ingested, XVal=X_val, XTest=X_FNA, XTest2=X_di, yTrain=y_ingested, yVal=y_val, yTest=y_FNA, yTest2=y_di):\n",
    "\n",
    "    models = get_models()\n",
    "    \n",
    "    ensemble = models[\"hard_voting\"]\n",
    "    ensemble.fit(XTrain, yTrain)\n",
    "    #=======================================\n",
    "\n",
    "    # Training Set\n",
    "    #plt.rcParams[\"figure.figsize\"] = (3,3)\n",
    "    X_train_predictions = ensemble.predict(X_train)\n",
    "    print(\"Training Set F1:\", f1_score(y_train, ensemble.predict(X_train), sample_weight=sampleW))\n",
    "    print(\"Training Set MCC:\", matthews_corrcoef(y_train, ensemble.predict(X_train), sample_weight=sampleW))\n",
    "    print(\"Training Set Accuracy:\", metrics.accuracy_score(y_train, X_train_predictions))\n",
    "    print(classification_report(y_train, X_train_predictions))\n",
    "    print(confusion_matrix(y_train, X_train_predictions))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr, tpr, _ = metrics.roc_curve(y_train, X_train_predictions)\n",
    "    plt.plot(fpr,tpr)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_train.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    # Val set\n",
    "    predictions_val  = ensemble.predict(XVal)\n",
    "    print(\"Ext Val Set F1:\", f1_score(yVal, ensemble.predict(XVal), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set MCC:\", matthews_corrcoef(yVal, ensemble.predict(XVal), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set Accuracy:\", metrics.accuracy_score(yVal, predictions_val))\n",
    "    print(classification_report(yVal, predictions_val))\n",
    "    print(confusion_matrix(yVal, predictions_val))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_val, tpr_val, _ = metrics.roc_curve(yVal, predictions_val)\n",
    "    plt.plot(fpr_val,tpr_val)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_test.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    f1_5_train = cross_val_score(ensemble, XTrain, yTrain, cv = 5, scoring=\"f1\")\n",
    "    print(\"5F-CV:\", avgScore(f1_5_train, 5))\n",
    "\n",
    "    # Test set\n",
    "    predictions_FNA = ensemble.predict(XTest)\n",
    "    print(\"FNA Set F1:\", f1_score(yTest, ensemble.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set MCC:\", matthews_corrcoef(yTest, ensemble.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set Recall:\", recall_score(yTest, ensemble.predict(XTest)))\n",
    "    print(\"FNA Test Set Accuracy:\", metrics.accuracy_score(yTest, predictions_FNA))\n",
    "    print(classification_report(yTest, predictions_FNA))\n",
    "    print(confusion_matrix(yTest, predictions_FNA))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_FNA, tpr_FNA, _ = metrics.roc_curve(yTest, predictions_FNA)\n",
    "    plt.plot(fpr_FNA,tpr_FNA)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"G:/raMSIn/XGB_Importance2/XGB2_ROC_FNAtest2.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    # Test2 set\n",
    "    predictions_di = ensemble.predict(XTest2)\n",
    "    print(\"DirectIn Set F1:\", f1_score(yTest2, ensemble.predict(XTest2), sample_weight=sampleDiW))\n",
    "    print(\"DirectIn Set MCC:\", matthews_corrcoef(yTest2, ensemble.predict(XTest2), sample_weight=sampleDiW))\n",
    "    print(\"DirectIn Set Recall:\", recall_score(yTest2, ensemble.predict(XTest2)))\n",
    "    print(\"DirectIn Test Set Accuracy:\", metrics.accuracy_score(yTest2, predictions_di))\n",
    "    print(classification_report(yTest2, predictions_di))\n",
    "    print(confusion_matrix(yTest2, predictions_di))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_di, tpr_di, _ = metrics.roc_curve(yTest2, predictions_di)\n",
    "    plt.plot(fpr_di,tpr_di)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"G:/raMSIn/XGB_Importance2/XGB2_ROC_FNAtest2.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e3647683",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set F1: 0.867384448588762\n",
      "Training Set MCC: 0.7331008810999835\n",
      "Training Set Accuracy: 0.8662379067722076\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.86      0.87     47449\n",
      "           1       0.85      0.87      0.86     43511\n",
      "\n",
      "    accuracy                           0.87     90960\n",
      "   macro avg       0.87      0.87      0.87     90960\n",
      "weighted avg       0.87      0.87      0.87     90960\n",
      "\n",
      "[[40807  6642]\n",
      " [ 5525 37986]]\n",
      "Ext Val Set F1: 0.7731213861968694\n",
      "Ext Val Set MCC: 0.5187040096323643\n",
      "Ext Val Set Accuracy: 0.7588477366255144\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.68      0.73      2943\n",
      "           1       0.74      0.83      0.78      3132\n",
      "\n",
      "    accuracy                           0.76      6075\n",
      "   macro avg       0.76      0.76      0.76      6075\n",
      "weighted avg       0.76      0.76      0.76      6075\n",
      "\n",
      "[[2012  931]\n",
      " [ 534 2598]]\n",
      "5F-CV: 0.8071199707050521\n",
      "FNA Set F1: 0.6591931872480512\n",
      "FNA Set MCC: 0.2562454287789621\n",
      "FNA Set Recall: 0.7241230950386087\n",
      "FNA Test Set Accuracy: 0.6251902458822336\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.53      0.59     44540\n",
      "           1       0.60      0.72      0.66     44161\n",
      "\n",
      "    accuracy                           0.63     88701\n",
      "   macro avg       0.63      0.63      0.62     88701\n",
      "weighted avg       0.63      0.63      0.62     88701\n",
      "\n",
      "[[23477 21063]\n",
      " [12183 31978]]\n",
      "DirectIn Set F1: 0.6266308784519021\n",
      "DirectIn Set MCC: 0.2740012858802455\n",
      "DirectIn Set Recall: 0.6095709570957095\n",
      "DirectIn Test Set Accuracy: 0.6367838864124153\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.66      0.65      3027\n",
      "           1       0.64      0.61      0.63      3030\n",
      "\n",
      "    accuracy                           0.64      6057\n",
      "   macro avg       0.64      0.64      0.64      6057\n",
      "weighted avg       0.64      0.64      0.64      6057\n",
      "\n",
      "[[2010 1017]\n",
      " [1183 1847]]\n"
     ]
    }
   ],
   "source": [
    "Voting_func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7c6aeb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib as jl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fdfc9ad1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('m1',\n",
       "                              LogisticRegression(C=0.001,\n",
       "                                                 class_weight={0: 0.9628,\n",
       "                                                               1: 1.0402},\n",
       "                                                 max_iter=5000, penalty='l1',\n",
       "                                                 random_state=42,\n",
       "                                                 solver='liblinear')),\n",
       "                             ('m2',\n",
       "                              LinearSVC(C=461,\n",
       "                                        class_weight={0: 0.9628, 1: 1.0402},\n",
       "                                        random_state=42)),\n",
       "                             ('m3',\n",
       "                              GradientBoostingClassifier(learning_rate=4,\n",
       "                                                         max_depth=7,\n",
       "                                                         min_samples_leaf=4,\n",
       "                                                         min_samples_split=30,\n",
       "                                                         n_estimators=50,\n",
       "                                                         n_iter_no_change=5,\n",
       "                                                         random_state=42))])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = get_models()\n",
    "    \n",
    "ensemble = models[\"hard_voting\"]\n",
    "ensemble.fit(X_ingested, y_ingested)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "65d8cb99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['H:\\\\3_output_raMSIn\\\\3_3_Output_raMSIn_HKU_Ingested4ALL\\\\XGB_ALL\\\\afterModelSelection\\\\cbMSIn_0d01\\\\model3to1Voting_cbMSIn0d01.joblib']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelSavePath = r\"H:\\3_output_raMSIn\\3_3_Output_raMSIn_HKU_Ingested4ALL\\XGB_ALL\\afterModelSelection\\cbMSIn_0d01\\model3to1Voting_cbMSIn0d01.joblib\"\n",
    "jl.dump(ensemble, modelSavePath, compress = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f9a9ba",
   "metadata": {},
   "source": [
    "## 3.3 Machine Learning Modeling: Model 1 (Train 6:6, Val 4:4, Test 3:3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49659b18",
   "metadata": {},
   "source": [
    "### 3.3.1. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7bcace0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build Logistic Regression Model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def LogisticRegression_func(XTrain=X_train, XVal=X_val, XTest=X_FNA, yTrain=y_train, yVal=y_val, yTest=y_FNA):\n",
    "    model_lr = LogisticRegression(C=0.001, penalty='l1', solver=\"liblinear\", max_iter=5000, random_state=42, class_weight={0:0.9628, 1:1.0402})  # max_iter=100\n",
    "    model_lr.fit(XTrain,yTrain)\n",
    "    \n",
    "    # Training Set\n",
    "    #plt.rcParams[\"figure.figsize\"] = (3,3)\n",
    "    X_train_predictions = model_lr.predict(X_train)\n",
    "    print(\"Training Set F1:\", f1_score(y_train, model_lr.predict(X_train), sample_weight=sampleW))\n",
    "    print(\"Training Set MCC:\", matthews_corrcoef(y_train, model_lr.predict(X_train), sample_weight=sampleW))\n",
    "    print(\"Training Set Accuracy:\", metrics.accuracy_score(y_train, X_train_predictions))\n",
    "    print(classification_report(y_train, X_train_predictions))\n",
    "    print(confusion_matrix(y_train, X_train_predictions))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr, tpr, _ = metrics.roc_curve(y_train, X_train_predictions)\n",
    "    plt.plot(fpr,tpr)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_train.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    # Val set\n",
    "    predictions_val  = model_lr.predict(XVal)\n",
    "    print(\"Ext Val Set F1:\", f1_score(yVal, model_lr.predict(XVal), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set MCC:\", matthews_corrcoef(yVal, model_lr.predict(XVal), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set Accuracy:\", metrics.accuracy_score(yVal, predictions_val))\n",
    "    print(classification_report(yVal, predictions_val))\n",
    "    print(confusion_matrix(yVal, predictions_val))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_val, tpr_val, _ = metrics.roc_curve(yVal, predictions_val)\n",
    "    plt.plot(fpr_val,tpr_val)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_test.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    f1_5_train = cross_val_score(model_lr, XTrain, yTrain, cv = 5, scoring=\"f1\")\n",
    "    print(\"5F-CV:\", avgScore(f1_5_train, 5))\n",
    "    \n",
    "    # Test set\n",
    "    predictions_FNA = model_lr.predict(XTest)\n",
    "    print(\"FNA Set F1:\", f1_score(yTest, model_lr.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set MCC:\", matthews_corrcoef(yTest, model_lr.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set Recall:\", recall_score(yTest, model_lr.predict(XTest)))\n",
    "    print(\"FNA Test Set Accuracy:\", metrics.accuracy_score(yTest, predictions_FNA))\n",
    "    print(classification_report(yTest, predictions_FNA))\n",
    "    print(confusion_matrix(yTest, predictions_FNA))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_FNA, tpr_FNA, _ = metrics.roc_curve(yTest, predictions_FNA)\n",
    "    plt.plot(fpr_FNA,tpr_FNA)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"G:/raMSIn/XGB_Importance2/XGB2_ROC_FNAtest2.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    # Visualize the importantance of the features\n",
    "    feature_imp = pd.Series(model_lr.coef_[0], index=XTrain.columns).sort_values(ascending=False)\n",
    "    x=feature_imp\n",
    "    y=feature_imp.index\n",
    "    \n",
    "    plt.subplots(dpi = 300)\n",
    "    #plt.rcParams[\"figure.figsize\"] = [4, 6]\n",
    "    #plt.rcParams[\"font.family\"] = \"Arial\"\n",
    "    #plt.rcParams.update({'font.size': 6})\n",
    "    plt.xlabel('Feature Importance Score', fontproperties='Arial', fontsize=17)\n",
    "    plt.ylabel('Features', fontproperties='Arial', fontsize=17)\n",
    "    plt.xticks(fontsize=15)\n",
    "    plt.yticks(fontsize=15)\n",
    "    plt.title(\"Important Molecular Features\", fontproperties='Arial', fontsize=20)\n",
    "    sns.barplot(x=feature_imp, y=feature_imp.index)\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_TopFeatures.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    #feature_importances = model_lr.coef_[0]\n",
    "    #feature_df=pd.DataFrame({'m/z':XTrain.columns,'coef':feature_importances})\n",
    "\n",
    "    #fig = px.bar(feature_df, x='coef', y='m/z')\n",
    "    #fig.show()\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5d284fc7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set F1: 0.8600304409083669\n",
      "Training Set MCC: 0.7161208154498504\n",
      "Training Set Accuracy: 0.8572339489885664\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.84      0.86     47449\n",
      "           1       0.84      0.87      0.85     43511\n",
      "\n",
      "    accuracy                           0.86     90960\n",
      "   macro avg       0.86      0.86      0.86     90960\n",
      "weighted avg       0.86      0.86      0.86     90960\n",
      "\n",
      "[[39983  7466]\n",
      " [ 5520 37991]]\n",
      "Ext Val Set F1: 0.7082142058904538\n",
      "Ext Val Set MCC: 0.37703588632445995\n",
      "Ext Val Set Accuracy: 0.688724279835391\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.61      0.66      2943\n",
      "           1       0.68      0.76      0.72      3132\n",
      "\n",
      "    accuracy                           0.69      6075\n",
      "   macro avg       0.69      0.69      0.69      6075\n",
      "weighted avg       0.69      0.69      0.69      6075\n",
      "\n",
      "[[1800 1143]\n",
      " [ 748 2384]]\n",
      "5F-CV: 0.7582464616420204\n",
      "FNA Set F1: 0.5125156241550143\n",
      "FNA Set MCC: -0.01666316842445585\n",
      "FNA Set Recall: 0.5343855438056203\n",
      "FNA Test Set Accuracy: 0.49151644288114\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.45      0.47     44540\n",
      "           1       0.49      0.53      0.51     44161\n",
      "\n",
      "    accuracy                           0.49     88701\n",
      "   macro avg       0.49      0.49      0.49     88701\n",
      "weighted avg       0.49      0.49      0.49     88701\n",
      "\n",
      "[[19999 24541]\n",
      " [20562 23599]]\n"
     ]
    }
   ],
   "source": [
    "coeff_LogReg, TOPfeatures_LogReg = LogisticRegression_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e368acdd",
   "metadata": {},
   "source": [
    "### 3.3.2. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "88f68e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build LinearSVC Model\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "def LinearSVC_func(XTrain=X_train, XVal=X_val, XTest=X_FNA, yTrain=y_train, yVal=y_val, yTest=y_FNA):\n",
    "    model_svm = LinearSVC(penalty='l2', loss=\"squared_hinge\", C=461, random_state=42, class_weight={0:0.9628, 1:1.0402})\n",
    "    model_svm.fit(XTrain,yTrain)\n",
    "    \n",
    "    # Training Set\n",
    "    #plt.rcParams[\"figure.figsize\"] = (3,3)\n",
    "    X_train_predictions = model_svm.predict(X_train)\n",
    "    print(\"Training Set F1:\", f1_score(y_train, model_svm.predict(X_train), sample_weight=sampleW))\n",
    "    print(\"Training Set MCC:\", matthews_corrcoef(y_train, model_svm.predict(X_train), sample_weight=sampleW))\n",
    "    print(\"Training Set Accuracy:\", metrics.accuracy_score(y_train, X_train_predictions))\n",
    "    print(classification_report(y_train, X_train_predictions))\n",
    "    print(confusion_matrix(y_train, X_train_predictions))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr, tpr, _ = metrics.roc_curve(y_train, X_train_predictions)\n",
    "    plt.plot(fpr,tpr)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_train.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    # Val set\n",
    "    predictions_val  = model_svm.predict(XVal)\n",
    "    print(\"Ext Val Set F1:\", f1_score(yVal, model_svm.predict(XVal), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set MCC:\", matthews_corrcoef(yVal, model_svm.predict(XVal), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set Accuracy:\", metrics.accuracy_score(yVal, predictions_val))\n",
    "    print(classification_report(yVal, predictions_val))\n",
    "    print(confusion_matrix(yVal, predictions_val))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_val, tpr_val, _ = metrics.roc_curve(yVal, predictions_val)\n",
    "    plt.plot(fpr_val,tpr_val)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_test.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    f1_5_train = cross_val_score(model_svm, XTrain, yTrain, cv = 5, scoring=\"f1\")\n",
    "    print(\"5F-CV:\", avgScore(f1_5_train, 5))\n",
    "    \n",
    "    # Test set\n",
    "    predictions_FNA = model_svm.predict(XTest)\n",
    "    print(\"FNA Set F1:\", f1_score(yTest, model_svm.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set MCC:\", matthews_corrcoef(yTest, model_svm.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set Recall:\", recall_score(yTest, model_svm.predict(XTest)))\n",
    "    print(\"FNA Test Set Accuracy:\", metrics.accuracy_score(yTest, predictions_FNA))\n",
    "    print(classification_report(yTest, predictions_FNA))\n",
    "    print(confusion_matrix(yTest, predictions_FNA))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_FNA, tpr_FNA, _ = metrics.roc_curve(yTest, predictions_FNA)\n",
    "    plt.plot(fpr_FNA,tpr_FNA)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"G:/raMSIn/XGB_Importance2/XGB2_ROC_FNAtest2.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    # Visualize the importantance of the features\n",
    "    feature_imp = pd.Series(model_svm.coef_[0], index=XTrain.columns).sort_values(ascending=False)\n",
    "    x=feature_imp\n",
    "    y=feature_imp.index\n",
    "    \n",
    "    plt.subplots(dpi = 300)\n",
    "    #plt.rcParams[\"figure.figsize\"] = [4, 6]\n",
    "    #plt.rcParams[\"font.family\"] = \"Arial\"\n",
    "    #plt.rcParams.update({'font.size': 6})\n",
    "    plt.xlabel('Feature Importance Score', fontproperties='Arial', fontsize=17)\n",
    "    plt.ylabel('Features', fontproperties='Arial', fontsize=17)\n",
    "    plt.xticks(fontsize=15)\n",
    "    plt.yticks(fontsize=15)\n",
    "    plt.title(\"Important Molecular Features\", fontproperties='Arial', fontsize=20)\n",
    "    sns.barplot(x=feature_imp, y=feature_imp.index)\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_TopFeatures.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    #feature_importances = model_svm.coef_[0]\n",
    "    #feature_df=pd.DataFrame({'m/z':XTrain.columns,'coef':feature_importances})\n",
    "\n",
    "    #fig = px.bar(feature_df, x='coef', y='m/z')\n",
    "    #fig.show()\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "90420725",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set F1: 0.9149578701413404\n",
      "Training Set MCC: 0.8477505017796539\n",
      "Training Set Accuracy: 0.9231640281442393\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.98      0.93     47449\n",
      "           1       0.98      0.86      0.91     43511\n",
      "\n",
      "    accuracy                           0.92     90960\n",
      "   macro avg       0.93      0.92      0.92     90960\n",
      "weighted avg       0.93      0.92      0.92     90960\n",
      "\n",
      "[[46706   743]\n",
      " [ 6246 37265]]\n",
      "Ext Val Set F1: 0.6052962247898845\n",
      "Ext Val Set MCC: 0.2416212848873085\n",
      "Ext Val Set Accuracy: 0.6192592592592593\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.66      0.63      2943\n",
      "           1       0.64      0.58      0.61      3132\n",
      "\n",
      "    accuracy                           0.62      6075\n",
      "   macro avg       0.62      0.62      0.62      6075\n",
      "weighted avg       0.62      0.62      0.62      6075\n",
      "\n",
      "[[1939 1004]\n",
      " [1309 1823]]\n",
      "5F-CV: 0.9000866375281692\n",
      "FNA Set F1: 0.43955259796757007\n",
      "FNA Set MCC: 0.09671757652595625\n",
      "FNA Set Recall: 0.35698919861416184\n",
      "FNA Test Set Accuracy: 0.5456195533308531\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.73      0.62     44540\n",
      "           1       0.57      0.36      0.44     44161\n",
      "\n",
      "    accuracy                           0.55     88701\n",
      "   macro avg       0.55      0.54      0.53     88701\n",
      "weighted avg       0.55      0.55      0.53     88701\n",
      "\n",
      "[[32632 11908]\n",
      " [28396 15765]]\n"
     ]
    }
   ],
   "source": [
    "coeff_SVM, TOPfeatures_SVM = LinearSVC_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228ac6cd",
   "metadata": {},
   "source": [
    "### 3.3.3. GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7428a256",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build GBM Model\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "def GBM_func(XTrain=X_train, XVal=X_val, XTest=X_FNA, yTrain=y_train, yVal=y_val, yTest=y_FNA):\n",
    "    model_gbm = GradientBoostingClassifier(learning_rate=4, n_estimators=50, max_depth=7, min_samples_leaf=4, min_samples_split=30, n_iter_no_change=5, random_state=42)\n",
    "    model_gbm.fit(XTrain,yTrain)\n",
    "    \n",
    "    # Training Set\n",
    "    #plt.rcParams[\"figure.figsize\"] = (3,3)\n",
    "    X_train_predictions = model_gbm.predict(X_train)\n",
    "    print(\"Training Set F1:\", f1_score(y_train, model_gbm.predict(X_train), sample_weight=sampleW))\n",
    "    print(\"Training Set MCC:\", matthews_corrcoef(y_train, model_gbm.predict(X_train), sample_weight=sampleW))\n",
    "    print(\"Training Set Accuracy:\", metrics.accuracy_score(y_train, X_train_predictions))\n",
    "    print(classification_report(y_train, X_train_predictions))\n",
    "    print(confusion_matrix(y_train, X_train_predictions))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr, tpr, _ = metrics.roc_curve(y_train, X_train_predictions)\n",
    "    plt.plot(fpr,tpr)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_train.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    # Val set\n",
    "    predictions_val  = model_gbm.predict(XVal)\n",
    "    print(\"Ext Val Set F1:\", f1_score(yVal, model_gbm.predict(XVal), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set MCC:\", matthews_corrcoef(yVal, model_gbm.predict(XVal), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set Accuracy:\", metrics.accuracy_score(yVal, predictions_val))\n",
    "    print(classification_report(yVal, predictions_val))\n",
    "    print(confusion_matrix(yVal, predictions_val))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_val, tpr_val, _ = metrics.roc_curve(yVal, predictions_val)\n",
    "    plt.plot(fpr_val,tpr_val)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_test.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    f1_5_train = cross_val_score(model_gbm, XTrain, yTrain, cv = 5, scoring=\"f1\")\n",
    "    print(\"5F-CV:\", avgScore(f1_5_train, 5))\n",
    "    \n",
    "    # Test set\n",
    "    predictions_FNA = model_gbm.predict(XTest)\n",
    "    print(\"FNA Set F1:\", f1_score(yTest, model_gbm.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set MCC:\", matthews_corrcoef(yTest, model_gbm.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set Recall:\", recall_score(yTest, model_gbm.predict(XTest)))\n",
    "    print(\"FNA Test Set Accuracy:\", metrics.accuracy_score(yTest, predictions_FNA))\n",
    "    print(classification_report(yTest, predictions_FNA))\n",
    "    print(confusion_matrix(yTest, predictions_FNA))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_FNA, tpr_FNA, _ = metrics.roc_curve(yTest, predictions_FNA)\n",
    "    plt.plot(fpr_FNA,tpr_FNA)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"G:/raMSIn/XGB_Importance2/XGB2_ROC_FNAtest2.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    # Visualize the importantance of the features\n",
    "    feature_imp = pd.Series(model_gbm.feature_importances_, index=XTrain.columns).sort_values(ascending=False)\n",
    "    x=feature_imp\n",
    "    y=feature_imp.index\n",
    "    \n",
    "    plt.subplots(dpi = 300)\n",
    "    #plt.rcParams[\"figure.figsize\"] = [4, 6]\n",
    "    #plt.rcParams[\"font.family\"] = \"Arial\"\n",
    "    #plt.rcParams.update({'font.size': 6})\n",
    "    plt.xlabel('Feature Importance Score', fontproperties='Arial', fontsize=17)\n",
    "    plt.ylabel('Features', fontproperties='Arial', fontsize=17)\n",
    "    plt.xticks(fontsize=15)\n",
    "    plt.yticks(fontsize=15)\n",
    "    plt.title(\"Important Molecular Features\", fontproperties='Arial', fontsize=20)\n",
    "    sns.barplot(x=feature_imp, y=feature_imp.index)\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/XGB_TopFeatures.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    # Visualize the boxplot of the important features between the two groups\n",
    "    #fig = px.box(data_frame = df_ROI_for_ML_Opti, x = feature_imp[:10].index,color= 'type')\n",
    "    #fig.show()\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "02a72f17",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set F1: 0.8061841091807248\n",
      "Training Set MCC: 0.591670770879875\n",
      "Training Set Accuracy: 0.7902374670184696\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.73      0.78     47449\n",
      "           1       0.74      0.86      0.80     43511\n",
      "\n",
      "    accuracy                           0.79     90960\n",
      "   macro avg       0.80      0.79      0.79     90960\n",
      "weighted avg       0.80      0.79      0.79     90960\n",
      "\n",
      "[[34444 13005]\n",
      " [ 6075 37436]]\n",
      "Ext Val Set F1: 0.4396715545061\n",
      "Ext Val Set MCC: -0.009301879229398942\n",
      "Ext Val Set Accuracy: 0.49234567901234566\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.59      0.53      2943\n",
      "           1       0.51      0.40      0.45      3132\n",
      "\n",
      "    accuracy                           0.49      6075\n",
      "   macro avg       0.50      0.50      0.49      6075\n",
      "weighted avg       0.50      0.49      0.49      6075\n",
      "\n",
      "[[1751 1192]\n",
      " [1892 1240]]\n",
      "5F-CV: 0.6970429627476681\n",
      "FNA Set F1: 0.616090128715452\n",
      "FNA Set MCC: 0.1629255891596497\n",
      "FNA Set Recall: 0.6739657163560607\n",
      "FNA Test Set Accuracy: 0.5796101509565845\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.49      0.54     44540\n",
      "           1       0.57      0.67      0.61     44161\n",
      "\n",
      "    accuracy                           0.58     88701\n",
      "   macro avg       0.58      0.58      0.58     88701\n",
      "weighted avg       0.58      0.58      0.58     88701\n",
      "\n",
      "[[21649 22891]\n",
      " [14398 29763]]\n"
     ]
    }
   ],
   "source": [
    "coeff_GBM, TOPfeatures_GBM = GBM_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9edf4a32",
   "metadata": {},
   "source": [
    "### 3.3.4. Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9e7e60e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build stacking Model\n",
    "\n",
    "def Stacking_func(XTrain=X_train, XVal=X_val, XTest=X_FNA, XTest2=X_di, yTrain=y_train, yVal=y_val, yTest=y_FNA, yTest2=y_di):\n",
    "\n",
    "    base_learners = []\n",
    "\n",
    "    # Define models to use in stacking ensemble\n",
    "    m1 = LogisticRegression(C=0.001, penalty='l1', solver=\"liblinear\", max_iter=5000, random_state=42, class_weight={0:0.9628, 1:1.0402})\n",
    "    base_learners.append(m1)\n",
    "\n",
    "    m2 = LinearSVC(penalty='l2', loss=\"squared_hinge\", C=461, random_state=42, class_weight={0:0.9628, 1:1.0402})\n",
    "    base_learners.append(m2)\n",
    "\n",
    "    m3 = GradientBoostingClassifier(learning_rate=4, n_estimators=50, max_depth=7, min_samples_leaf=4, min_samples_split=30, n_iter_no_change=5, random_state=42)\n",
    "    base_learners.append(m3)\n",
    "\n",
    "    # Define the meta-classifier to use for stacking\n",
    "    meta_learner = LogisticRegression(C=0.0011, penalty='l1', solver=\"liblinear\", max_iter=5000, random_state=42)\n",
    "\n",
    "    model_sc = StackingRegressor([[m1, m2, m3], [meta_learner]])\n",
    "    model_sc.fit(XTrain, yTrain)\n",
    "    \n",
    "    #=======================================\n",
    "    \n",
    "    # Training Set\n",
    "    #plt.rcParams[\"figure.figsize\"] = (3,3)\n",
    "    X_train_predictions = model_sc.predict(X_train)[-1]\n",
    "    print(\"Training Set F1:\", f1_score(y_train, model_sc.predict(X_train)[-1], sample_weight=sampleW))\n",
    "    print(\"Training Set MCC:\", matthews_corrcoef(y_train, model_sc.predict(X_train)[-1], sample_weight=sampleW))\n",
    "    print(\"Training Set Accuracy:\", metrics.accuracy_score(y_train, X_train_predictions))\n",
    "    print(classification_report(y_train, X_train_predictions))\n",
    "    print(confusion_matrix(y_train, X_train_predictions))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr, tpr, _ = metrics.roc_curve(y_train, X_train_predictions)\n",
    "    plt.plot(fpr,tpr)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_train.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    # Val set\n",
    "    predictions_val  = model_sc.predict(XVal)[-1]\n",
    "    print(\"Ext Val Set F1:\", f1_score(yVal, model_sc.predict(XVal)[-1], sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set MCC:\", matthews_corrcoef(yVal, model_sc.predict(XVal)[-1], sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set Accuracy:\", metrics.accuracy_score(yVal, predictions_val))\n",
    "    print(classification_report(yVal, predictions_val))\n",
    "    print(confusion_matrix(yVal, predictions_val))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_val, tpr_val, _ = metrics.roc_curve(yVal, predictions_val)\n",
    "    plt.plot(fpr_val,tpr_val)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_test.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    #f1_5_train = cross_val_score(model_sc, XTrain, yTrain, cv = 5, scoring=\"f1\")\n",
    "    #print(\"5F-CV:\", avgScore(f1_5_train, 5))\n",
    "    \n",
    "    # Test set\n",
    "    predictions_FNA = model_sc.predict(XTest)[-1]\n",
    "    print(\"FNA Set F1:\", f1_score(yTest, model_sc.predict(XTest)[-1], sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set MCC:\", matthews_corrcoef(yTest, model_sc.predict(XTest)[-1], sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set Recall:\", recall_score(yTest, model_sc.predict(XTest)[-1]))\n",
    "    print(\"FNA Test Set Accuracy:\", metrics.accuracy_score(yTest, predictions_FNA))\n",
    "    print(classification_report(yTest, predictions_FNA))\n",
    "    print(confusion_matrix(yTest, predictions_FNA))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_FNA, tpr_FNA, _ = metrics.roc_curve(yTest, predictions_FNA)\n",
    "    plt.plot(fpr_FNA,tpr_FNA)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"G:/raMSIn/XGB_Importance2/XGB2_ROC_FNAtest2.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    # Test2 set\n",
    "    predictions_di = model_sc.predict(XTest2)[-1]\n",
    "    print(\"DirectIn Set F1:\", f1_score(yTest2, model_sc.predict(XTest2)[-1], sample_weight=sampleDiW))\n",
    "    print(\"DirectIn Set MCC:\", matthews_corrcoef(yTest2, model_sc.predict(XTest2)[-1], sample_weight=sampleDiW))\n",
    "    print(\"DirectIn Set Recall:\", recall_score(yTest2, model_sc.predict(XTest2)[-1]))\n",
    "    print(\"DirectIn Test Set Accuracy:\", metrics.accuracy_score(yTest2, predictions_di))\n",
    "    print(classification_report(yTest2, predictions_di))\n",
    "    print(confusion_matrix(yTest2, predictions_di))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_di, tpr_di, _ = metrics.roc_curve(yTest2, predictions_di)\n",
    "    plt.plot(fpr_di,tpr_di)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"G:/raMSIn/XGB_Importance2/XGB2_ROC_FNAtest2.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "53611a51",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set F1: 0.8672381879677433\n",
      "Training Set MCC: 0.7306719563550863\n",
      "Training Set Accuracy: 0.8644788918205805\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.85      0.87     47449\n",
      "           1       0.84      0.88      0.86     43511\n",
      "\n",
      "    accuracy                           0.86     90960\n",
      "   macro avg       0.86      0.87      0.86     90960\n",
      "weighted avg       0.87      0.86      0.86     90960\n",
      "\n",
      "[[40308  7141]\n",
      " [ 5186 38325]]\n",
      "Ext Val Set F1: 0.7142561692359604\n",
      "Ext Val Set MCC: 0.4075389232751825\n",
      "Ext Val Set Accuracy: 0.7043621399176955\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.66      0.69      2943\n",
      "           1       0.70      0.74      0.72      3132\n",
      "\n",
      "    accuracy                           0.70      6075\n",
      "   macro avg       0.70      0.70      0.70      6075\n",
      "weighted avg       0.70      0.70      0.70      6075\n",
      "\n",
      "[[1955  988]\n",
      " [ 808 2324]]\n",
      "FNA Set F1: 0.501630878302306\n",
      "FNA Set MCC: -0.039090438155892866\n",
      "FNA Set Recall: 0.5228595366952741\n",
      "FNA Test Set Accuracy: 0.48034407729337886\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.44      0.46     44540\n",
      "           1       0.48      0.52      0.50     44161\n",
      "\n",
      "    accuracy                           0.48     88701\n",
      "   macro avg       0.48      0.48      0.48     88701\n",
      "weighted avg       0.48      0.48      0.48     88701\n",
      "\n",
      "[[19517 25023]\n",
      " [21071 23090]]\n",
      "DirectIn Set F1: 0.6075825619975319\n",
      "DirectIn Set MCC: 0.2359417265503074\n",
      "DirectIn Set Recall: 0.5917491749174918\n",
      "DirectIn Test Set Accuracy: 0.6177975895657917\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.64      0.63      3027\n",
      "           1       0.62      0.59      0.61      3030\n",
      "\n",
      "    accuracy                           0.62      6057\n",
      "   macro avg       0.62      0.62      0.62      6057\n",
      "weighted avg       0.62      0.62      0.62      6057\n",
      "\n",
      "[[1949 1078]\n",
      " [1237 1793]]\n"
     ]
    }
   ],
   "source": [
    "Stacking_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81113c91",
   "metadata": {},
   "source": [
    "### 3.3.5. Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3de1f12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Voting_func(XTrain=X_train, XVal=X_val, XTest=X_FNA, XTest2=X_di, yTrain=y_train, yVal=y_val, yTest=y_FNA, yTest2=y_di):\n",
    "\n",
    "    models = get_models()\n",
    "    \n",
    "    ensemble = models[\"hard_voting\"]\n",
    "    ensemble.fit(XTrain, yTrain)\n",
    "    #=======================================\n",
    "\n",
    "    # Training Set\n",
    "    #plt.rcParams[\"figure.figsize\"] = (3,3)\n",
    "    X_train_predictions = ensemble.predict(X_train)\n",
    "    print(\"Training Set F1:\", f1_score(y_train, ensemble.predict(X_train), sample_weight=sampleW))\n",
    "    print(\"Training Set MCC:\", matthews_corrcoef(y_train, ensemble.predict(X_train), sample_weight=sampleW))\n",
    "    print(\"Training Set Accuracy:\", metrics.accuracy_score(y_train, X_train_predictions))\n",
    "    print(classification_report(y_train, X_train_predictions))\n",
    "    print(confusion_matrix(y_train, X_train_predictions))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr, tpr, _ = metrics.roc_curve(y_train, X_train_predictions)\n",
    "    plt.plot(fpr,tpr)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_train.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    # Val set\n",
    "    predictions_val  = ensemble.predict(XVal)\n",
    "    print(\"Ext Val Set F1:\", f1_score(yVal, ensemble.predict(XVal), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set MCC:\", matthews_corrcoef(yVal, ensemble.predict(XVal), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set Accuracy:\", metrics.accuracy_score(yVal, predictions_val))\n",
    "    print(classification_report(yVal, predictions_val))\n",
    "    print(confusion_matrix(yVal, predictions_val))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_val, tpr_val, _ = metrics.roc_curve(yVal, predictions_val)\n",
    "    plt.plot(fpr_val,tpr_val)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_test.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    f1_5_train = cross_val_score(ensemble, XTrain, yTrain, cv = 5, scoring=\"f1\")\n",
    "    print(\"5F-CV:\", avgScore(f1_5_train, 5))\n",
    "\n",
    "    # Test set\n",
    "    predictions_FNA = ensemble.predict(XTest)\n",
    "    print(\"FNA Set F1:\", f1_score(yTest, ensemble.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set MCC:\", matthews_corrcoef(yTest, ensemble.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set Recall:\", recall_score(yTest, ensemble.predict(XTest)))\n",
    "    print(\"FNA Test Set Accuracy:\", metrics.accuracy_score(yTest, predictions_FNA))\n",
    "    print(classification_report(yTest, predictions_FNA))\n",
    "    print(confusion_matrix(yTest, predictions_FNA))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_FNA, tpr_FNA, _ = metrics.roc_curve(yTest, predictions_FNA)\n",
    "    plt.plot(fpr_FNA,tpr_FNA)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"G:/raMSIn/XGB_Importance2/XGB2_ROC_FNAtest2.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    # Test2 set\n",
    "    predictions_di = ensemble.predict(XTest2)\n",
    "    print(\"DirectIn Set F1:\", f1_score(yTest2, ensemble.predict(XTest2), sample_weight=sampleDiW))\n",
    "    print(\"DirectIn Set MCC:\", matthews_corrcoef(yTest2, ensemble.predict(XTest2), sample_weight=sampleDiW))\n",
    "    print(\"DirectIn Set Recall:\", recall_score(yTest2, ensemble.predict(XTest2)))\n",
    "    print(\"DirectIn Test Set Accuracy:\", metrics.accuracy_score(yTest2, predictions_di))\n",
    "    print(classification_report(yTest2, predictions_di))\n",
    "    print(confusion_matrix(yTest2, predictions_di))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_di, tpr_di, _ = metrics.roc_curve(yTest2, predictions_di)\n",
    "    plt.plot(fpr_di,tpr_di)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"G:/raMSIn/XGB_Importance2/XGB2_ROC_FNAtest2.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "becdb109",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set F1: 0.9246743212809228\n",
      "Training Set MCC: 0.858749866463674\n",
      "Training Set Accuracy: 0.9296723834652595\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.94     47449\n",
      "           1       0.96      0.89      0.92     43511\n",
      "\n",
      "    accuracy                           0.93     90960\n",
      "   macro avg       0.93      0.93      0.93     90960\n",
      "weighted avg       0.93      0.93      0.93     90960\n",
      "\n",
      "[[46025  1424]\n",
      " [ 4973 38538]]\n",
      "Ext Val Set F1: 0.6459228478616649\n",
      "Ext Val Set MCC: 0.29221312026869\n",
      "Ext Val Set Accuracy: 0.6460905349794238\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.65      0.64      2943\n",
      "           1       0.66      0.65      0.65      3132\n",
      "\n",
      "    accuracy                           0.65      6075\n",
      "   macro avg       0.65      0.65      0.65      6075\n",
      "weighted avg       0.65      0.65      0.65      6075\n",
      "\n",
      "[[1903 1040]\n",
      " [1110 2022]]\n",
      "5F-CV: 0.8672060076203614\n",
      "FNA Set F1: 0.5366705398105541\n",
      "FNA Set MCC: 0.08538475588958823\n",
      "FNA Set Recall: 0.5296981499513145\n",
      "FNA Test Set Accuracy: 0.542733452835932\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.56      0.55     44540\n",
      "           1       0.54      0.53      0.54     44161\n",
      "\n",
      "    accuracy                           0.54     88701\n",
      "   macro avg       0.54      0.54      0.54     88701\n",
      "weighted avg       0.54      0.54      0.54     88701\n",
      "\n",
      "[[24749 19791]\n",
      " [20769 23392]]\n",
      "DirectIn Set F1: 0.5450259541162419\n",
      "DirectIn Set MCC: 0.22863429953828257\n",
      "DirectIn Set Recall: 0.46765676567656767\n",
      "DirectIn Test Set Accuracy: 0.6095426778933466\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.75      0.66      3027\n",
      "           1       0.65      0.47      0.55      3030\n",
      "\n",
      "    accuracy                           0.61      6057\n",
      "   macro avg       0.62      0.61      0.60      6057\n",
      "weighted avg       0.62      0.61      0.60      6057\n",
      "\n",
      "[[2275  752]\n",
      " [1613 1417]]\n"
     ]
    }
   ],
   "source": [
    "Voting_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08fd62e",
   "metadata": {},
   "source": [
    "## 3.4 Machine Learning Modeling: Model 2 (Train 4:4, Val 6:6, Test 3:3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961246f0",
   "metadata": {},
   "source": [
    "### 3.4.1. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "99086aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build Logistic Regression Model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def LogisticRegression_func(XTrain=X_val, XVal=X_train, XTest=X_FNA, yTrain=y_val, yVal=y_train, yTest=y_FNA):\n",
    "    model_lr = LogisticRegression(C=0.001, penalty='l1', solver=\"liblinear\", max_iter=5000, random_state=42, class_weight={0:0.9628, 1:1.0402})  # max_iter=100\n",
    "    model_lr.fit(XTrain,yTrain)\n",
    "    \n",
    "    # Training Set\n",
    "    #plt.rcParams[\"figure.figsize\"] = (3,3)\n",
    "    X_train_predictions = model_lr.predict(XVal)\n",
    "    print(\"Training Set F1:\", f1_score(yVal, model_lr.predict(XVal), sample_weight=sampleW))\n",
    "    print(\"Training Set MCC:\", matthews_corrcoef(yVal, model_lr.predict(XVal), sample_weight=sampleW))\n",
    "    print(\"Training Set Accuracy:\", metrics.accuracy_score(yVal, X_train_predictions))\n",
    "    print(classification_report(yVal, X_train_predictions))\n",
    "    print(confusion_matrix(yVal, X_train_predictions))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr, tpr, _ = metrics.roc_curve(yVal, X_train_predictions)\n",
    "    plt.plot(fpr,tpr)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_train.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    # Val set\n",
    "    predictions_val  = model_lr.predict(XTrain)\n",
    "    print(\"Ext Val Set F1:\", f1_score(yTrain, model_lr.predict(XTrain), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set MCC:\", matthews_corrcoef(yTrain, model_lr.predict(XTrain), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set Accuracy:\", metrics.accuracy_score(yTrain, predictions_val))\n",
    "    print(classification_report(yTrain, predictions_val))\n",
    "    print(confusion_matrix(yTrain, predictions_val))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_val, tpr_val, _ = metrics.roc_curve(yTrain, predictions_val)\n",
    "    plt.plot(fpr_val,tpr_val)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_test.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    f1_5_train = cross_val_score(model_lr, XTrain, yTrain, cv = 5, scoring=\"f1\")\n",
    "    print(\"5F-CV:\", avgScore(f1_5_train, 5))\n",
    "    \n",
    "    # Test set\n",
    "    predictions_FNA = model_lr.predict(XTest)\n",
    "    print(\"FNA Set F1:\", f1_score(yTest, model_lr.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set MCC:\", matthews_corrcoef(yTest, model_lr.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set Recall:\", recall_score(yTest, model_lr.predict(XTest)))\n",
    "    print(\"FNA Test Set Accuracy:\", metrics.accuracy_score(yTest, predictions_FNA))\n",
    "    print(classification_report(yTest, predictions_FNA))\n",
    "    print(confusion_matrix(yTest, predictions_FNA))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_FNA, tpr_FNA, _ = metrics.roc_curve(yTest, predictions_FNA)\n",
    "    plt.plot(fpr_FNA,tpr_FNA)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"G:/raMSIn/XGB_Importance2/XGB2_ROC_FNAtest2.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    # Visualize the importantance of the features\n",
    "    feature_imp = pd.Series(model_lr.coef_[0], index=XTrain.columns).sort_values(ascending=False)\n",
    "    x=feature_imp\n",
    "    y=feature_imp.index\n",
    "    \n",
    "    plt.subplots(dpi = 300)\n",
    "    #plt.rcParams[\"figure.figsize\"] = [4, 6]\n",
    "    #plt.rcParams[\"font.family\"] = \"Arial\"\n",
    "    #plt.rcParams.update({'font.size': 6})\n",
    "    plt.xlabel('Feature Importance Score', fontproperties='Arial', fontsize=17)\n",
    "    plt.ylabel('Features', fontproperties='Arial', fontsize=17)\n",
    "    plt.xticks(fontsize=15)\n",
    "    plt.yticks(fontsize=15)\n",
    "    plt.title(\"Important Molecular Features\", fontproperties='Arial', fontsize=20)\n",
    "    sns.barplot(x=feature_imp, y=feature_imp.index)\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_TopFeatures.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    #feature_importances = model_lr.coef_[0]\n",
    "    #feature_df=pd.DataFrame({'m/z':XTrain.columns,'coef':feature_importances})\n",
    "\n",
    "    #fig = px.bar(feature_df, x='coef', y='m/z')\n",
    "    #fig.show()\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ff504fe8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set F1: 0.0\n",
      "Training Set MCC: 0.0\n",
      "Training Set Accuracy: 0.5216468777484609\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      1.00      0.69     47449\n",
      "           1       0.00      0.00      0.00     43511\n",
      "\n",
      "    accuracy                           0.52     90960\n",
      "   macro avg       0.26      0.50      0.34     90960\n",
      "weighted avg       0.27      0.52      0.36     90960\n",
      "\n",
      "[[47449     0]\n",
      " [43511     0]]\n",
      "Ext Val Set F1: 0.0\n",
      "Ext Val Set MCC: 0.0\n",
      "Ext Val Set Accuracy: 0.48444444444444446\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      1.00      0.65      2943\n",
      "           1       0.00      0.00      0.00      3132\n",
      "\n",
      "    accuracy                           0.48      6075\n",
      "   macro avg       0.24      0.50      0.33      6075\n",
      "weighted avg       0.23      0.48      0.32      6075\n",
      "\n",
      "[[2943    0]\n",
      " [3132    0]]\n",
      "5F-CV: 0.0\n",
      "FNA Set F1: 0.0\n",
      "FNA Set MCC: 0.0\n",
      "FNA Set Recall: 0.0\n",
      "FNA Test Set Accuracy: 0.5021363907960451\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67     44540\n",
      "           1       0.00      0.00      0.00     44161\n",
      "\n",
      "    accuracy                           0.50     88701\n",
      "   macro avg       0.25      0.50      0.33     88701\n",
      "weighted avg       0.25      0.50      0.34     88701\n",
      "\n",
      "[[44540     0]\n",
      " [44161     0]]\n"
     ]
    }
   ],
   "source": [
    "coeff_LogReg, TOPfeatures_LogReg = LogisticRegression_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a040e5",
   "metadata": {},
   "source": [
    "### 3.4.2. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ae3652ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build LinearSVC Model\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "def LinearSVC_func(XTrain=X_val, XVal=X_train, XTest=X_FNA, yTrain=y_val, yVal=y_train, yTest=y_FNA):\n",
    "    model_svm = LinearSVC(penalty='l2', loss=\"squared_hinge\", C=461, random_state=42, class_weight={0:0.9628, 1:1.0402})\n",
    "    model_svm.fit(XTrain,yTrain)\n",
    "    \n",
    "    # Training Set\n",
    "    #plt.rcParams[\"figure.figsize\"] = (3,3)\n",
    "    X_train_predictions = model_svm.predict(XVal)\n",
    "    print(\"Training Set F1:\", f1_score(yVal, model_svm.predict(XVal), sample_weight=sampleW))\n",
    "    print(\"Training Set MCC:\", matthews_corrcoef(yVal, model_svm.predict(XVal), sample_weight=sampleW))\n",
    "    print(\"Training Set Accuracy:\", metrics.accuracy_score(yVal, X_train_predictions))\n",
    "    print(classification_report(yVal, X_train_predictions))\n",
    "    print(confusion_matrix(yVal, X_train_predictions))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr, tpr, _ = metrics.roc_curve(yVal, X_train_predictions)\n",
    "    plt.plot(fpr,tpr)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_train.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    # Val set\n",
    "    predictions_val  = model_svm.predict(XTrain)\n",
    "    print(\"Ext Val Set F1:\", f1_score(yTrain, model_svm.predict(XTrain), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set MCC:\", matthews_corrcoef(yTrain, model_svm.predict(XTrain), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set Accuracy:\", metrics.accuracy_score(yTrain, predictions_val))\n",
    "    print(classification_report(yTrain, predictions_val))\n",
    "    print(confusion_matrix(yTrain, predictions_val))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_val, tpr_val, _ = metrics.roc_curve(yTrain, predictions_val)\n",
    "    plt.plot(fpr_val,tpr_val)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_test.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    f1_5_train = cross_val_score(model_svm, XTrain, yTrain, cv = 5, scoring=\"f1\")\n",
    "    print(\"5F-CV:\", avgScore(f1_5_train, 5))\n",
    "    \n",
    "    # Test set\n",
    "    predictions_FNA = model_svm.predict(XTest)\n",
    "    print(\"FNA Set F1:\", f1_score(yTest, model_svm.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set MCC:\", matthews_corrcoef(yTest, model_svm.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set Recall:\", recall_score(yTest, model_svm.predict(XTest)))\n",
    "    print(\"FNA Test Set Accuracy:\", metrics.accuracy_score(yTest, predictions_FNA))\n",
    "    print(classification_report(yTest, predictions_FNA))\n",
    "    print(confusion_matrix(yTest, predictions_FNA))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_FNA, tpr_FNA, _ = metrics.roc_curve(yTest, predictions_FNA)\n",
    "    plt.plot(fpr_FNA,tpr_FNA)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"G:/raMSIn/XGB_Importance2/XGB2_ROC_FNAtest2.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    # Visualize the importantance of the features\n",
    "    feature_imp = pd.Series(model_svm.coef_[0], index=XTrain.columns).sort_values(ascending=False)\n",
    "    x=feature_imp\n",
    "    y=feature_imp.index\n",
    "    \n",
    "    plt.subplots(dpi = 300)\n",
    "    #plt.rcParams[\"figure.figsize\"] = [4, 6]\n",
    "    #plt.rcParams[\"font.family\"] = \"Arial\"\n",
    "    #plt.rcParams.update({'font.size': 6})\n",
    "    plt.xlabel('Feature Importance Score', fontproperties='Arial', fontsize=17)\n",
    "    plt.ylabel('Features', fontproperties='Arial', fontsize=17)\n",
    "    plt.xticks(fontsize=15)\n",
    "    plt.yticks(fontsize=15)\n",
    "    plt.title(\"Important Molecular Features\", fontproperties='Arial', fontsize=20)\n",
    "    sns.barplot(x=feature_imp, y=feature_imp.index)\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_TopFeatures.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    #feature_importances = model_svm.coef_[0]\n",
    "    #feature_df=pd.DataFrame({'m/z':XTrain.columns,'coef':feature_importances})\n",
    "\n",
    "    #fig = px.bar(feature_df, x='coef', y='m/z')\n",
    "    #fig.show()\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8936e108",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set F1: 0.6607637902285834\n",
      "Training Set MCC: 0.19755082769440105\n",
      "Training Set Accuracy: 0.580617854001759\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.38      0.49     47449\n",
      "           1       0.54      0.80      0.65     43511\n",
      "\n",
      "    accuracy                           0.58     90960\n",
      "   macro avg       0.61      0.59      0.57     90960\n",
      "weighted avg       0.61      0.58      0.56     90960\n",
      "\n",
      "[[18040 29409]\n",
      " [ 8738 34773]]\n",
      "Ext Val Set F1: 0.9628408356310076\n",
      "Ext Val Set MCC: 0.9252484583666944\n",
      "Ext Val Set Accuracy: 0.962798353909465\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.96      2943\n",
      "           1       0.96      0.97      0.96      3132\n",
      "\n",
      "    accuracy                           0.96      6075\n",
      "   macro avg       0.96      0.96      0.96      6075\n",
      "weighted avg       0.96      0.96      0.96      6075\n",
      "\n",
      "[[2812  131]\n",
      " [  95 3037]]\n",
      "5F-CV: 0.8716998640758262\n",
      "FNA Set F1: 0.5268754130882048\n",
      "FNA Set MCC: -0.1016781709323809\n",
      "FNA Set Recall: 0.6104707773827586\n",
      "FNA Test Set Accuracy: 0.45111103595224405\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.29      0.35     44540\n",
      "           1       0.46      0.61      0.53     44161\n",
      "\n",
      "    accuracy                           0.45     88701\n",
      "   macro avg       0.45      0.45      0.44     88701\n",
      "weighted avg       0.45      0.45      0.44     88701\n",
      "\n",
      "[[13055 31485]\n",
      " [17202 26959]]\n"
     ]
    }
   ],
   "source": [
    "coeff_SVM, TOPfeatures_SVM = LinearSVC_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d25a8aa",
   "metadata": {},
   "source": [
    "### 3.4.3. GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0bf777fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build GBM Model\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "def GBM_func(XTrain=X_val, XVal=X_train, XTest=X_FNA, yTrain=y_val, yVal=y_train, yTest=y_FNA):\n",
    "    model_gbm = GradientBoostingClassifier(learning_rate=4, n_estimators=50, max_depth=7, min_samples_leaf=4, min_samples_split=30, n_iter_no_change=5, random_state=42)\n",
    "    model_gbm.fit(XTrain,yTrain)\n",
    "    \n",
    "    # Training Set\n",
    "    #plt.rcParams[\"figure.figsize\"] = (3,3)\n",
    "    X_train_predictions = model_gbm.predict(XVal)\n",
    "    print(\"Training Set F1:\", f1_score(yVal, model_gbm.predict(XVal), sample_weight=sampleW))\n",
    "    print(\"Training Set MCC:\", matthews_corrcoef(yVal, model_gbm.predict(XVal), sample_weight=sampleW))\n",
    "    print(\"Training Set Accuracy:\", metrics.accuracy_score(yVal, X_train_predictions))\n",
    "    print(classification_report(yVal, X_train_predictions))\n",
    "    print(confusion_matrix(yVal, X_train_predictions))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr, tpr, _ = metrics.roc_curve(yVal, X_train_predictions)\n",
    "    plt.plot(fpr,tpr)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_train.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    # Val set\n",
    "    predictions_val  = model_gbm.predict(XTrain)\n",
    "    print(\"Ext Val Set F1:\", f1_score(yTrain, model_gbm.predict(XTrain), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set MCC:\", matthews_corrcoef(yTrain, model_gbm.predict(XTrain), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set Accuracy:\", metrics.accuracy_score(yTrain, predictions_val))\n",
    "    print(classification_report(yTrain, predictions_val))\n",
    "    print(confusion_matrix(yTrain, predictions_val))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_val, tpr_val, _ = metrics.roc_curve(yTrain, predictions_val)\n",
    "    plt.plot(fpr_val,tpr_val)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_test.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    f1_5_train = cross_val_score(model_gbm, XTrain, yTrain, cv = 5, scoring=\"f1\")\n",
    "    print(\"5F-CV:\", avgScore(f1_5_train, 5))\n",
    "    \n",
    "    # Test set\n",
    "    predictions_FNA = model_gbm.predict(XTest)\n",
    "    print(\"FNA Set F1:\", f1_score(yTest, model_gbm.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set MCC:\", matthews_corrcoef(yTest, model_gbm.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set Recall:\", recall_score(yTest, model_gbm.predict(XTest)))\n",
    "    print(\"FNA Test Set Accuracy:\", metrics.accuracy_score(yTest, predictions_FNA))\n",
    "    print(classification_report(yTest, predictions_FNA))\n",
    "    print(confusion_matrix(yTest, predictions_FNA))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_FNA, tpr_FNA, _ = metrics.roc_curve(yTest, predictions_FNA)\n",
    "    plt.plot(fpr_FNA,tpr_FNA)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"G:/raMSIn/XGB_Importance2/XGB2_ROC_FNAtest2.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    # Visualize the importantance of the features\n",
    "    feature_imp = pd.Series(model_gbm.feature_importances_, index=XTrain.columns).sort_values(ascending=False)\n",
    "    x=feature_imp\n",
    "    y=feature_imp.index\n",
    "    \n",
    "    plt.subplots(dpi = 300)\n",
    "    #plt.rcParams[\"figure.figsize\"] = [4, 6]\n",
    "    #plt.rcParams[\"font.family\"] = \"Arial\"\n",
    "    #plt.rcParams.update({'font.size': 6})\n",
    "    plt.xlabel('Feature Importance Score', fontproperties='Arial', fontsize=17)\n",
    "    plt.ylabel('Features', fontproperties='Arial', fontsize=17)\n",
    "    plt.xticks(fontsize=15)\n",
    "    plt.yticks(fontsize=15)\n",
    "    plt.title(\"Important Molecular Features\", fontproperties='Arial', fontsize=20)\n",
    "    sns.barplot(x=feature_imp, y=feature_imp.index)\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/XGB_TopFeatures.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    # Visualize the boxplot of the important features between the two groups\n",
    "    #fig = px.box(data_frame = df_ROI_for_ML_Opti, x = feature_imp[:10].index,color= 'type')\n",
    "    #fig.show()\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "58c5dcd8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set F1: 0.7900182840433172\n",
      "Training Set MCC: 0.5434006030334095\n",
      "Training Set Accuracy: 0.7555738786279683\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.63      0.73     47449\n",
      "           1       0.69      0.90      0.78     43511\n",
      "\n",
      "    accuracy                           0.76     90960\n",
      "   macro avg       0.78      0.76      0.75     90960\n",
      "weighted avg       0.78      0.76      0.75     90960\n",
      "\n",
      "[[29679 17770]\n",
      " [ 4463 39048]]\n",
      "Ext Val Set F1: 0.8030522289272661\n",
      "Ext Val Set MCC: 0.5732201677194234\n",
      "Ext Val Set Accuracy: 0.7759670781893004\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.61      0.72      2943\n",
      "           1       0.72      0.93      0.81      3132\n",
      "\n",
      "    accuracy                           0.78      6075\n",
      "   macro avg       0.81      0.77      0.77      6075\n",
      "weighted avg       0.80      0.78      0.77      6075\n",
      "\n",
      "[[1788 1155]\n",
      " [ 206 2926]]\n",
      "5F-CV: 0.6916408166975695\n",
      "FNA Set F1: 0.6921362921140315\n",
      "FNA Set MCC: 0.24460338018898392\n",
      "FNA Set Recall: 0.9112112497452504\n",
      "FNA Test Set Accuracy: 0.5933191283074599\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.28      0.41     44540\n",
      "           1       0.56      0.91      0.69     44161\n",
      "\n",
      "    accuracy                           0.59     88701\n",
      "   macro avg       0.66      0.59      0.55     88701\n",
      "weighted avg       0.66      0.59      0.55     88701\n",
      "\n",
      "[[12388 32152]\n",
      " [ 3921 40240]]\n"
     ]
    }
   ],
   "source": [
    "coeff_GBM, TOPfeatures_GBM = GBM_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c276f472",
   "metadata": {},
   "source": [
    "### 3.4.4. Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b940433a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build stacking Model\n",
    "\n",
    "def Stacking_func(XTrain=X_val, XVal=X_train, XTest=X_FNA, XTest2=X_di, yTrain=y_val, yVal=y_train, yTest=y_FNA, yTest2=y_di):\n",
    "\n",
    "    base_learners = []\n",
    "\n",
    "    # Define models to use in stacking ensemble\n",
    "    m1 = LogisticRegression(C=0.001, penalty='l1', solver=\"liblinear\", max_iter=5000, random_state=42, class_weight={0:0.9628, 1:1.0402})\n",
    "    base_learners.append(m1)\n",
    "\n",
    "    m2 = LinearSVC(penalty='l2', loss=\"squared_hinge\", C=461, random_state=42, class_weight={0:0.9628, 1:1.0402})\n",
    "    base_learners.append(m2)\n",
    "\n",
    "    m3 = GradientBoostingClassifier(learning_rate=4, n_estimators=50, max_depth=7, min_samples_leaf=4, min_samples_split=30, n_iter_no_change=5, random_state=42)\n",
    "    base_learners.append(m3)\n",
    "\n",
    "    # Define the meta-classifier to use for stacking\n",
    "    meta_learner = LogisticRegression(C=0.0011, penalty='l1', solver=\"liblinear\", max_iter=5000, random_state=42)\n",
    "\n",
    "    model_sc = StackingRegressor([[m1, m2, m3], [meta_learner]])\n",
    "    model_sc.fit(XTrain, yTrain)\n",
    "    \n",
    "    #=======================================\n",
    "    \n",
    "    # Training Set\n",
    "    #plt.rcParams[\"figure.figsize\"] = (3,3)\n",
    "    X_train_predictions = model_sc.predict(XVal)[-1]\n",
    "    print(\"Training Set F1:\", f1_score(yVal, model_sc.predict(XVal)[-1], sample_weight=sampleW))\n",
    "    print(\"Training Set MCC:\", matthews_corrcoef(yVal, model_sc.predict(XVal)[-1], sample_weight=sampleW))\n",
    "    print(\"Training Set Accuracy:\", metrics.accuracy_score(yVal, X_train_predictions))\n",
    "    print(classification_report(yVal, X_train_predictions))\n",
    "    print(confusion_matrix(yVal, X_train_predictions))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr, tpr, _ = metrics.roc_curve(yVal, X_train_predictions)\n",
    "    plt.plot(fpr,tpr)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_train.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    # Val set\n",
    "    predictions_val  = model_sc.predict(XTrain)[-1]\n",
    "    print(\"Ext Val Set F1:\", f1_score(yTrain, model_sc.predict(XTrain)[-1], sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set MCC:\", matthews_corrcoef(yTrain, model_sc.predict(XTrain)[-1], sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set Accuracy:\", metrics.accuracy_score(yTrain, predictions_val))\n",
    "    print(classification_report(yTrain, predictions_val))\n",
    "    print(confusion_matrix(yTrain, predictions_val))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_val, tpr_val, _ = metrics.roc_curve(yTrain, predictions_val)\n",
    "    plt.plot(fpr_val,tpr_val)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_test.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    #f1_5_train = cross_val_score(model_sc, XTrain, yTrain, cv = 5, scoring=\"f1\")\n",
    "    #print(\"5F-CV:\", avgScore(f1_5_train, 5))\n",
    "    \n",
    "    # Test set\n",
    "    predictions_FNA = model_sc.predict(XTest)[-1]\n",
    "    print(\"FNA Set F1:\", f1_score(yTest, model_sc.predict(XTest)[-1], sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set MCC:\", matthews_corrcoef(yTest, model_sc.predict(XTest)[-1], sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set Recall:\", recall_score(yTest, model_sc.predict(XTest)[-1]))\n",
    "    print(\"FNA Test Set Accuracy:\", metrics.accuracy_score(yTest, predictions_FNA))\n",
    "    print(classification_report(yTest, predictions_FNA))\n",
    "    print(confusion_matrix(yTest, predictions_FNA))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_FNA, tpr_FNA, _ = metrics.roc_curve(yTest, predictions_FNA)\n",
    "    plt.plot(fpr_FNA,tpr_FNA)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"G:/raMSIn/XGB_Importance2/XGB2_ROC_FNAtest2.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    # Test2 set\n",
    "    predictions_di = model_sc.predict(XTest2)[-1]\n",
    "    print(\"DirectIn Set F1:\", f1_score(yTest2, model_sc.predict(XTest2)[-1], sample_weight=sampleDiW))\n",
    "    print(\"DirectIn Set MCC:\", matthews_corrcoef(yTest2, model_sc.predict(XTest2)[-1], sample_weight=sampleDiW))\n",
    "    print(\"DirectIn Set Recall:\", recall_score(yTest2, model_sc.predict(XTest2)[-1]))\n",
    "    print(\"DirectIn Test Set Accuracy:\", metrics.accuracy_score(yTest2, predictions_di))\n",
    "    print(classification_report(yTest2, predictions_di))\n",
    "    print(confusion_matrix(yTest2, predictions_di))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_di, tpr_di, _ = metrics.roc_curve(yTest2, predictions_di)\n",
    "    plt.plot(fpr_di,tpr_di)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"G:/raMSIn/XGB_Importance2/XGB2_ROC_FNAtest2.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "74cbb345",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set F1: 0.0\n",
      "Training Set MCC: 0.0\n",
      "Training Set Accuracy: 0.5216468777484609\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      1.00      0.69     47449\n",
      "           1       0.00      0.00      0.00     43511\n",
      "\n",
      "    accuracy                           0.52     90960\n",
      "   macro avg       0.26      0.50      0.34     90960\n",
      "weighted avg       0.27      0.52      0.36     90960\n",
      "\n",
      "[[47449     0]\n",
      " [43511     0]]\n",
      "Ext Val Set F1: 0.0\n",
      "Ext Val Set MCC: 0.0\n",
      "Ext Val Set Accuracy: 0.48444444444444446\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      1.00      0.65      2943\n",
      "           1       0.00      0.00      0.00      3132\n",
      "\n",
      "    accuracy                           0.48      6075\n",
      "   macro avg       0.24      0.50      0.33      6075\n",
      "weighted avg       0.23      0.48      0.32      6075\n",
      "\n",
      "[[2943    0]\n",
      " [3132    0]]\n",
      "FNA Set F1: 0.0\n",
      "FNA Set MCC: 0.0\n",
      "FNA Set Recall: 0.0\n",
      "FNA Test Set Accuracy: 0.5021363907960451\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67     44540\n",
      "           1       0.00      0.00      0.00     44161\n",
      "\n",
      "    accuracy                           0.50     88701\n",
      "   macro avg       0.25      0.50      0.33     88701\n",
      "weighted avg       0.25      0.50      0.34     88701\n",
      "\n",
      "[[44540     0]\n",
      " [44161     0]]\n",
      "DirectIn Set F1: 0.0\n",
      "DirectIn Set MCC: 0.0\n",
      "DirectIn Set Recall: 0.0\n",
      "DirectIn Test Set Accuracy: 0.49975235264982665\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67      3027\n",
      "           1       0.00      0.00      0.00      3030\n",
      "\n",
      "    accuracy                           0.50      6057\n",
      "   macro avg       0.25      0.50      0.33      6057\n",
      "weighted avg       0.25      0.50      0.33      6057\n",
      "\n",
      "[[3027    0]\n",
      " [3030    0]]\n"
     ]
    }
   ],
   "source": [
    "Stacking_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b896917b",
   "metadata": {},
   "source": [
    "### 3.4.5. Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d03a0a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Voting_func(XTrain=X_val, XVal=X_train, XTest=X_FNA, XTest2=X_di, yTrain=y_val, yVal=y_train, yTest=y_FNA, yTest2=y_di):\n",
    "\n",
    "    models = get_models()\n",
    "    \n",
    "    ensemble = models[\"hard_voting\"]\n",
    "    ensemble.fit(XTrain, yTrain)\n",
    "    #=======================================\n",
    "\n",
    "    # Training Set\n",
    "    #plt.rcParams[\"figure.figsize\"] = (3,3)\n",
    "    X_train_predictions = ensemble.predict(XVal)\n",
    "    print(\"Training Set F1:\", f1_score(yVal, ensemble.predict(XVal), sample_weight=sampleW))\n",
    "    print(\"Training Set MCC:\", matthews_corrcoef(yVal, ensemble.predict(XVal), sample_weight=sampleW))\n",
    "    print(\"Training Set Accuracy:\", metrics.accuracy_score(yVal, X_train_predictions))\n",
    "    print(classification_report(yVal, X_train_predictions))\n",
    "    print(confusion_matrix(yVal, X_train_predictions))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr, tpr, _ = metrics.roc_curve(yVal, X_train_predictions)\n",
    "    plt.plot(fpr,tpr)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_train.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    # Val set\n",
    "    predictions_val  = ensemble.predict(XTrain)\n",
    "    print(\"Ext Val Set F1:\", f1_score(yTrain, ensemble.predict(XTrain), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set MCC:\", matthews_corrcoef(yTrain, ensemble.predict(XTrain), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set Accuracy:\", metrics.accuracy_score(yTrain, predictions_val))\n",
    "    print(classification_report(yTrain, predictions_val))\n",
    "    print(confusion_matrix(yTrain, predictions_val))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_val, tpr_val, _ = metrics.roc_curve(yTrain, predictions_val)\n",
    "    plt.plot(fpr_val,tpr_val)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_test.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    f1_5_train = cross_val_score(ensemble, XTrain, yTrain, cv = 5, scoring=\"f1\")\n",
    "    print(\"5F-CV:\", avgScore(f1_5_train, 5))\n",
    "\n",
    "    # Test set\n",
    "    predictions_FNA = ensemble.predict(XTest)\n",
    "    print(\"FNA Set F1:\", f1_score(yTest, ensemble.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set MCC:\", matthews_corrcoef(yTest, ensemble.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set Recall:\", recall_score(yTest, ensemble.predict(XTest)))\n",
    "    print(\"FNA Test Set Accuracy:\", metrics.accuracy_score(yTest, predictions_FNA))\n",
    "    print(classification_report(yTest, predictions_FNA))\n",
    "    print(confusion_matrix(yTest, predictions_FNA))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_FNA, tpr_FNA, _ = metrics.roc_curve(yTest, predictions_FNA)\n",
    "    plt.plot(fpr_FNA,tpr_FNA)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"G:/raMSIn/XGB_Importance2/XGB2_ROC_FNAtest2.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    # Test2 set\n",
    "    predictions_di = ensemble.predict(XTest2)\n",
    "    print(\"DirectIn Set F1:\", f1_score(yTest2, ensemble.predict(XTest2), sample_weight=sampleDiW))\n",
    "    print(\"DirectIn Set MCC:\", matthews_corrcoef(yTest2, ensemble.predict(XTest2), sample_weight=sampleDiW))\n",
    "    print(\"DirectIn Set Recall:\", recall_score(yTest2, ensemble.predict(XTest2)))\n",
    "    print(\"DirectIn Test Set Accuracy:\", metrics.accuracy_score(yTest2, predictions_di))\n",
    "    print(classification_report(yTest2, predictions_di))\n",
    "    print(confusion_matrix(yTest2, predictions_di))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_di, tpr_di, _ = metrics.roc_curve(yTest2, predictions_di)\n",
    "    plt.plot(fpr_di,tpr_di)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"G:/raMSIn/XGB_Importance2/XGB2_ROC_FNAtest2.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2e1865ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set F1: 0.7432145435939308\n",
      "Training Set MCC: 0.47919968834769444\n",
      "Training Set Accuracy: 0.7388742304309587\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.73      0.74     47449\n",
      "           1       0.72      0.75      0.73     43511\n",
      "\n",
      "    accuracy                           0.74     90960\n",
      "   macro avg       0.74      0.74      0.74     90960\n",
      "weighted avg       0.74      0.74      0.74     90960\n",
      "\n",
      "[[34403 13046]\n",
      " [10706 32805]]\n",
      "Ext Val Set F1: 0.946847563332849\n",
      "Ext Val Set MCC: 0.900000235458269\n",
      "Ext Val Set Accuracy: 0.9476543209876543\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.99      0.95      2943\n",
      "           1       0.99      0.91      0.95      3132\n",
      "\n",
      "    accuracy                           0.95      6075\n",
      "   macro avg       0.95      0.95      0.95      6075\n",
      "weighted avg       0.95      0.95      0.95      6075\n",
      "\n",
      "[[2900   43]\n",
      " [ 275 2857]]\n",
      "5F-CV: 0.6829751123223412\n",
      "FNA Set F1: 0.5269179043394204\n",
      "FNA Set MCC: -0.004118960016678157\n",
      "FNA Set Recall: 0.5591585335477005\n",
      "FNA Test Set Accuracy: 0.49769450175308055\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.44      0.47     44540\n",
      "           1       0.50      0.56      0.53     44161\n",
      "\n",
      "    accuracy                           0.50     88701\n",
      "   macro avg       0.50      0.50      0.50     88701\n",
      "weighted avg       0.50      0.50      0.50     88701\n",
      "\n",
      "[[19453 25087]\n",
      " [19468 24693]]\n",
      "DirectIn Set F1: 0.4867464448389006\n",
      "DirectIn Set MCC: -0.039152342019011036\n",
      "DirectIn Set Recall: 0.49273927392739275\n",
      "DirectIn Test Set Accuracy: 0.4804358593363051\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.47      0.47      3027\n",
      "           1       0.48      0.49      0.49      3030\n",
      "\n",
      "    accuracy                           0.48      6057\n",
      "   macro avg       0.48      0.48      0.48      6057\n",
      "weighted avg       0.48      0.48      0.48      6057\n",
      "\n",
      "[[1417 1610]\n",
      " [1537 1493]]\n"
     ]
    }
   ],
   "source": [
    "Voting_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a613c4",
   "metadata": {},
   "source": [
    "# 4. Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5cafba",
   "metadata": {},
   "source": [
    "## 4.1 Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0ab74741",
   "metadata": {},
   "outputs": [],
   "source": [
    "## deploy models for training set ##\n",
    "model_voting = jl.load(r\"H:\\3_output_raMSIn\\3_3_Output_raMSIn_HKU_Ingested4ALL\\XGB_ALL\\afterModelSelection\\cbMSIn_0d01\\model3to1Voting_cbMSIn0d01.joblib\")\n",
    "#\n",
    "## deploy model ##\n",
    "predicted0n1_train = model_voting.predict(X_train)\n",
    "#predicted0n1_trainProba = model_voting.predict_proba(X_train)         \n",
    "trainDEFSDf[\"predicted0n1\"] = predicted0n1_train\n",
    "T_ = []\n",
    "F_ = []\n",
    "for i in range(len(trainDEFSDf)):\n",
    "    if trainDEFSDf.iloc[i][\"predicted0n1\"] == 1:\n",
    "        T_.append(1)\n",
    "        F_.append(0)\n",
    "    elif trainDEFSDf.iloc[i][\"predicted0n1\"] == 0:\n",
    "        F_.append(1)\n",
    "        T_.append(0)\n",
    "trainDEFSDf[\"T\"] = T_\n",
    "trainDEFSDf[\"F\"] = F_\n",
    "#\n",
    "## save ##, ouputing trainSet df\n",
    "savePath = r\"H:\\3_output_raMSIn\\3_3_Output_raMSIn_HKU_Ingested4ALL\\XGB_ALL\\afterModelSelection\\cbMSIn_0d01\\df_train_cbMSIn0d01_norm_0n1.csv\"\n",
    "trainDEFSDf.to_csv(savePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "76d7c323",
   "metadata": {},
   "outputs": [],
   "source": [
    "## deploy models for Ext Val set ##\n",
    "model_voting = jl.load(r\"H:\\3_output_raMSIn\\3_3_Output_raMSIn_HKU_Ingested4ALL\\XGB_ALL\\afterModelSelection\\cbMSIn_0d01\\model3to1Voting_cbMSIn0d01.joblib\")\n",
    "#\n",
    "## deploy model ##\n",
    "predicted0n1_ext = model_voting.predict(X_val)\n",
    "extDEFSDf[\"predicted0n1\"] = predicted0n1_ext\n",
    "T_ = []\n",
    "F_ = []\n",
    "for i in range(len(extDEFSDf)):\n",
    "    if extDEFSDf.iloc[i][\"predicted0n1\"] == 1:\n",
    "        T_.append(1)\n",
    "        F_.append(0)\n",
    "    elif extDEFSDf.iloc[i][\"predicted0n1\"] == 0:\n",
    "        F_.append(1)\n",
    "        T_.append(0)\n",
    "extDEFSDf[\"T\"] = T_\n",
    "extDEFSDf[\"F\"] = F_\n",
    "#\n",
    "## save ##, ouputing extSet df\n",
    "savePath = r\"H:\\3_output_raMSIn\\3_3_Output_raMSIn_HKU_Ingested4ALL\\XGB_ALL\\afterModelSelection\\cbMSIn_0d01\\df_ext_cbMSIn0d01_norm_0n1.csv\"\n",
    "extDEFSDf.to_csv(savePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "3a327944",
   "metadata": {},
   "outputs": [],
   "source": [
    "## deploy models for FNA set ##\n",
    "model_voting = jl.load(r\"H:\\3_output_raMSIn\\3_3_Output_raMSIn_HKU_Ingested4ALL\\XGB_ALL\\afterModelSelection\\cbMSIn_0d01\\model3to1Voting_cbMSIn0d01.joblib\")\n",
    "#\n",
    "## deploy model ##\n",
    "predicted0n1_FNA = model_voting.predict(X_FNA)\n",
    "fnaDEFSDf[\"predicted0n1\"] = predicted0n1_FNA\n",
    "T_ = []\n",
    "F_ = []\n",
    "for i in range(len(fnaDEFSDf)):\n",
    "    if fnaDEFSDf.iloc[i][\"predicted0n1\"] == 1:\n",
    "        T_.append(1)\n",
    "        F_.append(0)\n",
    "    elif fnaDEFSDf.iloc[i][\"predicted0n1\"] == 0:\n",
    "        F_.append(1)\n",
    "        T_.append(0)\n",
    "fnaDEFSDf[\"T\"] = T_\n",
    "fnaDEFSDf[\"F\"] = F_\n",
    "#\n",
    "## save ##, ouputing extSet df\n",
    "savePath = r\"H:\\3_output_raMSIn\\3_3_Output_raMSIn_HKU_Ingested4ALL\\XGB_ALL\\afterModelSelection\\cbMSIn_0d01\\df_FNA_cbMSIn0d01_norm_0n1.csv\"\n",
    "fnaDEFSDf.to_csv(savePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e771a1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "## deploy models for DirectInfusion set ##\n",
    "model_voting = jl.load(r\"H:\\3_output_raMSIn\\3_3_Output_raMSIn_HKU_Ingested4ALL\\XGB_ALL\\afterModelSelection\\cbMSIn_0d01\\model3to1Voting_cbMSIn0d01.joblib\")\n",
    "#\n",
    "## deploy model ##\n",
    "predicted0n1_Di = model_voting.predict(X_di)\n",
    "diDEFSDf[\"predicted0n1\"] = predicted0n1_Di\n",
    "T_ = []\n",
    "F_ = []\n",
    "for i in range(len(diDEFSDf)):\n",
    "    if diDEFSDf.iloc[i][\"predicted0n1\"] == 1:\n",
    "        T_.append(1)\n",
    "        F_.append(0)\n",
    "    elif diDEFSDf.iloc[i][\"predicted0n1\"] == 0:\n",
    "        F_.append(1)\n",
    "        T_.append(0)\n",
    "diDEFSDf[\"T\"] = T_\n",
    "diDEFSDf[\"F\"] = F_\n",
    "#\n",
    "## save ##, ouputing extSet df\n",
    "savePath = r\"H:\\3_output_raMSIn\\3_3_Output_raMSIn_HKU_Ingested4ALL\\XGB_ALL\\afterModelSelection\\cbMSIn_0d01\\df_Di_cbMSIn0d01_norm_0n1.csv\"\n",
    "diDEFSDf.to_csv(savePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3082152",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
