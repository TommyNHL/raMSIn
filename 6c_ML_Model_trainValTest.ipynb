{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b137a905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\Users\\\\user\\\\anaconda3\\\\lib\\\\site-packages\\\\config']\n",
      "2.12.0-dev20221107\n",
      "2.12.0\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import glob\n",
    "import xlwings as xw\n",
    "import math\n",
    "from pathlib import Path\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "from matplotlib import cm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mclr\n",
    "import plotly.express as px\n",
    "import statsmodels.api as sm\n",
    "import pylab as py\n",
    "import os, cv2, glob, tempfile\n",
    "import joblib\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "import sklearn\n",
    "from sklearn import datasets\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "make_scorer = sklearn.metrics.make_scorer\n",
    "f1 = make_scorer(f1_score, pos_label=1, average=\"binary\")\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate, KFold\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import BatchNormalization, Conv2D, MaxPooling2D, Activation, Dropout, Flatten, Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras import utils as np_utils\n",
    "from keras import models\n",
    "import keras_tuner as kt\n",
    "from scipy import signal\n",
    "\n",
    "import config as config\n",
    "print(config.__path__)\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import to_categorical\n",
    "from keras import backend as K\n",
    "\n",
    "import argparse\n",
    "# from sklearn.utils import class_weight\n",
    "print(tf.__version__)\n",
    "print(keras.__version__)\n",
    "\n",
    "import shutil\n",
    "import xlwings as xw\n",
    "\n",
    "%matplotlib inline\n",
    "mpl.use(\"Agg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5c8a718",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build XGBoost Model\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statsmodels.graphics.tsaplots import plot_acf,plot_pacf\n",
    "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV,train_test_split\n",
    "from skopt import BayesSearchCV\n",
    "from sklearn.metrics import accuracy_score,f1_score,roc_auc_score,confusion_matrix,roc_curve\n",
    "import xgboost as xgb\n",
    "import time\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30868f12",
   "metadata": {},
   "source": [
    "# 1. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aaf8674d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDEFSDf = pd.read_csv(r\"H:\\\\3_output_raMSIn\\\\3_3_Output_raMSIn_HKU_Ingested4ALL\\\\XGB_ALL\\\\df_train_raMSIn4nonInDI_norm.csv\")\n",
    "diDEFSDf = pd.read_csv(r\"H:\\\\3_output_raMSIn\\\\3_3_Output_raMSIn_HKU_Ingested4ALL\\\\XGB_ALL\\\\df_nonInDI_raMSIn4nonInDI_norm.csv\")\n",
    "cDEFSDf = pd.read_csv(r\"H:\\\\3_output_raMSIn\\\\3_3_Output_raMSIn_HKU_Ingested4ALL\\\\XGB_ALL\\\\df_nonInDI_raMSIn4nonInClinicsMSI3_norm.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "421e74a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel_id</th>\n",
       "      <th>311.1684</th>\n",
       "      <th>269.2486</th>\n",
       "      <th>215.0328</th>\n",
       "      <th>295.2278</th>\n",
       "      <th>883.5331</th>\n",
       "      <th>309.1704</th>\n",
       "      <th>738.5059</th>\n",
       "      <th>435.2965</th>\n",
       "      <th>280.2361</th>\n",
       "      <th>241.2173</th>\n",
       "      <th>311.2228</th>\n",
       "      <th>339.1996</th>\n",
       "      <th>353.2005</th>\n",
       "      <th>325.1842</th>\n",
       "      <th>250.1449</th>\n",
       "      <th>514.2846</th>\n",
       "      <th>265.1478</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HKULiver_Post29wk_HCCAMCLiver_Left_Mice03_Slid...</td>\n",
       "      <td>0.318762</td>\n",
       "      <td>0.142569</td>\n",
       "      <td>-0.119108</td>\n",
       "      <td>-0.067104</td>\n",
       "      <td>-0.070573</td>\n",
       "      <td>0.383846</td>\n",
       "      <td>-0.096633</td>\n",
       "      <td>0.116723</td>\n",
       "      <td>-0.082643</td>\n",
       "      <td>0.226587</td>\n",
       "      <td>-0.001602</td>\n",
       "      <td>0.230782</td>\n",
       "      <td>0.249302</td>\n",
       "      <td>0.293672</td>\n",
       "      <td>0.126130</td>\n",
       "      <td>-0.041471</td>\n",
       "      <td>0.322926</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HKULiver_Post29wk_HCCAMCLiver_Left_Mice03_Slid...</td>\n",
       "      <td>0.440852</td>\n",
       "      <td>0.374051</td>\n",
       "      <td>-0.038276</td>\n",
       "      <td>-0.067104</td>\n",
       "      <td>-0.038380</td>\n",
       "      <td>0.479313</td>\n",
       "      <td>-0.159106</td>\n",
       "      <td>0.056822</td>\n",
       "      <td>-0.102495</td>\n",
       "      <td>0.292239</td>\n",
       "      <td>-0.001602</td>\n",
       "      <td>0.312509</td>\n",
       "      <td>0.313193</td>\n",
       "      <td>0.399217</td>\n",
       "      <td>0.300442</td>\n",
       "      <td>-0.041471</td>\n",
       "      <td>0.392715</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HKULiver_Post29wk_HCCAMCLiver_Left_Mice03_Slid...</td>\n",
       "      <td>0.297857</td>\n",
       "      <td>0.157616</td>\n",
       "      <td>-0.083684</td>\n",
       "      <td>-0.067104</td>\n",
       "      <td>-0.068081</td>\n",
       "      <td>0.316539</td>\n",
       "      <td>-0.149709</td>\n",
       "      <td>-0.030859</td>\n",
       "      <td>-0.088191</td>\n",
       "      <td>0.210583</td>\n",
       "      <td>-0.001602</td>\n",
       "      <td>0.229702</td>\n",
       "      <td>0.257193</td>\n",
       "      <td>0.267803</td>\n",
       "      <td>0.208765</td>\n",
       "      <td>-0.041471</td>\n",
       "      <td>0.315261</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HKULiver_Post29wk_HCCAMCLiver_Left_Mice03_Slid...</td>\n",
       "      <td>0.276321</td>\n",
       "      <td>0.109249</td>\n",
       "      <td>-0.042441</td>\n",
       "      <td>-0.067104</td>\n",
       "      <td>-0.052794</td>\n",
       "      <td>0.298499</td>\n",
       "      <td>-0.142240</td>\n",
       "      <td>-0.019492</td>\n",
       "      <td>-0.106804</td>\n",
       "      <td>0.272798</td>\n",
       "      <td>-0.001602</td>\n",
       "      <td>0.221045</td>\n",
       "      <td>0.207979</td>\n",
       "      <td>0.247309</td>\n",
       "      <td>0.187136</td>\n",
       "      <td>-0.041471</td>\n",
       "      <td>0.303828</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HKULiver_Post29wk_HCCAMCLiver_Left_Mice03_Slid...</td>\n",
       "      <td>0.172631</td>\n",
       "      <td>0.189790</td>\n",
       "      <td>-0.131907</td>\n",
       "      <td>-0.067104</td>\n",
       "      <td>-0.051093</td>\n",
       "      <td>0.218653</td>\n",
       "      <td>-0.145202</td>\n",
       "      <td>0.138638</td>\n",
       "      <td>-0.064496</td>\n",
       "      <td>0.166785</td>\n",
       "      <td>-0.001602</td>\n",
       "      <td>0.138934</td>\n",
       "      <td>0.193695</td>\n",
       "      <td>0.151397</td>\n",
       "      <td>0.094756</td>\n",
       "      <td>-0.041471</td>\n",
       "      <td>0.213316</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90955</th>\n",
       "      <td>HKULiver_Post29wk_HCCLiver_Left_Mice12_Slide4F...</td>\n",
       "      <td>0.035492</td>\n",
       "      <td>-0.257989</td>\n",
       "      <td>0.004160</td>\n",
       "      <td>-0.067104</td>\n",
       "      <td>-0.141142</td>\n",
       "      <td>0.062400</td>\n",
       "      <td>-0.198284</td>\n",
       "      <td>0.241318</td>\n",
       "      <td>-0.173729</td>\n",
       "      <td>-0.248718</td>\n",
       "      <td>-0.001602</td>\n",
       "      <td>0.042842</td>\n",
       "      <td>0.065963</td>\n",
       "      <td>0.035220</td>\n",
       "      <td>0.038142</td>\n",
       "      <td>0.211848</td>\n",
       "      <td>0.036046</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90956</th>\n",
       "      <td>HKULiver_Post29wk_HCCLiver_Left_Mice12_Slide4F...</td>\n",
       "      <td>0.021825</td>\n",
       "      <td>-0.257989</td>\n",
       "      <td>-0.091239</td>\n",
       "      <td>-0.067104</td>\n",
       "      <td>-0.060784</td>\n",
       "      <td>0.073737</td>\n",
       "      <td>-0.189855</td>\n",
       "      <td>0.299056</td>\n",
       "      <td>-0.195168</td>\n",
       "      <td>0.152713</td>\n",
       "      <td>-0.001602</td>\n",
       "      <td>0.050350</td>\n",
       "      <td>0.069850</td>\n",
       "      <td>0.037012</td>\n",
       "      <td>0.210595</td>\n",
       "      <td>-0.041471</td>\n",
       "      <td>0.018584</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90957</th>\n",
       "      <td>HKULiver_Post29wk_HCCLiver_Left_Mice12_Slide4F...</td>\n",
       "      <td>0.030906</td>\n",
       "      <td>0.315221</td>\n",
       "      <td>-0.093394</td>\n",
       "      <td>-0.067104</td>\n",
       "      <td>-0.089608</td>\n",
       "      <td>0.044004</td>\n",
       "      <td>-0.113996</td>\n",
       "      <td>0.194365</td>\n",
       "      <td>-0.156702</td>\n",
       "      <td>-0.248718</td>\n",
       "      <td>-0.001602</td>\n",
       "      <td>0.046823</td>\n",
       "      <td>0.102615</td>\n",
       "      <td>0.037402</td>\n",
       "      <td>0.143269</td>\n",
       "      <td>-0.041471</td>\n",
       "      <td>-0.052561</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90958</th>\n",
       "      <td>HKULiver_Post29wk_HCCLiver_Left_Mice12_Slide4F...</td>\n",
       "      <td>0.045523</td>\n",
       "      <td>-0.257989</td>\n",
       "      <td>-0.122676</td>\n",
       "      <td>-0.067104</td>\n",
       "      <td>-0.161856</td>\n",
       "      <td>0.059421</td>\n",
       "      <td>-0.137691</td>\n",
       "      <td>0.148243</td>\n",
       "      <td>-0.163096</td>\n",
       "      <td>-0.248718</td>\n",
       "      <td>-0.001602</td>\n",
       "      <td>0.033917</td>\n",
       "      <td>-0.067990</td>\n",
       "      <td>0.036382</td>\n",
       "      <td>0.189004</td>\n",
       "      <td>-0.041471</td>\n",
       "      <td>0.048036</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90959</th>\n",
       "      <td>HKULiver_Post29wk_HCCLiver_Left_Mice12_Slide4F...</td>\n",
       "      <td>0.017844</td>\n",
       "      <td>-0.257989</td>\n",
       "      <td>-0.120908</td>\n",
       "      <td>-0.067104</td>\n",
       "      <td>-0.391064</td>\n",
       "      <td>0.048939</td>\n",
       "      <td>-0.112142</td>\n",
       "      <td>0.100398</td>\n",
       "      <td>-0.231281</td>\n",
       "      <td>-0.248718</td>\n",
       "      <td>-0.001602</td>\n",
       "      <td>0.041783</td>\n",
       "      <td>-0.067990</td>\n",
       "      <td>0.028760</td>\n",
       "      <td>0.177638</td>\n",
       "      <td>-0.041471</td>\n",
       "      <td>0.035261</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90960 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                pixel_id  311.1684  269.2486  \\\n",
       "0      HKULiver_Post29wk_HCCAMCLiver_Left_Mice03_Slid...  0.318762  0.142569   \n",
       "1      HKULiver_Post29wk_HCCAMCLiver_Left_Mice03_Slid...  0.440852  0.374051   \n",
       "2      HKULiver_Post29wk_HCCAMCLiver_Left_Mice03_Slid...  0.297857  0.157616   \n",
       "3      HKULiver_Post29wk_HCCAMCLiver_Left_Mice03_Slid...  0.276321  0.109249   \n",
       "4      HKULiver_Post29wk_HCCAMCLiver_Left_Mice03_Slid...  0.172631  0.189790   \n",
       "...                                                  ...       ...       ...   \n",
       "90955  HKULiver_Post29wk_HCCLiver_Left_Mice12_Slide4F...  0.035492 -0.257989   \n",
       "90956  HKULiver_Post29wk_HCCLiver_Left_Mice12_Slide4F...  0.021825 -0.257989   \n",
       "90957  HKULiver_Post29wk_HCCLiver_Left_Mice12_Slide4F...  0.030906  0.315221   \n",
       "90958  HKULiver_Post29wk_HCCLiver_Left_Mice12_Slide4F...  0.045523 -0.257989   \n",
       "90959  HKULiver_Post29wk_HCCLiver_Left_Mice12_Slide4F...  0.017844 -0.257989   \n",
       "\n",
       "       215.0328  295.2278  883.5331  309.1704  738.5059  435.2965  280.2361  \\\n",
       "0     -0.119108 -0.067104 -0.070573  0.383846 -0.096633  0.116723 -0.082643   \n",
       "1     -0.038276 -0.067104 -0.038380  0.479313 -0.159106  0.056822 -0.102495   \n",
       "2     -0.083684 -0.067104 -0.068081  0.316539 -0.149709 -0.030859 -0.088191   \n",
       "3     -0.042441 -0.067104 -0.052794  0.298499 -0.142240 -0.019492 -0.106804   \n",
       "4     -0.131907 -0.067104 -0.051093  0.218653 -0.145202  0.138638 -0.064496   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "90955  0.004160 -0.067104 -0.141142  0.062400 -0.198284  0.241318 -0.173729   \n",
       "90956 -0.091239 -0.067104 -0.060784  0.073737 -0.189855  0.299056 -0.195168   \n",
       "90957 -0.093394 -0.067104 -0.089608  0.044004 -0.113996  0.194365 -0.156702   \n",
       "90958 -0.122676 -0.067104 -0.161856  0.059421 -0.137691  0.148243 -0.163096   \n",
       "90959 -0.120908 -0.067104 -0.391064  0.048939 -0.112142  0.100398 -0.231281   \n",
       "\n",
       "       241.2173  311.2228  339.1996  353.2005  325.1842  250.1449  514.2846  \\\n",
       "0      0.226587 -0.001602  0.230782  0.249302  0.293672  0.126130 -0.041471   \n",
       "1      0.292239 -0.001602  0.312509  0.313193  0.399217  0.300442 -0.041471   \n",
       "2      0.210583 -0.001602  0.229702  0.257193  0.267803  0.208765 -0.041471   \n",
       "3      0.272798 -0.001602  0.221045  0.207979  0.247309  0.187136 -0.041471   \n",
       "4      0.166785 -0.001602  0.138934  0.193695  0.151397  0.094756 -0.041471   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "90955 -0.248718 -0.001602  0.042842  0.065963  0.035220  0.038142  0.211848   \n",
       "90956  0.152713 -0.001602  0.050350  0.069850  0.037012  0.210595 -0.041471   \n",
       "90957 -0.248718 -0.001602  0.046823  0.102615  0.037402  0.143269 -0.041471   \n",
       "90958 -0.248718 -0.001602  0.033917 -0.067990  0.036382  0.189004 -0.041471   \n",
       "90959 -0.248718 -0.001602  0.041783 -0.067990  0.028760  0.177638 -0.041471   \n",
       "\n",
       "       265.1478  type  \n",
       "0      0.322926     0  \n",
       "1      0.392715     0  \n",
       "2      0.315261     0  \n",
       "3      0.303828     0  \n",
       "4      0.213316     0  \n",
       "...         ...   ...  \n",
       "90955  0.036046     1  \n",
       "90956  0.018584     1  \n",
       "90957 -0.052561     1  \n",
       "90958  0.048036     1  \n",
       "90959  0.035261     1  \n",
       "\n",
       "[90960 rows x 19 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDEFSDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cff93a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "can = []\n",
    "for i in list(range(0,9)) + list(range(15,17)) + [len(list(trainDEFSDf.columns))-1]:\n",
    "    can.append(list(trainDEFSDf.columns)[i])\n",
    "\n",
    "dican = []\n",
    "for i in list(range(0,9)) + list(range(15,17)) + [len(list(diDEFSDf.columns))-1]:\n",
    "    dican.append(list(diDEFSDf.columns)[i])\n",
    "    \n",
    "ccan = []\n",
    "for i in list(range(0,9)) + list(range(15,17)) + [len(list(cDEFSDf.columns))-1]:\n",
    "    ccan.append(list(cDEFSDf.columns)[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2619f93a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pixel_id',\n",
       " '311.1684',\n",
       " '269.2486',\n",
       " '215.0328',\n",
       " '295.2278',\n",
       " '883.5331',\n",
       " '309.1704',\n",
       " '738.5059',\n",
       " '435.2965',\n",
       " '250.1449',\n",
       " '514.2846',\n",
       " 'type']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "can"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c3f86e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pixel_id',\n",
       " '311.169',\n",
       " '269.2486',\n",
       " '215.032',\n",
       " '295.2279',\n",
       " '883.5375',\n",
       " '309.1728',\n",
       " '738.5084',\n",
       " '435.2966',\n",
       " '250.145',\n",
       " '514.2844',\n",
       " 'type']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dican"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4d4a079",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pixel_id',\n",
       " '311.1689',\n",
       " '269.2486',\n",
       " '215.0324',\n",
       " '295.2278',\n",
       " '883.5322',\n",
       " '309.1744',\n",
       " '738.5034',\n",
       " '435.2966',\n",
       " '250.1448',\n",
       " '498.2896',\n",
       " 'type']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ccan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d2530f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## input training set ## 90960 x 20 df\n",
    "trainDEFSDf = pd.read_csv(r\"H:\\\\3_output_raMSIn\\\\3_3_Output_raMSIn_HKU_Ingested4ALL\\\\XGB_ALL\\\\df_train_raMSIn4nonInDI_norm.csv\")\n",
    "#trainDEFSDf[trainDEFSDf.type .== 1, :]\n",
    "## calculate weight ## 0: 47449, 1: 43511\n",
    "trainDEFSDf = trainDEFSDf[can]\n",
    "Yy_train = trainDEFSDf[\"type\"]  # 0.9585; 1.0453\n",
    "sampleW = []\n",
    "for w in Yy_train:\n",
    "    if w == 0:\n",
    "        sampleW.append(0.9585)\n",
    "    elif w == 1:\n",
    "        sampleW.append(1.0453) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26f6b926",
   "metadata": {},
   "outputs": [],
   "source": [
    "## input ext val set ## 6075 x 20 df\n",
    "extDEFSDf = pd.read_csv(r\"H:\\\\3_output_raMSIn\\\\3_3_Output_raMSIn_HKU_Ingested4ALL\\\\XGB_ALL\\\\df_ext_raMSIn4nonInDI_norm.csv\")\n",
    "#extDEFSDf[extDEFSDf.type .== 1, :]\n",
    "## calculate weight ## 0: 2943, 1: 3132\n",
    "extDEFSDf = extDEFSDf[can]\n",
    "Yy_ext = extDEFSDf[\"type\"]  # 1.0321; 0.9698\n",
    "sampleExtW = []\n",
    "for w in Yy_ext:\n",
    "    if w == 0:\n",
    "        sampleExtW.append(1.0321)\n",
    "    elif w == 1:\n",
    "        sampleExtW.append(0.9698) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f13b3818",
   "metadata": {},
   "outputs": [],
   "source": [
    "## input ingested set ## 97035 x 20 df\n",
    "ingestedDEFSDf = pd.read_csv(r\"H:\\\\3_output_raMSIn\\\\3_3_Output_raMSIn_HKU_Ingested4ALL\\\\XGB_ALL\\\\df_ingested_raMSIn4nonInDI_norm.csv\")\n",
    "#ingestedDEFSDf[extDEFSDf.type .== 1, :]\n",
    "## calculate weight ## 0: 50392, 1: 46643\n",
    "ingestedDEFSDf = ingestedDEFSDf[can]\n",
    "Yy_ingested = ingestedDEFSDf[\"type\"]  # 0.9628; 1.0402\n",
    "sampleIngestedW = []\n",
    "for w in Yy_ingested:\n",
    "    if w == 0:\n",
    "        sampleIngestedW.append(0.9628)\n",
    "    elif w == 1:\n",
    "        sampleIngestedW.append(1.0402)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a884cb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "## input FNA set ## 88701 x 20 df\n",
    "fnaDEFSDf = pd.read_csv(r\"H:\\\\3_output_raMSIn\\\\3_3_Output_raMSIn_HKU_Ingested4ALL\\\\XGB_ALL\\\\df_FNA_raMSIn4nonInDI_norm.csv\")\n",
    "#fnaDEFSDf[fnaDEFSDf.type .== 1, :]\n",
    "## calculate weight ##  0: 44540, 1: 44161\n",
    "fnaDEFSDf = fnaDEFSDf[can]\n",
    "Yy_FNA = fnaDEFSDf[\"type\"]  # 0.9957; 1.0043\n",
    "sampleFNAW = []\n",
    "for w in Yy_FNA:\n",
    "    if w == 0:\n",
    "        sampleFNAW.append(0.9957)\n",
    "    elif w == 1:\n",
    "        sampleFNAW.append(1.0043)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "29c8a09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## input DirectIn set ## 6057 x 20 df\n",
    "diDEFSDf = pd.read_csv(r\"H:\\\\3_output_raMSIn\\\\3_3_Output_raMSIn_HKU_Ingested4ALL\\\\XGB_ALL\\\\df_nonInDI_raMSIn4nonInDI_norm.csv\")\n",
    "#diDEFSDf[diDEFSDf.type .== 1, :]\n",
    "## calculate weight ## 0: 3027, 1: 3030\n",
    "diDEFSDf = diDEFSDf[dican]\n",
    "diDEFSDf = diDEFSDf.rename(columns={\"311.169\": \"311.1684\", \"215.032\": \"215.0328\", \"295.2279\":\"295.2278\", \"883.5375\":\"883.5331\", \n",
    "                         \"309.1728\":\"309.1704\", \"738.5084\":\"738.5059\", \"435.2966\":\"435.2965\", \"250.145\":\"250.1449\", \n",
    "                         \"514.2844\":\"514.2846\"})\n",
    "Yy_DI = diDEFSDf[\"type\"]  # 1.0005; 0.9995\n",
    "sampleDiW = []\n",
    "for w in Yy_DI:\n",
    "    if w == 0:\n",
    "        sampleDiW.append(1.0005)\n",
    "    elif w == 1:\n",
    "        sampleDiW.append(0.9995)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e2f39f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "## input Clinics set ## 6711 x 20 df\n",
    "cDEFSDf = pd.read_csv(r\"H:\\\\3_output_raMSIn\\\\3_3_Output_raMSIn_HKU_Ingested4ALL\\\\XGB_ALL\\\\df_nonInDI_raMSIn4nonInClinicsMSI3_norm.csv\")\n",
    "#diDEFSDf[diDEFSDf.type .== 1, :]\n",
    "## calculate weight ## 0: 3449; 1: 3262\n",
    "cDEFSDf = cDEFSDf[ccan]\n",
    "cDEFSDf = cDEFSDf.rename(columns={\"311.1689\": \"311.1684\", \"215.0324\": \"215.0324\", \"883.5322\":\"883.5331\", \n",
    "                         \"309.1744\":\"309.1704\", \"738.5034\":\"738.5059\", \"435.2966\":\"435.2965\", \"250.1448\":\"250.1449\", \n",
    "                         \"498.2896\":\"514.2846\"})\n",
    "Yy_c = cDEFSDf[\"type\"]  # 0.9729; 1.0287\n",
    "sampleCW = []\n",
    "for w in Yy_c:\n",
    "    if w == 0:\n",
    "        sampleCW.append(0.9729)\n",
    "    elif w == 1:\n",
    "        sampleCW.append(1.0287)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1e6365",
   "metadata": {},
   "outputs": [],
   "source": [
    "## input Clinics set ## 6711 x 20 df\n",
    "cDEFSDf = pd.read_csv(r\"H:\\\\3_output_raMSIn\\\\3_3_Output_raMSIn_HKU_Ingested4ALL\\\\XGB_ALL\\\\df_nonInDI_raMSIn4nonInClinicsMSI2_norm.csv\")\n",
    "#diDEFSDf[diDEFSDf.type .== 1, :]\n",
    "## calculate weight ## 0: 3449; 1: 3262\n",
    "cDEFSDf = cDEFSDf[ccan]\n",
    "cDEFSDf = cDEFSDf.rename(columns={\"311.1689\": \"311.1684\", \"215.0324\": \"215.0324\", \"883.5322\":\"883.5331\", \n",
    "                         \"309.1744\":\"309.1704\", \"738.5034\":\"738.5059\", \"435.2966\":\"435.2965\", \"250.1448\":\"250.1449\", \n",
    "                         \"448.3072\":\"514.2846\"})\n",
    "Yy_c = cDEFSDf[\"type\"]  # 0.9729; 1.0287\n",
    "sampleCW = []\n",
    "for w in Yy_c:\n",
    "    if w == 0:\n",
    "        sampleCW.append(0.9729)\n",
    "    elif w == 1:\n",
    "        sampleCW.append(1.0287)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "95558b9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel_id</th>\n",
       "      <th>311.1684</th>\n",
       "      <th>269.2486</th>\n",
       "      <th>215.0328</th>\n",
       "      <th>295.2278</th>\n",
       "      <th>883.5331</th>\n",
       "      <th>309.1704</th>\n",
       "      <th>738.5059</th>\n",
       "      <th>435.2965</th>\n",
       "      <th>250.1449</th>\n",
       "      <th>514.2846</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HKULiver_Post29wk_HCCAMCLiver_DirectIn_MiceNL_...</td>\n",
       "      <td>0.005233</td>\n",
       "      <td>0.142288</td>\n",
       "      <td>0.041701</td>\n",
       "      <td>0.003879</td>\n",
       "      <td>0.077996</td>\n",
       "      <td>0.211155</td>\n",
       "      <td>0.061852</td>\n",
       "      <td>0.125873</td>\n",
       "      <td>0.467335</td>\n",
       "      <td>0.036498</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HKULiver_Post29wk_HCCAMCLiver_DirectIn_MiceNL_...</td>\n",
       "      <td>0.089591</td>\n",
       "      <td>0.156412</td>\n",
       "      <td>0.177360</td>\n",
       "      <td>0.001265</td>\n",
       "      <td>0.167022</td>\n",
       "      <td>0.317443</td>\n",
       "      <td>0.127993</td>\n",
       "      <td>0.145532</td>\n",
       "      <td>0.583291</td>\n",
       "      <td>0.099618</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HKULiver_Post29wk_HCCAMCLiver_DirectIn_MiceNL_...</td>\n",
       "      <td>0.032985</td>\n",
       "      <td>0.134206</td>\n",
       "      <td>0.036942</td>\n",
       "      <td>-0.069655</td>\n",
       "      <td>0.121979</td>\n",
       "      <td>0.212954</td>\n",
       "      <td>0.028980</td>\n",
       "      <td>0.076831</td>\n",
       "      <td>0.465178</td>\n",
       "      <td>0.056825</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HKULiver_Post29wk_HCCAMCLiver_DirectIn_MiceNL_...</td>\n",
       "      <td>0.081001</td>\n",
       "      <td>0.235152</td>\n",
       "      <td>0.064446</td>\n",
       "      <td>0.057514</td>\n",
       "      <td>0.129092</td>\n",
       "      <td>0.303459</td>\n",
       "      <td>0.108110</td>\n",
       "      <td>0.193013</td>\n",
       "      <td>0.550683</td>\n",
       "      <td>0.090339</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HKULiver_Post29wk_HCCAMCLiver_DirectIn_MiceNL_...</td>\n",
       "      <td>0.132548</td>\n",
       "      <td>0.236938</td>\n",
       "      <td>0.155128</td>\n",
       "      <td>0.080273</td>\n",
       "      <td>0.239269</td>\n",
       "      <td>0.394214</td>\n",
       "      <td>0.236241</td>\n",
       "      <td>0.204562</td>\n",
       "      <td>0.645485</td>\n",
       "      <td>0.147333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6052</th>\n",
       "      <td>HKULiver_Post29wk_HCCLiver_DirectIn_MiceHCC_S1...</td>\n",
       "      <td>-0.002046</td>\n",
       "      <td>-0.209455</td>\n",
       "      <td>0.129955</td>\n",
       "      <td>-0.039157</td>\n",
       "      <td>-0.042523</td>\n",
       "      <td>-0.056631</td>\n",
       "      <td>0.023261</td>\n",
       "      <td>0.147171</td>\n",
       "      <td>-0.089381</td>\n",
       "      <td>0.163267</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6053</th>\n",
       "      <td>HKULiver_Post29wk_HCCLiver_DirectIn_MiceHCC_S1...</td>\n",
       "      <td>-0.313188</td>\n",
       "      <td>-0.217983</td>\n",
       "      <td>-0.306277</td>\n",
       "      <td>-0.299289</td>\n",
       "      <td>-0.273013</td>\n",
       "      <td>-0.303023</td>\n",
       "      <td>-0.280535</td>\n",
       "      <td>-0.277840</td>\n",
       "      <td>-0.025246</td>\n",
       "      <td>-0.251944</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6054</th>\n",
       "      <td>HKULiver_Post29wk_HCCLiver_DirectIn_MiceHCC_S1...</td>\n",
       "      <td>-0.158181</td>\n",
       "      <td>-0.037213</td>\n",
       "      <td>0.001781</td>\n",
       "      <td>-0.048526</td>\n",
       "      <td>-0.045113</td>\n",
       "      <td>-0.153125</td>\n",
       "      <td>-0.084896</td>\n",
       "      <td>-0.039408</td>\n",
       "      <td>-0.089381</td>\n",
       "      <td>0.091528</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6055</th>\n",
       "      <td>HKULiver_Post29wk_HCCLiver_DirectIn_MiceHCC_S1...</td>\n",
       "      <td>-0.130111</td>\n",
       "      <td>-0.100314</td>\n",
       "      <td>0.068282</td>\n",
       "      <td>-0.107947</td>\n",
       "      <td>-0.006814</td>\n",
       "      <td>-0.127231</td>\n",
       "      <td>-0.068984</td>\n",
       "      <td>-0.070642</td>\n",
       "      <td>-0.010182</td>\n",
       "      <td>-0.018040</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6056</th>\n",
       "      <td>HKULiver_Post29wk_HCCLiver_DirectIn_MiceHCC_S1...</td>\n",
       "      <td>-0.375053</td>\n",
       "      <td>-0.421196</td>\n",
       "      <td>-0.306277</td>\n",
       "      <td>-0.382957</td>\n",
       "      <td>-0.273013</td>\n",
       "      <td>-0.362289</td>\n",
       "      <td>-0.280535</td>\n",
       "      <td>-0.277840</td>\n",
       "      <td>-0.025772</td>\n",
       "      <td>-0.312439</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6057 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               pixel_id  311.1684  269.2486  \\\n",
       "0     HKULiver_Post29wk_HCCAMCLiver_DirectIn_MiceNL_...  0.005233  0.142288   \n",
       "1     HKULiver_Post29wk_HCCAMCLiver_DirectIn_MiceNL_...  0.089591  0.156412   \n",
       "2     HKULiver_Post29wk_HCCAMCLiver_DirectIn_MiceNL_...  0.032985  0.134206   \n",
       "3     HKULiver_Post29wk_HCCAMCLiver_DirectIn_MiceNL_...  0.081001  0.235152   \n",
       "4     HKULiver_Post29wk_HCCAMCLiver_DirectIn_MiceNL_...  0.132548  0.236938   \n",
       "...                                                 ...       ...       ...   \n",
       "6052  HKULiver_Post29wk_HCCLiver_DirectIn_MiceHCC_S1... -0.002046 -0.209455   \n",
       "6053  HKULiver_Post29wk_HCCLiver_DirectIn_MiceHCC_S1... -0.313188 -0.217983   \n",
       "6054  HKULiver_Post29wk_HCCLiver_DirectIn_MiceHCC_S1... -0.158181 -0.037213   \n",
       "6055  HKULiver_Post29wk_HCCLiver_DirectIn_MiceHCC_S1... -0.130111 -0.100314   \n",
       "6056  HKULiver_Post29wk_HCCLiver_DirectIn_MiceHCC_S1... -0.375053 -0.421196   \n",
       "\n",
       "      215.0328  295.2278  883.5331  309.1704  738.5059  435.2965  250.1449  \\\n",
       "0     0.041701  0.003879  0.077996  0.211155  0.061852  0.125873  0.467335   \n",
       "1     0.177360  0.001265  0.167022  0.317443  0.127993  0.145532  0.583291   \n",
       "2     0.036942 -0.069655  0.121979  0.212954  0.028980  0.076831  0.465178   \n",
       "3     0.064446  0.057514  0.129092  0.303459  0.108110  0.193013  0.550683   \n",
       "4     0.155128  0.080273  0.239269  0.394214  0.236241  0.204562  0.645485   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "6052  0.129955 -0.039157 -0.042523 -0.056631  0.023261  0.147171 -0.089381   \n",
       "6053 -0.306277 -0.299289 -0.273013 -0.303023 -0.280535 -0.277840 -0.025246   \n",
       "6054  0.001781 -0.048526 -0.045113 -0.153125 -0.084896 -0.039408 -0.089381   \n",
       "6055  0.068282 -0.107947 -0.006814 -0.127231 -0.068984 -0.070642 -0.010182   \n",
       "6056 -0.306277 -0.382957 -0.273013 -0.362289 -0.280535 -0.277840 -0.025772   \n",
       "\n",
       "      514.2846  type  \n",
       "0     0.036498     0  \n",
       "1     0.099618     0  \n",
       "2     0.056825     0  \n",
       "3     0.090339     0  \n",
       "4     0.147333     0  \n",
       "...        ...   ...  \n",
       "6052  0.163267     1  \n",
       "6053 -0.251944     1  \n",
       "6054  0.091528     1  \n",
       "6055 -0.018040     1  \n",
       "6056 -0.312439     1  \n",
       "\n",
       "[6057 rows x 12 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diDEFSDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "332cc304",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel_id</th>\n",
       "      <th>311.1684</th>\n",
       "      <th>269.2486</th>\n",
       "      <th>215.0324</th>\n",
       "      <th>295.2278</th>\n",
       "      <th>883.5331</th>\n",
       "      <th>309.1704</th>\n",
       "      <th>738.5059</th>\n",
       "      <th>435.2965</th>\n",
       "      <th>250.1449</th>\n",
       "      <th>514.2846</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HKULiver_Post29wk_HCCAMCLiver_Clinics_Liver_S1...</td>\n",
       "      <td>0.018504</td>\n",
       "      <td>-0.147476</td>\n",
       "      <td>-0.004369</td>\n",
       "      <td>-0.143675</td>\n",
       "      <td>-0.258001</td>\n",
       "      <td>-0.040594</td>\n",
       "      <td>-0.274653</td>\n",
       "      <td>-0.076837</td>\n",
       "      <td>-0.024790</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HKULiver_Post29wk_HCCAMCLiver_Clinics_Liver_S1...</td>\n",
       "      <td>0.036609</td>\n",
       "      <td>-0.093800</td>\n",
       "      <td>0.005776</td>\n",
       "      <td>-0.143675</td>\n",
       "      <td>-0.183186</td>\n",
       "      <td>0.064776</td>\n",
       "      <td>-0.274653</td>\n",
       "      <td>-0.076837</td>\n",
       "      <td>0.029801</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HKULiver_Post29wk_HCCAMCLiver_Clinics_Liver_S1...</td>\n",
       "      <td>0.036910</td>\n",
       "      <td>-0.123263</td>\n",
       "      <td>0.035984</td>\n",
       "      <td>-0.143675</td>\n",
       "      <td>-0.258001</td>\n",
       "      <td>0.063125</td>\n",
       "      <td>-0.274653</td>\n",
       "      <td>-0.076837</td>\n",
       "      <td>0.047941</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HKULiver_Post29wk_HCCAMCLiver_Clinics_Liver_S1...</td>\n",
       "      <td>0.042402</td>\n",
       "      <td>-0.108017</td>\n",
       "      <td>0.022454</td>\n",
       "      <td>-0.143675</td>\n",
       "      <td>-0.258001</td>\n",
       "      <td>0.058306</td>\n",
       "      <td>-0.274653</td>\n",
       "      <td>-0.076837</td>\n",
       "      <td>0.039621</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HKULiver_Post29wk_HCCAMCLiver_Clinics_Liver_S1...</td>\n",
       "      <td>0.029885</td>\n",
       "      <td>-0.092652</td>\n",
       "      <td>0.014073</td>\n",
       "      <td>-0.143675</td>\n",
       "      <td>-0.258001</td>\n",
       "      <td>0.053608</td>\n",
       "      <td>-0.274653</td>\n",
       "      <td>0.212530</td>\n",
       "      <td>0.020894</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6706</th>\n",
       "      <td>HKULiver_Post29wk_HCCLiver_Clinics_Liver_S7_27_24</td>\n",
       "      <td>-0.054617</td>\n",
       "      <td>-0.202530</td>\n",
       "      <td>-0.039259</td>\n",
       "      <td>-0.143675</td>\n",
       "      <td>-0.258001</td>\n",
       "      <td>-0.040594</td>\n",
       "      <td>-0.274653</td>\n",
       "      <td>-0.076837</td>\n",
       "      <td>-0.325840</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6707</th>\n",
       "      <td>HKULiver_Post29wk_HCCLiver_Clinics_Liver_S7_33_25</td>\n",
       "      <td>-0.052310</td>\n",
       "      <td>-0.225144</td>\n",
       "      <td>-0.039259</td>\n",
       "      <td>-0.143675</td>\n",
       "      <td>-0.258001</td>\n",
       "      <td>-0.040594</td>\n",
       "      <td>-0.087148</td>\n",
       "      <td>-0.076837</td>\n",
       "      <td>-0.405295</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6708</th>\n",
       "      <td>HKULiver_Post29wk_HCCLiver_Clinics_Liver_S7_34_25</td>\n",
       "      <td>-0.027895</td>\n",
       "      <td>-0.183689</td>\n",
       "      <td>-0.039259</td>\n",
       "      <td>-0.143675</td>\n",
       "      <td>-0.258001</td>\n",
       "      <td>-0.040594</td>\n",
       "      <td>-0.093638</td>\n",
       "      <td>-0.076837</td>\n",
       "      <td>-0.363926</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6709</th>\n",
       "      <td>HKULiver_Post29wk_HCCLiver_Clinics_Liver_S7_35_25</td>\n",
       "      <td>-0.045657</td>\n",
       "      <td>-0.200992</td>\n",
       "      <td>-0.039259</td>\n",
       "      <td>-0.143675</td>\n",
       "      <td>-0.258001</td>\n",
       "      <td>-0.040594</td>\n",
       "      <td>-0.103156</td>\n",
       "      <td>-0.076837</td>\n",
       "      <td>-0.295754</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6710</th>\n",
       "      <td>HKULiver_Post29wk_HCCLiver_Clinics_Liver_S7_36_25</td>\n",
       "      <td>-0.062553</td>\n",
       "      <td>-0.215307</td>\n",
       "      <td>-0.039259</td>\n",
       "      <td>-0.143675</td>\n",
       "      <td>-0.258001</td>\n",
       "      <td>0.054031</td>\n",
       "      <td>-0.152314</td>\n",
       "      <td>-0.076837</td>\n",
       "      <td>-0.373219</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6711 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               pixel_id  311.1684  269.2486  \\\n",
       "0     HKULiver_Post29wk_HCCAMCLiver_Clinics_Liver_S1...  0.018504 -0.147476   \n",
       "1     HKULiver_Post29wk_HCCAMCLiver_Clinics_Liver_S1...  0.036609 -0.093800   \n",
       "2     HKULiver_Post29wk_HCCAMCLiver_Clinics_Liver_S1...  0.036910 -0.123263   \n",
       "3     HKULiver_Post29wk_HCCAMCLiver_Clinics_Liver_S1...  0.042402 -0.108017   \n",
       "4     HKULiver_Post29wk_HCCAMCLiver_Clinics_Liver_S1...  0.029885 -0.092652   \n",
       "...                                                 ...       ...       ...   \n",
       "6706  HKULiver_Post29wk_HCCLiver_Clinics_Liver_S7_27_24 -0.054617 -0.202530   \n",
       "6707  HKULiver_Post29wk_HCCLiver_Clinics_Liver_S7_33_25 -0.052310 -0.225144   \n",
       "6708  HKULiver_Post29wk_HCCLiver_Clinics_Liver_S7_34_25 -0.027895 -0.183689   \n",
       "6709  HKULiver_Post29wk_HCCLiver_Clinics_Liver_S7_35_25 -0.045657 -0.200992   \n",
       "6710  HKULiver_Post29wk_HCCLiver_Clinics_Liver_S7_36_25 -0.062553 -0.215307   \n",
       "\n",
       "      215.0324  295.2278  883.5331  309.1704  738.5059  435.2965  250.1449  \\\n",
       "0    -0.004369 -0.143675 -0.258001 -0.040594 -0.274653 -0.076837 -0.024790   \n",
       "1     0.005776 -0.143675 -0.183186  0.064776 -0.274653 -0.076837  0.029801   \n",
       "2     0.035984 -0.143675 -0.258001  0.063125 -0.274653 -0.076837  0.047941   \n",
       "3     0.022454 -0.143675 -0.258001  0.058306 -0.274653 -0.076837  0.039621   \n",
       "4     0.014073 -0.143675 -0.258001  0.053608 -0.274653  0.212530  0.020894   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "6706 -0.039259 -0.143675 -0.258001 -0.040594 -0.274653 -0.076837 -0.325840   \n",
       "6707 -0.039259 -0.143675 -0.258001 -0.040594 -0.087148 -0.076837 -0.405295   \n",
       "6708 -0.039259 -0.143675 -0.258001 -0.040594 -0.093638 -0.076837 -0.363926   \n",
       "6709 -0.039259 -0.143675 -0.258001 -0.040594 -0.103156 -0.076837 -0.295754   \n",
       "6710 -0.039259 -0.143675 -0.258001  0.054031 -0.152314 -0.076837 -0.373219   \n",
       "\n",
       "      514.2846  type  \n",
       "0            0     0  \n",
       "1            0     0  \n",
       "2            0     0  \n",
       "3            0     0  \n",
       "4            0     0  \n",
       "...        ...   ...  \n",
       "6706         0     1  \n",
       "6707         0     1  \n",
       "6708         0     1  \n",
       "6709         0     1  \n",
       "6710         0     1  \n",
       "\n",
       "[6711 rows x 12 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cDEFSDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ca171d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "## define functions for performace evaluation ##\n",
    "\n",
    "# Average score\n",
    "def avgScore(arrAcc, cv):\n",
    "    sumAcc = 0\n",
    "    for acc in arrAcc:\n",
    "        sumAcc += acc\n",
    "    return sumAcc / cv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9ccef0bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>311.1684</th>\n",
       "      <th>269.2486</th>\n",
       "      <th>215.0328</th>\n",
       "      <th>295.2278</th>\n",
       "      <th>883.5331</th>\n",
       "      <th>309.1704</th>\n",
       "      <th>738.5059</th>\n",
       "      <th>435.2965</th>\n",
       "      <th>250.1449</th>\n",
       "      <th>514.2846</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.318762</td>\n",
       "      <td>0.142569</td>\n",
       "      <td>-0.119108</td>\n",
       "      <td>-0.067104</td>\n",
       "      <td>-0.070573</td>\n",
       "      <td>0.383846</td>\n",
       "      <td>-0.096633</td>\n",
       "      <td>0.116723</td>\n",
       "      <td>0.126130</td>\n",
       "      <td>-0.041471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.440852</td>\n",
       "      <td>0.374051</td>\n",
       "      <td>-0.038276</td>\n",
       "      <td>-0.067104</td>\n",
       "      <td>-0.038380</td>\n",
       "      <td>0.479313</td>\n",
       "      <td>-0.159106</td>\n",
       "      <td>0.056822</td>\n",
       "      <td>0.300442</td>\n",
       "      <td>-0.041471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.297857</td>\n",
       "      <td>0.157616</td>\n",
       "      <td>-0.083684</td>\n",
       "      <td>-0.067104</td>\n",
       "      <td>-0.068081</td>\n",
       "      <td>0.316539</td>\n",
       "      <td>-0.149709</td>\n",
       "      <td>-0.030859</td>\n",
       "      <td>0.208765</td>\n",
       "      <td>-0.041471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.276321</td>\n",
       "      <td>0.109249</td>\n",
       "      <td>-0.042441</td>\n",
       "      <td>-0.067104</td>\n",
       "      <td>-0.052794</td>\n",
       "      <td>0.298499</td>\n",
       "      <td>-0.142240</td>\n",
       "      <td>-0.019492</td>\n",
       "      <td>0.187136</td>\n",
       "      <td>-0.041471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.172631</td>\n",
       "      <td>0.189790</td>\n",
       "      <td>-0.131907</td>\n",
       "      <td>-0.067104</td>\n",
       "      <td>-0.051093</td>\n",
       "      <td>0.218653</td>\n",
       "      <td>-0.145202</td>\n",
       "      <td>0.138638</td>\n",
       "      <td>0.094756</td>\n",
       "      <td>-0.041471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90955</th>\n",
       "      <td>0.035492</td>\n",
       "      <td>-0.257989</td>\n",
       "      <td>0.004160</td>\n",
       "      <td>-0.067104</td>\n",
       "      <td>-0.141142</td>\n",
       "      <td>0.062400</td>\n",
       "      <td>-0.198284</td>\n",
       "      <td>0.241318</td>\n",
       "      <td>0.038142</td>\n",
       "      <td>0.211848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90956</th>\n",
       "      <td>0.021825</td>\n",
       "      <td>-0.257989</td>\n",
       "      <td>-0.091239</td>\n",
       "      <td>-0.067104</td>\n",
       "      <td>-0.060784</td>\n",
       "      <td>0.073737</td>\n",
       "      <td>-0.189855</td>\n",
       "      <td>0.299056</td>\n",
       "      <td>0.210595</td>\n",
       "      <td>-0.041471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90957</th>\n",
       "      <td>0.030906</td>\n",
       "      <td>0.315221</td>\n",
       "      <td>-0.093394</td>\n",
       "      <td>-0.067104</td>\n",
       "      <td>-0.089608</td>\n",
       "      <td>0.044004</td>\n",
       "      <td>-0.113996</td>\n",
       "      <td>0.194365</td>\n",
       "      <td>0.143269</td>\n",
       "      <td>-0.041471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90958</th>\n",
       "      <td>0.045523</td>\n",
       "      <td>-0.257989</td>\n",
       "      <td>-0.122676</td>\n",
       "      <td>-0.067104</td>\n",
       "      <td>-0.161856</td>\n",
       "      <td>0.059421</td>\n",
       "      <td>-0.137691</td>\n",
       "      <td>0.148243</td>\n",
       "      <td>0.189004</td>\n",
       "      <td>-0.041471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90959</th>\n",
       "      <td>0.017844</td>\n",
       "      <td>-0.257989</td>\n",
       "      <td>-0.120908</td>\n",
       "      <td>-0.067104</td>\n",
       "      <td>-0.391064</td>\n",
       "      <td>0.048939</td>\n",
       "      <td>-0.112142</td>\n",
       "      <td>0.100398</td>\n",
       "      <td>0.177638</td>\n",
       "      <td>-0.041471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90960 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       311.1684  269.2486  215.0328  295.2278  883.5331  309.1704  738.5059  \\\n",
       "0      0.318762  0.142569 -0.119108 -0.067104 -0.070573  0.383846 -0.096633   \n",
       "1      0.440852  0.374051 -0.038276 -0.067104 -0.038380  0.479313 -0.159106   \n",
       "2      0.297857  0.157616 -0.083684 -0.067104 -0.068081  0.316539 -0.149709   \n",
       "3      0.276321  0.109249 -0.042441 -0.067104 -0.052794  0.298499 -0.142240   \n",
       "4      0.172631  0.189790 -0.131907 -0.067104 -0.051093  0.218653 -0.145202   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "90955  0.035492 -0.257989  0.004160 -0.067104 -0.141142  0.062400 -0.198284   \n",
       "90956  0.021825 -0.257989 -0.091239 -0.067104 -0.060784  0.073737 -0.189855   \n",
       "90957  0.030906  0.315221 -0.093394 -0.067104 -0.089608  0.044004 -0.113996   \n",
       "90958  0.045523 -0.257989 -0.122676 -0.067104 -0.161856  0.059421 -0.137691   \n",
       "90959  0.017844 -0.257989 -0.120908 -0.067104 -0.391064  0.048939 -0.112142   \n",
       "\n",
       "       435.2965  250.1449  514.2846  \n",
       "0      0.116723  0.126130 -0.041471  \n",
       "1      0.056822  0.300442 -0.041471  \n",
       "2     -0.030859  0.208765 -0.041471  \n",
       "3     -0.019492  0.187136 -0.041471  \n",
       "4      0.138638  0.094756 -0.041471  \n",
       "...         ...       ...       ...  \n",
       "90955  0.241318  0.038142  0.211848  \n",
       "90956  0.299056  0.210595 -0.041471  \n",
       "90957  0.194365  0.143269 -0.041471  \n",
       "90958  0.148243  0.189004 -0.041471  \n",
       "90959  0.100398  0.177638 -0.041471  \n",
       "\n",
       "[90960 rows x 10 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDEFSDf[trainDEFSDf.columns[1:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f68e145",
   "metadata": {},
   "outputs": [],
   "source": [
    "## define a function for Gradient Boost ##\n",
    "def optimXGBoostClass(inputDB, inputDB_ingested, inputDB_ext, inputDB_FNA, inputDB_di):\n",
    "    #lr_r = [15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5]  # 11\n",
    "    #lr_r = [4, 4.5, 5, 5.5, 6, 6.5, 7, 7.5, 8]  # 9\n",
    "    #lr_r = [5, 4.9, 4.8, 4.7, 4.6, 4.5, 4.4, 4.3, 4.2, 4.1]  # 10\n",
    "    #lr_r = [4.6, 4.62, 4.64, 4.66, 4.68, 4.7, 4.72, 4.74, 4.76, 4.78, 4.8, 4.82, 4.84, 4.86, 4.88, 4.9, 4.92, 4.94, 4.96, 4.98, 5, 5.02, 5.04, 5.06, 5.08, 5.1, 5.12, 5.14, 5.16, 5.18, 5.2, 5.22, 5.24, 5.26, 5.28, 5.3, 5.32, 5.34, 5.36, 5.38, 5.4, 5.42, 5.44, 5.46, 5.48, 5.5]  # 46\n",
    "    lr_r = [4.6, 4.61, 4.62, 4.63, 4.64, 4.65, 4.66, 4.67, 4.68, 4.69, 4.7, 4.71, 4.72, 4.73, 4.74, 4.75, 4.76, 4.77, 4.78, 4.79, 4.8]  # 21\n",
    "    #cols_r = [0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 1]  # 7\n",
    "    #cols_r = [0.8, 0.825, 0.85, 0.875, 0.9, 0.925, 0.95, 0.975, 1]  # 9\n",
    "    #cols_r = [0.89, 0.9, 0.91, 0.92, 0.93, 0.94, 0.95, 0.96, 0.97, 0.98, 0.99, 1]  # 12\n",
    "    cols_r = [1]  # 1\n",
    "    #depth_r = [3, 4, 5, 6]  # 4\n",
    "    #depth_r = [3, 4, 5]  # 3\n",
    "    depth_r = [3, 4]  # 2\n",
    "    #subs_r = [0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7]  # 7\n",
    "    #subs_r = [0.4, 0.425, 0.45, 0.475, 0.5, 0.525, 0.55, 0.575, 0.6]  # 9\n",
    "    subs_r = [0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.6]  # 10\n",
    "    #tree_r = [100]  # 1\n",
    "    #tree_r = [100, 150]  # 2\n",
    "    #tree_r = [150, 200]  # 2\n",
    "    #tree_r = [200, 300]  # 2\n",
    "    tree_r = [25, 50, 75, 100, 200, 300, 500]  # 7\n",
    "    #est_r = [8, 32] # 2\n",
    "    #est_r = [5, 32, 64] # 3\n",
    "    #est_r = [64, 96] # 2\n",
    "    #est_r = [96, 128] # 2\n",
    "    est_r = [2, 8, 16, 32, 64, 96] # 6\n",
    "\n",
    "    rs = 42\n",
    "    z = np.zeros(38)\n",
    "    itr = 1\n",
    "\n",
    "    N_train = inputDB\n",
    "    M_train = inputDB_ingested\n",
    "    M_ext = inputDB_ext\n",
    "    M_FNA = inputDB_FNA\n",
    "    M_di = inputDB_di\n",
    "\n",
    "    for lr in lr_r:\n",
    "        for c in cols_r:\n",
    "            for d in depth_r:\n",
    "                for s in subs_r:\n",
    "                    for t in tree_r:\n",
    "                        for est in est_r:\n",
    "    \n",
    "                            print(\"itr=\", itr, \", lr=\", lr, \", cols=\", c, \", depth=\", d, \", sub=\", s, \", tree=\", t, \", est=\", est)\n",
    "                            print(\"## loading in data ##\")\n",
    "                            Xx_train = M_train[M_train.columns[1:-1]]\n",
    "                            nn_train = N_train[N_train.columns[1:-1]]\n",
    "                            Xx_Ext = M_ext[M_ext.columns[1:-1]]\n",
    "                            Xx_FNA = M_FNA[M_FNA.columns[1:-1]]\n",
    "                            Xx_di = M_di[M_di.columns[1:-1]]\n",
    "                            #\n",
    "                            Yy_train = M_train[\"type\"]\n",
    "                            mm_train = N_train[\"type\"]\n",
    "                            Yy_Ext = M_ext[\"type\"]\n",
    "                            Yy_FNA = M_FNA[\"type\"]\n",
    "                            Yy_di = M_di[\"type\"]\n",
    "                            print(\"## Classification ##\")\n",
    "                            model_xgb = xgb.XGBClassifier(\n",
    "                                base_score = 0.5, \n",
    "                                booster = 'gbtree', \n",
    "                                colsample_bylevel = 1, \n",
    "                                colsample_bynode = 1, \n",
    "                                colsample_bytree = c, \n",
    "                                enable_categorical = False, \n",
    "                                eval_metric = 'auc', \n",
    "                                gamma = 0, \n",
    "                                gpu_id = -1, \n",
    "                                grow_policy = 'lossguide', \n",
    "                                importance_type = None, \n",
    "                                learning_rate = lr, \n",
    "                                max_bin = 256, \n",
    "                                max_cat_to_onehot = 4, \n",
    "                                max_delta_step = 0, \n",
    "                                max_depth = d, \n",
    "                                max_leaves = 0, \n",
    "                                min_child_weight = 1, \n",
    "                                #missing = nan, \n",
    "                                monotone_constraints = '()', \n",
    "                                n_estimators = t, \n",
    "                                n_jobs = 0, \n",
    "                                num_parallel_tree = 1, \n",
    "                                objective = 'binary:hinge', \n",
    "                                predictor = 'auto', \n",
    "                                random_state = 0, \n",
    "                                reg_alpha = 0, \n",
    "                                reg_lambda = 1, \n",
    "                                sampling_method = 'uniform', \n",
    "                                scale_pos_weight = None, \n",
    "                                subsample = s, \n",
    "                                tree_method = 'hist', \n",
    "                                use_label_encoder = False, \n",
    "                                validate_parameters = 1, \n",
    "                                verbosity = None, \n",
    "                                early_stopping_rounds = est)\n",
    "\n",
    "                            # Training Set\n",
    "                            model_xgb.fit(Xx_train, Yy_train, \n",
    "                                          eval_set=[(Xx_FNA, Yy_FNA), (Xx_di, Yy_di)])\n",
    "\n",
    "                            fit_params = {'eval_set': [[Xx_FNA, Yy_FNA], [Xx_di, Yy_di]]}\n",
    "\n",
    "                            importances = permutation_importance(model_xgb, Xx_FNA, Yy_FNA, n_repeats=10, random_state=42, n_jobs=-1)\n",
    "                            #print(importances[\"importances_mean\"])\n",
    "\n",
    "                            if itr == 1:\n",
    "                                z[0] = lr\n",
    "                                z[1] = c\n",
    "                                z[2] = d\n",
    "                                z[3] = s\n",
    "                                z[4] = t\n",
    "                                z[5] = est\n",
    "                                z[6] = f1_score(mm_train, model_xgb.predict(nn_train), sample_weight=sampleW)\n",
    "                                z[7] = matthews_corrcoef(mm_train, model_xgb.predict(nn_train), sample_weight=sampleW)\n",
    "                                z[8] = f1_score(Yy_Ext, model_xgb.predict(Xx_Ext), sample_weight=sampleExtW)\n",
    "                                z[9] = matthews_corrcoef(Yy_Ext, model_xgb.predict(Xx_Ext), sample_weight=sampleExtW)\n",
    "                                print(\"## No CV ##\")\n",
    "                                scores_XGB = cross_val_score(model_xgb, Xx_train, Yy_train, cv=5, scoring = \"f1\", fit_params = fit_params)\n",
    "                                z[10] = scores_XGB.mean()\n",
    "                                #print(scores_XGB.mean())\n",
    "                                z[11] = f1_score(Yy_FNA, model_xgb.predict(Xx_FNA), sample_weight=sampleFNAW)\n",
    "                                z[12] = matthews_corrcoef(Yy_FNA, model_xgb.predict(Xx_FNA), sample_weight=sampleFNAW)\n",
    "                                z[13] = recall_score(Yy_FNA, model_xgb.predict(Xx_FNA))\n",
    "                                z[14] = f1_score(Yy_di, model_xgb.predict(Xx_di), sample_weight=sampleDiW)\n",
    "                                z[15] = matthews_corrcoef(Yy_di, model_xgb.predict(Xx_di), sample_weight=sampleDiW)\n",
    "                                z[16] = recall_score(Yy_di, model_xgb.predict(Xx_di))\n",
    "                                z[17] = rs\n",
    "                                z[18] = importances[\"importances_mean\"][0]\n",
    "                                z[19] = importances[\"importances_mean\"][1]\n",
    "                                z[20] = importances[\"importances_mean\"][2]\n",
    "                                z[21] = importances[\"importances_mean\"][3]\n",
    "                                z[22] = importances[\"importances_mean\"][4]\n",
    "                                z[23] = importances[\"importances_mean\"][5]\n",
    "                                z[24] = importances[\"importances_mean\"][6]\n",
    "                                z[25] = importances[\"importances_mean\"][7]\n",
    "                                z[26] = importances[\"importances_mean\"][8]\n",
    "                                z[27] = importances[\"importances_mean\"][9]\n",
    "                                z[28] = importances[\"importances_std\"][0]\n",
    "                                z[29] = importances[\"importances_std\"][1]\n",
    "                                z[30] = importances[\"importances_std\"][2]\n",
    "                                z[31] = importances[\"importances_std\"][3]\n",
    "                                z[32] = importances[\"importances_std\"][4]\n",
    "                                z[33] = importances[\"importances_std\"][5]\n",
    "                                z[34] = importances[\"importances_std\"][6]\n",
    "                                z[35] = importances[\"importances_std\"][7]\n",
    "                                z[36] = importances[\"importances_std\"][8]\n",
    "                                z[37] = importances[\"importances_std\"][9]\n",
    "                            else:\n",
    "                                itrain = f1_score(mm_train, model_xgb.predict(nn_train), sample_weight=sampleW)\n",
    "                                jtrain = matthews_corrcoef(mm_train, model_xgb.predict(nn_train), sample_weight=sampleW)\n",
    "                                ival = f1_score(Yy_Ext, model_xgb.predict(Xx_Ext), sample_weight=sampleExtW)\n",
    "                                jval = matthews_corrcoef(Yy_Ext, model_xgb.predict(Xx_Ext), sample_weight=sampleExtW)\n",
    "                                print(\"## No CV ##\")\n",
    "                                scores_XGB = cross_val_score(model_xgb, Xx_train, Yy_train, cv=5, scoring = \"f1\", fit_params = fit_params)\n",
    "                                traincvtrain = scores_XGB.mean()\n",
    "                                f1s = f1_score(Yy_FNA, model_xgb.predict(Xx_FNA), sample_weight=sampleFNAW)\n",
    "                                mccs = matthews_corrcoef(Yy_FNA, model_xgb.predict(Xx_FNA), sample_weight=sampleFNAW)\n",
    "                                rec = recall_score(Yy_FNA, model_xgb.predict(Xx_FNA))\n",
    "                                f1s2 = f1_score(Yy_di, model_xgb.predict(Xx_di), sample_weight=sampleDiW)\n",
    "                                mccs2 = matthews_corrcoef(Yy_di, model_xgb.predict(Xx_di), sample_weight=sampleDiW)\n",
    "                                rec2 = recall_score(Yy_di, model_xgb.predict(Xx_di))\n",
    "                                im1 = importances[\"importances_mean\"][0]\n",
    "                                im2 = importances[\"importances_mean\"][1]\n",
    "                                im3 = importances[\"importances_mean\"][2]\n",
    "                                im4 = importances[\"importances_mean\"][3]\n",
    "                                im5 = importances[\"importances_mean\"][4]\n",
    "                                im6 = importances[\"importances_mean\"][5]\n",
    "                                im7 = importances[\"importances_mean\"][6]\n",
    "                                im8 = importances[\"importances_mean\"][7]\n",
    "                                im9 = importances[\"importances_mean\"][8]\n",
    "                                im10 = importances[\"importances_mean\"][9]\n",
    "                                sd1 = importances[\"importances_std\"][0]\n",
    "                                sd2 = importances[\"importances_std\"][1]\n",
    "                                sd3 = importances[\"importances_std\"][2]\n",
    "                                sd4 = importances[\"importances_std\"][3]\n",
    "                                sd5 = importances[\"importances_std\"][4]\n",
    "                                sd6 = importances[\"importances_std\"][5]\n",
    "                                sd7 = importances[\"importances_std\"][6]\n",
    "                                sd8 = importances[\"importances_std\"][7]\n",
    "                                sd9 = importances[\"importances_std\"][8]\n",
    "                                sd10 = importances[\"importances_std\"][9]\n",
    "                                tem = np.array([lr, c, d, s, t, est, itrain, jtrain, ival, jval, traincvtrain, f1s, mccs, rec, f1s2, mccs2, rec2, rs, im1, im2, im3, im4, im5, im6, im7, im8, im9, im10, sd1, sd2, sd3, sd4, sd5, sd6, sd7, sd8, sd9, sd10])\n",
    "                                z = np.row_stack([z, tem])\n",
    "                                #print(z[-1])\n",
    "                            print(\"End of \", itr, \" iterations\")\n",
    "                            itr += 1\n",
    "    z_df = pd.DataFrame(z, columns=[\"lr\", \"cols\", \"depth\", \"subs\", \"tree\", \"est\", \n",
    "                                    \"f1_train\", \"mcc_train\", \"f1_ext\", \"mcc_ext\", \n",
    "                                    \"f1_5Ftrain\", \"f1_fna\", \"mcc_fna\", \"recall_fna\", \n",
    "                                    \"f1_di\", \"mcc_di\", \"recall_di\", \"state\", \n",
    "                                    \"im1\", \"im2\", \"im3\", \"im4\", \"im5\", \"im6\", \"im7\", \"im8\", \"im9\", \"im10\", \n",
    "                                    \"sd1\", \"sd2\", \"sd3\", \"sd4\", \"sd5\", \"sd6\", \"sd7\", \"sd8\", \"sd9\", \"sd10\"])\n",
    "\n",
    "    return z_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ff9f9ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2799165c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## call Gradient Boost ##\n",
    "optiSearch_df = optimXGBoostClass(trainDEFSDf, ingestedDEFSDf, extDEFSDf, fnaDEFSDf, diDEFSDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419cfa83",
   "metadata": {},
   "outputs": [],
   "source": [
    "## save ##\n",
    "optiSearch_df.to_csv(r\"H:/3_output_raMSIn/3_3_Output_raMSIn_HKU_Ingested4ALL/XGB_ALL/modeling/hyperparameterTuning_modelSelection_XGB6.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5774f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "95c56eae",
   "metadata": {},
   "source": [
    "# 2. Unsupervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8049959",
   "metadata": {},
   "source": [
    "## 2.1. Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "56926254",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 720x720 with 0 Axes>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from matplotlib.pyplot import figure\n",
    "plt.rcParams['figure.figsize'] = [10, 10]\n",
    "plt.grid(visible=None)\n",
    "plt.close()\n",
    "figure(figsize=(10, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "62a3d9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ROI_for_ML_Opti = pd.concat([trainDEFSDf, extDEFSDf, fnaDEFSDf, diDEFSDf]).set_index('pixel_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e9061d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ROI_for_ML_Opti_ingested = ingestedDEFSDf.set_index('pixel_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7d1ef236",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ROI_for_ML_Opti_train = trainDEFSDf.set_index('pixel_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f9f05550",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ROI_for_ML_Opti_ext = extDEFSDf.set_index('pixel_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0dfe922b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ROI_for_ML_Opti_FNA = fnaDEFSDf.set_index('pixel_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c9f03908",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ROI_for_ML_Opti_di = diDEFSDf.set_index('pixel_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "50e43a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ROI_for_ML_Opti_c = cDEFSDf.set_index('pixel_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e32c1d5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>311.1684</th>\n",
       "      <th>269.2486</th>\n",
       "      <th>215.0328</th>\n",
       "      <th>295.2278</th>\n",
       "      <th>883.5331</th>\n",
       "      <th>309.1704</th>\n",
       "      <th>738.5059</th>\n",
       "      <th>435.2965</th>\n",
       "      <th>250.1449</th>\n",
       "      <th>514.2846</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6.057000e+03</td>\n",
       "      <td>6.057000e+03</td>\n",
       "      <td>6.057000e+03</td>\n",
       "      <td>6.057000e+03</td>\n",
       "      <td>6.057000e+03</td>\n",
       "      <td>6.057000e+03</td>\n",
       "      <td>6.057000e+03</td>\n",
       "      <td>6.057000e+03</td>\n",
       "      <td>6.057000e+03</td>\n",
       "      <td>6.057000e+03</td>\n",
       "      <td>6057.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.786097e-18</td>\n",
       "      <td>6.620646e-17</td>\n",
       "      <td>1.140100e-16</td>\n",
       "      <td>-1.438873e-18</td>\n",
       "      <td>-5.146581e-16</td>\n",
       "      <td>9.102472e-17</td>\n",
       "      <td>5.544700e-17</td>\n",
       "      <td>-1.341561e-15</td>\n",
       "      <td>-1.901503e-15</td>\n",
       "      <td>-7.857894e-17</td>\n",
       "      <td>0.500248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.259709e-01</td>\n",
       "      <td>1.439456e-01</td>\n",
       "      <td>1.644103e-01</td>\n",
       "      <td>1.354221e-01</td>\n",
       "      <td>1.815312e-01</td>\n",
       "      <td>1.711848e-01</td>\n",
       "      <td>1.276838e-01</td>\n",
       "      <td>2.073881e-01</td>\n",
       "      <td>1.914128e-01</td>\n",
       "      <td>1.330110e-01</td>\n",
       "      <td>0.500041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-3.936976e-01</td>\n",
       "      <td>-4.211962e-01</td>\n",
       "      <td>-3.062768e-01</td>\n",
       "      <td>-4.545066e-01</td>\n",
       "      <td>-2.730134e-01</td>\n",
       "      <td>-3.622890e-01</td>\n",
       "      <td>-2.805354e-01</td>\n",
       "      <td>-2.778402e-01</td>\n",
       "      <td>-8.938063e-02</td>\n",
       "      <td>-3.327803e-01</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-7.672668e-02</td>\n",
       "      <td>-6.810890e-02</td>\n",
       "      <td>-9.451451e-02</td>\n",
       "      <td>-6.188994e-02</td>\n",
       "      <td>-1.070219e-01</td>\n",
       "      <td>-8.982515e-02</td>\n",
       "      <td>-5.995209e-02</td>\n",
       "      <td>-2.778402e-01</td>\n",
       "      <td>-8.938063e-02</td>\n",
       "      <td>-6.633725e-02</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.552356e-03</td>\n",
       "      <td>-6.986512e-03</td>\n",
       "      <td>1.673886e-02</td>\n",
       "      <td>1.774746e-02</td>\n",
       "      <td>3.089123e-02</td>\n",
       "      <td>-3.331810e-02</td>\n",
       "      <td>1.460550e-02</td>\n",
       "      <td>6.108422e-03</td>\n",
       "      <td>-8.938063e-02</td>\n",
       "      <td>-1.853303e-02</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.000432e-02</td>\n",
       "      <td>5.958404e-02</td>\n",
       "      <td>1.127564e-01</td>\n",
       "      <td>7.451773e-02</td>\n",
       "      <td>1.304366e-01</td>\n",
       "      <td>3.533862e-02</td>\n",
       "      <td>6.956954e-02</td>\n",
       "      <td>1.665798e-01</td>\n",
       "      <td>-1.203494e-03</td>\n",
       "      <td>8.938771e-02</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.063024e-01</td>\n",
       "      <td>5.788038e-01</td>\n",
       "      <td>6.937232e-01</td>\n",
       "      <td>5.454934e-01</td>\n",
       "      <td>7.269866e-01</td>\n",
       "      <td>6.377110e-01</td>\n",
       "      <td>7.194646e-01</td>\n",
       "      <td>7.221598e-01</td>\n",
       "      <td>9.106194e-01</td>\n",
       "      <td>6.672197e-01</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           311.1684      269.2486      215.0328      295.2278      883.5331  \\\n",
       "count  6.057000e+03  6.057000e+03  6.057000e+03  6.057000e+03  6.057000e+03   \n",
       "mean   2.786097e-18  6.620646e-17  1.140100e-16 -1.438873e-18 -5.146581e-16   \n",
       "std    1.259709e-01  1.439456e-01  1.644103e-01  1.354221e-01  1.815312e-01   \n",
       "min   -3.936976e-01 -4.211962e-01 -3.062768e-01 -4.545066e-01 -2.730134e-01   \n",
       "25%   -7.672668e-02 -6.810890e-02 -9.451451e-02 -6.188994e-02 -1.070219e-01   \n",
       "50%    9.552356e-03 -6.986512e-03  1.673886e-02  1.774746e-02  3.089123e-02   \n",
       "75%    9.000432e-02  5.958404e-02  1.127564e-01  7.451773e-02  1.304366e-01   \n",
       "max    6.063024e-01  5.788038e-01  6.937232e-01  5.454934e-01  7.269866e-01   \n",
       "\n",
       "           309.1704      738.5059      435.2965      250.1449      514.2846  \\\n",
       "count  6.057000e+03  6.057000e+03  6.057000e+03  6.057000e+03  6.057000e+03   \n",
       "mean   9.102472e-17  5.544700e-17 -1.341561e-15 -1.901503e-15 -7.857894e-17   \n",
       "std    1.711848e-01  1.276838e-01  2.073881e-01  1.914128e-01  1.330110e-01   \n",
       "min   -3.622890e-01 -2.805354e-01 -2.778402e-01 -8.938063e-02 -3.327803e-01   \n",
       "25%   -8.982515e-02 -5.995209e-02 -2.778402e-01 -8.938063e-02 -6.633725e-02   \n",
       "50%   -3.331810e-02  1.460550e-02  6.108422e-03 -8.938063e-02 -1.853303e-02   \n",
       "75%    3.533862e-02  6.956954e-02  1.665798e-01 -1.203494e-03  8.938771e-02   \n",
       "max    6.377110e-01  7.194646e-01  7.221598e-01  9.106194e-01  6.672197e-01   \n",
       "\n",
       "              type  \n",
       "count  6057.000000  \n",
       "mean      0.500248  \n",
       "std       0.500041  \n",
       "min       0.000000  \n",
       "25%       0.000000  \n",
       "50%       1.000000  \n",
       "75%       1.000000  \n",
       "max       1.000000  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ROI_for_ML_Opti_di.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ad4f473e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>311.1684</th>\n",
       "      <th>269.2486</th>\n",
       "      <th>215.0324</th>\n",
       "      <th>295.2278</th>\n",
       "      <th>883.5331</th>\n",
       "      <th>309.1704</th>\n",
       "      <th>738.5059</th>\n",
       "      <th>435.2965</th>\n",
       "      <th>250.1449</th>\n",
       "      <th>514.2846</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6.711000e+03</td>\n",
       "      <td>6.711000e+03</td>\n",
       "      <td>6.711000e+03</td>\n",
       "      <td>6.711000e+03</td>\n",
       "      <td>6.711000e+03</td>\n",
       "      <td>6.711000e+03</td>\n",
       "      <td>6.711000e+03</td>\n",
       "      <td>6.711000e+03</td>\n",
       "      <td>6.711000e+03</td>\n",
       "      <td>6711.0</td>\n",
       "      <td>6711.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-9.284945e-19</td>\n",
       "      <td>-8.555384e-17</td>\n",
       "      <td>2.700596e-16</td>\n",
       "      <td>1.367397e-15</td>\n",
       "      <td>1.236118e-16</td>\n",
       "      <td>6.881478e-16</td>\n",
       "      <td>6.407233e-17</td>\n",
       "      <td>-6.577960e-16</td>\n",
       "      <td>-7.867182e-17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.486068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.023863e-01</td>\n",
       "      <td>1.683266e-01</td>\n",
       "      <td>8.112107e-02</td>\n",
       "      <td>2.135591e-01</td>\n",
       "      <td>2.068261e-01</td>\n",
       "      <td>7.224478e-02</td>\n",
       "      <td>1.878837e-01</td>\n",
       "      <td>1.768442e-01</td>\n",
       "      <td>2.099804e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.499843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-9.204706e-02</td>\n",
       "      <td>-3.264215e-01</td>\n",
       "      <td>-3.925883e-02</td>\n",
       "      <td>-1.436749e-01</td>\n",
       "      <td>-2.580012e-01</td>\n",
       "      <td>-4.059445e-02</td>\n",
       "      <td>-2.746533e-01</td>\n",
       "      <td>-7.683659e-02</td>\n",
       "      <td>-4.504028e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-4.865604e-02</td>\n",
       "      <td>-1.331893e-01</td>\n",
       "      <td>-3.925883e-02</td>\n",
       "      <td>-1.436749e-01</td>\n",
       "      <td>-1.768592e-01</td>\n",
       "      <td>-4.059445e-02</td>\n",
       "      <td>-1.459359e-01</td>\n",
       "      <td>-7.683659e-02</td>\n",
       "      <td>-2.021631e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-2.287788e-02</td>\n",
       "      <td>-4.055695e-02</td>\n",
       "      <td>-3.925883e-02</td>\n",
       "      <td>-1.436749e-01</td>\n",
       "      <td>-1.555795e-02</td>\n",
       "      <td>-4.059445e-02</td>\n",
       "      <td>-4.521608e-03</td>\n",
       "      <td>-7.683659e-02</td>\n",
       "      <td>2.809078e-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.584626e-02</td>\n",
       "      <td>9.233885e-02</td>\n",
       "      <td>1.584092e-02</td>\n",
       "      <td>1.287667e-01</td>\n",
       "      <td>1.305847e-01</td>\n",
       "      <td>5.592892e-02</td>\n",
       "      <td>1.404563e-01</td>\n",
       "      <td>-7.683659e-02</td>\n",
       "      <td>1.773428e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.079529e-01</td>\n",
       "      <td>6.735785e-01</td>\n",
       "      <td>9.607412e-01</td>\n",
       "      <td>8.563251e-01</td>\n",
       "      <td>7.419988e-01</td>\n",
       "      <td>9.594056e-01</td>\n",
       "      <td>7.253467e-01</td>\n",
       "      <td>9.231634e-01</td>\n",
       "      <td>5.495972e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           311.1684      269.2486      215.0324      295.2278      883.5331  \\\n",
       "count  6.711000e+03  6.711000e+03  6.711000e+03  6.711000e+03  6.711000e+03   \n",
       "mean  -9.284945e-19 -8.555384e-17  2.700596e-16  1.367397e-15  1.236118e-16   \n",
       "std    1.023863e-01  1.683266e-01  8.112107e-02  2.135591e-01  2.068261e-01   \n",
       "min   -9.204706e-02 -3.264215e-01 -3.925883e-02 -1.436749e-01 -2.580012e-01   \n",
       "25%   -4.865604e-02 -1.331893e-01 -3.925883e-02 -1.436749e-01 -1.768592e-01   \n",
       "50%   -2.287788e-02 -4.055695e-02 -3.925883e-02 -1.436749e-01 -1.555795e-02   \n",
       "75%    1.584626e-02  9.233885e-02  1.584092e-02  1.287667e-01  1.305847e-01   \n",
       "max    9.079529e-01  6.735785e-01  9.607412e-01  8.563251e-01  7.419988e-01   \n",
       "\n",
       "           309.1704      738.5059      435.2965      250.1449  514.2846  \\\n",
       "count  6.711000e+03  6.711000e+03  6.711000e+03  6.711000e+03    6711.0   \n",
       "mean   6.881478e-16  6.407233e-17 -6.577960e-16 -7.867182e-17       0.0   \n",
       "std    7.224478e-02  1.878837e-01  1.768442e-01  2.099804e-01       0.0   \n",
       "min   -4.059445e-02 -2.746533e-01 -7.683659e-02 -4.504028e-01       0.0   \n",
       "25%   -4.059445e-02 -1.459359e-01 -7.683659e-02 -2.021631e-01       0.0   \n",
       "50%   -4.059445e-02 -4.521608e-03 -7.683659e-02  2.809078e-02       0.0   \n",
       "75%    5.592892e-02  1.404563e-01 -7.683659e-02  1.773428e-01       0.0   \n",
       "max    9.594056e-01  7.253467e-01  9.231634e-01  5.495972e-01       0.0   \n",
       "\n",
       "              type  \n",
       "count  6711.000000  \n",
       "mean      0.486068  \n",
       "std       0.499843  \n",
       "min       0.000000  \n",
       "25%       0.000000  \n",
       "50%       0.000000  \n",
       "75%       1.000000  \n",
       "max       1.000000  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ROI_for_ML_Opti_c.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c25aab6",
   "metadata": {},
   "source": [
    "## 2.2. PCA Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e9735181",
   "metadata": {},
   "outputs": [],
   "source": [
    "## PCA Analysis\n",
    "\n",
    "def pca_visual(df=df_ROI_for_ML_Opti_c):\n",
    "\n",
    "    pca = PCA(n_components=3)\n",
    "    raMSI_ML_mz_df = df.drop(\"type\", axis = 1)\n",
    "    pca.fit(raMSI_ML_mz_df)\n",
    "    result = pd.DataFrame(pca.transform(raMSI_ML_mz_df), columns=['PCA%i' % i for i in range(3)], index=df_ROI_for_ML_Opti_c.index)\n",
    "    \n",
    "    plt.subplots(dpi = 300)\n",
    "    plt.scatter(result['PCA1'], result['PCA2'], c = df['type'], s=1)\n",
    "    plt.xlabel('PC1', size=20)\n",
    "    plt.ylabel('PC2', size=20)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    plt.savefig(r\"H:/3_output_raMSIn/3_3_Output_raMSIn_HKU_Ingested4ALL/XGB_ALL/afterModelSelection/PCA_c.tif\", bbox_inches = 'tight')\n",
    "\n",
    "    components = pca.fit_transform(raMSI_ML_mz_df)\n",
    "    total_var = pca.explained_variance_ratio_.sum() * 100\n",
    "    fig = px.scatter_3d(\n",
    "        components, x=0, y=1, z=2, color=df['type'],\n",
    "        title = f'Total Explained Variance: {total_var:.2f}%',\n",
    "        labels = {'0': 'PC 1', '1': 'PC 2', '2': 'PC 3'}\n",
    "    )\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07893c06",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "pca_visual()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a0c5f5",
   "metadata": {},
   "source": [
    "# 3. Supervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cdf76b0",
   "metadata": {},
   "source": [
    "## 3.1. Preparation of training and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a9518fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(df=df_ROI_for_ML_Opti_ingested):\n",
    "    raMSI_ML_NoType = df.drop(\"type\", axis = 1)\n",
    "    raMSI_ML_Type=df[['type']]\n",
    "    X_train,X_test,y_train,y_test=train_test_split(raMSI_ML_NoType,raMSI_ML_Type,test_size=0.2,random_state=42)\n",
    "    return X_train,X_test,y_train,y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7a5146",
   "metadata": {},
   "source": [
    "X_train,X_test,y_train,y_test=split_dataset(df=df_ROI_for_ML_Opti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "92b9ff22",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ingested = df_ROI_for_ML_Opti_ingested[df_ROI_for_ML_Opti_ingested.columns[:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "071b9d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ingested = df_ROI_for_ML_Opti_ingested[df_ROI_for_ML_Opti_ingested.columns[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "78235c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_ROI_for_ML_Opti_train[df_ROI_for_ML_Opti_train.columns[:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "226a001d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_ROI_for_ML_Opti_train[df_ROI_for_ML_Opti_train.columns[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "21066a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = df_ROI_for_ML_Opti_ext[df_ROI_for_ML_Opti_ext.columns[:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "375fd7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val = df_ROI_for_ML_Opti_ext[df_ROI_for_ML_Opti_ext.columns[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "460faa79",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_FNA = df_ROI_for_ML_Opti_FNA[df_ROI_for_ML_Opti_FNA.columns[:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dd2eede7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_FNA = df_ROI_for_ML_Opti_FNA[df_ROI_for_ML_Opti_FNA.columns[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ed82f1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_di = df_ROI_for_ML_Opti_di[df_ROI_for_ML_Opti_di.columns[:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9f1717b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_di = df_ROI_for_ML_Opti_di[df_ROI_for_ML_Opti_di.columns[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e402685e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_c = df_ROI_for_ML_Opti_c[df_ROI_for_ML_Opti_c.columns[:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ad0f5b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_c = df_ROI_for_ML_Opti_c[df_ROI_for_ML_Opti_c.columns[-1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02cd4f6d",
   "metadata": {},
   "source": [
    "## 3.2 Machine Learning Modeling: Model 1+2 (Train 10:10, Val 4:4, Test 3:3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6d458bee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 720x720 with 0 Axes>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from matplotlib.pyplot import figure\n",
    "plt.rcParams['figure.figsize'] = [10, 10]\n",
    "plt.grid(visible=None)\n",
    "plt.close()\n",
    "figure(figsize=(10, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462143af",
   "metadata": {},
   "source": [
    "### 3.2.1. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a3165db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build Logistic Regression Model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def LogisticRegression_func(XTrain=X_ingested, XVal=X_val, XTest=X_FNA, yTrain=y_ingested, yVal=y_val, yTest=y_FNA):\n",
    "    model_lr = LogisticRegression(C=0.001, penalty='l1', solver=\"liblinear\", max_iter=5000, random_state=42, class_weight={0:0.9628, 1:1.0402})  # max_iter=100\n",
    "    model_lr.fit(XTrain,yTrain)\n",
    "    \n",
    "    # Training Set\n",
    "    #plt.rcParams[\"figure.figsize\"] = (3,3)\n",
    "    X_train_predictions = model_lr.predict(X_train)\n",
    "    print(\"Training Set F1:\", f1_score(y_train, model_lr.predict(X_train), sample_weight=sampleW))\n",
    "    print(\"Training Set MCC:\", matthews_corrcoef(y_train, model_lr.predict(X_train), sample_weight=sampleW))\n",
    "    print(\"Training Set Accuracy:\", metrics.accuracy_score(y_train, X_train_predictions))\n",
    "    print(classification_report(y_train, X_train_predictions))\n",
    "    print(confusion_matrix(y_train, X_train_predictions))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr, tpr, _ = metrics.roc_curve(y_train, X_train_predictions)\n",
    "    plt.plot(fpr,tpr)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_train.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    # Val set\n",
    "    predictions_val  = model_lr.predict(XVal)\n",
    "    print(\"Ext Val Set F1:\", f1_score(yVal, model_lr.predict(XVal), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set MCC:\", matthews_corrcoef(yVal, model_lr.predict(XVal), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set Accuracy:\", metrics.accuracy_score(yVal, predictions_val))\n",
    "    print(classification_report(yVal, predictions_val))\n",
    "    print(confusion_matrix(yVal, predictions_val))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_val, tpr_val, _ = metrics.roc_curve(yVal, predictions_val)\n",
    "    plt.plot(fpr_val,tpr_val)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_test.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    f1_5_train = cross_val_score(model_lr, XTrain, yTrain, cv = 5, scoring=\"f1\")\n",
    "    print(\"5F-CV:\", avgScore(f1_5_train, 5))\n",
    "    \n",
    "    # Test set\n",
    "    predictions_FNA = model_lr.predict(XTest)\n",
    "    print(\"FNA Set F1:\", f1_score(yTest, model_lr.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set MCC:\", matthews_corrcoef(yTest, model_lr.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set Recall:\", recall_score(yTest, model_lr.predict(XTest)))\n",
    "    print(\"FNA Test Set Accuracy:\", metrics.accuracy_score(yTest, predictions_FNA))\n",
    "    print(classification_report(yTest, predictions_FNA))\n",
    "    print(confusion_matrix(yTest, predictions_FNA))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_FNA, tpr_FNA, _ = metrics.roc_curve(yTest, predictions_FNA)\n",
    "    plt.plot(fpr_FNA,tpr_FNA)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"G:/raMSIn/XGB_Importance2/XGB2_ROC_FNAtest2.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    # Visualize the importantance of the features\n",
    "    feature_imp = pd.Series(model_lr.coef_[0], index=XTrain.columns).sort_values(ascending=False)\n",
    "    x=feature_imp\n",
    "    y=feature_imp.index\n",
    "    \n",
    "    plt.subplots(dpi = 300)\n",
    "    #plt.rcParams[\"figure.figsize\"] = [4, 6]\n",
    "    #plt.rcParams[\"font.family\"] = \"Arial\"\n",
    "    #plt.rcParams.update({'font.size': 6})\n",
    "    plt.xlabel('Feature Importance Score', fontproperties='Arial', fontsize=17)\n",
    "    plt.ylabel('Features', fontproperties='Arial', fontsize=17)\n",
    "    plt.xticks(fontsize=15)\n",
    "    plt.yticks(fontsize=15)\n",
    "    plt.title(\"Important Molecular Features\", fontproperties='Arial', fontsize=20)\n",
    "    sns.barplot(x=feature_imp, y=feature_imp.index)\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_TopFeatures.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    #feature_importances = model_lr.coef_[0]\n",
    "    #feature_df=pd.DataFrame({'m/z':XTrain.columns,'coef':feature_importances})\n",
    "\n",
    "    #fig = px.bar(feature_df, x='coef', y='m/z')\n",
    "    #fig.show()\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "e4810838",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set F1: 0.8430329884924959\n",
      "Training Set MCC: 0.6836475146482217\n",
      "Training Set Accuracy: 0.8414357959542657\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.83      0.85     47449\n",
      "           1       0.82      0.85      0.84     43511\n",
      "\n",
      "    accuracy                           0.84     90960\n",
      "   macro avg       0.84      0.84      0.84     90960\n",
      "weighted avg       0.84      0.84      0.84     90960\n",
      "\n",
      "[[39564  7885]\n",
      " [ 6538 36973]]\n",
      "Ext Val Set F1: 0.7604911114661329\n",
      "Ext Val Set MCC: 0.48929462435535054\n",
      "Ext Val Set Accuracy: 0.7440329218106996\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.66      0.71      2943\n",
      "           1       0.72      0.82      0.77      3132\n",
      "\n",
      "    accuracy                           0.74      6075\n",
      "   macro avg       0.75      0.74      0.74      6075\n",
      "weighted avg       0.75      0.74      0.74      6075\n",
      "\n",
      "[[1950  993]\n",
      " [ 562 2570]]\n",
      "5F-CV: 0.63477535114233\n",
      "FNA Set F1: 0.6867020742849309\n",
      "FNA Set MCC: 0.3861627738084234\n",
      "FNA Set Recall: 0.6730372953511017\n",
      "FNA Test Set Accuracy: 0.6930136075128803\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.71      0.70     44540\n",
      "           1       0.70      0.67      0.69     44161\n",
      "\n",
      "    accuracy                           0.69     88701\n",
      "   macro avg       0.69      0.69      0.69     88701\n",
      "weighted avg       0.69      0.69      0.69     88701\n",
      "\n",
      "[[31749 12791]\n",
      " [14439 29722]]\n"
     ]
    }
   ],
   "source": [
    "coeff_LogReg, TOPfeatures_LogReg = LogisticRegression_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4284f432",
   "metadata": {},
   "source": [
    "### 3.2.2. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "618531f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build LinearSVC Model\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "def LinearSVC_func(XTrain=X_ingested, XVal=X_val, XTest=X_FNA, yTrain=y_ingested, yVal=y_val, yTest=y_FNA):\n",
    "    model_svm = LinearSVC(penalty='l2', loss=\"squared_hinge\", C=461, random_state=42, class_weight={0:0.9628, 1:1.0402})\n",
    "    model_svm.fit(XTrain,yTrain)\n",
    "    \n",
    "    # Training Set\n",
    "    #plt.rcParams[\"figure.figsize\"] = (3,3)\n",
    "    X_train_predictions = model_svm.predict(X_train)\n",
    "    print(\"Training Set F1:\", f1_score(y_train, model_svm.predict(X_train), sample_weight=sampleW))\n",
    "    print(\"Training Set MCC:\", matthews_corrcoef(y_train, model_svm.predict(X_train), sample_weight=sampleW))\n",
    "    print(\"Training Set Accuracy:\", metrics.accuracy_score(y_train, X_train_predictions))\n",
    "    print(classification_report(y_train, X_train_predictions))\n",
    "    print(confusion_matrix(y_train, X_train_predictions))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr, tpr, _ = metrics.roc_curve(y_train, X_train_predictions)\n",
    "    plt.plot(fpr,tpr)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_train.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    # Val set\n",
    "    predictions_val  = model_svm.predict(XVal)\n",
    "    print(\"Ext Val Set F1:\", f1_score(yVal, model_svm.predict(XVal), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set MCC:\", matthews_corrcoef(yVal, model_svm.predict(XVal), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set Accuracy:\", metrics.accuracy_score(yVal, predictions_val))\n",
    "    print(classification_report(yVal, predictions_val))\n",
    "    print(confusion_matrix(yVal, predictions_val))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_val, tpr_val, _ = metrics.roc_curve(yVal, predictions_val)\n",
    "    plt.plot(fpr_val,tpr_val)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_test.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    f1_5_train = cross_val_score(model_svm, XTrain, yTrain, cv = 5, scoring=\"f1\")\n",
    "    print(\"5F-CV:\", avgScore(f1_5_train, 5))\n",
    "    \n",
    "    # Test set\n",
    "    predictions_FNA = model_svm.predict(XTest)\n",
    "    print(\"FNA Set F1:\", f1_score(yTest, model_svm.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set MCC:\", matthews_corrcoef(yTest, model_svm.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set Recall:\", recall_score(yTest, model_svm.predict(XTest)))\n",
    "    print(\"FNA Test Set Accuracy:\", metrics.accuracy_score(yTest, predictions_FNA))\n",
    "    print(classification_report(yTest, predictions_FNA))\n",
    "    print(confusion_matrix(yTest, predictions_FNA))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_FNA, tpr_FNA, _ = metrics.roc_curve(yTest, predictions_FNA)\n",
    "    plt.plot(fpr_FNA,tpr_FNA)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"G:/raMSIn/XGB_Importance2/XGB2_ROC_FNAtest2.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    # Visualize the importantance of the features\n",
    "    feature_imp = pd.Series(model_svm.coef_[0], index=XTrain.columns).sort_values(ascending=False)\n",
    "    x=feature_imp\n",
    "    y=feature_imp.index\n",
    "    \n",
    "    plt.subplots(dpi = 300)\n",
    "    #plt.rcParams[\"figure.figsize\"] = [4, 6]\n",
    "    #plt.rcParams[\"font.family\"] = \"Arial\"\n",
    "    #plt.rcParams.update({'font.size': 6})\n",
    "    plt.xlabel('Feature Importance Score', fontproperties='Arial', fontsize=17)\n",
    "    plt.ylabel('Features', fontproperties='Arial', fontsize=17)\n",
    "    plt.xticks(fontsize=15)\n",
    "    plt.yticks(fontsize=15)\n",
    "    plt.title(\"Important Molecular Features\", fontproperties='Arial', fontsize=20)\n",
    "    sns.barplot(x=feature_imp, y=feature_imp.index)\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_TopFeatures.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    #feature_importances = model_svm.coef_[0]\n",
    "    #feature_df=pd.DataFrame({'m/z':XTrain.columns,'coef':feature_importances})\n",
    "\n",
    "    #fig = px.bar(feature_df, x='coef', y='m/z')\n",
    "    #fig.show()\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "e31abc39",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set F1: 0.9021109890997605\n",
      "Training Set MCC: 0.8006734916665643\n",
      "Training Set Accuracy: 0.8989885664028144\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.88      0.90     47449\n",
      "           1       0.87      0.92      0.90     43511\n",
      "\n",
      "    accuracy                           0.90     90960\n",
      "   macro avg       0.90      0.90      0.90     90960\n",
      "weighted avg       0.90      0.90      0.90     90960\n",
      "\n",
      "[[41653  5796]\n",
      " [ 3392 40119]]\n",
      "Ext Val Set F1: 0.8167024478137483\n",
      "Ext Val Set MCC: 0.6328256913082616\n",
      "Ext Val Set Accuracy: 0.8164609053497942\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      2943\n",
      "           1       0.82      0.82      0.82      3132\n",
      "\n",
      "    accuracy                           0.82      6075\n",
      "   macro avg       0.82      0.82      0.82      6075\n",
      "weighted avg       0.82      0.82      0.82      6075\n",
      "\n",
      "[[2398  545]\n",
      " [ 570 2562]]\n",
      "5F-CV: 0.8973965894540947\n",
      "FNA Set F1: 0.6719472156105745\n",
      "FNA Set MCC: 0.3008123820278503\n",
      "FNA Set Recall: 0.7190960349629764\n",
      "FNA Test Set Accuracy: 0.6486172647433512\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.58      0.62     44540\n",
      "           1       0.63      0.72      0.67     44161\n",
      "\n",
      "    accuracy                           0.65     88701\n",
      "   macro avg       0.65      0.65      0.65     88701\n",
      "weighted avg       0.65      0.65      0.65     88701\n",
      "\n",
      "[[25777 18763]\n",
      " [12405 31756]]\n"
     ]
    }
   ],
   "source": [
    "coeff_SVM, TOPfeatures_SVM = LinearSVC_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc43f9a6",
   "metadata": {},
   "source": [
    "### 3.2.3. GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8ac17af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build GBM Model\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "def GBM_func(XTrain=X_ingested, XVal=X_val, XTest=X_FNA, yTrain=y_ingested, yVal=y_val, yTest=y_FNA):\n",
    "    model_gbm = GradientBoostingClassifier(learning_rate=4, n_estimators=50, max_depth=7, min_samples_leaf=4, min_samples_split=30, n_iter_no_change=5, random_state=42)\n",
    "    model_gbm.fit(XTrain,yTrain)\n",
    "    \n",
    "    # Training Set\n",
    "    #plt.rcParams[\"figure.figsize\"] = (3,3)\n",
    "    X_train_predictions = model_gbm.predict(X_train)\n",
    "    print(\"Training Set F1:\", f1_score(y_train, model_gbm.predict(X_train), sample_weight=sampleW))\n",
    "    print(\"Training Set MCC:\", matthews_corrcoef(y_train, model_gbm.predict(X_train), sample_weight=sampleW))\n",
    "    print(\"Training Set Accuracy:\", metrics.accuracy_score(y_train, X_train_predictions))\n",
    "    print(classification_report(y_train, X_train_predictions))\n",
    "    print(confusion_matrix(y_train, X_train_predictions))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr, tpr, _ = metrics.roc_curve(y_train, X_train_predictions)\n",
    "    plt.plot(fpr,tpr)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_train.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    # Val set\n",
    "    predictions_val  = model_gbm.predict(XVal)\n",
    "    print(\"Ext Val Set F1:\", f1_score(yVal, model_gbm.predict(XVal), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set MCC:\", matthews_corrcoef(yVal, model_gbm.predict(XVal), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set Accuracy:\", metrics.accuracy_score(yVal, predictions_val))\n",
    "    print(classification_report(yVal, predictions_val))\n",
    "    print(confusion_matrix(yVal, predictions_val))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_val, tpr_val, _ = metrics.roc_curve(yVal, predictions_val)\n",
    "    plt.plot(fpr_val,tpr_val)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_test.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    f1_5_train = cross_val_score(model_gbm, XTrain, yTrain, cv = 5, scoring=\"f1\")\n",
    "    print(\"5F-CV:\", avgScore(f1_5_train, 5))\n",
    "    \n",
    "    # Test set\n",
    "    predictions_FNA = model_gbm.predict(XTest)\n",
    "    print(\"FNA Set F1:\", f1_score(yTest, model_gbm.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set MCC:\", matthews_corrcoef(yTest, model_gbm.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set Recall:\", recall_score(yTest, model_gbm.predict(XTest)))\n",
    "    print(\"FNA Test Set Accuracy:\", metrics.accuracy_score(yTest, predictions_FNA))\n",
    "    print(classification_report(yTest, predictions_FNA))\n",
    "    print(confusion_matrix(yTest, predictions_FNA))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_FNA, tpr_FNA, _ = metrics.roc_curve(yTest, predictions_FNA)\n",
    "    plt.plot(fpr_FNA,tpr_FNA)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"G:/raMSIn/XGB_Importance2/XGB2_ROC_FNAtest2.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    # Visualize the importantance of the features\n",
    "    feature_imp = pd.Series(model_gbm.feature_importances_, index=XTrain.columns).sort_values(ascending=False)\n",
    "    x=feature_imp\n",
    "    y=feature_imp.index\n",
    "    \n",
    "    plt.subplots(dpi = 300)\n",
    "    #plt.rcParams[\"figure.figsize\"] = [4, 6]\n",
    "    #plt.rcParams[\"font.family\"] = \"Arial\"\n",
    "    #plt.rcParams.update({'font.size': 6})\n",
    "    plt.xlabel('Feature Importance Score', fontproperties='Arial', fontsize=17)\n",
    "    plt.ylabel('Features', fontproperties='Arial', fontsize=17)\n",
    "    plt.xticks(fontsize=15)\n",
    "    plt.yticks(fontsize=15)\n",
    "    plt.title(\"Important Molecular Features\", fontproperties='Arial', fontsize=20)\n",
    "    sns.barplot(x=feature_imp, y=feature_imp.index)\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/XGB_TopFeatures.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    # Visualize the boxplot of the important features between the two groups\n",
    "    #fig = px.box(data_frame = df_ROI_for_ML_Opti, x = feature_imp[:10].index,color= 'type')\n",
    "    #fig.show()\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "246afd8e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set F1: 0.815544068289169\n",
      "Training Set MCC: 0.6270812048466379\n",
      "Training Set Accuracy: 0.8129727352682498\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.80      0.82     47449\n",
      "           1       0.79      0.82      0.81     43511\n",
      "\n",
      "    accuracy                           0.81     90960\n",
      "   macro avg       0.81      0.81      0.81     90960\n",
      "weighted avg       0.81      0.81      0.81     90960\n",
      "\n",
      "[[38063  9386]\n",
      " [ 7626 35885]]\n",
      "Ext Val Set F1: 0.6453865155845363\n",
      "Ext Val Set MCC: 0.22111975811978574\n",
      "Ext Val Set Accuracy: 0.611358024691358\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.50      0.56      2943\n",
      "           1       0.60      0.71      0.65      3132\n",
      "\n",
      "    accuracy                           0.61      6075\n",
      "   macro avg       0.61      0.61      0.61      6075\n",
      "weighted avg       0.61      0.61      0.61      6075\n",
      "\n",
      "[[1480 1463]\n",
      " [ 898 2234]]\n",
      "5F-CV: 0.7745528373934336\n",
      "FNA Set F1: 0.6985438774353916\n",
      "FNA Set MCC: 0.3088592161420611\n",
      "FNA Set Recall: 0.8250266071873372\n",
      "FNA Test Set Accuracy: 0.6431720048251993\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.46      0.57     44540\n",
      "           1       0.60      0.83      0.70     44161\n",
      "\n",
      "    accuracy                           0.64     88701\n",
      "   macro avg       0.67      0.64      0.63     88701\n",
      "weighted avg       0.67      0.64      0.63     88701\n",
      "\n",
      "[[20616 23924]\n",
      " [ 7727 36434]]\n"
     ]
    }
   ],
   "source": [
    "coeff_GBM, TOPfeatures_GBM = GBM_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89d376d",
   "metadata": {},
   "source": [
    "### 3.2.4. Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "30895166",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StackingRegressor():\n",
    "    \n",
    "    def __init__(self, learners):\n",
    "        self.level_sizes = []\n",
    "        self.learners = []\n",
    "        \n",
    "        for learning_level in learners:\n",
    "            self.level_sizes.append(len(learning_level))\n",
    "            level_learners = []\n",
    "            \n",
    "            for learner in learning_level:\n",
    "                level_learners.append(deepcopy(learner))\n",
    "            self.learners.append(level_learners)\n",
    "            \n",
    "            \n",
    "    def fit(self, x, y):\n",
    "        \n",
    "        meta_data = [x,x,x]\n",
    "        meta_targets = [y,y,y]\n",
    "        \n",
    "        for i in range(len(self.learners)):\n",
    "            level_size = self.level_sizes[i]\n",
    "            \n",
    "            data_z = np.zeros((level_size, len(x)))\n",
    "            target_z = np.zeros(len(x))\n",
    "            \n",
    "            train_x = meta_data[i]\n",
    "            train_y = meta_targets[i]\n",
    "            \n",
    "            # Define number of folds\n",
    "            num_folds = 5\n",
    "            \n",
    "            # Create the k-fold cross-validation object\n",
    "            KF = KFold(n_splits=num_folds)\n",
    "            m = 0\n",
    "\n",
    "            # Loop over each fold of the cross-validation\n",
    "            for train_indices, test_indices in KF.split(x):\n",
    "                \n",
    "                for j in range(len(self.learners[i])):\n",
    "                    train_x = pd.DataFrame(train_x)\n",
    "                    train_y = pd.DataFrame(train_y)\n",
    "\n",
    "                    learner = self.learners[i][j]\n",
    "                    learner.fit(train_x.iloc[train_indices], train_y.iloc[train_indices])\n",
    "                    p = learner.predict(train_x.iloc[test_indices])\n",
    "                    data_z[j][m: m+len(test_indices) ] = p\n",
    "\n",
    "\n",
    "                train_y = pd.DataFrame(train_y)\n",
    "                train_y_array = (np.array(train_y)).reshape(-1,)\n",
    "                zty_ind = (np.array(train_y.iloc[test_indices])).reshape(-1,)\n",
    "                target_z[m: m+len(test_indices)] = train_y_array[zty_ind]\n",
    "                m += len(test_indices)\n",
    "                \n",
    "\n",
    "            data_z = data_z.transpose()\n",
    "            meta_data.append(data_z)\n",
    "            meta_targets.append(target_z)\n",
    "            \n",
    "            \n",
    "            for learner in self.learners[i]:\n",
    "                train_x = pd.DataFrame(train_x)\n",
    "                train_y = pd.DataFrame(train_y)\n",
    "                learner.fit(train_x, train_y)\n",
    "                \n",
    "                \n",
    "    def predict(self, x):\n",
    "        \n",
    "        meta_data = [x,x,x]\n",
    "        for i in range(len(self.learners)):\n",
    "            \n",
    "            level_size = self.level_sizes[i]\n",
    "            \n",
    "            data_z = np.zeros((level_size, len(x)))\n",
    "            \n",
    "            test_x = meta_data[i]\n",
    "            \n",
    "            for j in range(len(self.learners[i])):\n",
    "                \n",
    "                learner = self.learners[i][j]\n",
    "                predictions = learner.predict(test_x)\n",
    "                data_z[j] = predictions\n",
    "                \n",
    "            \n",
    "            data_z = data_z.transpose()\n",
    "            meta_data.append(data_z)\n",
    "            \n",
    "        return meta_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "e9a9a75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build stacking Model\n",
    "\n",
    "def Stacking_func(XTrain=X_ingested, XVal=X_val, XTest=X_FNA, XTest2=X_di, yTrain=y_ingested, yVal=y_val, yTest=y_FNA, yTest2=y_di):\n",
    "\n",
    "    base_learners = []\n",
    "\n",
    "    # Define models to use in stacking ensemble\n",
    "    m1 = LogisticRegression(C=0.001, penalty='l1', solver=\"liblinear\", max_iter=5000, random_state=42, class_weight={0:0.9628, 1:1.0402})\n",
    "    base_learners.append(m1)\n",
    "\n",
    "    m2 = LinearSVC(penalty='l2', loss=\"squared_hinge\", C=461, random_state=42, class_weight={0:0.9628, 1:1.0402})\n",
    "    base_learners.append(m2)\n",
    "\n",
    "    m3 = GradientBoostingClassifier(learning_rate=4, n_estimators=50, max_depth=7, min_samples_leaf=4, min_samples_split=30, n_iter_no_change=5, random_state=42)\n",
    "    base_learners.append(m3)\n",
    "\n",
    "    # Define the meta-classifier to use for stacking\n",
    "    #meta_learner = LinearDiscriminantAnalysis()  # 0.90,0.80; 0.75,0.51; 0.65,0.27; 0.64,0.26\n",
    "    #meta_learner = QuadraticDiscriminantAnalysis()  # 0.93,0.86; 0.67,0.39; 0.67,0.15; 0.68,0.20\n",
    "    \n",
    "    #meta_learner = LogisticRegression()  # 0.90,0.79; 0.82,0.65; 0.64,0.24; 0.64;0.27\n",
    "    #meta_learner = LogisticRegression(C=1, penalty='l1', solver=\"liblinear\", max_iter=5000, random_state=42)\n",
    "    ## C=1: 0.90,0.79; 0.82,0.65; 0.65,0.25; 0.65;0.27\n",
    "    #meta_learner = LogisticRegression(C=0.1, penalty='l1', solver=\"liblinear\", max_iter=5000, random_state=42)\n",
    "    ## C=0.1: 0.90,0.79; 0.82,0.65; 0.65,0.25; 0.65;0.28\n",
    "    #meta_learner = LogisticRegression(C=0.01, penalty='l1', solver=\"liblinear\", max_iter=5000, random_state=42)\n",
    "    ## C=0.01: 0.89,0.78; 0.81,0.63; 0.63,0.22; 0.65;0.29\n",
    "    #meta_learner = LogisticRegression(C=0.0075, penalty='l1', solver=\"liblinear\", max_iter=5000, random_state=42)\n",
    "    ## C=0.0075: 0.89,0.77; 0.81,0.63; 0.62,0.20; 0.65;0.29\n",
    "    #meta_learner = LogisticRegression(C=0.005, penalty='l1', solver=\"liblinear\", max_iter=5000, random_state=42)\n",
    "    ## C=0.005: 0.88,0.76; 0.82,0.64; 0.60,0.17; 0.66;0.31\n",
    "    #meta_learner = LogisticRegression(C=0.0025, penalty='l1', solver=\"liblinear\", max_iter=5000, random_state=42)\n",
    "    ## C=0.0025: 0.86,0.72; 0.83,0.66; 0.53,0.02; 0.64;0.31\n",
    "    #meta_learner = LogisticRegression(C=0.0015, penalty='l1', solver=\"liblinear\", max_iter=5000, random_state=42)\n",
    "    ## C=0.0015: 0.85,0.70; 0.80,0.60; 0.55,0.09; 0.64;0.30\n",
    "    #meta_learner = LogisticRegression(C=0.0013, penalty='l1', solver=\"liblinear\", max_iter=5000, random_state=42)\n",
    "    ## C=0.0013: 0.85,0.70; 0.78,0.56; 0.58,0.16; 0.63;0.29\n",
    "    #meta_learner = LogisticRegression(C=0.0012, penalty='l1', solver=\"liblinear\", max_iter=5000, random_state=42)\n",
    "    ## C=0.0012: 0.85,0.69; 0.77,0.52; 0.60,0.22; 0.63;0.27\n",
    "    meta_learner = LogisticRegression(C=0.0011, penalty='l1', solver=\"liblinear\", max_iter=5000, random_state=42)\n",
    "    ## C=0.0011: 0.85,0.69; 0.77,0.51; 0.64,0.30; 0.62;0.25\n",
    "    #meta_learner = LogisticRegression(C=0.001, penalty='l1', solver=\"liblinear\", max_iter=5000, random_state=42)\n",
    "    ## C=0.001: 0.84,0.68; 0.76,0.49; 0.68,0.38; 0.61;0.22\n",
    "    #meta_learner = LogisticRegression(C=0.0005, penalty='l1', solver=\"liblinear\", max_iter=5000, random_state=42)\n",
    "    ## C=0.0005: 0.83,0.66; 0.74,0.45; 0.65,0.37; 0.60;0.18\n",
    "    \n",
    "    #meta_learner = LinearSVC()  # 0.90,0.80; 0.82,0.65; 0.64,0.24; 0.65,0.27\n",
    "    #meta_learner = KNeighborsClassifier()  # 0.98,0.96; 0.65,0.30; 0.68,0.21; 0.52,-0.05\n",
    "    #meta_learner = DecisionTreeClassifier()  # 0.94,0.87; 0.54,0.15; 0.66,0.11; 0.46,-0.11\n",
    "    #meta_learner = RandomForestClassifier()  # 0.98,0.95; 0.54,0.20; 0.66,0.11; 0.49;-0.01\n",
    "    #meta_learner = GradientBoostingClassifier()  # 0.97,0.94; 0.56,0.27; 0.66,0.13; 0.48,-0.09\n",
    "    #meta_learner = AdaBoostClassifier()  # 0.96,0.93; 0.69,0.42; 0.62,0.10; 0.54,0.11\n",
    "    #meta_learner = xgb.XGBClassifier()  # 0.98,0.95; 0.59,0.30; 0.66,0.10; 0.44,-0.12\n",
    "\n",
    "    model_sc = StackingRegressor([[m1, m2, m3], [meta_learner]])\n",
    "    model_sc.fit(XTrain, yTrain)\n",
    "    \n",
    "    #=======================================\n",
    "    \n",
    "    # Training Set\n",
    "    #plt.rcParams[\"figure.figsize\"] = (3,3)\n",
    "    X_train_predictions = model_sc.predict(X_train)[-1]\n",
    "    print(\"Training Set F1:\", f1_score(y_train, model_sc.predict(X_train)[-1], sample_weight=sampleW))\n",
    "    print(\"Training Set MCC:\", matthews_corrcoef(y_train, model_sc.predict(X_train)[-1], sample_weight=sampleW))\n",
    "    print(\"Training Set Accuracy:\", metrics.accuracy_score(y_train, X_train_predictions))\n",
    "    print(classification_report(y_train, X_train_predictions))\n",
    "    print(confusion_matrix(y_train, X_train_predictions))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr, tpr, _ = metrics.roc_curve(y_train, X_train_predictions)\n",
    "    plt.plot(fpr,tpr)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_train.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    # Val set\n",
    "    predictions_val  = model_sc.predict(XVal)[-1]\n",
    "    print(\"Ext Val Set F1:\", f1_score(yVal, model_sc.predict(XVal)[-1], sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set MCC:\", matthews_corrcoef(yVal, model_sc.predict(XVal)[-1], sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set Accuracy:\", metrics.accuracy_score(yVal, predictions_val))\n",
    "    print(classification_report(yVal, predictions_val))\n",
    "    print(confusion_matrix(yVal, predictions_val))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_val, tpr_val, _ = metrics.roc_curve(yVal, predictions_val)\n",
    "    plt.plot(fpr_val,tpr_val)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_test.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    #f1_5_train = cross_val_score(model_sc, XTrain, yTrain, cv = 5, scoring=\"f1\")\n",
    "    #print(\"5F-CV:\", avgScore(f1_5_train, 5))\n",
    "    \n",
    "    # Test set\n",
    "    predictions_FNA = model_sc.predict(XTest)[-1]\n",
    "    print(\"FNA Set F1:\", f1_score(yTest, model_sc.predict(XTest)[-1], sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set MCC:\", matthews_corrcoef(yTest, model_sc.predict(XTest)[-1], sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set Recall:\", recall_score(yTest, model_sc.predict(XTest)[-1]))\n",
    "    print(\"FNA Test Set Accuracy:\", metrics.accuracy_score(yTest, predictions_FNA))\n",
    "    print(classification_report(yTest, predictions_FNA))\n",
    "    print(confusion_matrix(yTest, predictions_FNA))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_FNA, tpr_FNA, _ = metrics.roc_curve(yTest, predictions_FNA)\n",
    "    plt.plot(fpr_FNA,tpr_FNA)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"G:/raMSIn/XGB_Importance2/XGB2_ROC_FNAtest2.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    # Test2 set\n",
    "    predictions_di = model_sc.predict(XTest2)[-1]\n",
    "    print(\"DirectIn Set F1:\", f1_score(yTest2, model_sc.predict(XTest2)[-1], sample_weight=sampleDiW))\n",
    "    print(\"DirectIn Set MCC:\", matthews_corrcoef(yTest2, model_sc.predict(XTest2)[-1], sample_weight=sampleDiW))\n",
    "    print(\"DirectIn Set Recall:\", recall_score(yTest2, model_sc.predict(XTest2)[-1]))\n",
    "    print(\"DirectIn Test Set Accuracy:\", metrics.accuracy_score(yTest2, predictions_di))\n",
    "    print(classification_report(yTest2, predictions_di))\n",
    "    print(confusion_matrix(yTest2, predictions_di))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_di, tpr_di, _ = metrics.roc_curve(yTest2, predictions_di)\n",
    "    plt.plot(fpr_di,tpr_di)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"G:/raMSIn/XGB_Importance2/XGB2_ROC_FNAtest2.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "d7f50068",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set F1: 0.845665937432104\n",
      "Training Set MCC: 0.6887113783050509\n",
      "Training Set Accuracy: 0.8439204045734389\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.84      0.85     47449\n",
      "           1       0.83      0.85      0.84     43511\n",
      "\n",
      "    accuracy                           0.84     90960\n",
      "   macro avg       0.84      0.84      0.84     90960\n",
      "weighted avg       0.84      0.84      0.84     90960\n",
      "\n",
      "[[39643  7806]\n",
      " [ 6391 37120]]\n",
      "Ext Val Set F1: 0.7664154045726581\n",
      "Ext Val Set MCC: 0.5095637318580211\n",
      "Ext Val Set Accuracy: 0.7548971193415638\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.70      0.73      2943\n",
      "           1       0.74      0.81      0.77      3132\n",
      "\n",
      "    accuracy                           0.75      6075\n",
      "   macro avg       0.76      0.75      0.75      6075\n",
      "weighted avg       0.76      0.75      0.75      6075\n",
      "\n",
      "[[2049  894]\n",
      " [ 595 2537]]\n",
      "FNA Set F1: 0.6396126843366011\n",
      "FNA Set MCC: 0.30036957083751364\n",
      "FNA Set Recall: 0.6212721632209416\n",
      "FNA Test Set Accuracy: 0.6500603149908118\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.68      0.66     44540\n",
      "           1       0.66      0.62      0.64     44161\n",
      "\n",
      "    accuracy                           0.65     88701\n",
      "   macro avg       0.65      0.65      0.65     88701\n",
      "weighted avg       0.65      0.65      0.65     88701\n",
      "\n",
      "[[30225 14315]\n",
      " [16725 27436]]\n",
      "DirectIn Set F1: 0.6189520697171584\n",
      "DirectIn Set MCC: 0.2533172372995218\n",
      "DirectIn Set Recall: 0.6066006600660065\n",
      "DirectIn Test Set Accuracy: 0.6265477959385835\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.65      0.63      3027\n",
      "           1       0.63      0.61      0.62      3030\n",
      "\n",
      "    accuracy                           0.63      6057\n",
      "   macro avg       0.63      0.63      0.63      6057\n",
      "weighted avg       0.63      0.63      0.63      6057\n",
      "\n",
      "[[1957 1070]\n",
      " [1192 1838]]\n"
     ]
    }
   ],
   "source": [
    "Stacking_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d944dc91",
   "metadata": {},
   "source": [
    "### 3.2.5. Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8a982bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a voting ensemble of models\n",
    "def get_voting():\n",
    "    models = list()\n",
    "    # Define the base models\n",
    "    models.append((\"m1\", LogisticRegression(C=0.001, penalty='l1', solver=\"liblinear\", max_iter=5000, random_state=42, class_weight={0:0.9628, 1:1.0402})))\n",
    "    models.append((\"m2\", LinearSVC(penalty='l2', loss=\"squared_hinge\", C=461, random_state=42, class_weight={0:0.9628, 1:1.0402})))\n",
    "    models.append((\"m3\", GradientBoostingClassifier(learning_rate=4, n_estimators=50, max_depth=7, min_samples_leaf=4, min_samples_split=30, n_iter_no_change=5, random_state=42)))\n",
    "\n",
    "    # define the voting ensemble\n",
    "    ensemble = VotingClassifier(estimators=models, voting='hard')\n",
    "    return ensemble\n",
    "\n",
    "# get a list of models to evaluate\n",
    "def get_models():\n",
    "    models = dict()\n",
    "    models['m1'] = LogisticRegression(C=0.001, penalty='l1', solver=\"liblinear\", max_iter=5000, random_state=42, class_weight={0:0.9628, 1:1.0402})\n",
    "    models['m2'] = LinearSVC(penalty='l2', loss=\"squared_hinge\", C=461, random_state=42, class_weight={0:0.9628, 1:1.0402})\n",
    "    models['m3'] = GradientBoostingClassifier(learning_rate=4, n_estimators=50, max_depth=7, min_samples_leaf=4, min_samples_split=30, n_iter_no_change=5, random_state=42)\n",
    "    models['hard_voting'] = get_voting()\n",
    "    return models\n",
    "\n",
    "\n",
    "# evaluate a give model using cross-validation\n",
    "def evaluate_model(model, XX, yy):\n",
    "    cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=10, random_state=42)\n",
    "    scores = cross_val_score(model, XX, yy, scoring='f1', cv=cv, n_jobs=-1, error_score='raise')\n",
    "    return scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "048c0346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 720x720 with 0 Axes>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from matplotlib.pyplot import figure\n",
    "plt.rcParams['figure.figsize'] = [10, 10]\n",
    "plt.close()\n",
    "figure(figsize=(10, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "32798a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">m1 0.833 (0.003)\n",
      ">m2 0.929 (0.016)\n",
      ">m3 0.655 (0.145)\n",
      ">hard_voting 0.910 (0.021)\n"
     ]
    }
   ],
   "source": [
    "# get the models to evaluate\n",
    "models = get_models()\n",
    "\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "    scores = evaluate_model(model, XX=X_ingested, yy=y_ingested)\n",
    "    results.append(scores)\n",
    "    names.append(name)\n",
    "    print('>%s %.3f (%.3f)' % (name, np.mean(scores), np.std(scores)))\n",
    "    \n",
    "# plot model performance for comparison\n",
    "plt.subplots(dpi = 600)\n",
    "plt.boxplot(results, labels=names, showmeans=True)\n",
    "plt.ylabel('F1 score')\n",
    "plt.xlabel('Predictive Models')\n",
    "plt.savefig(r\"H:/3_output_raMSIn/3_3_Output_raMSIn_HKU_Ingested4ALL/XGB_ALL/afterModelSelection/voting.jpg\", bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6a745488",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Voting_func(XTrain=X_ingested, XVal=X_val, XTest=X_FNA, XTest2=X_di,  XTest3=X_c, yTrain=y_ingested, yVal=y_val, yTest=y_FNA, yTest2=y_di, yTest3=y_c):\n",
    "\n",
    "    models = get_models()\n",
    "    \n",
    "    ensemble = models[\"hard_voting\"]\n",
    "    ensemble.fit(XTrain, yTrain)\n",
    "    #=======================================\n",
    "\n",
    "    # Training Set\n",
    "    #plt.rcParams[\"figure.figsize\"] = (3,3)\n",
    "    X_train_predictions = ensemble.predict(X_train)\n",
    "    print(\"Training Set F1:\", f1_score(y_train, ensemble.predict(X_train), sample_weight=sampleW))\n",
    "    print(\"Training Set MCC:\", matthews_corrcoef(y_train, ensemble.predict(X_train), sample_weight=sampleW))\n",
    "    print(\"Training Set Accuracy:\", metrics.accuracy_score(y_train, X_train_predictions))\n",
    "    print(classification_report(y_train, X_train_predictions))\n",
    "    print(confusion_matrix(y_train, X_train_predictions))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr, tpr, _ = metrics.roc_curve(y_train, X_train_predictions)\n",
    "    plt.plot(fpr,tpr)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_train.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    # Val set\n",
    "    predictions_val  = ensemble.predict(XVal)\n",
    "    print(\"Ext Val Set F1:\", f1_score(yVal, ensemble.predict(XVal), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set MCC:\", matthews_corrcoef(yVal, ensemble.predict(XVal), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set Accuracy:\", metrics.accuracy_score(yVal, predictions_val))\n",
    "    print(classification_report(yVal, predictions_val))\n",
    "    print(confusion_matrix(yVal, predictions_val))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_val, tpr_val, _ = metrics.roc_curve(yVal, predictions_val)\n",
    "    plt.plot(fpr_val,tpr_val)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_test.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    f1_5_train = cross_val_score(ensemble, XTrain, yTrain, cv = 5, scoring=\"f1\")\n",
    "    print(\"5F-CV:\", avgScore(f1_5_train, 5))\n",
    "\n",
    "    # Test set\n",
    "    predictions_FNA = ensemble.predict(XTest)\n",
    "    print(\"FNA Set F1:\", f1_score(yTest, ensemble.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set MCC:\", matthews_corrcoef(yTest, ensemble.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set Recall:\", recall_score(yTest, ensemble.predict(XTest)))\n",
    "    print(\"FNA Test Set Accuracy:\", metrics.accuracy_score(yTest, predictions_FNA))\n",
    "    print(classification_report(yTest, predictions_FNA))\n",
    "    print(confusion_matrix(yTest, predictions_FNA))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_FNA, tpr_FNA, _ = metrics.roc_curve(yTest, predictions_FNA)\n",
    "    plt.plot(fpr_FNA,tpr_FNA)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"G:/raMSIn/XGB_Importance2/XGB2_ROC_FNAtest2.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    # Test2 set\n",
    "    predictions_di = ensemble.predict(XTest2)\n",
    "    print(\"DirectIn Set F1:\", f1_score(yTest2, ensemble.predict(XTest2), sample_weight=sampleDiW))\n",
    "    print(\"DirectIn Set MCC:\", matthews_corrcoef(yTest2, ensemble.predict(XTest2), sample_weight=sampleDiW))\n",
    "    print(\"DirectIn Set Recall:\", recall_score(yTest2, ensemble.predict(XTest2)))\n",
    "    print(\"DirectIn Test Set Accuracy:\", metrics.accuracy_score(yTest2, predictions_di))\n",
    "    print(classification_report(yTest2, predictions_di))\n",
    "    print(confusion_matrix(yTest2, predictions_di))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_di, tpr_di, _ = metrics.roc_curve(yTest2, predictions_di)\n",
    "    plt.plot(fpr_di,tpr_di)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"G:/raMSIn/XGB_Importance2/XGB2_ROC_FNAtest2.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    # Test3 set\n",
    "    predictions_c = ensemble.predict(XTest3)\n",
    "    print(\"Clincal Set F1:\", f1_score(yTest3, ensemble.predict(XTest3), sample_weight=sampleCW))\n",
    "    print(\"Clincal Set MCC:\", matthews_corrcoef(yTest3, ensemble.predict(XTest3), sample_weight=sampleCW))\n",
    "    print(\"Clincal Set Recall:\", recall_score(yTest3, ensemble.predict(XTest3)))\n",
    "    print(\"Clincal Test Set Accuracy:\", metrics.accuracy_score(yTest3, predictions_c))\n",
    "    print(classification_report(yTest3, predictions_c))\n",
    "    print(confusion_matrix(yTest3, predictions_c))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_c, tpr_c, _ = metrics.roc_curve(yTest3, predictions_c)\n",
    "    plt.plot(fpr_c,tpr_c)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"G:/raMSIn/XGB_Importance2/XGB2_ROC_FNAtest2.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "433ebf4d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set F1: 0.8688785114553915\n",
      "Training Set MCC: 0.7386108084662532\n",
      "Training Set Accuracy: 0.8694371152154793\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.87      0.87     47449\n",
      "           1       0.86      0.87      0.86     43511\n",
      "\n",
      "    accuracy                           0.87     90960\n",
      "   macro avg       0.87      0.87      0.87     90960\n",
      "weighted avg       0.87      0.87      0.87     90960\n",
      "\n",
      "[[41400  6049]\n",
      " [ 5827 37684]]\n",
      "Ext Val Set F1: 0.781510573494584\n",
      "Ext Val Set MCC: 0.5395392423030002\n",
      "Ext Val Set Accuracy: 0.7695473251028807\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.70      0.75      2943\n",
      "           1       0.75      0.83      0.79      3132\n",
      "\n",
      "    accuracy                           0.77      6075\n",
      "   macro avg       0.77      0.77      0.77      6075\n",
      "weighted avg       0.77      0.77      0.77      6075\n",
      "\n",
      "[[2071  872]\n",
      " [ 528 2604]]\n",
      "5F-CV: 0.8526931216047146\n",
      "FNA Set F1: 0.7217738711066483\n",
      "FNA Set MCC: 0.4273143934262256\n",
      "FNA Set Recall: 0.7438463802903014\n",
      "FNA Test Set Accuracy: 0.7131261203368621\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.68      0.71     44540\n",
      "           1       0.70      0.74      0.72     44161\n",
      "\n",
      "    accuracy                           0.71     88701\n",
      "   macro avg       0.71      0.71      0.71     88701\n",
      "weighted avg       0.71      0.71      0.71     88701\n",
      "\n",
      "[[30406 14134]\n",
      " [11312 32849]]\n",
      "DirectIn Set F1: 0.6589554726158737\n",
      "DirectIn Set MCC: 0.30834877589530985\n",
      "DirectIn Set Recall: 0.6683168316831684\n",
      "DirectIn Test Set Accuracy: 0.6541192009245501\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.64      0.65      3027\n",
      "           1       0.65      0.67      0.66      3030\n",
      "\n",
      "    accuracy                           0.65      6057\n",
      "   macro avg       0.65      0.65      0.65      6057\n",
      "weighted avg       0.65      0.65      0.65      6057\n",
      "\n",
      "[[1937 1090]\n",
      " [1005 2025]]\n",
      "Clincal Set F1: 0.606205321884741\n",
      "Clincal Set MCC: 0.10611504439309845\n",
      "Clincal Set Recall: 0.6912936848559166\n",
      "Clincal Test Set Accuracy: 0.5470123677544331\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.41      0.48      3449\n",
      "           1       0.53      0.69      0.60      3262\n",
      "\n",
      "    accuracy                           0.55      6711\n",
      "   macro avg       0.56      0.55      0.54      6711\n",
      "weighted avg       0.56      0.55      0.54      6711\n",
      "\n",
      "[[1416 2033]\n",
      " [1007 2255]]\n"
     ]
    }
   ],
   "source": [
    "Voting_func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e129136d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib as jl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "f9c2441f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('m1',\n",
       "                              LogisticRegression(C=0.001,\n",
       "                                                 class_weight={0: 0.9628,\n",
       "                                                               1: 1.0402},\n",
       "                                                 max_iter=5000, penalty='l1',\n",
       "                                                 random_state=42,\n",
       "                                                 solver='liblinear')),\n",
       "                             ('m2',\n",
       "                              LinearSVC(C=461,\n",
       "                                        class_weight={0: 0.9628, 1: 1.0402},\n",
       "                                        random_state=42)),\n",
       "                             ('m3',\n",
       "                              GradientBoostingClassifier(learning_rate=4,\n",
       "                                                         max_depth=7,\n",
       "                                                         min_samples_leaf=4,\n",
       "                                                         min_samples_split=30,\n",
       "                                                         n_estimators=50,\n",
       "                                                         n_iter_no_change=5,\n",
       "                                                         random_state=42))])"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = get_models()\n",
    "    \n",
    "ensemble = models[\"hard_voting\"]\n",
    "ensemble.fit(X_ingested, y_ingested)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "7c6aeb4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['H:\\\\3_output_raMSIn\\\\3_3_Output_raMSIn_HKU_Ingested4ALL\\\\XGB_ALL\\\\afterModelSelection\\\\model3to1Voting_raMSIn.joblib']"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelSavePath = r\"H:\\3_output_raMSIn\\3_3_Output_raMSIn_HKU_Ingested4ALL\\XGB_ALL\\afterModelSelection\\model3to1Voting_raMSIn.joblib\"\n",
    "jl.dump(ensemble, modelSavePath, compress = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f9a9ba",
   "metadata": {},
   "source": [
    "## 3.3 Machine Learning Modeling: Model 1 (Train 6:6, Val 4:4, Test 3:3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49659b18",
   "metadata": {},
   "source": [
    "### 3.3.1. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "bfe4db1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build Logistic Regression Model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def LogisticRegression_func(XTrain=X_train, XVal=X_val, XTest=X_FNA, yTrain=y_train, yVal=y_val, yTest=y_FNA):\n",
    "    model_lr = LogisticRegression(C=0.001, penalty='l1', solver=\"liblinear\", max_iter=5000, random_state=42, class_weight={0:0.9628, 1:1.0402})  # max_iter=100\n",
    "    model_lr.fit(XTrain,yTrain)\n",
    "    \n",
    "    # Training Set\n",
    "    #plt.rcParams[\"figure.figsize\"] = (3,3)\n",
    "    X_train_predictions = model_lr.predict(X_train)\n",
    "    print(\"Training Set F1:\", f1_score(y_train, model_lr.predict(X_train), sample_weight=sampleW))\n",
    "    print(\"Training Set MCC:\", matthews_corrcoef(y_train, model_lr.predict(X_train), sample_weight=sampleW))\n",
    "    print(\"Training Set Accuracy:\", metrics.accuracy_score(y_train, X_train_predictions))\n",
    "    print(classification_report(y_train, X_train_predictions))\n",
    "    print(confusion_matrix(y_train, X_train_predictions))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr, tpr, _ = metrics.roc_curve(y_train, X_train_predictions)\n",
    "    plt.plot(fpr,tpr)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_train.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    # Val set\n",
    "    predictions_val  = model_lr.predict(XVal)\n",
    "    print(\"Ext Val Set F1:\", f1_score(yVal, model_lr.predict(XVal), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set MCC:\", matthews_corrcoef(yVal, model_lr.predict(XVal), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set Accuracy:\", metrics.accuracy_score(yVal, predictions_val))\n",
    "    print(classification_report(yVal, predictions_val))\n",
    "    print(confusion_matrix(yVal, predictions_val))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_val, tpr_val, _ = metrics.roc_curve(yVal, predictions_val)\n",
    "    plt.plot(fpr_val,tpr_val)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_test.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    f1_5_train = cross_val_score(model_lr, XTrain, yTrain, cv = 5, scoring=\"f1\")\n",
    "    print(\"5F-CV:\", avgScore(f1_5_train, 5))\n",
    "    \n",
    "    # Test set\n",
    "    predictions_FNA = model_lr.predict(XTest)\n",
    "    print(\"FNA Set F1:\", f1_score(yTest, model_lr.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set MCC:\", matthews_corrcoef(yTest, model_lr.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set Recall:\", recall_score(yTest, model_lr.predict(XTest)))\n",
    "    print(\"FNA Test Set Accuracy:\", metrics.accuracy_score(yTest, predictions_FNA))\n",
    "    print(classification_report(yTest, predictions_FNA))\n",
    "    print(confusion_matrix(yTest, predictions_FNA))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_FNA, tpr_FNA, _ = metrics.roc_curve(yTest, predictions_FNA)\n",
    "    plt.plot(fpr_FNA,tpr_FNA)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"G:/raMSIn/XGB_Importance2/XGB2_ROC_FNAtest2.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    # Visualize the importantance of the features\n",
    "    feature_imp = pd.Series(model_lr.coef_[0], index=XTrain.columns).sort_values(ascending=False)\n",
    "    x=feature_imp\n",
    "    y=feature_imp.index\n",
    "    \n",
    "    plt.subplots(dpi = 300)\n",
    "    #plt.rcParams[\"figure.figsize\"] = [4, 6]\n",
    "    #plt.rcParams[\"font.family\"] = \"Arial\"\n",
    "    #plt.rcParams.update({'font.size': 6})\n",
    "    plt.xlabel('Feature Importance Score', fontproperties='Arial', fontsize=17)\n",
    "    plt.ylabel('Features', fontproperties='Arial', fontsize=17)\n",
    "    plt.xticks(fontsize=15)\n",
    "    plt.yticks(fontsize=15)\n",
    "    plt.title(\"Important Molecular Features\", fontproperties='Arial', fontsize=20)\n",
    "    sns.barplot(x=feature_imp, y=feature_imp.index)\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_TopFeatures.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    #feature_importances = model_lr.coef_[0]\n",
    "    #feature_df=pd.DataFrame({'m/z':XTrain.columns,'coef':feature_importances})\n",
    "\n",
    "    #fig = px.bar(feature_df, x='coef', y='m/z')\n",
    "    #fig.show()\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "5d284fc7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set F1: 0.8600329237228741\n",
      "Training Set MCC: 0.7164513767775393\n",
      "Training Set Accuracy: 0.8574868073878628\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.84      0.86     47449\n",
      "           1       0.84      0.87      0.85     43511\n",
      "\n",
      "    accuracy                           0.86     90960\n",
      "   macro avg       0.86      0.86      0.86     90960\n",
      "weighted avg       0.86      0.86      0.86     90960\n",
      "\n",
      "[[40057  7392]\n",
      " [ 5571 37940]]\n",
      "Ext Val Set F1: 0.7575673199806856\n",
      "Ext Val Set MCC: 0.48866781565405754\n",
      "Ext Val Set Accuracy: 0.7443621399176955\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.68      0.72      2943\n",
      "           1       0.73      0.80      0.76      3132\n",
      "\n",
      "    accuracy                           0.74      6075\n",
      "   macro avg       0.75      0.74      0.74      6075\n",
      "weighted avg       0.75      0.74      0.74      6075\n",
      "\n",
      "[[2001  942]\n",
      " [ 611 2521]]\n",
      "5F-CV: 0.7463549217253332\n",
      "FNA Set F1: 0.538910211937088\n",
      "FNA Set MCC: 0.04249418164100868\n",
      "FNA Set Recall: 0.5596114218428024\n",
      "FNA Test Set Accuracy: 0.5210200561436736\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.48      0.50     44540\n",
      "           1       0.52      0.56      0.54     44161\n",
      "\n",
      "    accuracy                           0.52     88701\n",
      "   macro avg       0.52      0.52      0.52     88701\n",
      "weighted avg       0.52      0.52      0.52     88701\n",
      "\n",
      "[[21502 23038]\n",
      " [19448 24713]]\n"
     ]
    }
   ],
   "source": [
    "coeff_LogReg, TOPfeatures_LogReg = LogisticRegression_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa66f3fe",
   "metadata": {},
   "source": [
    "### 3.3.2. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "88f68e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build LinearSVC Model\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "def LinearSVC_func(XTrain=X_train, XVal=X_val, XTest=X_FNA, yTrain=y_train, yVal=y_val, yTest=y_FNA):\n",
    "    model_svm = LinearSVC(penalty='l2', loss=\"squared_hinge\", C=461, random_state=42, class_weight={0:0.9628, 1:1.0402})\n",
    "    model_svm.fit(XTrain,yTrain)\n",
    "    \n",
    "    # Training Set\n",
    "    #plt.rcParams[\"figure.figsize\"] = (3,3)\n",
    "    X_train_predictions = model_svm.predict(X_train)\n",
    "    print(\"Training Set F1:\", f1_score(y_train, model_svm.predict(X_train), sample_weight=sampleW))\n",
    "    print(\"Training Set MCC:\", matthews_corrcoef(y_train, model_svm.predict(X_train), sample_weight=sampleW))\n",
    "    print(\"Training Set Accuracy:\", metrics.accuracy_score(y_train, X_train_predictions))\n",
    "    print(classification_report(y_train, X_train_predictions))\n",
    "    print(confusion_matrix(y_train, X_train_predictions))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr, tpr, _ = metrics.roc_curve(y_train, X_train_predictions)\n",
    "    plt.plot(fpr,tpr)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_train.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    # Val set\n",
    "    predictions_val  = model_svm.predict(XVal)\n",
    "    print(\"Ext Val Set F1:\", f1_score(yVal, model_svm.predict(XVal), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set MCC:\", matthews_corrcoef(yVal, model_svm.predict(XVal), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set Accuracy:\", metrics.accuracy_score(yVal, predictions_val))\n",
    "    print(classification_report(yVal, predictions_val))\n",
    "    print(confusion_matrix(yVal, predictions_val))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_val, tpr_val, _ = metrics.roc_curve(yVal, predictions_val)\n",
    "    plt.plot(fpr_val,tpr_val)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_test.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    f1_5_train = cross_val_score(model_svm, XTrain, yTrain, cv = 5, scoring=\"f1\")\n",
    "    print(\"5F-CV:\", avgScore(f1_5_train, 5))\n",
    "    \n",
    "    # Test set\n",
    "    predictions_FNA = model_svm.predict(XTest)\n",
    "    print(\"FNA Set F1:\", f1_score(yTest, model_svm.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set MCC:\", matthews_corrcoef(yTest, model_svm.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set Recall:\", recall_score(yTest, model_svm.predict(XTest)))\n",
    "    print(\"FNA Test Set Accuracy:\", metrics.accuracy_score(yTest, predictions_FNA))\n",
    "    print(classification_report(yTest, predictions_FNA))\n",
    "    print(confusion_matrix(yTest, predictions_FNA))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_FNA, tpr_FNA, _ = metrics.roc_curve(yTest, predictions_FNA)\n",
    "    plt.plot(fpr_FNA,tpr_FNA)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"G:/raMSIn/XGB_Importance2/XGB2_ROC_FNAtest2.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    # Visualize the importantance of the features\n",
    "    feature_imp = pd.Series(model_svm.coef_[0], index=XTrain.columns).sort_values(ascending=False)\n",
    "    x=feature_imp\n",
    "    y=feature_imp.index\n",
    "    \n",
    "    plt.subplots(dpi = 300)\n",
    "    #plt.rcParams[\"figure.figsize\"] = [4, 6]\n",
    "    #plt.rcParams[\"font.family\"] = \"Arial\"\n",
    "    #plt.rcParams.update({'font.size': 6})\n",
    "    plt.xlabel('Feature Importance Score', fontproperties='Arial', fontsize=17)\n",
    "    plt.ylabel('Features', fontproperties='Arial', fontsize=17)\n",
    "    plt.xticks(fontsize=15)\n",
    "    plt.yticks(fontsize=15)\n",
    "    plt.title(\"Important Molecular Features\", fontproperties='Arial', fontsize=20)\n",
    "    sns.barplot(x=feature_imp, y=feature_imp.index)\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_TopFeatures.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    #feature_importances = model_svm.coef_[0]\n",
    "    #feature_df=pd.DataFrame({'m/z':XTrain.columns,'coef':feature_importances})\n",
    "\n",
    "    #fig = px.bar(feature_df, x='coef', y='m/z')\n",
    "    #fig.show()\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "90420725",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set F1: 0.9445382724365645\n",
      "Training Set MCC: 0.8890977317271368\n",
      "Training Set Accuracy: 0.9445580474934037\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.95     47449\n",
      "           1       0.94      0.94      0.94     43511\n",
      "\n",
      "    accuracy                           0.94     90960\n",
      "   macro avg       0.94      0.94      0.94     90960\n",
      "weighted avg       0.94      0.94      0.94     90960\n",
      "\n",
      "[[44828  2621]\n",
      " [ 2422 41089]]\n",
      "Ext Val Set F1: 0.5121785079841246\n",
      "Ext Val Set MCC: -0.057854866343210604\n",
      "Ext Val Set Accuracy: 0.4740740740740741\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.39      0.42      2943\n",
      "           1       0.49      0.55      0.52      3132\n",
      "\n",
      "    accuracy                           0.47      6075\n",
      "   macro avg       0.47      0.47      0.47      6075\n",
      "weighted avg       0.47      0.47      0.47      6075\n",
      "\n",
      "[[1142 1801]\n",
      " [1394 1738]]\n",
      "5F-CV: 0.8974100093073373\n",
      "FNA Set F1: 0.5692930699495394\n",
      "FNA Set MCC: 0.06804389353980003\n",
      "FNA Set Recall: 0.6165168361223704\n",
      "FNA Test Set Accuracy: 0.5331957926066222\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.45      0.49     44540\n",
      "           1       0.53      0.62      0.57     44161\n",
      "\n",
      "    accuracy                           0.53     88701\n",
      "   macro avg       0.53      0.53      0.53     88701\n",
      "weighted avg       0.53      0.53      0.53     88701\n",
      "\n",
      "[[20069 24471]\n",
      " [16935 27226]]\n"
     ]
    }
   ],
   "source": [
    "coeff_SVM, TOPfeatures_SVM = LinearSVC_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d5e3d8",
   "metadata": {},
   "source": [
    "### 3.3.3. GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "1ebc5ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build GBM Model\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "def GBM_func(XTrain=X_train, XVal=X_val, XTest=X_FNA, yTrain=y_train, yVal=y_val, yTest=y_FNA):\n",
    "    model_gbm = GradientBoostingClassifier(learning_rate=4, n_estimators=50, max_depth=7, min_samples_leaf=4, min_samples_split=30, n_iter_no_change=5, random_state=42)\n",
    "    model_gbm.fit(XTrain,yTrain)\n",
    "    \n",
    "    # Training Set\n",
    "    #plt.rcParams[\"figure.figsize\"] = (3,3)\n",
    "    X_train_predictions = model_gbm.predict(X_train)\n",
    "    print(\"Training Set F1:\", f1_score(y_train, model_gbm.predict(X_train), sample_weight=sampleW))\n",
    "    print(\"Training Set MCC:\", matthews_corrcoef(y_train, model_gbm.predict(X_train), sample_weight=sampleW))\n",
    "    print(\"Training Set Accuracy:\", metrics.accuracy_score(y_train, X_train_predictions))\n",
    "    print(classification_report(y_train, X_train_predictions))\n",
    "    print(confusion_matrix(y_train, X_train_predictions))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr, tpr, _ = metrics.roc_curve(y_train, X_train_predictions)\n",
    "    plt.plot(fpr,tpr)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_train.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    # Val set\n",
    "    predictions_val  = model_gbm.predict(XVal)\n",
    "    print(\"Ext Val Set F1:\", f1_score(yVal, model_gbm.predict(XVal), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set MCC:\", matthews_corrcoef(yVal, model_gbm.predict(XVal), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set Accuracy:\", metrics.accuracy_score(yVal, predictions_val))\n",
    "    print(classification_report(yVal, predictions_val))\n",
    "    print(confusion_matrix(yVal, predictions_val))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_val, tpr_val, _ = metrics.roc_curve(yVal, predictions_val)\n",
    "    plt.plot(fpr_val,tpr_val)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_test.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    f1_5_train = cross_val_score(model_gbm, XTrain, yTrain, cv = 5, scoring=\"f1\")\n",
    "    print(\"5F-CV:\", avgScore(f1_5_train, 5))\n",
    "    \n",
    "    # Test set\n",
    "    predictions_FNA = model_gbm.predict(XTest)\n",
    "    print(\"FNA Set F1:\", f1_score(yTest, model_gbm.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set MCC:\", matthews_corrcoef(yTest, model_gbm.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set Recall:\", recall_score(yTest, model_gbm.predict(XTest)))\n",
    "    print(\"FNA Test Set Accuracy:\", metrics.accuracy_score(yTest, predictions_FNA))\n",
    "    print(classification_report(yTest, predictions_FNA))\n",
    "    print(confusion_matrix(yTest, predictions_FNA))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_FNA, tpr_FNA, _ = metrics.roc_curve(yTest, predictions_FNA)\n",
    "    plt.plot(fpr_FNA,tpr_FNA)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"G:/raMSIn/XGB_Importance2/XGB2_ROC_FNAtest2.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    # Visualize the importantance of the features\n",
    "    feature_imp = pd.Series(model_gbm.feature_importances_, index=XTrain.columns).sort_values(ascending=False)\n",
    "    x=feature_imp\n",
    "    y=feature_imp.index\n",
    "    \n",
    "    plt.subplots(dpi = 300)\n",
    "    #plt.rcParams[\"figure.figsize\"] = [4, 6]\n",
    "    #plt.rcParams[\"font.family\"] = \"Arial\"\n",
    "    #plt.rcParams.update({'font.size': 6})\n",
    "    plt.xlabel('Feature Importance Score', fontproperties='Arial', fontsize=17)\n",
    "    plt.ylabel('Features', fontproperties='Arial', fontsize=17)\n",
    "    plt.xticks(fontsize=15)\n",
    "    plt.yticks(fontsize=15)\n",
    "    plt.title(\"Important Molecular Features\", fontproperties='Arial', fontsize=20)\n",
    "    sns.barplot(x=feature_imp, y=feature_imp.index)\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/XGB_TopFeatures.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    # Visualize the boxplot of the important features between the two groups\n",
    "    #fig = px.box(data_frame = df_ROI_for_ML_Opti, x = feature_imp[:10].index,color= 'type')\n",
    "    #fig.show()\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "05aae3c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set F1: 0.6826731809797296\n",
      "Training Set MCC: 0.4253128464919214\n",
      "Training Set Accuracy: 0.7132475813544416\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.79      0.74     47449\n",
      "           1       0.74      0.62      0.68     43511\n",
      "\n",
      "    accuracy                           0.71     90960\n",
      "   macro avg       0.72      0.71      0.71     90960\n",
      "weighted avg       0.72      0.71      0.71     90960\n",
      "\n",
      "[[37692  9757]\n",
      " [16326 27185]]\n",
      "Ext Val Set F1: 0.41098028501167566\n",
      "Ext Val Set MCC: -0.16235423514717934\n",
      "Ext Val Set Accuracy: 0.41843621399176956\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.43      0.42      2943\n",
      "           1       0.43      0.41      0.42      3132\n",
      "\n",
      "    accuracy                           0.42      6075\n",
      "   macro avg       0.42      0.42      0.42      6075\n",
      "weighted avg       0.42      0.42      0.42      6075\n",
      "\n",
      "[[1272 1671]\n",
      " [1862 1270]]\n",
      "5F-CV: 0.6392939843542356\n",
      "FNA Set F1: 0.5967155403830094\n",
      "FNA Set MCC: 0.18002748341005734\n",
      "FNA Set Recall: 0.6066891601186567\n",
      "FNA Test Set Accuracy: 0.589891883969741\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.57      0.58     44540\n",
      "           1       0.58      0.61      0.60     44161\n",
      "\n",
      "    accuracy                           0.59     88701\n",
      "   macro avg       0.59      0.59      0.59     88701\n",
      "weighted avg       0.59      0.59      0.59     88701\n",
      "\n",
      "[[25532 19008]\n",
      " [17369 26792]]\n"
     ]
    }
   ],
   "source": [
    "coeff_GBM, TOPfeatures_GBM = GBM_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4fa001",
   "metadata": {},
   "source": [
    "### 3.3.4. Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "b2eea591",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build stacking Model\n",
    "\n",
    "def Stacking_func(XTrain=X_train, XVal=X_val, XTest=X_FNA, XTest2=X_di, yTrain=y_train, yVal=y_val, yTest=y_FNA, yTest2=y_di):\n",
    "\n",
    "    base_learners = []\n",
    "\n",
    "    # Define models to use in stacking ensemble\n",
    "    m1 = LogisticRegression(C=0.001, penalty='l1', solver=\"liblinear\", max_iter=5000, random_state=42, class_weight={0:0.9628, 1:1.0402})\n",
    "    base_learners.append(m1)\n",
    "\n",
    "    m2 = LinearSVC(penalty='l2', loss=\"squared_hinge\", C=461, random_state=42, class_weight={0:0.9628, 1:1.0402})\n",
    "    base_learners.append(m2)\n",
    "\n",
    "    m3 = GradientBoostingClassifier(learning_rate=4, n_estimators=50, max_depth=7, min_samples_leaf=4, min_samples_split=30, n_iter_no_change=5, random_state=42)\n",
    "    base_learners.append(m3)\n",
    "\n",
    "    # Define the meta-classifier to use for stacking\n",
    "    meta_learner = LogisticRegression(C=0.0011, penalty='l1', solver=\"liblinear\", max_iter=5000, random_state=42)\n",
    "\n",
    "    model_sc = StackingRegressor([[m1, m2, m3], [meta_learner]])\n",
    "    model_sc.fit(XTrain, yTrain)\n",
    "    \n",
    "    #=======================================\n",
    "    \n",
    "    # Training Set\n",
    "    #plt.rcParams[\"figure.figsize\"] = (3,3)\n",
    "    X_train_predictions = model_sc.predict(X_train)[-1]\n",
    "    print(\"Training Set F1:\", f1_score(y_train, model_sc.predict(X_train)[-1], sample_weight=sampleW))\n",
    "    print(\"Training Set MCC:\", matthews_corrcoef(y_train, model_sc.predict(X_train)[-1], sample_weight=sampleW))\n",
    "    print(\"Training Set Accuracy:\", metrics.accuracy_score(y_train, X_train_predictions))\n",
    "    print(classification_report(y_train, X_train_predictions))\n",
    "    print(confusion_matrix(y_train, X_train_predictions))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr, tpr, _ = metrics.roc_curve(y_train, X_train_predictions)\n",
    "    plt.plot(fpr,tpr)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_train.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    # Val set\n",
    "    predictions_val  = model_sc.predict(XVal)[-1]\n",
    "    print(\"Ext Val Set F1:\", f1_score(yVal, model_sc.predict(XVal)[-1], sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set MCC:\", matthews_corrcoef(yVal, model_sc.predict(XVal)[-1], sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set Accuracy:\", metrics.accuracy_score(yVal, predictions_val))\n",
    "    print(classification_report(yVal, predictions_val))\n",
    "    print(confusion_matrix(yVal, predictions_val))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_val, tpr_val, _ = metrics.roc_curve(yVal, predictions_val)\n",
    "    plt.plot(fpr_val,tpr_val)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_test.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    #f1_5_train = cross_val_score(model_sc, XTrain, yTrain, cv = 5, scoring=\"f1\")\n",
    "    #print(\"5F-CV:\", avgScore(f1_5_train, 5))\n",
    "    \n",
    "    # Test set\n",
    "    predictions_FNA = model_sc.predict(XTest)[-1]\n",
    "    print(\"FNA Set F1:\", f1_score(yTest, model_sc.predict(XTest)[-1], sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set MCC:\", matthews_corrcoef(yTest, model_sc.predict(XTest)[-1], sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set Recall:\", recall_score(yTest, model_sc.predict(XTest)[-1]))\n",
    "    print(\"FNA Test Set Accuracy:\", metrics.accuracy_score(yTest, predictions_FNA))\n",
    "    print(classification_report(yTest, predictions_FNA))\n",
    "    print(confusion_matrix(yTest, predictions_FNA))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_FNA, tpr_FNA, _ = metrics.roc_curve(yTest, predictions_FNA)\n",
    "    plt.plot(fpr_FNA,tpr_FNA)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"G:/raMSIn/XGB_Importance2/XGB2_ROC_FNAtest2.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    # Test2 set\n",
    "    predictions_di = model_sc.predict(XTest2)[-1]\n",
    "    print(\"DirectIn Set F1:\", f1_score(yTest2, model_sc.predict(XTest2)[-1], sample_weight=sampleDiW))\n",
    "    print(\"DirectIn Set MCC:\", matthews_corrcoef(yTest2, model_sc.predict(XTest2)[-1], sample_weight=sampleDiW))\n",
    "    print(\"DirectIn Set Recall:\", recall_score(yTest2, model_sc.predict(XTest2)[-1]))\n",
    "    print(\"DirectIn Test Set Accuracy:\", metrics.accuracy_score(yTest2, predictions_di))\n",
    "    print(classification_report(yTest2, predictions_di))\n",
    "    print(confusion_matrix(yTest2, predictions_di))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_di, tpr_di, _ = metrics.roc_curve(yTest2, predictions_di)\n",
    "    plt.plot(fpr_di,tpr_di)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"G:/raMSIn/XGB_Importance2/XGB2_ROC_FNAtest2.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "ede40144",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set F1: 0.867193045250268\n",
      "Training Set MCC: 0.7313980756690507\n",
      "Training Set Accuracy: 0.8650725593667546\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.85      0.87     47449\n",
      "           1       0.85      0.88      0.86     43511\n",
      "\n",
      "    accuracy                           0.87     90960\n",
      "   macro avg       0.86      0.87      0.86     90960\n",
      "weighted avg       0.87      0.87      0.87     90960\n",
      "\n",
      "[[40501  6948]\n",
      " [ 5325 38186]]\n",
      "Ext Val Set F1: 0.7518009383615407\n",
      "Ext Val Set MCC: 0.4934417994808307\n",
      "Ext Val Set Accuracy: 0.7471604938271605\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.73      0.74      2943\n",
      "           1       0.75      0.77      0.76      3132\n",
      "\n",
      "    accuracy                           0.75      6075\n",
      "   macro avg       0.75      0.75      0.75      6075\n",
      "weighted avg       0.75      0.75      0.75      6075\n",
      "\n",
      "[[2134  809]\n",
      " [ 727 2405]]\n",
      "FNA Set F1: 0.5005887966850374\n",
      "FNA Set MCC: -0.02561376065706162\n",
      "FNA Set Recall: 0.5139829261112746\n",
      "FNA Test Set Accuracy: 0.487097101498292\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.46      0.47     44540\n",
      "           1       0.49      0.51      0.50     44161\n",
      "\n",
      "    accuracy                           0.49     88701\n",
      "   macro avg       0.49      0.49      0.49     88701\n",
      "weighted avg       0.49      0.49      0.49     88701\n",
      "\n",
      "[[20508 24032]\n",
      " [21463 22698]]\n",
      "DirectIn Set F1: 0.6042244352809262\n",
      "DirectIn Set MCC: 0.22898588564664638\n",
      "DirectIn Set Recall: 0.5887788778877888\n",
      "DirectIn Test Set Accuracy: 0.6143305266633647\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.64      0.62      3027\n",
      "           1       0.62      0.59      0.60      3030\n",
      "\n",
      "    accuracy                           0.61      6057\n",
      "   macro avg       0.61      0.61      0.61      6057\n",
      "weighted avg       0.61      0.61      0.61      6057\n",
      "\n",
      "[[1937 1090]\n",
      " [1246 1784]]\n"
     ]
    }
   ],
   "source": [
    "Stacking_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8f2e83",
   "metadata": {},
   "source": [
    "### 3.3.5. Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "0d965f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Voting_func(XTrain=X_train, XVal=X_val, XTest=X_FNA, XTest2=X_di, yTrain=y_train, yVal=y_val, yTest=y_FNA, yTest2=y_di):\n",
    "\n",
    "    models = get_models()\n",
    "    \n",
    "    ensemble = models[\"hard_voting\"]\n",
    "    ensemble.fit(XTrain, yTrain)\n",
    "    #=======================================\n",
    "\n",
    "    # Training Set\n",
    "    #plt.rcParams[\"figure.figsize\"] = (3,3)\n",
    "    X_train_predictions = ensemble.predict(X_train)\n",
    "    print(\"Training Set F1:\", f1_score(y_train, ensemble.predict(X_train), sample_weight=sampleW))\n",
    "    print(\"Training Set MCC:\", matthews_corrcoef(y_train, ensemble.predict(X_train), sample_weight=sampleW))\n",
    "    print(\"Training Set Accuracy:\", metrics.accuracy_score(y_train, X_train_predictions))\n",
    "    print(classification_report(y_train, X_train_predictions))\n",
    "    print(confusion_matrix(y_train, X_train_predictions))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr, tpr, _ = metrics.roc_curve(y_train, X_train_predictions)\n",
    "    plt.plot(fpr,tpr)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_train.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    # Val set\n",
    "    predictions_val  = ensemble.predict(XVal)\n",
    "    print(\"Ext Val Set F1:\", f1_score(yVal, ensemble.predict(XVal), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set MCC:\", matthews_corrcoef(yVal, ensemble.predict(XVal), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set Accuracy:\", metrics.accuracy_score(yVal, predictions_val))\n",
    "    print(classification_report(yVal, predictions_val))\n",
    "    print(confusion_matrix(yVal, predictions_val))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_val, tpr_val, _ = metrics.roc_curve(yVal, predictions_val)\n",
    "    plt.plot(fpr_val,tpr_val)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_test.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    f1_5_train = cross_val_score(ensemble, XTrain, yTrain, cv = 5, scoring=\"f1\")\n",
    "    print(\"5F-CV:\", avgScore(f1_5_train, 5))\n",
    "\n",
    "    # Test set\n",
    "    predictions_FNA = ensemble.predict(XTest)\n",
    "    print(\"FNA Set F1:\", f1_score(yTest, ensemble.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set MCC:\", matthews_corrcoef(yTest, ensemble.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set Recall:\", recall_score(yTest, ensemble.predict(XTest)))\n",
    "    print(\"FNA Test Set Accuracy:\", metrics.accuracy_score(yTest, predictions_FNA))\n",
    "    print(classification_report(yTest, predictions_FNA))\n",
    "    print(confusion_matrix(yTest, predictions_FNA))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_FNA, tpr_FNA, _ = metrics.roc_curve(yTest, predictions_FNA)\n",
    "    plt.plot(fpr_FNA,tpr_FNA)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"G:/raMSIn/XGB_Importance2/XGB2_ROC_FNAtest2.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    # Test2 set\n",
    "    predictions_di = ensemble.predict(XTest2)\n",
    "    print(\"DirectIn Set F1:\", f1_score(yTest2, ensemble.predict(XTest2), sample_weight=sampleDiW))\n",
    "    print(\"DirectIn Set MCC:\", matthews_corrcoef(yTest2, ensemble.predict(XTest2), sample_weight=sampleDiW))\n",
    "    print(\"DirectIn Set Recall:\", recall_score(yTest2, ensemble.predict(XTest2)))\n",
    "    print(\"DirectIn Test Set Accuracy:\", metrics.accuracy_score(yTest2, predictions_di))\n",
    "    print(classification_report(yTest2, predictions_di))\n",
    "    print(confusion_matrix(yTest2, predictions_di))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_di, tpr_di, _ = metrics.roc_curve(yTest2, predictions_di)\n",
    "    plt.plot(fpr_di,tpr_di)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"G:/raMSIn/XGB_Importance2/XGB2_ROC_FNAtest2.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "77d31b0f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set F1: 0.945916914668018\n",
      "Training Set MCC: 0.8912927001219332\n",
      "Training Set Accuracy: 0.9453825857519789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.95     47449\n",
      "           1       0.94      0.95      0.94     43511\n",
      "\n",
      "    accuracy                           0.95     90960\n",
      "   macro avg       0.95      0.95      0.95     90960\n",
      "weighted avg       0.95      0.95      0.95     90960\n",
      "\n",
      "[[44609  2840]\n",
      " [ 2128 41383]]\n",
      "Ext Val Set F1: 0.5580855299737123\n",
      "Ext Val Set MCC: 0.0312802903319481\n",
      "Ext Val Set Accuracy: 0.5183539094650206\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.42      0.46      2943\n",
      "           1       0.53      0.61      0.57      3132\n",
      "\n",
      "    accuracy                           0.52      6075\n",
      "   macro avg       0.52      0.52      0.51      6075\n",
      "weighted avg       0.52      0.52      0.51      6075\n",
      "\n",
      "[[1232 1711]\n",
      " [1215 1917]]\n",
      "5F-CV: 0.8542820904780086\n",
      "FNA Set F1: 0.5632665297402503\n",
      "FNA Set MCC: 0.07283024809759306\n",
      "FNA Set Recall: 0.5982427934150042\n",
      "FNA Test Set Accuracy: 0.5358676903304359\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.47      0.51     44540\n",
      "           1       0.53      0.60      0.56     44161\n",
      "\n",
      "    accuracy                           0.54     88701\n",
      "   macro avg       0.54      0.54      0.53     88701\n",
      "weighted avg       0.54      0.54      0.53     88701\n",
      "\n",
      "[[21113 23427]\n",
      " [17742 26419]]\n",
      "DirectIn Set F1: 0.612254073740111\n",
      "DirectIn Set MCC: 0.23637935107738547\n",
      "DirectIn Set Recall: 0.602970297029703\n",
      "DirectIn Test Set Accuracy: 0.6181277860326895\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.63      0.62      3027\n",
      "           1       0.62      0.60      0.61      3030\n",
      "\n",
      "    accuracy                           0.62      6057\n",
      "   macro avg       0.62      0.62      0.62      6057\n",
      "weighted avg       0.62      0.62      0.62      6057\n",
      "\n",
      "[[1917 1110]\n",
      " [1203 1827]]\n"
     ]
    }
   ],
   "source": [
    "Voting_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08fd62e",
   "metadata": {},
   "source": [
    "## 3.4 Machine Learning Modeling: Model 2 (Train 4:4, Val 6:6, Test 3:3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4c3185",
   "metadata": {},
   "source": [
    "### 3.4.1. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "99086aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build Logistic Regression Model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def LogisticRegression_func(XTrain=X_val, XVal=X_train, XTest=X_FNA, yTrain=y_val, yVal=y_train, yTest=y_FNA):\n",
    "    model_lr = LogisticRegression(C=0.001, penalty='l1', solver=\"liblinear\", max_iter=5000, random_state=42, class_weight={0:0.9628, 1:1.0402})  # max_iter=100\n",
    "    model_lr.fit(XTrain,yTrain)\n",
    "    \n",
    "    # Training Set\n",
    "    #plt.rcParams[\"figure.figsize\"] = (3,3)\n",
    "    X_train_predictions = model_lr.predict(XVal)\n",
    "    print(\"Training Set F1:\", f1_score(yVal, model_lr.predict(XVal), sample_weight=sampleW))\n",
    "    print(\"Training Set MCC:\", matthews_corrcoef(yVal, model_lr.predict(XVal), sample_weight=sampleW))\n",
    "    print(\"Training Set Accuracy:\", metrics.accuracy_score(yVal, X_train_predictions))\n",
    "    print(classification_report(yVal, X_train_predictions))\n",
    "    print(confusion_matrix(yVal, X_train_predictions))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr, tpr, _ = metrics.roc_curve(yVal, X_train_predictions)\n",
    "    plt.plot(fpr,tpr)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_train.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    # Val set\n",
    "    predictions_val  = model_lr.predict(XTrain)\n",
    "    print(\"Ext Val Set F1:\", f1_score(yTrain, model_lr.predict(XTrain), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set MCC:\", matthews_corrcoef(yTrain, model_lr.predict(XTrain), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set Accuracy:\", metrics.accuracy_score(yTrain, predictions_val))\n",
    "    print(classification_report(yTrain, predictions_val))\n",
    "    print(confusion_matrix(yTrain, predictions_val))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_val, tpr_val, _ = metrics.roc_curve(yTrain, predictions_val)\n",
    "    plt.plot(fpr_val,tpr_val)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_test.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    f1_5_train = cross_val_score(model_lr, XTrain, yTrain, cv = 5, scoring=\"f1\")\n",
    "    print(\"5F-CV:\", avgScore(f1_5_train, 5))\n",
    "    \n",
    "    # Test set\n",
    "    predictions_FNA = model_lr.predict(XTest)\n",
    "    print(\"FNA Set F1:\", f1_score(yTest, model_lr.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set MCC:\", matthews_corrcoef(yTest, model_lr.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set Recall:\", recall_score(yTest, model_lr.predict(XTest)))\n",
    "    print(\"FNA Test Set Accuracy:\", metrics.accuracy_score(yTest, predictions_FNA))\n",
    "    print(classification_report(yTest, predictions_FNA))\n",
    "    print(confusion_matrix(yTest, predictions_FNA))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_FNA, tpr_FNA, _ = metrics.roc_curve(yTest, predictions_FNA)\n",
    "    plt.plot(fpr_FNA,tpr_FNA)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"G:/raMSIn/XGB_Importance2/XGB2_ROC_FNAtest2.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    # Visualize the importantance of the features\n",
    "    feature_imp = pd.Series(model_lr.coef_[0], index=XTrain.columns).sort_values(ascending=False)\n",
    "    x=feature_imp\n",
    "    y=feature_imp.index\n",
    "    \n",
    "    plt.subplots(dpi = 300)\n",
    "    #plt.rcParams[\"figure.figsize\"] = [4, 6]\n",
    "    #plt.rcParams[\"font.family\"] = \"Arial\"\n",
    "    #plt.rcParams.update({'font.size': 6})\n",
    "    plt.xlabel('Feature Importance Score', fontproperties='Arial', fontsize=17)\n",
    "    plt.ylabel('Features', fontproperties='Arial', fontsize=17)\n",
    "    plt.xticks(fontsize=15)\n",
    "    plt.yticks(fontsize=15)\n",
    "    plt.title(\"Important Molecular Features\", fontproperties='Arial', fontsize=20)\n",
    "    sns.barplot(x=feature_imp, y=feature_imp.index)\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_TopFeatures.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    #feature_importances = model_lr.coef_[0]\n",
    "    #feature_df=pd.DataFrame({'m/z':XTrain.columns,'coef':feature_importances})\n",
    "\n",
    "    #fig = px.bar(feature_df, x='coef', y='m/z')\n",
    "    #fig.show()\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "ff504fe8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set F1: 0.0\n",
      "Training Set MCC: 0.0\n",
      "Training Set Accuracy: 0.5216468777484609\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      1.00      0.69     47449\n",
      "           1       0.00      0.00      0.00     43511\n",
      "\n",
      "    accuracy                           0.52     90960\n",
      "   macro avg       0.26      0.50      0.34     90960\n",
      "weighted avg       0.27      0.52      0.36     90960\n",
      "\n",
      "[[47449     0]\n",
      " [43511     0]]\n",
      "Ext Val Set F1: 0.0\n",
      "Ext Val Set MCC: 0.0\n",
      "Ext Val Set Accuracy: 0.48444444444444446\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      1.00      0.65      2943\n",
      "           1       0.00      0.00      0.00      3132\n",
      "\n",
      "    accuracy                           0.48      6075\n",
      "   macro avg       0.24      0.50      0.33      6075\n",
      "weighted avg       0.23      0.48      0.32      6075\n",
      "\n",
      "[[2943    0]\n",
      " [3132    0]]\n",
      "5F-CV: 0.0\n",
      "FNA Set F1: 0.0\n",
      "FNA Set MCC: 0.0\n",
      "FNA Set Recall: 0.0\n",
      "FNA Test Set Accuracy: 0.5021363907960451\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67     44540\n",
      "           1       0.00      0.00      0.00     44161\n",
      "\n",
      "    accuracy                           0.50     88701\n",
      "   macro avg       0.25      0.50      0.33     88701\n",
      "weighted avg       0.25      0.50      0.34     88701\n",
      "\n",
      "[[44540     0]\n",
      " [44161     0]]\n"
     ]
    }
   ],
   "source": [
    "coeff_LogReg, TOPfeatures_LogReg = LogisticRegression_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ee44f3",
   "metadata": {},
   "source": [
    "### 3.4.2. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "ae3652ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build LinearSVC Model\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "def LinearSVC_func(XTrain=X_val, XVal=X_train, XTest=X_FNA, yTrain=y_val, yVal=y_train, yTest=y_FNA):\n",
    "    model_svm = LinearSVC(penalty='l2', loss=\"squared_hinge\", C=461, random_state=42, class_weight={0:0.9628, 1:1.0402})\n",
    "    model_svm.fit(XTrain,yTrain)\n",
    "    \n",
    "    # Training Set\n",
    "    #plt.rcParams[\"figure.figsize\"] = (3,3)\n",
    "    X_train_predictions = model_svm.predict(XVal)\n",
    "    print(\"Training Set F1:\", f1_score(yVal, model_svm.predict(XVal), sample_weight=sampleW))\n",
    "    print(\"Training Set MCC:\", matthews_corrcoef(yVal, model_svm.predict(XVal), sample_weight=sampleW))\n",
    "    print(\"Training Set Accuracy:\", metrics.accuracy_score(yVal, X_train_predictions))\n",
    "    print(classification_report(yVal, X_train_predictions))\n",
    "    print(confusion_matrix(yVal, X_train_predictions))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr, tpr, _ = metrics.roc_curve(yVal, X_train_predictions)\n",
    "    plt.plot(fpr,tpr)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_train.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    # Val set\n",
    "    predictions_val  = model_svm.predict(XTrain)\n",
    "    print(\"Ext Val Set F1:\", f1_score(yTrain, model_svm.predict(XTrain), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set MCC:\", matthews_corrcoef(yTrain, model_svm.predict(XTrain), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set Accuracy:\", metrics.accuracy_score(yTrain, predictions_val))\n",
    "    print(classification_report(yTrain, predictions_val))\n",
    "    print(confusion_matrix(yTrain, predictions_val))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_val, tpr_val, _ = metrics.roc_curve(yTrain, predictions_val)\n",
    "    plt.plot(fpr_val,tpr_val)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_test.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    f1_5_train = cross_val_score(model_svm, XTrain, yTrain, cv = 5, scoring=\"f1\")\n",
    "    print(\"5F-CV:\", avgScore(f1_5_train, 5))\n",
    "    \n",
    "    # Test set\n",
    "    predictions_FNA = model_svm.predict(XTest)\n",
    "    print(\"FNA Set F1:\", f1_score(yTest, model_svm.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set MCC:\", matthews_corrcoef(yTest, model_svm.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set Recall:\", recall_score(yTest, model_svm.predict(XTest)))\n",
    "    print(\"FNA Test Set Accuracy:\", metrics.accuracy_score(yTest, predictions_FNA))\n",
    "    print(classification_report(yTest, predictions_FNA))\n",
    "    print(confusion_matrix(yTest, predictions_FNA))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_FNA, tpr_FNA, _ = metrics.roc_curve(yTest, predictions_FNA)\n",
    "    plt.plot(fpr_FNA,tpr_FNA)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"G:/raMSIn/XGB_Importance2/XGB2_ROC_FNAtest2.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    # Visualize the importantance of the features\n",
    "    feature_imp = pd.Series(model_svm.coef_[0], index=XTrain.columns).sort_values(ascending=False)\n",
    "    x=feature_imp\n",
    "    y=feature_imp.index\n",
    "    \n",
    "    plt.subplots(dpi = 300)\n",
    "    #plt.rcParams[\"figure.figsize\"] = [4, 6]\n",
    "    #plt.rcParams[\"font.family\"] = \"Arial\"\n",
    "    #plt.rcParams.update({'font.size': 6})\n",
    "    plt.xlabel('Feature Importance Score', fontproperties='Arial', fontsize=17)\n",
    "    plt.ylabel('Features', fontproperties='Arial', fontsize=17)\n",
    "    plt.xticks(fontsize=15)\n",
    "    plt.yticks(fontsize=15)\n",
    "    plt.title(\"Important Molecular Features\", fontproperties='Arial', fontsize=20)\n",
    "    sns.barplot(x=feature_imp, y=feature_imp.index)\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_TopFeatures.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    #feature_importances = model_svm.coef_[0]\n",
    "    #feature_df=pd.DataFrame({'m/z':XTrain.columns,'coef':feature_importances})\n",
    "\n",
    "    #fig = px.bar(feature_df, x='coef', y='m/z')\n",
    "    #fig.show()\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "8936e108",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set F1: 0.6434531166141041\n",
      "Training Set MCC: 0.1818606377620566\n",
      "Training Set Accuracy: 0.5791336851363237\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.43      0.51     47449\n",
      "           1       0.54      0.75      0.63     43511\n",
      "\n",
      "    accuracy                           0.58     90960\n",
      "   macro avg       0.60      0.59      0.57     90960\n",
      "weighted avg       0.60      0.58      0.57     90960\n",
      "\n",
      "[[20178 27271]\n",
      " [11011 32500]]\n",
      "Ext Val Set F1: 0.9515950615814753\n",
      "Ext Val Set MCC: 0.9057835067658231\n",
      "Ext Val Set Accuracy: 0.9519341563786008\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95      2943\n",
      "           1       0.97      0.93      0.95      3132\n",
      "\n",
      "    accuracy                           0.95      6075\n",
      "   macro avg       0.95      0.95      0.95      6075\n",
      "weighted avg       0.95      0.95      0.95      6075\n",
      "\n",
      "[[2861   82]\n",
      " [ 210 2922]]\n",
      "5F-CV: 0.8767516690905474\n",
      "FNA Set F1: 0.4620807000445212\n",
      "FNA Set MCC: -0.14752886606918636\n",
      "FNA Set Recall: 0.49231222119064333\n",
      "FNA Test Set Accuracy: 0.42659045557547265\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.36      0.39     44540\n",
      "           1       0.43      0.49      0.46     44161\n",
      "\n",
      "    accuracy                           0.43     88701\n",
      "   macro avg       0.43      0.43      0.42     88701\n",
      "weighted avg       0.43      0.43      0.42     88701\n",
      "\n",
      "[[16098 28442]\n",
      " [22420 21741]]\n"
     ]
    }
   ],
   "source": [
    "coeff_SVM, TOPfeatures_SVM = LinearSVC_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d174863d",
   "metadata": {},
   "source": [
    "### 3.4.3. GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "19a6e165",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build GBM Model\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "def GBM_func(XTrain=X_val, XVal=X_train, XTest=X_FNA, yTrain=y_val, yVal=y_train, yTest=y_FNA):\n",
    "    model_gbm = GradientBoostingClassifier(learning_rate=4, n_estimators=50, max_depth=7, min_samples_leaf=4, min_samples_split=30, n_iter_no_change=5, random_state=42)\n",
    "    model_gbm.fit(XTrain,yTrain)\n",
    "    \n",
    "    # Training Set\n",
    "    #plt.rcParams[\"figure.figsize\"] = (3,3)\n",
    "    X_train_predictions = model_gbm.predict(XVal)\n",
    "    print(\"Training Set F1:\", f1_score(yVal, model_gbm.predict(XVal), sample_weight=sampleW))\n",
    "    print(\"Training Set MCC:\", matthews_corrcoef(yVal, model_gbm.predict(XVal), sample_weight=sampleW))\n",
    "    print(\"Training Set Accuracy:\", metrics.accuracy_score(yVal, X_train_predictions))\n",
    "    print(classification_report(yVal, X_train_predictions))\n",
    "    print(confusion_matrix(yVal, X_train_predictions))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr, tpr, _ = metrics.roc_curve(yVal, X_train_predictions)\n",
    "    plt.plot(fpr,tpr)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_train.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    # Val set\n",
    "    predictions_val  = model_gbm.predict(XTrain)\n",
    "    print(\"Ext Val Set F1:\", f1_score(yTrain, model_gbm.predict(XTrain), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set MCC:\", matthews_corrcoef(yTrain, model_gbm.predict(XTrain), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set Accuracy:\", metrics.accuracy_score(yTrain, predictions_val))\n",
    "    print(classification_report(yTrain, predictions_val))\n",
    "    print(confusion_matrix(yTrain, predictions_val))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_val, tpr_val, _ = metrics.roc_curve(yTrain, predictions_val)\n",
    "    plt.plot(fpr_val,tpr_val)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_test.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    f1_5_train = cross_val_score(model_gbm, XTrain, yTrain, cv = 5, scoring=\"f1\")\n",
    "    print(\"5F-CV:\", avgScore(f1_5_train, 5))\n",
    "    \n",
    "    # Test set\n",
    "    predictions_FNA = model_gbm.predict(XTest)\n",
    "    print(\"FNA Set F1:\", f1_score(yTest, model_gbm.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set MCC:\", matthews_corrcoef(yTest, model_gbm.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set Recall:\", recall_score(yTest, model_gbm.predict(XTest)))\n",
    "    print(\"FNA Test Set Accuracy:\", metrics.accuracy_score(yTest, predictions_FNA))\n",
    "    print(classification_report(yTest, predictions_FNA))\n",
    "    print(confusion_matrix(yTest, predictions_FNA))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_FNA, tpr_FNA, _ = metrics.roc_curve(yTest, predictions_FNA)\n",
    "    plt.plot(fpr_FNA,tpr_FNA)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"G:/raMSIn/XGB_Importance2/XGB2_ROC_FNAtest2.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    # Visualize the importantance of the features\n",
    "    feature_imp = pd.Series(model_gbm.feature_importances_, index=XTrain.columns).sort_values(ascending=False)\n",
    "    x=feature_imp\n",
    "    y=feature_imp.index\n",
    "    \n",
    "    plt.subplots(dpi = 300)\n",
    "    #plt.rcParams[\"figure.figsize\"] = [4, 6]\n",
    "    #plt.rcParams[\"font.family\"] = \"Arial\"\n",
    "    #plt.rcParams.update({'font.size': 6})\n",
    "    plt.xlabel('Feature Importance Score', fontproperties='Arial', fontsize=17)\n",
    "    plt.ylabel('Features', fontproperties='Arial', fontsize=17)\n",
    "    plt.xticks(fontsize=15)\n",
    "    plt.yticks(fontsize=15)\n",
    "    plt.title(\"Important Molecular Features\", fontproperties='Arial', fontsize=20)\n",
    "    sns.barplot(x=feature_imp, y=feature_imp.index)\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/XGB_TopFeatures.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    # Visualize the boxplot of the important features between the two groups\n",
    "    #fig = px.box(data_frame = df_ROI_for_ML_Opti, x = feature_imp[:10].index,color= 'type')\n",
    "    #fig.show()\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "9144e872",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set F1: 0.682390743679324\n",
      "Training Set MCC: 0.31840264604856455\n",
      "Training Set Accuracy: 0.6537489006156553\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.58      0.64     47449\n",
      "           1       0.62      0.74      0.67     43511\n",
      "\n",
      "    accuracy                           0.65     90960\n",
      "   macro avg       0.66      0.66      0.65     90960\n",
      "weighted avg       0.66      0.65      0.65     90960\n",
      "\n",
      "[[27418 20031]\n",
      " [11464 32047]]\n",
      "Ext Val Set F1: 0.6555620440389948\n",
      "Ext Val Set MCC: 0.39247624180193447\n",
      "Ext Val Set Accuracy: 0.688559670781893\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.80      0.71      2943\n",
      "           1       0.75      0.59      0.66      3132\n",
      "\n",
      "    accuracy                           0.69      6075\n",
      "   macro avg       0.70      0.69      0.69      6075\n",
      "weighted avg       0.70      0.69      0.69      6075\n",
      "\n",
      "[[2346  597]\n",
      " [1295 1837]]\n",
      "5F-CV: 0.8007870480575973\n",
      "FNA Set F1: 0.6620528105147825\n",
      "FNA Set MCC: 0.3048178846260322\n",
      "FNA Set Recall: 0.681438373225244\n",
      "FNA Test Set Accuracy: 0.6520219614209536\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.62      0.64     44540\n",
      "           1       0.64      0.68      0.66     44161\n",
      "\n",
      "    accuracy                           0.65     88701\n",
      "   macro avg       0.65      0.65      0.65     88701\n",
      "weighted avg       0.65      0.65      0.65     88701\n",
      "\n",
      "[[27742 16798]\n",
      " [14068 30093]]\n"
     ]
    }
   ],
   "source": [
    "coeff_GBM, TOPfeatures_GBM = GBM_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54dee61b",
   "metadata": {},
   "source": [
    "### 3.4.4. Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "b131b153",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build stacking Model\n",
    "\n",
    "def Stacking_func(XTrain=X_val, XVal=X_train, XTest=X_FNA, XTest2=X_di, yTrain=y_val, yVal=y_train, yTest=y_FNA, yTest2=y_di):\n",
    "\n",
    "    base_learners = []\n",
    "\n",
    "    # Define models to use in stacking ensemble\n",
    "    m1 = LogisticRegression(C=0.001, penalty='l1', solver=\"liblinear\", max_iter=5000, random_state=42, class_weight={0:0.9628, 1:1.0402})\n",
    "    base_learners.append(m1)\n",
    "\n",
    "    m2 = LinearSVC(penalty='l2', loss=\"squared_hinge\", C=461, random_state=42, class_weight={0:0.9628, 1:1.0402})\n",
    "    base_learners.append(m2)\n",
    "\n",
    "    m3 = GradientBoostingClassifier(learning_rate=4, n_estimators=50, max_depth=7, min_samples_leaf=4, min_samples_split=30, n_iter_no_change=5, random_state=42)\n",
    "    base_learners.append(m3)\n",
    "\n",
    "    # Define the meta-classifier to use for stacking\n",
    "    meta_learner = LogisticRegression(C=0.0011, penalty='l1', solver=\"liblinear\", max_iter=5000, random_state=42)\n",
    "\n",
    "    model_sc = StackingRegressor([[m1, m2, m3], [meta_learner]])\n",
    "    model_sc.fit(XTrain, yTrain)\n",
    "    \n",
    "    #=======================================\n",
    "    \n",
    "    # Training Set\n",
    "    #plt.rcParams[\"figure.figsize\"] = (3,3)\n",
    "    X_train_predictions = model_sc.predict(XVal)[-1]\n",
    "    print(\"Training Set F1:\", f1_score(yVal, model_sc.predict(XVal)[-1], sample_weight=sampleW))\n",
    "    print(\"Training Set MCC:\", matthews_corrcoef(yVal, model_sc.predict(XVal)[-1], sample_weight=sampleW))\n",
    "    print(\"Training Set Accuracy:\", metrics.accuracy_score(yVal, X_train_predictions))\n",
    "    print(classification_report(yVal, X_train_predictions))\n",
    "    print(confusion_matrix(yVal, X_train_predictions))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr, tpr, _ = metrics.roc_curve(yVal, X_train_predictions)\n",
    "    plt.plot(fpr,tpr)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_train.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    # Val set\n",
    "    predictions_val  = model_sc.predict(XTrain)[-1]\n",
    "    print(\"Ext Val Set F1:\", f1_score(yTrain, model_sc.predict(XTrain)[-1], sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set MCC:\", matthews_corrcoef(yTrain, model_sc.predict(XTrain)[-1], sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set Accuracy:\", metrics.accuracy_score(yTrain, predictions_val))\n",
    "    print(classification_report(yTrain, predictions_val))\n",
    "    print(confusion_matrix(yTrain, predictions_val))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_val, tpr_val, _ = metrics.roc_curve(yTrain, predictions_val)\n",
    "    plt.plot(fpr_val,tpr_val)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_test.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    #f1_5_train = cross_val_score(model_sc, XTrain, yTrain, cv = 5, scoring=\"f1\")\n",
    "    #print(\"5F-CV:\", avgScore(f1_5_train, 5))\n",
    "    \n",
    "    # Test set\n",
    "    predictions_FNA = model_sc.predict(XTest)[-1]\n",
    "    print(\"FNA Set F1:\", f1_score(yTest, model_sc.predict(XTest)[-1], sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set MCC:\", matthews_corrcoef(yTest, model_sc.predict(XTest)[-1], sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set Recall:\", recall_score(yTest, model_sc.predict(XTest)[-1]))\n",
    "    print(\"FNA Test Set Accuracy:\", metrics.accuracy_score(yTest, predictions_FNA))\n",
    "    print(classification_report(yTest, predictions_FNA))\n",
    "    print(confusion_matrix(yTest, predictions_FNA))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_FNA, tpr_FNA, _ = metrics.roc_curve(yTest, predictions_FNA)\n",
    "    plt.plot(fpr_FNA,tpr_FNA)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"G:/raMSIn/XGB_Importance2/XGB2_ROC_FNAtest2.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    # Test2 set\n",
    "    predictions_di = model_sc.predict(XTest2)[-1]\n",
    "    print(\"DirectIn Set F1:\", f1_score(yTest2, model_sc.predict(XTest2)[-1], sample_weight=sampleDiW))\n",
    "    print(\"DirectIn Set MCC:\", matthews_corrcoef(yTest2, model_sc.predict(XTest2)[-1], sample_weight=sampleDiW))\n",
    "    print(\"DirectIn Set Recall:\", recall_score(yTest2, model_sc.predict(XTest2)[-1]))\n",
    "    print(\"DirectIn Test Set Accuracy:\", metrics.accuracy_score(yTest2, predictions_di))\n",
    "    print(classification_report(yTest2, predictions_di))\n",
    "    print(confusion_matrix(yTest2, predictions_di))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_di, tpr_di, _ = metrics.roc_curve(yTest2, predictions_di)\n",
    "    plt.plot(fpr_di,tpr_di)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"G:/raMSIn/XGB_Importance2/XGB2_ROC_FNAtest2.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "be042b51",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set F1: 0.0\n",
      "Training Set MCC: 0.0\n",
      "Training Set Accuracy: 0.5216468777484609\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      1.00      0.69     47449\n",
      "           1       0.00      0.00      0.00     43511\n",
      "\n",
      "    accuracy                           0.52     90960\n",
      "   macro avg       0.26      0.50      0.34     90960\n",
      "weighted avg       0.27      0.52      0.36     90960\n",
      "\n",
      "[[47449     0]\n",
      " [43511     0]]\n",
      "Ext Val Set F1: 0.0\n",
      "Ext Val Set MCC: 0.0\n",
      "Ext Val Set Accuracy: 0.48444444444444446\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      1.00      0.65      2943\n",
      "           1       0.00      0.00      0.00      3132\n",
      "\n",
      "    accuracy                           0.48      6075\n",
      "   macro avg       0.24      0.50      0.33      6075\n",
      "weighted avg       0.23      0.48      0.32      6075\n",
      "\n",
      "[[2943    0]\n",
      " [3132    0]]\n",
      "FNA Set F1: 0.0\n",
      "FNA Set MCC: 0.0\n",
      "FNA Set Recall: 0.0\n",
      "FNA Test Set Accuracy: 0.5021363907960451\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67     44540\n",
      "           1       0.00      0.00      0.00     44161\n",
      "\n",
      "    accuracy                           0.50     88701\n",
      "   macro avg       0.25      0.50      0.33     88701\n",
      "weighted avg       0.25      0.50      0.34     88701\n",
      "\n",
      "[[44540     0]\n",
      " [44161     0]]\n",
      "DirectIn Set F1: 0.0\n",
      "DirectIn Set MCC: 0.0\n",
      "DirectIn Set Recall: 0.0\n",
      "DirectIn Test Set Accuracy: 0.49975235264982665\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67      3027\n",
      "           1       0.00      0.00      0.00      3030\n",
      "\n",
      "    accuracy                           0.50      6057\n",
      "   macro avg       0.25      0.50      0.33      6057\n",
      "weighted avg       0.25      0.50      0.33      6057\n",
      "\n",
      "[[3027    0]\n",
      " [3030    0]]\n"
     ]
    }
   ],
   "source": [
    "Stacking_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba4b24c",
   "metadata": {},
   "source": [
    "### 3.4.5. Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "7410e9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Voting_func(XTrain=X_val, XVal=X_train, XTest=X_FNA, XTest2=X_di, yTrain=y_val, yVal=y_train, yTest=y_FNA, yTest2=y_di):\n",
    "\n",
    "    models = get_models()\n",
    "    \n",
    "    ensemble = models[\"hard_voting\"]\n",
    "    ensemble.fit(XTrain, yTrain)\n",
    "    #=======================================\n",
    "\n",
    "    # Training Set\n",
    "    #plt.rcParams[\"figure.figsize\"] = (3,3)\n",
    "    X_train_predictions = ensemble.predict(XVal)\n",
    "    print(\"Training Set F1:\", f1_score(yVal, ensemble.predict(XVal), sample_weight=sampleW))\n",
    "    print(\"Training Set MCC:\", matthews_corrcoef(yVal, ensemble.predict(XVal), sample_weight=sampleW))\n",
    "    print(\"Training Set Accuracy:\", metrics.accuracy_score(yVal, X_train_predictions))\n",
    "    print(classification_report(yVal, X_train_predictions))\n",
    "    print(confusion_matrix(yVal, X_train_predictions))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr, tpr, _ = metrics.roc_curve(yVal, X_train_predictions)\n",
    "    plt.plot(fpr,tpr)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_train.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    # Val set\n",
    "    predictions_val  = ensemble.predict(XTrain)\n",
    "    print(\"Ext Val Set F1:\", f1_score(yTrain, ensemble.predict(XTrain), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set MCC:\", matthews_corrcoef(yTrain, ensemble.predict(XTrain), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set Accuracy:\", metrics.accuracy_score(yTrain, predictions_val))\n",
    "    print(classification_report(yTrain, predictions_val))\n",
    "    print(confusion_matrix(yTrain, predictions_val))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_val, tpr_val, _ = metrics.roc_curve(yTrain, predictions_val)\n",
    "    plt.plot(fpr_val,tpr_val)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_test.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    f1_5_train = cross_val_score(ensemble, XTrain, yTrain, cv = 5, scoring=\"f1\")\n",
    "    print(\"5F-CV:\", avgScore(f1_5_train, 5))\n",
    "\n",
    "    # Test set\n",
    "    predictions_FNA = ensemble.predict(XTest)\n",
    "    print(\"FNA Set F1:\", f1_score(yTest, ensemble.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set MCC:\", matthews_corrcoef(yTest, ensemble.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set Recall:\", recall_score(yTest, ensemble.predict(XTest)))\n",
    "    print(\"FNA Test Set Accuracy:\", metrics.accuracy_score(yTest, predictions_FNA))\n",
    "    print(classification_report(yTest, predictions_FNA))\n",
    "    print(confusion_matrix(yTest, predictions_FNA))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_FNA, tpr_FNA, _ = metrics.roc_curve(yTest, predictions_FNA)\n",
    "    plt.plot(fpr_FNA,tpr_FNA)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"G:/raMSIn/XGB_Importance2/XGB2_ROC_FNAtest2.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    # Test2 set\n",
    "    predictions_di = ensemble.predict(XTest2)\n",
    "    print(\"DirectIn Set F1:\", f1_score(yTest2, ensemble.predict(XTest2), sample_weight=sampleDiW))\n",
    "    print(\"DirectIn Set MCC:\", matthews_corrcoef(yTest2, ensemble.predict(XTest2), sample_weight=sampleDiW))\n",
    "    print(\"DirectIn Set Recall:\", recall_score(yTest2, ensemble.predict(XTest2)))\n",
    "    print(\"DirectIn Test Set Accuracy:\", metrics.accuracy_score(yTest2, predictions_di))\n",
    "    print(classification_report(yTest2, predictions_di))\n",
    "    print(confusion_matrix(yTest2, predictions_di))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_di, tpr_di, _ = metrics.roc_curve(yTest2, predictions_di)\n",
    "    plt.plot(fpr_di,tpr_di)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"G:/raMSIn/XGB_Importance2/XGB2_ROC_FNAtest2.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "662b3eaa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set F1: 0.6808192970772039\n",
      "Training Set MCC: 0.38326049363413506\n",
      "Training Set Accuracy: 0.6926341248900616\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.72      0.71     47449\n",
      "           1       0.69      0.66      0.67     43511\n",
      "\n",
      "    accuracy                           0.69     90960\n",
      "   macro avg       0.69      0.69      0.69     90960\n",
      "weighted avg       0.69      0.69      0.69     90960\n",
      "\n",
      "[[34345 13104]\n",
      " [14854 28657]]\n",
      "Ext Val Set F1: 0.6868105867104608\n",
      "Ext Val Set MCC: 0.5794151200655429\n",
      "Ext Val Set Accuracy: 0.7509465020576132\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.99      0.79      2943\n",
      "           1       0.97      0.53      0.69      3132\n",
      "\n",
      "    accuracy                           0.75      6075\n",
      "   macro avg       0.82      0.76      0.74      6075\n",
      "weighted avg       0.82      0.75      0.74      6075\n",
      "\n",
      "[[2900   43]\n",
      " [1470 1662]]\n",
      "5F-CV: 0.7882903995642334\n",
      "FNA Set F1: 0.48516454874205456\n",
      "FNA Set MCC: 0.17201341559751537\n",
      "FNA Set Recall: 0.3958243699191594\n",
      "FNA Test Set Accuracy: 0.5807488077924713\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.76      0.65     44540\n",
      "           1       0.62      0.40      0.48     44161\n",
      "\n",
      "    accuracy                           0.58     88701\n",
      "   macro avg       0.59      0.58      0.57     88701\n",
      "weighted avg       0.59      0.58      0.57     88701\n",
      "\n",
      "[[34033 10507]\n",
      " [26681 17480]]\n",
      "DirectIn Set F1: 0.47261692239600955\n",
      "DirectIn Set MCC: 0.05700741752808045\n",
      "DirectIn Set Recall: 0.4231023102310231\n",
      "DirectIn Test Set Accuracy: 0.52781905233614\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.63      0.57      3027\n",
      "           1       0.54      0.42      0.47      3030\n",
      "\n",
      "    accuracy                           0.53      6057\n",
      "   macro avg       0.53      0.53      0.52      6057\n",
      "weighted avg       0.53      0.53      0.52      6057\n",
      "\n",
      "[[1915 1112]\n",
      " [1748 1282]]\n"
     ]
    }
   ],
   "source": [
    "Voting_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bfe116c",
   "metadata": {},
   "source": [
    "# 4. Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90e766a",
   "metadata": {},
   "source": [
    "## 4.1 Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ed6121d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## deploy models for training set ##\n",
    "model_voting = jl.load(r\"H:\\3_output_raMSIn\\3_3_Output_raMSIn_HKU_Ingested4ALL\\XGB_ALL\\afterModelSelection\\model3to1Voting_raMSIn.joblib\")\n",
    "#\n",
    "## deploy model ##\n",
    "predicted0n1_train = model_voting.predict(X_train)\n",
    "#predicted0n1_trainProba = model_voting.predict_proba(X_train)         \n",
    "trainDEFSDf[\"predicted0n1\"] = predicted0n1_train\n",
    "T_ = []\n",
    "F_ = []\n",
    "for i in range(len(trainDEFSDf)):\n",
    "    if trainDEFSDf.iloc[i][\"predicted0n1\"] == 1:\n",
    "        T_.append(1)\n",
    "        F_.append(0)\n",
    "    elif trainDEFSDf.iloc[i][\"predicted0n1\"] == 0:\n",
    "        F_.append(1)\n",
    "        T_.append(0)\n",
    "trainDEFSDf[\"T\"] = T_\n",
    "trainDEFSDf[\"F\"] = F_\n",
    "#\n",
    "## save ##, ouputing trainSet df\n",
    "savePath = r\"H:\\3_output_raMSIn\\3_3_Output_raMSIn_HKU_Ingested4ALL\\XGB_ALL\\afterModelSelection\\df_train_raMSIn_norm_0n1.csv\"\n",
    "trainDEFSDf.to_csv(savePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a777fba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## deploy models for Ext Val set ##\n",
    "model_voting = jl.load(r\"H:\\3_output_raMSIn\\3_3_Output_raMSIn_HKU_Ingested4ALL\\XGB_ALL\\afterModelSelection\\model3to1Voting_raMSIn.joblib\")\n",
    "#\n",
    "## deploy model ##\n",
    "predicted0n1_ext = model_voting.predict(X_val)\n",
    "extDEFSDf[\"predicted0n1\"] = predicted0n1_ext\n",
    "T_ = []\n",
    "F_ = []\n",
    "for i in range(len(extDEFSDf)):\n",
    "    if extDEFSDf.iloc[i][\"predicted0n1\"] == 1:\n",
    "        T_.append(1)\n",
    "        F_.append(0)\n",
    "    elif extDEFSDf.iloc[i][\"predicted0n1\"] == 0:\n",
    "        F_.append(1)\n",
    "        T_.append(0)\n",
    "extDEFSDf[\"T\"] = T_\n",
    "extDEFSDf[\"F\"] = F_\n",
    "#\n",
    "## save ##, ouputing extSet df\n",
    "savePath = r\"H:\\3_output_raMSIn\\3_3_Output_raMSIn_HKU_Ingested4ALL\\XGB_ALL\\afterModelSelection\\df_ext_raMSIn_norm_0n1.csv\"\n",
    "extDEFSDf.to_csv(savePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "959bda0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## deploy models for FNA set ##\n",
    "model_voting = jl.load(r\"H:\\3_output_raMSIn\\3_3_Output_raMSIn_HKU_Ingested4ALL\\XGB_ALL\\afterModelSelection\\model3to1Voting_raMSIn.joblib\")\n",
    "#\n",
    "## deploy model ##\n",
    "predicted0n1_FNA = model_voting.predict(X_FNA)\n",
    "fnaDEFSDf[\"predicted0n1\"] = predicted0n1_FNA\n",
    "T_ = []\n",
    "F_ = []\n",
    "for i in range(len(fnaDEFSDf)):\n",
    "    if fnaDEFSDf.iloc[i][\"predicted0n1\"] == 1:\n",
    "        T_.append(1)\n",
    "        F_.append(0)\n",
    "    elif fnaDEFSDf.iloc[i][\"predicted0n1\"] == 0:\n",
    "        F_.append(1)\n",
    "        T_.append(0)\n",
    "fnaDEFSDf[\"T\"] = T_\n",
    "fnaDEFSDf[\"F\"] = F_\n",
    "#\n",
    "## save ##, ouputing extSet df\n",
    "savePath = r\"H:\\3_output_raMSIn\\3_3_Output_raMSIn_HKU_Ingested4ALL\\XGB_ALL\\afterModelSelection\\df_FNA_raMSIn_norm_0n1.csv\"\n",
    "fnaDEFSDf.to_csv(savePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3c6b9288",
   "metadata": {},
   "outputs": [],
   "source": [
    "## deploy models for DirectInfusion set ##\n",
    "model_voting = jl.load(r\"H:\\3_output_raMSIn\\3_3_Output_raMSIn_HKU_Ingested4ALL\\XGB_ALL\\afterModelSelection\\model3to1Voting_raMSIn.joblib\")\n",
    "#\n",
    "## deploy model ##\n",
    "predicted0n1_Di = model_voting.predict(X_di)\n",
    "diDEFSDf[\"predicted0n1\"] = predicted0n1_Di\n",
    "T_ = []\n",
    "F_ = []\n",
    "for i in range(len(diDEFSDf)):\n",
    "    if diDEFSDf.iloc[i][\"predicted0n1\"] == 1:\n",
    "        T_.append(1)\n",
    "        F_.append(0)\n",
    "    elif diDEFSDf.iloc[i][\"predicted0n1\"] == 0:\n",
    "        F_.append(1)\n",
    "        T_.append(0)\n",
    "diDEFSDf[\"T\"] = T_\n",
    "diDEFSDf[\"F\"] = F_\n",
    "#\n",
    "## save ##, ouputing extSet df\n",
    "savePath = r\"H:\\3_output_raMSIn\\3_3_Output_raMSIn_HKU_Ingested4ALL\\XGB_ALL\\afterModelSelection\\df_Di_raMSIn_norm_0n1.csv\"\n",
    "diDEFSDf.to_csv(savePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7ac83ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## deploy models for Clinics set ##\n",
    "model_voting = jl.load(r\"H:\\3_output_raMSIn\\3_3_Output_raMSIn_HKU_Ingested4ALL\\XGB_ALL\\afterModelSelection\\model3to1Voting_raMSIn.joblib\")\n",
    "#\n",
    "## deploy model ##\n",
    "predicted0n1_C = model_voting.predict(X_c)\n",
    "cDEFSDf[\"predicted0n1\"] = predicted0n1_C\n",
    "T_ = []\n",
    "F_ = []\n",
    "for i in range(len(cDEFSDf)):\n",
    "    if cDEFSDf.iloc[i][\"predicted0n1\"] == 1:\n",
    "        T_.append(1)\n",
    "        F_.append(0)\n",
    "    elif cDEFSDf.iloc[i][\"predicted0n1\"] == 0:\n",
    "        F_.append(1)\n",
    "        T_.append(0)\n",
    "cDEFSDf[\"T\"] = T_\n",
    "cDEFSDf[\"F\"] = F_\n",
    "#\n",
    "## save ##, ouputing extSet df\n",
    "savePath = r\"H:\\3_output_raMSIn\\3_3_Output_raMSIn_HKU_Ingested4ALL\\XGB_ALL\\afterModelSelection\\df_Clinics3_raMSIn_norm_0n1.csv\"\n",
    "cDEFSDf.to_csv(savePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b62afc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
