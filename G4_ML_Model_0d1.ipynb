{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b137a905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\Users\\\\user\\\\anaconda3\\\\lib\\\\site-packages\\\\config']\n",
      "2.12.0-dev20221107\n",
      "2.12.0\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import glob\n",
    "import xlwings as xw\n",
    "import math\n",
    "from pathlib import Path\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "from matplotlib import cm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mclr\n",
    "import plotly.express as px\n",
    "import statsmodels.api as sm\n",
    "import pylab as py\n",
    "import os, cv2, glob, tempfile\n",
    "import joblib\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "import sklearn\n",
    "from sklearn import datasets\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "make_scorer = sklearn.metrics.make_scorer\n",
    "f1 = make_scorer(f1_score, pos_label=1, average=\"binary\")\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate, KFold\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import BatchNormalization, Conv2D, MaxPooling2D, Activation, Dropout, Flatten, Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras import utils as np_utils\n",
    "from keras import models\n",
    "import keras_tuner as kt\n",
    "from scipy import signal\n",
    "\n",
    "import config as config\n",
    "print(config.__path__)\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import to_categorical\n",
    "from keras import backend as K\n",
    "\n",
    "import argparse\n",
    "# from sklearn.utils import class_weight\n",
    "print(tf.__version__)\n",
    "print(keras.__version__)\n",
    "\n",
    "import shutil\n",
    "import xlwings as xw\n",
    "\n",
    "%matplotlib inline\n",
    "mpl.use(\"Agg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5c8a718",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build XGBoost Model\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statsmodels.graphics.tsaplots import plot_acf,plot_pacf\n",
    "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV,train_test_split\n",
    "from skopt import BayesSearchCV\n",
    "from sklearn.metrics import accuracy_score,f1_score,roc_auc_score,confusion_matrix,roc_curve\n",
    "import xgboost as xgb\n",
    "import time\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30868f12",
   "metadata": {},
   "source": [
    "# 1. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "daf38283",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDEFSDf = pd.read_csv(r\"H:\\\\3_output_raMSIn\\\\3_3_Output_raMSIn_HKU_Ingested4ALL\\\\XGB_ALL\\\\df_train_cbMSIn0d14nonInDI_norm.csv\")\n",
    "diDEFSDf = pd.read_csv(r\"H:\\\\3_output_raMSIn\\\\3_3_Output_raMSIn_HKU_Ingested4ALL\\\\XGB_ALL\\\\df_nonInDI_cbMSIn0d14nonInDI_norm.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36740c29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel_id</th>\n",
       "      <th>311.15</th>\n",
       "      <th>269.25</th>\n",
       "      <th>215.0</th>\n",
       "      <th>295.1</th>\n",
       "      <th>883.55</th>\n",
       "      <th>309.2</th>\n",
       "      <th>738.55</th>\n",
       "      <th>435.2</th>\n",
       "      <th>280.25</th>\n",
       "      <th>241.1</th>\n",
       "      <th>311.2</th>\n",
       "      <th>339.1</th>\n",
       "      <th>353.2</th>\n",
       "      <th>325.2</th>\n",
       "      <th>250.1</th>\n",
       "      <th>514.3</th>\n",
       "      <th>265.05</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HKULiver_Post29wk_HCCAMCLiver_Left_Mice03_Slid...</td>\n",
       "      <td>0.306614</td>\n",
       "      <td>0.155823</td>\n",
       "      <td>-0.014750</td>\n",
       "      <td>0.167718</td>\n",
       "      <td>-0.083734</td>\n",
       "      <td>0.256635</td>\n",
       "      <td>-0.155483</td>\n",
       "      <td>0.117061</td>\n",
       "      <td>-0.083208</td>\n",
       "      <td>0.218163</td>\n",
       "      <td>0.306614</td>\n",
       "      <td>0.224674</td>\n",
       "      <td>0.269023</td>\n",
       "      <td>0.292024</td>\n",
       "      <td>0.125619</td>\n",
       "      <td>-0.041124</td>\n",
       "      <td>0.319844</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HKULiver_Post29wk_HCCAMCLiver_Left_Mice03_Slid...</td>\n",
       "      <td>0.426535</td>\n",
       "      <td>0.413081</td>\n",
       "      <td>0.099901</td>\n",
       "      <td>0.288114</td>\n",
       "      <td>-0.052378</td>\n",
       "      <td>0.340275</td>\n",
       "      <td>-0.127744</td>\n",
       "      <td>0.057160</td>\n",
       "      <td>-0.103060</td>\n",
       "      <td>0.283815</td>\n",
       "      <td>0.426535</td>\n",
       "      <td>0.306224</td>\n",
       "      <td>0.329107</td>\n",
       "      <td>0.397299</td>\n",
       "      <td>0.299930</td>\n",
       "      <td>-0.041124</td>\n",
       "      <td>0.387575</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HKULiver_Post29wk_HCCAMCLiver_Left_Mice03_Slid...</td>\n",
       "      <td>0.283540</td>\n",
       "      <td>0.172545</td>\n",
       "      <td>0.049710</td>\n",
       "      <td>0.137600</td>\n",
       "      <td>-0.081307</td>\n",
       "      <td>0.200232</td>\n",
       "      <td>-0.162255</td>\n",
       "      <td>-0.030521</td>\n",
       "      <td>-0.088757</td>\n",
       "      <td>0.202159</td>\n",
       "      <td>0.283540</td>\n",
       "      <td>0.223596</td>\n",
       "      <td>0.244158</td>\n",
       "      <td>0.266221</td>\n",
       "      <td>0.208253</td>\n",
       "      <td>0.104304</td>\n",
       "      <td>0.310121</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HKULiver_Post29wk_HCCAMCLiver_Left_Mice03_Slid...</td>\n",
       "      <td>0.264706</td>\n",
       "      <td>0.118793</td>\n",
       "      <td>-0.002867</td>\n",
       "      <td>0.190098</td>\n",
       "      <td>-0.066417</td>\n",
       "      <td>0.197218</td>\n",
       "      <td>-0.155254</td>\n",
       "      <td>-0.019154</td>\n",
       "      <td>-0.107369</td>\n",
       "      <td>0.264374</td>\n",
       "      <td>0.264706</td>\n",
       "      <td>0.214958</td>\n",
       "      <td>0.196900</td>\n",
       "      <td>0.245780</td>\n",
       "      <td>0.199638</td>\n",
       "      <td>-0.041124</td>\n",
       "      <td>0.298688</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HKULiver_Post29wk_HCCAMCLiver_Left_Mice03_Slid...</td>\n",
       "      <td>0.162278</td>\n",
       "      <td>0.208302</td>\n",
       "      <td>-0.049377</td>\n",
       "      <td>0.145323</td>\n",
       "      <td>-0.064760</td>\n",
       "      <td>0.118803</td>\n",
       "      <td>-0.158031</td>\n",
       "      <td>0.138977</td>\n",
       "      <td>-0.065062</td>\n",
       "      <td>0.158361</td>\n",
       "      <td>0.162278</td>\n",
       "      <td>0.133026</td>\n",
       "      <td>0.183183</td>\n",
       "      <td>0.150113</td>\n",
       "      <td>0.094244</td>\n",
       "      <td>-0.041124</td>\n",
       "      <td>0.214619</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90955</th>\n",
       "      <td>HKULiver_Post29wk_HCCLiver_Left_Mice12_Slide4F...</td>\n",
       "      <td>0.021175</td>\n",
       "      <td>-0.289340</td>\n",
       "      <td>-0.057136</td>\n",
       "      <td>-0.066866</td>\n",
       "      <td>-0.037735</td>\n",
       "      <td>0.020800</td>\n",
       "      <td>-0.207775</td>\n",
       "      <td>0.241656</td>\n",
       "      <td>-0.174294</td>\n",
       "      <td>-0.257142</td>\n",
       "      <td>0.021175</td>\n",
       "      <td>0.037142</td>\n",
       "      <td>0.060526</td>\n",
       "      <td>0.034232</td>\n",
       "      <td>0.037630</td>\n",
       "      <td>0.212195</td>\n",
       "      <td>0.060493</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90956</th>\n",
       "      <td>HKULiver_Post29wk_HCCLiver_Left_Mice12_Slide4F...</td>\n",
       "      <td>0.007508</td>\n",
       "      <td>-0.289340</td>\n",
       "      <td>-0.152535</td>\n",
       "      <td>-0.066866</td>\n",
       "      <td>-0.074200</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>-0.090080</td>\n",
       "      <td>0.299395</td>\n",
       "      <td>-0.195733</td>\n",
       "      <td>0.144289</td>\n",
       "      <td>0.007508</td>\n",
       "      <td>0.044634</td>\n",
       "      <td>0.064259</td>\n",
       "      <td>0.036020</td>\n",
       "      <td>0.210084</td>\n",
       "      <td>0.134625</td>\n",
       "      <td>0.033504</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90957</th>\n",
       "      <td>HKULiver_Post29wk_HCCLiver_Left_Mice12_Slide4F...</td>\n",
       "      <td>0.016589</td>\n",
       "      <td>0.347700</td>\n",
       "      <td>-0.094148</td>\n",
       "      <td>-0.066866</td>\n",
       "      <td>-0.102274</td>\n",
       "      <td>0.050359</td>\n",
       "      <td>-0.070099</td>\n",
       "      <td>0.194703</td>\n",
       "      <td>-0.114568</td>\n",
       "      <td>-0.257142</td>\n",
       "      <td>0.016589</td>\n",
       "      <td>0.041114</td>\n",
       "      <td>0.095722</td>\n",
       "      <td>0.036409</td>\n",
       "      <td>0.142757</td>\n",
       "      <td>-0.041124</td>\n",
       "      <td>-0.057701</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90958</th>\n",
       "      <td>HKULiver_Post29wk_HCCLiver_Left_Mice12_Slide4F...</td>\n",
       "      <td>0.031206</td>\n",
       "      <td>-0.289340</td>\n",
       "      <td>-0.090194</td>\n",
       "      <td>-0.066866</td>\n",
       "      <td>-0.081719</td>\n",
       "      <td>0.027120</td>\n",
       "      <td>-0.055867</td>\n",
       "      <td>0.148581</td>\n",
       "      <td>-0.163662</td>\n",
       "      <td>-0.257142</td>\n",
       "      <td>0.031206</td>\n",
       "      <td>0.028236</td>\n",
       "      <td>0.055537</td>\n",
       "      <td>0.035391</td>\n",
       "      <td>0.188492</td>\n",
       "      <td>-0.041124</td>\n",
       "      <td>0.060124</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90959</th>\n",
       "      <td>HKULiver_Post29wk_HCCLiver_Left_Mice12_Slide4F...</td>\n",
       "      <td>0.003527</td>\n",
       "      <td>-0.289340</td>\n",
       "      <td>-0.182204</td>\n",
       "      <td>-0.066866</td>\n",
       "      <td>-0.188495</td>\n",
       "      <td>0.010275</td>\n",
       "      <td>-0.069131</td>\n",
       "      <td>0.100736</td>\n",
       "      <td>-0.231847</td>\n",
       "      <td>-0.257142</td>\n",
       "      <td>0.003527</td>\n",
       "      <td>0.036085</td>\n",
       "      <td>-0.068104</td>\n",
       "      <td>0.027788</td>\n",
       "      <td>0.177126</td>\n",
       "      <td>-0.041124</td>\n",
       "      <td>0.030121</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90960 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                pixel_id    311.15    269.25  \\\n",
       "0      HKULiver_Post29wk_HCCAMCLiver_Left_Mice03_Slid...  0.306614  0.155823   \n",
       "1      HKULiver_Post29wk_HCCAMCLiver_Left_Mice03_Slid...  0.426535  0.413081   \n",
       "2      HKULiver_Post29wk_HCCAMCLiver_Left_Mice03_Slid...  0.283540  0.172545   \n",
       "3      HKULiver_Post29wk_HCCAMCLiver_Left_Mice03_Slid...  0.264706  0.118793   \n",
       "4      HKULiver_Post29wk_HCCAMCLiver_Left_Mice03_Slid...  0.162278  0.208302   \n",
       "...                                                  ...       ...       ...   \n",
       "90955  HKULiver_Post29wk_HCCLiver_Left_Mice12_Slide4F...  0.021175 -0.289340   \n",
       "90956  HKULiver_Post29wk_HCCLiver_Left_Mice12_Slide4F...  0.007508 -0.289340   \n",
       "90957  HKULiver_Post29wk_HCCLiver_Left_Mice12_Slide4F...  0.016589  0.347700   \n",
       "90958  HKULiver_Post29wk_HCCLiver_Left_Mice12_Slide4F...  0.031206 -0.289340   \n",
       "90959  HKULiver_Post29wk_HCCLiver_Left_Mice12_Slide4F...  0.003527 -0.289340   \n",
       "\n",
       "          215.0     295.1    883.55     309.2    738.55     435.2    280.25  \\\n",
       "0     -0.014750  0.167718 -0.083734  0.256635 -0.155483  0.117061 -0.083208   \n",
       "1      0.099901  0.288114 -0.052378  0.340275 -0.127744  0.057160 -0.103060   \n",
       "2      0.049710  0.137600 -0.081307  0.200232 -0.162255 -0.030521 -0.088757   \n",
       "3     -0.002867  0.190098 -0.066417  0.197218 -0.155254 -0.019154 -0.107369   \n",
       "4     -0.049377  0.145323 -0.064760  0.118803 -0.158031  0.138977 -0.065062   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "90955 -0.057136 -0.066866 -0.037735  0.020800 -0.207775  0.241656 -0.174294   \n",
       "90956 -0.152535 -0.066866 -0.074200  0.032496 -0.090080  0.299395 -0.195733   \n",
       "90957 -0.094148 -0.066866 -0.102274  0.050359 -0.070099  0.194703 -0.114568   \n",
       "90958 -0.090194 -0.066866 -0.081719  0.027120 -0.055867  0.148581 -0.163662   \n",
       "90959 -0.182204 -0.066866 -0.188495  0.010275 -0.069131  0.100736 -0.231847   \n",
       "\n",
       "          241.1     311.2     339.1     353.2     325.2     250.1     514.3  \\\n",
       "0      0.218163  0.306614  0.224674  0.269023  0.292024  0.125619 -0.041124   \n",
       "1      0.283815  0.426535  0.306224  0.329107  0.397299  0.299930 -0.041124   \n",
       "2      0.202159  0.283540  0.223596  0.244158  0.266221  0.208253  0.104304   \n",
       "3      0.264374  0.264706  0.214958  0.196900  0.245780  0.199638 -0.041124   \n",
       "4      0.158361  0.162278  0.133026  0.183183  0.150113  0.094244 -0.041124   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "90955 -0.257142  0.021175  0.037142  0.060526  0.034232  0.037630  0.212195   \n",
       "90956  0.144289  0.007508  0.044634  0.064259  0.036020  0.210084  0.134625   \n",
       "90957 -0.257142  0.016589  0.041114  0.095722  0.036409  0.142757 -0.041124   \n",
       "90958 -0.257142  0.031206  0.028236  0.055537  0.035391  0.188492 -0.041124   \n",
       "90959 -0.257142  0.003527  0.036085 -0.068104  0.027788  0.177126 -0.041124   \n",
       "\n",
       "         265.05  type  \n",
       "0      0.319844     0  \n",
       "1      0.387575     0  \n",
       "2      0.310121     0  \n",
       "3      0.298688     0  \n",
       "4      0.214619     0  \n",
       "...         ...   ...  \n",
       "90955  0.060493     1  \n",
       "90956  0.033504     1  \n",
       "90957 -0.057701     1  \n",
       "90958  0.060124     1  \n",
       "90959  0.030121     1  \n",
       "\n",
       "[90960 rows x 19 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDEFSDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "558c10c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "can = []\n",
    "for i in list(range(0,9)) + list(range(15,17)) + [len(list(trainDEFSDf.columns))-1]:\n",
    "    can.append(list(trainDEFSDf.columns)[i])\n",
    "\n",
    "dican = []\n",
    "for i in list(range(0,9)) + list(range(15,17)) + [len(list(diDEFSDf.columns))-1]:\n",
    "    dican.append(list(diDEFSDf.columns)[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85c654ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pixel_id',\n",
       " '311.15',\n",
       " '269.25',\n",
       " '215.0',\n",
       " '295.1',\n",
       " '883.55',\n",
       " '309.2',\n",
       " '738.55',\n",
       " '435.2',\n",
       " '250.1',\n",
       " '514.3',\n",
       " 'type']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "can"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c5daef9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pixel_id',\n",
       " '311.2',\n",
       " '269.2',\n",
       " '215.0',\n",
       " '295.2',\n",
       " '883.6',\n",
       " '309.2',\n",
       " '738.6',\n",
       " '435.2',\n",
       " '250.1',\n",
       " '514.2',\n",
       " 'type']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dican"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d2530f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## input training set ## 90960 x 20 df\n",
    "trainDEFSDf = pd.read_csv(r\"H:\\\\3_output_raMSIn\\\\3_3_Output_raMSIn_HKU_Ingested4ALL\\\\XGB_ALL\\\\df_train_cbMSIn0d14nonInDI_norm.csv\")\n",
    "#trainDEFSDf[trainDEFSDf.type .== 1, :]\n",
    "## calculate weight ## 0: 47449, 1: 43511\n",
    "trainDEFSDf = trainDEFSDf[can]\n",
    "Yy_train = trainDEFSDf[\"type\"]  # 0.9585; 1.0453\n",
    "sampleW = []\n",
    "for w in Yy_train:\n",
    "    if w == 0:\n",
    "        sampleW.append(0.9585)\n",
    "    elif w == 1:\n",
    "        sampleW.append(1.0453) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26f6b926",
   "metadata": {},
   "outputs": [],
   "source": [
    "## input ext val set ## 6075 x 20 df\n",
    "extDEFSDf = pd.read_csv(r\"H:\\\\3_output_raMSIn\\\\3_3_Output_raMSIn_HKU_Ingested4ALL\\\\XGB_ALL\\\\df_ext_cbMSIn0d14nonInDI_norm.csv\")\n",
    "#extDEFSDf[extDEFSDf.type .== 1, :]\n",
    "## calculate weight ## 0: 2943, 1: 3132\n",
    "extDEFSDf = extDEFSDf[can]\n",
    "Yy_ext = extDEFSDf[\"type\"]  # 1.0321; 0.9698\n",
    "sampleExtW = []\n",
    "for w in Yy_ext:\n",
    "    if w == 0:\n",
    "        sampleExtW.append(1.0321)\n",
    "    elif w == 1:\n",
    "        sampleExtW.append(0.9698) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f13b3818",
   "metadata": {},
   "outputs": [],
   "source": [
    "## input ingested set ## 97035 x 20 df\n",
    "ingestedDEFSDf = pd.read_csv(r\"H:\\\\3_output_raMSIn\\\\3_3_Output_raMSIn_HKU_Ingested4ALL\\\\XGB_ALL\\\\df_ingested_cbMSIn0d14nonInDI_norm.csv\")\n",
    "#ingestedDEFSDf[extDEFSDf.type .== 1, :]\n",
    "## calculate weight ## 0: 50392, 1: 46643\n",
    "ingestedDEFSDf = ingestedDEFSDf[can]\n",
    "Yy_ingested = ingestedDEFSDf[\"type\"]  # 0.9628; 1.0402\n",
    "sampleIngestedW = []\n",
    "for w in Yy_ingested:\n",
    "    if w == 0:\n",
    "        sampleIngestedW.append(0.9628)\n",
    "    elif w == 1:\n",
    "        sampleIngestedW.append(1.0402)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a884cb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "## input FNA set ## 88701 x 20 df\n",
    "fnaDEFSDf = pd.read_csv(r\"H:\\\\3_output_raMSIn\\\\3_3_Output_raMSIn_HKU_Ingested4ALL\\\\XGB_ALL\\\\df_FNA_cbMSIn0d14nonInDI_norm.csv\")\n",
    "#fnaDEFSDf[fnaDEFSDf.type .== 1, :]\n",
    "## calculate weight ##  0: 44540, 1: 44161\n",
    "fnaDEFSDf = fnaDEFSDf[can]\n",
    "Yy_FNA = fnaDEFSDf[\"type\"]  # 0.9957; 1.0043\n",
    "sampleFNAW = []\n",
    "for w in Yy_FNA:\n",
    "    if w == 0:\n",
    "        sampleFNAW.append(0.9957)\n",
    "    elif w == 1:\n",
    "        sampleFNAW.append(1.0043)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b2cfbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## input DirectIn set ## 88701 x 20 df\n",
    "diDEFSDf = pd.read_csv(r\"H:\\\\3_output_raMSIn\\\\3_3_Output_raMSIn_HKU_Ingested4ALL\\\\XGB_ALL\\\\df_nonInDI_cbMSIn0d14nonInDI_norm.csv\")\n",
    "#diDEFSDf[diDEFSDf.type .== 1, :]\n",
    "## calculate weight ## 0: 3027, 1: 3030\n",
    "diDEFSDf = diDEFSDf[dican]\n",
    "diDEFSDf = diDEFSDf.rename(columns={\"311.2\": \"311.15\", \"269.2\":\"269.25\", \"295.2\":\"295.1\", \"883.6\":\"883.55\", \n",
    "                                    \"738.6\":\"738.55\", \"280.2\":\"280.25\", \n",
    "                                    \"339.2\":\"339.1\", \n",
    "                                    \"514.2\":\"514.3\", \"265.2\":\"265.05\"})\n",
    "Yy_DI = diDEFSDf[\"type\"]  # 1.0005; 0.9995\n",
    "sampleDiW = []\n",
    "for w in Yy_DI:\n",
    "    if w == 0:\n",
    "        sampleDiW.append(1.0005)\n",
    "    elif w == 1:\n",
    "        sampleDiW.append(0.9995)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95558b9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel_id</th>\n",
       "      <th>311.15</th>\n",
       "      <th>269.25</th>\n",
       "      <th>215.0</th>\n",
       "      <th>295.1</th>\n",
       "      <th>883.55</th>\n",
       "      <th>309.2</th>\n",
       "      <th>738.55</th>\n",
       "      <th>435.2</th>\n",
       "      <th>250.1</th>\n",
       "      <th>514.3</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HKULiver_Post29wk_HCCAMCLiver_DirectIn_MiceNL_...</td>\n",
       "      <td>-0.000522</td>\n",
       "      <td>-0.016303</td>\n",
       "      <td>0.027673</td>\n",
       "      <td>0.021522</td>\n",
       "      <td>0.045789</td>\n",
       "      <td>0.116087</td>\n",
       "      <td>0.061222</td>\n",
       "      <td>0.010616</td>\n",
       "      <td>0.437911</td>\n",
       "      <td>0.036473</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HKULiver_Post29wk_HCCAMCLiver_DirectIn_MiceNL_...</td>\n",
       "      <td>0.083005</td>\n",
       "      <td>0.027506</td>\n",
       "      <td>0.116839</td>\n",
       "      <td>0.031732</td>\n",
       "      <td>0.127053</td>\n",
       "      <td>0.216725</td>\n",
       "      <td>0.134751</td>\n",
       "      <td>0.003907</td>\n",
       "      <td>0.553596</td>\n",
       "      <td>0.099593</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HKULiver_Post29wk_HCCAMCLiver_DirectIn_MiceNL_...</td>\n",
       "      <td>0.025963</td>\n",
       "      <td>-0.010108</td>\n",
       "      <td>0.011686</td>\n",
       "      <td>-0.046683</td>\n",
       "      <td>0.118207</td>\n",
       "      <td>0.127443</td>\n",
       "      <td>0.028351</td>\n",
       "      <td>0.052377</td>\n",
       "      <td>0.434098</td>\n",
       "      <td>0.056801</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HKULiver_Post29wk_HCCAMCLiver_DirectIn_MiceNL_...</td>\n",
       "      <td>0.074431</td>\n",
       "      <td>0.087626</td>\n",
       "      <td>0.059979</td>\n",
       "      <td>0.071668</td>\n",
       "      <td>0.092430</td>\n",
       "      <td>0.203181</td>\n",
       "      <td>0.107481</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.520221</td>\n",
       "      <td>0.090314</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HKULiver_Post29wk_HCCAMCLiver_DirectIn_MiceNL_...</td>\n",
       "      <td>0.128189</td>\n",
       "      <td>0.110326</td>\n",
       "      <td>0.113772</td>\n",
       "      <td>0.132852</td>\n",
       "      <td>0.193001</td>\n",
       "      <td>0.280986</td>\n",
       "      <td>0.235611</td>\n",
       "      <td>0.124496</td>\n",
       "      <td>0.605425</td>\n",
       "      <td>0.147309</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6052</th>\n",
       "      <td>HKULiver_Post29wk_HCCLiver_DirectIn_MiceHCC_S1...</td>\n",
       "      <td>-0.005316</td>\n",
       "      <td>-0.009320</td>\n",
       "      <td>0.122463</td>\n",
       "      <td>-0.019665</td>\n",
       "      <td>0.019314</td>\n",
       "      <td>-0.015528</td>\n",
       "      <td>0.022632</td>\n",
       "      <td>0.150664</td>\n",
       "      <td>-0.037582</td>\n",
       "      <td>0.163243</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6053</th>\n",
       "      <td>HKULiver_Post29wk_HCCLiver_DirectIn_MiceHCC_S1...</td>\n",
       "      <td>-0.313499</td>\n",
       "      <td>-0.280980</td>\n",
       "      <td>-0.221368</td>\n",
       "      <td>-0.290503</td>\n",
       "      <td>-0.274617</td>\n",
       "      <td>-0.372822</td>\n",
       "      <td>-0.281165</td>\n",
       "      <td>-0.334752</td>\n",
       "      <td>-0.035654</td>\n",
       "      <td>-0.250800</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6054</th>\n",
       "      <td>HKULiver_Post29wk_HCCLiver_DirectIn_MiceHCC_S1...</td>\n",
       "      <td>-0.142502</td>\n",
       "      <td>-0.014532</td>\n",
       "      <td>0.041403</td>\n",
       "      <td>-0.055275</td>\n",
       "      <td>-0.066586</td>\n",
       "      <td>-0.108891</td>\n",
       "      <td>-0.085526</td>\n",
       "      <td>-0.066395</td>\n",
       "      <td>-0.129441</td>\n",
       "      <td>0.091504</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6055</th>\n",
       "      <td>HKULiver_Post29wk_HCCLiver_DirectIn_MiceHCC_S1...</td>\n",
       "      <td>-0.126710</td>\n",
       "      <td>-0.072820</td>\n",
       "      <td>0.097524</td>\n",
       "      <td>-0.092329</td>\n",
       "      <td>-0.003292</td>\n",
       "      <td>-0.106890</td>\n",
       "      <td>-0.069614</td>\n",
       "      <td>-0.061199</td>\n",
       "      <td>0.005436</td>\n",
       "      <td>-0.018064</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6056</th>\n",
       "      <td>HKULiver_Post29wk_HCCLiver_DirectIn_MiceHCC_S1...</td>\n",
       "      <td>-0.378286</td>\n",
       "      <td>-0.383749</td>\n",
       "      <td>-0.356742</td>\n",
       "      <td>-0.403914</td>\n",
       "      <td>-0.274617</td>\n",
       "      <td>-0.449901</td>\n",
       "      <td>-0.281165</td>\n",
       "      <td>-0.334752</td>\n",
       "      <td>-0.065833</td>\n",
       "      <td>-0.312463</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6057 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               pixel_id    311.15    269.25  \\\n",
       "0     HKULiver_Post29wk_HCCAMCLiver_DirectIn_MiceNL_... -0.000522 -0.016303   \n",
       "1     HKULiver_Post29wk_HCCAMCLiver_DirectIn_MiceNL_...  0.083005  0.027506   \n",
       "2     HKULiver_Post29wk_HCCAMCLiver_DirectIn_MiceNL_...  0.025963 -0.010108   \n",
       "3     HKULiver_Post29wk_HCCAMCLiver_DirectIn_MiceNL_...  0.074431  0.087626   \n",
       "4     HKULiver_Post29wk_HCCAMCLiver_DirectIn_MiceNL_...  0.128189  0.110326   \n",
       "...                                                 ...       ...       ...   \n",
       "6052  HKULiver_Post29wk_HCCLiver_DirectIn_MiceHCC_S1... -0.005316 -0.009320   \n",
       "6053  HKULiver_Post29wk_HCCLiver_DirectIn_MiceHCC_S1... -0.313499 -0.280980   \n",
       "6054  HKULiver_Post29wk_HCCLiver_DirectIn_MiceHCC_S1... -0.142502 -0.014532   \n",
       "6055  HKULiver_Post29wk_HCCLiver_DirectIn_MiceHCC_S1... -0.126710 -0.072820   \n",
       "6056  HKULiver_Post29wk_HCCLiver_DirectIn_MiceHCC_S1... -0.378286 -0.383749   \n",
       "\n",
       "         215.0     295.1    883.55     309.2    738.55     435.2     250.1  \\\n",
       "0     0.027673  0.021522  0.045789  0.116087  0.061222  0.010616  0.437911   \n",
       "1     0.116839  0.031732  0.127053  0.216725  0.134751  0.003907  0.553596   \n",
       "2     0.011686 -0.046683  0.118207  0.127443  0.028351  0.052377  0.434098   \n",
       "3     0.059979  0.071668  0.092430  0.203181  0.107481  0.083333  0.520221   \n",
       "4     0.113772  0.132852  0.193001  0.280986  0.235611  0.124496  0.605425   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "6052  0.122463 -0.019665  0.019314 -0.015528  0.022632  0.150664 -0.037582   \n",
       "6053 -0.221368 -0.290503 -0.274617 -0.372822 -0.281165 -0.334752 -0.035654   \n",
       "6054  0.041403 -0.055275 -0.066586 -0.108891 -0.085526 -0.066395 -0.129441   \n",
       "6055  0.097524 -0.092329 -0.003292 -0.106890 -0.069614 -0.061199  0.005436   \n",
       "6056 -0.356742 -0.403914 -0.274617 -0.449901 -0.281165 -0.334752 -0.065833   \n",
       "\n",
       "         514.3  type  \n",
       "0     0.036473     0  \n",
       "1     0.099593     0  \n",
       "2     0.056801     0  \n",
       "3     0.090314     0  \n",
       "4     0.147309     0  \n",
       "...        ...   ...  \n",
       "6052  0.163243     1  \n",
       "6053 -0.250800     1  \n",
       "6054  0.091504     1  \n",
       "6055 -0.018064     1  \n",
       "6056 -0.312463     1  \n",
       "\n",
       "[6057 rows x 12 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diDEFSDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca171d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "## define functions for performace evaluation ##\n",
    "\n",
    "# Average score\n",
    "def avgScore(arrAcc, cv):\n",
    "    sumAcc = 0\n",
    "    for acc in arrAcc:\n",
    "        sumAcc += acc\n",
    "    return sumAcc / cv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ccef0bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>311.15</th>\n",
       "      <th>269.25</th>\n",
       "      <th>215.0</th>\n",
       "      <th>295.1</th>\n",
       "      <th>883.55</th>\n",
       "      <th>309.2</th>\n",
       "      <th>738.55</th>\n",
       "      <th>435.2</th>\n",
       "      <th>250.1</th>\n",
       "      <th>514.3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.306614</td>\n",
       "      <td>0.155823</td>\n",
       "      <td>-0.014750</td>\n",
       "      <td>0.167718</td>\n",
       "      <td>-0.083734</td>\n",
       "      <td>0.256635</td>\n",
       "      <td>-0.155483</td>\n",
       "      <td>0.117061</td>\n",
       "      <td>0.125619</td>\n",
       "      <td>-0.041124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.426535</td>\n",
       "      <td>0.413081</td>\n",
       "      <td>0.099901</td>\n",
       "      <td>0.288114</td>\n",
       "      <td>-0.052378</td>\n",
       "      <td>0.340275</td>\n",
       "      <td>-0.127744</td>\n",
       "      <td>0.057160</td>\n",
       "      <td>0.299930</td>\n",
       "      <td>-0.041124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.283540</td>\n",
       "      <td>0.172545</td>\n",
       "      <td>0.049710</td>\n",
       "      <td>0.137600</td>\n",
       "      <td>-0.081307</td>\n",
       "      <td>0.200232</td>\n",
       "      <td>-0.162255</td>\n",
       "      <td>-0.030521</td>\n",
       "      <td>0.208253</td>\n",
       "      <td>0.104304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.264706</td>\n",
       "      <td>0.118793</td>\n",
       "      <td>-0.002867</td>\n",
       "      <td>0.190098</td>\n",
       "      <td>-0.066417</td>\n",
       "      <td>0.197218</td>\n",
       "      <td>-0.155254</td>\n",
       "      <td>-0.019154</td>\n",
       "      <td>0.199638</td>\n",
       "      <td>-0.041124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.162278</td>\n",
       "      <td>0.208302</td>\n",
       "      <td>-0.049377</td>\n",
       "      <td>0.145323</td>\n",
       "      <td>-0.064760</td>\n",
       "      <td>0.118803</td>\n",
       "      <td>-0.158031</td>\n",
       "      <td>0.138977</td>\n",
       "      <td>0.094244</td>\n",
       "      <td>-0.041124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90955</th>\n",
       "      <td>0.021175</td>\n",
       "      <td>-0.289340</td>\n",
       "      <td>-0.057136</td>\n",
       "      <td>-0.066866</td>\n",
       "      <td>-0.037735</td>\n",
       "      <td>0.020800</td>\n",
       "      <td>-0.207775</td>\n",
       "      <td>0.241656</td>\n",
       "      <td>0.037630</td>\n",
       "      <td>0.212195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90956</th>\n",
       "      <td>0.007508</td>\n",
       "      <td>-0.289340</td>\n",
       "      <td>-0.152535</td>\n",
       "      <td>-0.066866</td>\n",
       "      <td>-0.074200</td>\n",
       "      <td>0.032496</td>\n",
       "      <td>-0.090080</td>\n",
       "      <td>0.299395</td>\n",
       "      <td>0.210084</td>\n",
       "      <td>0.134625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90957</th>\n",
       "      <td>0.016589</td>\n",
       "      <td>0.347700</td>\n",
       "      <td>-0.094148</td>\n",
       "      <td>-0.066866</td>\n",
       "      <td>-0.102274</td>\n",
       "      <td>0.050359</td>\n",
       "      <td>-0.070099</td>\n",
       "      <td>0.194703</td>\n",
       "      <td>0.142757</td>\n",
       "      <td>-0.041124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90958</th>\n",
       "      <td>0.031206</td>\n",
       "      <td>-0.289340</td>\n",
       "      <td>-0.090194</td>\n",
       "      <td>-0.066866</td>\n",
       "      <td>-0.081719</td>\n",
       "      <td>0.027120</td>\n",
       "      <td>-0.055867</td>\n",
       "      <td>0.148581</td>\n",
       "      <td>0.188492</td>\n",
       "      <td>-0.041124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90959</th>\n",
       "      <td>0.003527</td>\n",
       "      <td>-0.289340</td>\n",
       "      <td>-0.182204</td>\n",
       "      <td>-0.066866</td>\n",
       "      <td>-0.188495</td>\n",
       "      <td>0.010275</td>\n",
       "      <td>-0.069131</td>\n",
       "      <td>0.100736</td>\n",
       "      <td>0.177126</td>\n",
       "      <td>-0.041124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90960 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         311.15    269.25     215.0     295.1    883.55     309.2    738.55  \\\n",
       "0      0.306614  0.155823 -0.014750  0.167718 -0.083734  0.256635 -0.155483   \n",
       "1      0.426535  0.413081  0.099901  0.288114 -0.052378  0.340275 -0.127744   \n",
       "2      0.283540  0.172545  0.049710  0.137600 -0.081307  0.200232 -0.162255   \n",
       "3      0.264706  0.118793 -0.002867  0.190098 -0.066417  0.197218 -0.155254   \n",
       "4      0.162278  0.208302 -0.049377  0.145323 -0.064760  0.118803 -0.158031   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "90955  0.021175 -0.289340 -0.057136 -0.066866 -0.037735  0.020800 -0.207775   \n",
       "90956  0.007508 -0.289340 -0.152535 -0.066866 -0.074200  0.032496 -0.090080   \n",
       "90957  0.016589  0.347700 -0.094148 -0.066866 -0.102274  0.050359 -0.070099   \n",
       "90958  0.031206 -0.289340 -0.090194 -0.066866 -0.081719  0.027120 -0.055867   \n",
       "90959  0.003527 -0.289340 -0.182204 -0.066866 -0.188495  0.010275 -0.069131   \n",
       "\n",
       "          435.2     250.1     514.3  \n",
       "0      0.117061  0.125619 -0.041124  \n",
       "1      0.057160  0.299930 -0.041124  \n",
       "2     -0.030521  0.208253  0.104304  \n",
       "3     -0.019154  0.199638 -0.041124  \n",
       "4      0.138977  0.094244 -0.041124  \n",
       "...         ...       ...       ...  \n",
       "90955  0.241656  0.037630  0.212195  \n",
       "90956  0.299395  0.210084  0.134625  \n",
       "90957  0.194703  0.142757 -0.041124  \n",
       "90958  0.148581  0.188492 -0.041124  \n",
       "90959  0.100736  0.177126 -0.041124  \n",
       "\n",
       "[90960 rows x 10 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDEFSDf[trainDEFSDf.columns[1:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ff9f9ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c56eae",
   "metadata": {},
   "source": [
    "# 2. Unsupervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8049959",
   "metadata": {},
   "source": [
    "## 2.1. Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "56926254",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 720x720 with 0 Axes>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from matplotlib.pyplot import figure\n",
    "plt.rcParams['figure.figsize'] = [10, 10]\n",
    "plt.grid(visible=None)\n",
    "plt.close()\n",
    "figure(figsize=(10, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "62a3d9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ROI_for_ML_Opti = pd.concat([trainDEFSDf, extDEFSDf, fnaDEFSDf, diDEFSDf]).set_index('pixel_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e9061d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ROI_for_ML_Opti_ingested = ingestedDEFSDf.set_index('pixel_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7d1ef236",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ROI_for_ML_Opti_train = trainDEFSDf.set_index('pixel_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f9f05550",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ROI_for_ML_Opti_ext = extDEFSDf.set_index('pixel_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0dfe922b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ROI_for_ML_Opti_FNA = fnaDEFSDf.set_index('pixel_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f17e49c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ROI_for_ML_Opti_di = diDEFSDf.set_index('pixel_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9c15f5e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>311.15</th>\n",
       "      <th>269.25</th>\n",
       "      <th>215.0</th>\n",
       "      <th>295.1</th>\n",
       "      <th>883.55</th>\n",
       "      <th>309.2</th>\n",
       "      <th>738.55</th>\n",
       "      <th>435.2</th>\n",
       "      <th>250.1</th>\n",
       "      <th>514.3</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6.057000e+03</td>\n",
       "      <td>6.057000e+03</td>\n",
       "      <td>6.057000e+03</td>\n",
       "      <td>6.057000e+03</td>\n",
       "      <td>6.057000e+03</td>\n",
       "      <td>6.057000e+03</td>\n",
       "      <td>6.057000e+03</td>\n",
       "      <td>6.057000e+03</td>\n",
       "      <td>6.057000e+03</td>\n",
       "      <td>6.057000e+03</td>\n",
       "      <td>6057.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-4.303787e-17</td>\n",
       "      <td>6.686633e-17</td>\n",
       "      <td>-1.367845e-16</td>\n",
       "      <td>-1.968598e-17</td>\n",
       "      <td>-8.858689e-17</td>\n",
       "      <td>1.546376e-16</td>\n",
       "      <td>7.654435e-17</td>\n",
       "      <td>-6.484091e-17</td>\n",
       "      <td>5.154738e-16</td>\n",
       "      <td>-5.315580e-19</td>\n",
       "      <td>0.500248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.244602e-01</td>\n",
       "      <td>1.225812e-01</td>\n",
       "      <td>1.425257e-01</td>\n",
       "      <td>1.355446e-01</td>\n",
       "      <td>1.755429e-01</td>\n",
       "      <td>1.525340e-01</td>\n",
       "      <td>1.278292e-01</td>\n",
       "      <td>1.785266e-01</td>\n",
       "      <td>1.882975e-01</td>\n",
       "      <td>1.329823e-01</td>\n",
       "      <td>0.500041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-4.080066e-01</td>\n",
       "      <td>-4.162738e-01</td>\n",
       "      <td>-3.567420e-01</td>\n",
       "      <td>-4.723469e-01</td>\n",
       "      <td>-2.746170e-01</td>\n",
       "      <td>-4.499012e-01</td>\n",
       "      <td>-2.811650e-01</td>\n",
       "      <td>-3.347515e-01</td>\n",
       "      <td>-1.294412e-01</td>\n",
       "      <td>-3.328045e-01</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-7.203839e-02</td>\n",
       "      <td>-4.670358e-02</td>\n",
       "      <td>-7.034140e-02</td>\n",
       "      <td>-5.548548e-02</td>\n",
       "      <td>-9.740304e-02</td>\n",
       "      <td>-6.680087e-02</td>\n",
       "      <td>-6.020093e-02</td>\n",
       "      <td>-1.225706e-01</td>\n",
       "      <td>-1.294412e-01</td>\n",
       "      <td>-6.636153e-02</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.038792e-02</td>\n",
       "      <td>1.566504e-02</td>\n",
       "      <td>9.645582e-03</td>\n",
       "      <td>1.623459e-02</td>\n",
       "      <td>2.527424e-02</td>\n",
       "      <td>-7.133968e-03</td>\n",
       "      <td>1.495291e-02</td>\n",
       "      <td>-7.940668e-03</td>\n",
       "      <td>-3.531219e-02</td>\n",
       "      <td>-1.855730e-02</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.697130e-02</td>\n",
       "      <td>7.564939e-02</td>\n",
       "      <td>8.470268e-02</td>\n",
       "      <td>7.445151e-02</td>\n",
       "      <td>1.230419e-01</td>\n",
       "      <td>5.221173e-02</td>\n",
       "      <td>6.986257e-02</td>\n",
       "      <td>1.154688e-01</td>\n",
       "      <td>1.845510e-02</td>\n",
       "      <td>8.936343e-02</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.919934e-01</td>\n",
       "      <td>5.837262e-01</td>\n",
       "      <td>6.432580e-01</td>\n",
       "      <td>5.276531e-01</td>\n",
       "      <td>7.253830e-01</td>\n",
       "      <td>5.500988e-01</td>\n",
       "      <td>7.188350e-01</td>\n",
       "      <td>6.652485e-01</td>\n",
       "      <td>8.705588e-01</td>\n",
       "      <td>6.671955e-01</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             311.15        269.25         215.0         295.1        883.55  \\\n",
       "count  6.057000e+03  6.057000e+03  6.057000e+03  6.057000e+03  6.057000e+03   \n",
       "mean  -4.303787e-17  6.686633e-17 -1.367845e-16 -1.968598e-17 -8.858689e-17   \n",
       "std    1.244602e-01  1.225812e-01  1.425257e-01  1.355446e-01  1.755429e-01   \n",
       "min   -4.080066e-01 -4.162738e-01 -3.567420e-01 -4.723469e-01 -2.746170e-01   \n",
       "25%   -7.203839e-02 -4.670358e-02 -7.034140e-02 -5.548548e-02 -9.740304e-02   \n",
       "50%    1.038792e-02  1.566504e-02  9.645582e-03  1.623459e-02  2.527424e-02   \n",
       "75%    8.697130e-02  7.564939e-02  8.470268e-02  7.445151e-02  1.230419e-01   \n",
       "max    5.919934e-01  5.837262e-01  6.432580e-01  5.276531e-01  7.253830e-01   \n",
       "\n",
       "              309.2        738.55         435.2         250.1         514.3  \\\n",
       "count  6.057000e+03  6.057000e+03  6.057000e+03  6.057000e+03  6.057000e+03   \n",
       "mean   1.546376e-16  7.654435e-17 -6.484091e-17  5.154738e-16 -5.315580e-19   \n",
       "std    1.525340e-01  1.278292e-01  1.785266e-01  1.882975e-01  1.329823e-01   \n",
       "min   -4.499012e-01 -2.811650e-01 -3.347515e-01 -1.294412e-01 -3.328045e-01   \n",
       "25%   -6.680087e-02 -6.020093e-02 -1.225706e-01 -1.294412e-01 -6.636153e-02   \n",
       "50%   -7.133968e-03  1.495291e-02 -7.940668e-03 -3.531219e-02 -1.855730e-02   \n",
       "75%    5.221173e-02  6.986257e-02  1.154688e-01  1.845510e-02  8.936343e-02   \n",
       "max    5.500988e-01  7.188350e-01  6.652485e-01  8.705588e-01  6.671955e-01   \n",
       "\n",
       "              type  \n",
       "count  6057.000000  \n",
       "mean      0.500248  \n",
       "std       0.500041  \n",
       "min       0.000000  \n",
       "25%       0.000000  \n",
       "50%       1.000000  \n",
       "75%       1.000000  \n",
       "max       1.000000  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ROI_for_ML_Opti_di.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c25aab6",
   "metadata": {},
   "source": [
    "## 2.2. PCA Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e9735181",
   "metadata": {},
   "outputs": [],
   "source": [
    "## PCA Analysis\n",
    "\n",
    "def pca_visual(df=df_ROI_for_ML_Opti_di):\n",
    "\n",
    "    pca = PCA(n_components=3)\n",
    "    raMSI_ML_mz_df = df.drop(\"type\", axis = 1)\n",
    "    pca.fit(raMSI_ML_mz_df)\n",
    "    result = pd.DataFrame(pca.transform(raMSI_ML_mz_df), columns=['PCA%i' % i for i in range(3)], index=df_ROI_for_ML_Opti_di.index)\n",
    "    \n",
    "    plt.subplots(dpi = 300)\n",
    "    plt.scatter(result['PCA1'], result['PCA2'], c = df['type'], s=1)\n",
    "    plt.xlabel('PC1', size=20)\n",
    "    plt.ylabel('PC2', size=20)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    plt.savefig(r\"H:/3_output_raMSIn/3_3_Output_raMSIn_HKU_Ingested4ALL/XGB_ALL/afterModelSelection/cbMSIn_0d1/PCA_di.tif\", bbox_inches = 'tight')\n",
    "\n",
    "    components = pca.fit_transform(raMSI_ML_mz_df)\n",
    "    total_var = pca.explained_variance_ratio_.sum() * 100\n",
    "    fig = px.scatter_3d(\n",
    "        components, x=0, y=1, z=2, color=df['type'],\n",
    "        title = f'Total Explained Variance: {total_var:.2f}%',\n",
    "        labels = {'0': 'PC 1', '1': 'PC 2', '2': 'PC 3'}\n",
    "    )\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fff2e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_visual()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a0c5f5",
   "metadata": {},
   "source": [
    "# 3. Supervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cdf76b0",
   "metadata": {},
   "source": [
    "## 3.1. Preparation of training and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a9518fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(df=df_ROI_for_ML_Opti_ingested):\n",
    "    raMSI_ML_NoType = df.drop(\"type\", axis = 1)\n",
    "    raMSI_ML_Type=df[['type']]\n",
    "    X_train,X_test,y_train,y_test=train_test_split(raMSI_ML_NoType,raMSI_ML_Type,test_size=0.2,random_state=42)\n",
    "    return X_train,X_test,y_train,y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7a5146",
   "metadata": {},
   "source": [
    "X_train,X_test,y_train,y_test=split_dataset(df=df_ROI_for_ML_Opti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "92b9ff22",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ingested = df_ROI_for_ML_Opti_ingested[df_ROI_for_ML_Opti_ingested.columns[:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "071b9d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ingested = df_ROI_for_ML_Opti_ingested[df_ROI_for_ML_Opti_ingested.columns[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "78235c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_ROI_for_ML_Opti_train[df_ROI_for_ML_Opti_train.columns[:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "226a001d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_ROI_for_ML_Opti_train[df_ROI_for_ML_Opti_train.columns[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "21066a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = df_ROI_for_ML_Opti_ext[df_ROI_for_ML_Opti_ext.columns[:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "375fd7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val = df_ROI_for_ML_Opti_ext[df_ROI_for_ML_Opti_ext.columns[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "460faa79",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_FNA = df_ROI_for_ML_Opti_FNA[df_ROI_for_ML_Opti_FNA.columns[:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dd2eede7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_FNA = df_ROI_for_ML_Opti_FNA[df_ROI_for_ML_Opti_FNA.columns[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c1e0ca85",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_di = df_ROI_for_ML_Opti_di[df_ROI_for_ML_Opti_di.columns[:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3529c5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_di = df_ROI_for_ML_Opti_di[df_ROI_for_ML_Opti_di.columns[-1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02cd4f6d",
   "metadata": {},
   "source": [
    "## 3.2 Machine Learning Modeling: Model 1+2 (Train 10:10, Val 4:4, Test 3:3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6d458bee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 720x720 with 0 Axes>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from matplotlib.pyplot import figure\n",
    "plt.rcParams['figure.figsize'] = [10, 10]\n",
    "plt.grid(visible=None)\n",
    "plt.close()\n",
    "figure(figsize=(10, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462143af",
   "metadata": {},
   "source": [
    "### 3.2.1. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2bdf27e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build Logistic Regression Model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def LogisticRegression_func(XTrain=X_ingested, XVal=X_val, XTest=X_FNA, yTrain=y_ingested, yVal=y_val, yTest=y_FNA):\n",
    "    model_lr = LogisticRegression(C=0.001, penalty='l1', solver=\"liblinear\", max_iter=5000, random_state=42, class_weight={0:0.9628, 1:1.0402})  # max_iter=100\n",
    "    model_lr.fit(XTrain,yTrain)\n",
    "    \n",
    "    # Training Set\n",
    "    #plt.rcParams[\"figure.figsize\"] = (3,3)\n",
    "    X_train_predictions = model_lr.predict(X_train)\n",
    "    print(\"Training Set F1:\", f1_score(y_train, model_lr.predict(X_train), sample_weight=sampleW))\n",
    "    print(\"Training Set MCC:\", matthews_corrcoef(y_train, model_lr.predict(X_train), sample_weight=sampleW))\n",
    "    print(\"Training Set Accuracy:\", metrics.accuracy_score(y_train, X_train_predictions))\n",
    "    print(classification_report(y_train, X_train_predictions))\n",
    "    print(confusion_matrix(y_train, X_train_predictions))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr, tpr, _ = metrics.roc_curve(y_train, X_train_predictions)\n",
    "    plt.plot(fpr,tpr)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_train.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    # Val set\n",
    "    predictions_val  = model_lr.predict(XVal)\n",
    "    print(\"Ext Val Set F1:\", f1_score(yVal, model_lr.predict(XVal), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set MCC:\", matthews_corrcoef(yVal, model_lr.predict(XVal), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set Accuracy:\", metrics.accuracy_score(yVal, predictions_val))\n",
    "    print(classification_report(yVal, predictions_val))\n",
    "    print(confusion_matrix(yVal, predictions_val))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_val, tpr_val, _ = metrics.roc_curve(yVal, predictions_val)\n",
    "    plt.plot(fpr_val,tpr_val)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_test.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    f1_5_train = cross_val_score(model_lr, XTrain, yTrain, cv = 5, scoring=\"f1\")\n",
    "    print(\"5F-CV:\", avgScore(f1_5_train, 5))\n",
    "    \n",
    "    # Test set\n",
    "    predictions_FNA = model_lr.predict(XTest)\n",
    "    print(\"FNA Set F1:\", f1_score(yTest, model_lr.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set MCC:\", matthews_corrcoef(yTest, model_lr.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set Recall:\", recall_score(yTest, model_lr.predict(XTest)))\n",
    "    print(\"FNA Test Set Accuracy:\", metrics.accuracy_score(yTest, predictions_FNA))\n",
    "    print(classification_report(yTest, predictions_FNA))\n",
    "    print(confusion_matrix(yTest, predictions_FNA))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_FNA, tpr_FNA, _ = metrics.roc_curve(yTest, predictions_FNA)\n",
    "    plt.plot(fpr_FNA,tpr_FNA)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"G:/raMSIn/XGB_Importance2/XGB2_ROC_FNAtest2.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    # Visualize the importantance of the features\n",
    "    feature_imp = pd.Series(model_lr.coef_[0], index=XTrain.columns).sort_values(ascending=False)\n",
    "    x=feature_imp\n",
    "    y=feature_imp.index\n",
    "    \n",
    "    plt.subplots(dpi = 300)\n",
    "    #plt.rcParams[\"figure.figsize\"] = [4, 6]\n",
    "    #plt.rcParams[\"font.family\"] = \"Arial\"\n",
    "    #plt.rcParams.update({'font.size': 6})\n",
    "    plt.xlabel('Feature Importance Score', fontproperties='Arial', fontsize=17)\n",
    "    plt.ylabel('Features', fontproperties='Arial', fontsize=17)\n",
    "    plt.xticks(fontsize=15)\n",
    "    plt.yticks(fontsize=15)\n",
    "    plt.title(\"Important Molecular Features\", fontproperties='Arial', fontsize=20)\n",
    "    sns.barplot(x=feature_imp, y=feature_imp.index)\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_TopFeatures.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    #feature_importances = model_lr.coef_[0]\n",
    "    #feature_df=pd.DataFrame({'m/z':XTrain.columns,'coef':feature_importances})\n",
    "\n",
    "    #fig = px.bar(feature_df, x='coef', y='m/z')\n",
    "    #fig.show()\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e4810838",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set F1: 0.8408210677463104\n",
      "Training Set MCC: 0.6836806332505082\n",
      "Training Set Accuracy: 0.8420844327176781\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.85      0.85     47449\n",
      "           1       0.83      0.84      0.84     43511\n",
      "\n",
      "    accuracy                           0.84     90960\n",
      "   macro avg       0.84      0.84      0.84     90960\n",
      "weighted avg       0.84      0.84      0.84     90960\n",
      "\n",
      "[[40240  7209]\n",
      " [ 7155 36356]]\n",
      "Ext Val Set F1: 0.7663903187532383\n",
      "Ext Val Set MCC: 0.4917921638077761\n",
      "Ext Val Set Accuracy: 0.7427160493827161\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.62      0.70      2943\n",
      "           1       0.71      0.86      0.77      3132\n",
      "\n",
      "    accuracy                           0.74      6075\n",
      "   macro avg       0.75      0.74      0.74      6075\n",
      "weighted avg       0.75      0.74      0.74      6075\n",
      "\n",
      "[[1831 1112]\n",
      " [ 451 2681]]\n",
      "5F-CV: 0.5934811363879445\n",
      "FNA Set F1: 0.8023948911234491\n",
      "FNA Set MCC: 0.6068015381993419\n",
      "FNA Set Recall: 0.7983514866058287\n",
      "FNA Test Set Accuracy: 0.803406951443614\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81     44540\n",
      "           1       0.81      0.80      0.80     44161\n",
      "\n",
      "    accuracy                           0.80     88701\n",
      "   macro avg       0.80      0.80      0.80     88701\n",
      "weighted avg       0.80      0.80      0.80     88701\n",
      "\n",
      "[[36007  8533]\n",
      " [ 8905 35256]]\n"
     ]
    }
   ],
   "source": [
    "coeff_LogReg, TOPfeatures_LogReg = LogisticRegression_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b7a08c",
   "metadata": {},
   "source": [
    "### 3.2.2. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "aab84224",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build LinearSVC Model\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "def LinearSVC_func(XTrain=X_ingested, XVal=X_val, XTest=X_FNA, yTrain=y_ingested, yVal=y_val, yTest=y_FNA):\n",
    "    model_svm = LinearSVC(penalty='l2', loss=\"squared_hinge\", C=461, random_state=42, class_weight={0:0.9628, 1:1.0402})\n",
    "    model_svm.fit(XTrain,yTrain)\n",
    "    \n",
    "    # Training Set\n",
    "    #plt.rcParams[\"figure.figsize\"] = (3,3)\n",
    "    X_train_predictions = model_svm.predict(X_train)\n",
    "    print(\"Training Set F1:\", f1_score(y_train, model_svm.predict(X_train), sample_weight=sampleW))\n",
    "    print(\"Training Set MCC:\", matthews_corrcoef(y_train, model_svm.predict(X_train), sample_weight=sampleW))\n",
    "    print(\"Training Set Accuracy:\", metrics.accuracy_score(y_train, X_train_predictions))\n",
    "    print(classification_report(y_train, X_train_predictions))\n",
    "    print(confusion_matrix(y_train, X_train_predictions))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr, tpr, _ = metrics.roc_curve(y_train, X_train_predictions)\n",
    "    plt.plot(fpr,tpr)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_train.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    # Val set\n",
    "    predictions_val  = model_svm.predict(XVal)\n",
    "    print(\"Ext Val Set F1:\", f1_score(yVal, model_svm.predict(XVal), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set MCC:\", matthews_corrcoef(yVal, model_svm.predict(XVal), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set Accuracy:\", metrics.accuracy_score(yVal, predictions_val))\n",
    "    print(classification_report(yVal, predictions_val))\n",
    "    print(confusion_matrix(yVal, predictions_val))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_val, tpr_val, _ = metrics.roc_curve(yVal, predictions_val)\n",
    "    plt.plot(fpr_val,tpr_val)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_test.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    f1_5_train = cross_val_score(model_svm, XTrain, yTrain, cv = 5, scoring=\"f1\")\n",
    "    print(\"5F-CV:\", avgScore(f1_5_train, 5))\n",
    "    \n",
    "    # Test set\n",
    "    predictions_FNA = model_svm.predict(XTest)\n",
    "    print(\"FNA Set F1:\", f1_score(yTest, model_svm.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set MCC:\", matthews_corrcoef(yTest, model_svm.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set Recall:\", recall_score(yTest, model_svm.predict(XTest)))\n",
    "    print(\"FNA Test Set Accuracy:\", metrics.accuracy_score(yTest, predictions_FNA))\n",
    "    print(classification_report(yTest, predictions_FNA))\n",
    "    print(confusion_matrix(yTest, predictions_FNA))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_FNA, tpr_FNA, _ = metrics.roc_curve(yTest, predictions_FNA)\n",
    "    plt.plot(fpr_FNA,tpr_FNA)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"G:/raMSIn/XGB_Importance2/XGB2_ROC_FNAtest2.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    # Visualize the importantance of the features\n",
    "    feature_imp = pd.Series(model_svm.coef_[0], index=XTrain.columns).sort_values(ascending=False)\n",
    "    x=feature_imp\n",
    "    y=feature_imp.index\n",
    "    \n",
    "    plt.subplots(dpi = 300)\n",
    "    #plt.rcParams[\"figure.figsize\"] = [4, 6]\n",
    "    #plt.rcParams[\"font.family\"] = \"Arial\"\n",
    "    #plt.rcParams.update({'font.size': 6})\n",
    "    plt.xlabel('Feature Importance Score', fontproperties='Arial', fontsize=17)\n",
    "    plt.ylabel('Features', fontproperties='Arial', fontsize=17)\n",
    "    plt.xticks(fontsize=15)\n",
    "    plt.yticks(fontsize=15)\n",
    "    plt.title(\"Important Molecular Features\", fontproperties='Arial', fontsize=20)\n",
    "    sns.barplot(x=feature_imp, y=feature_imp.index)\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_TopFeatures.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    #feature_importances = model_svm.coef_[0]\n",
    "    #feature_df=pd.DataFrame({'m/z':XTrain.columns,'coef':feature_importances})\n",
    "\n",
    "    #fig = px.bar(feature_df, x='coef', y='m/z')\n",
    "    #fig.show()\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "78a85b62",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set F1: 0.8625276945774187\n",
      "Training Set MCC: 0.7222981688430185\n",
      "Training Set Accuracy: 0.8606090589270009\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.85      0.86     47449\n",
      "           1       0.84      0.87      0.86     43511\n",
      "\n",
      "    accuracy                           0.86     90960\n",
      "   macro avg       0.86      0.86      0.86     90960\n",
      "weighted avg       0.86      0.86      0.86     90960\n",
      "\n",
      "[[40354  7095]\n",
      " [ 5584 37927]]\n",
      "Ext Val Set F1: 0.7002656056685465\n",
      "Ext Val Set MCC: 0.3343660885401798\n",
      "Ext Val Set Accuracy: 0.665514403292181\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.53      0.61      2943\n",
      "           1       0.64      0.79      0.71      3132\n",
      "\n",
      "    accuracy                           0.67      6075\n",
      "   macro avg       0.67      0.66      0.66      6075\n",
      "weighted avg       0.67      0.67      0.66      6075\n",
      "\n",
      "[[1566 1377]\n",
      " [ 655 2477]]\n",
      "5F-CV: 0.818769918713504\n",
      "FNA Set F1: 0.7307993360907897\n",
      "FNA Set MCC: 0.419444631748827\n",
      "FNA Set Recall: 0.7975815765041553\n",
      "FNA Test Set Accuracy: 0.7057981307989764\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.61      0.68     44540\n",
      "           1       0.67      0.80      0.73     44161\n",
      "\n",
      "    accuracy                           0.71     88701\n",
      "   macro avg       0.71      0.71      0.70     88701\n",
      "weighted avg       0.71      0.71      0.70     88701\n",
      "\n",
      "[[27383 17157]\n",
      " [ 8939 35222]]\n"
     ]
    }
   ],
   "source": [
    "coeff_SVM, TOPfeatures_SVM = LinearSVC_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e84218",
   "metadata": {},
   "source": [
    "### 3.2.3. GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "44b76c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build GBM Model\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "def GBM_func(XTrain=X_ingested, XVal=X_val, XTest=X_FNA, yTrain=y_ingested, yVal=y_val, yTest=y_FNA):\n",
    "    model_gbm = GradientBoostingClassifier(learning_rate=4, n_estimators=50, max_depth=7, min_samples_leaf=4, min_samples_split=30, n_iter_no_change=5, random_state=42)\n",
    "    model_gbm.fit(XTrain,yTrain)\n",
    "    \n",
    "    # Training Set\n",
    "    #plt.rcParams[\"figure.figsize\"] = (3,3)\n",
    "    X_train_predictions = model_gbm.predict(X_train)\n",
    "    print(\"Training Set F1:\", f1_score(y_train, model_gbm.predict(X_train), sample_weight=sampleW))\n",
    "    print(\"Training Set MCC:\", matthews_corrcoef(y_train, model_gbm.predict(X_train), sample_weight=sampleW))\n",
    "    print(\"Training Set Accuracy:\", metrics.accuracy_score(y_train, X_train_predictions))\n",
    "    print(classification_report(y_train, X_train_predictions))\n",
    "    print(confusion_matrix(y_train, X_train_predictions))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr, tpr, _ = metrics.roc_curve(y_train, X_train_predictions)\n",
    "    plt.plot(fpr,tpr)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_train.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    # Val set\n",
    "    predictions_val  = model_gbm.predict(XVal)\n",
    "    print(\"Ext Val Set F1:\", f1_score(yVal, model_gbm.predict(XVal), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set MCC:\", matthews_corrcoef(yVal, model_gbm.predict(XVal), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set Accuracy:\", metrics.accuracy_score(yVal, predictions_val))\n",
    "    print(classification_report(yVal, predictions_val))\n",
    "    print(confusion_matrix(yVal, predictions_val))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_val, tpr_val, _ = metrics.roc_curve(yVal, predictions_val)\n",
    "    plt.plot(fpr_val,tpr_val)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_test.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    f1_5_train = cross_val_score(model_gbm, XTrain, yTrain, cv = 5, scoring=\"f1\")\n",
    "    print(\"5F-CV:\", avgScore(f1_5_train, 5))\n",
    "    \n",
    "    # Test set\n",
    "    predictions_FNA = model_gbm.predict(XTest)\n",
    "    print(\"FNA Set F1:\", f1_score(yTest, model_gbm.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set MCC:\", matthews_corrcoef(yTest, model_gbm.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set Recall:\", recall_score(yTest, model_gbm.predict(XTest)))\n",
    "    print(\"FNA Test Set Accuracy:\", metrics.accuracy_score(yTest, predictions_FNA))\n",
    "    print(classification_report(yTest, predictions_FNA))\n",
    "    print(confusion_matrix(yTest, predictions_FNA))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_FNA, tpr_FNA, _ = metrics.roc_curve(yTest, predictions_FNA)\n",
    "    plt.plot(fpr_FNA,tpr_FNA)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"G:/raMSIn/XGB_Importance2/XGB2_ROC_FNAtest2.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    # Visualize the importantance of the features\n",
    "    feature_imp = pd.Series(model_gbm.feature_importances_, index=XTrain.columns).sort_values(ascending=False)\n",
    "    x=feature_imp\n",
    "    y=feature_imp.index\n",
    "    \n",
    "    plt.subplots(dpi = 300)\n",
    "    #plt.rcParams[\"figure.figsize\"] = [4, 6]\n",
    "    #plt.rcParams[\"font.family\"] = \"Arial\"\n",
    "    #plt.rcParams.update({'font.size': 6})\n",
    "    plt.xlabel('Feature Importance Score', fontproperties='Arial', fontsize=17)\n",
    "    plt.ylabel('Features', fontproperties='Arial', fontsize=17)\n",
    "    plt.xticks(fontsize=15)\n",
    "    plt.yticks(fontsize=15)\n",
    "    plt.title(\"Important Molecular Features\", fontproperties='Arial', fontsize=20)\n",
    "    sns.barplot(x=feature_imp, y=feature_imp.index)\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/XGB_TopFeatures.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    # Visualize the boxplot of the important features between the two groups\n",
    "    #fig = px.box(data_frame = df_ROI_for_ML_Opti, x = feature_imp[:10].index,color= 'type')\n",
    "    #fig.show()\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2dcef352",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set F1: 0.6472767285845505\n",
      "Training Set MCC: 0.27144438301690627\n",
      "Training Set Accuracy: 0.6339599824098505\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.60      0.63     47449\n",
      "           1       0.61      0.67      0.64     43511\n",
      "\n",
      "    accuracy                           0.63     90960\n",
      "   macro avg       0.64      0.64      0.63     90960\n",
      "weighted avg       0.64      0.63      0.63     90960\n",
      "\n",
      "[[28555 18894]\n",
      " [14401 29110]]\n",
      "Ext Val Set F1: 0.2282017391299275\n",
      "Ext Val Set MCC: -0.3829667931547765\n",
      "Ext Val Set Accuracy: 0.30979423868312755\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.42      0.37      2943\n",
      "           1       0.27      0.20      0.23      3132\n",
      "\n",
      "    accuracy                           0.31      6075\n",
      "   macro avg       0.30      0.31      0.30      6075\n",
      "weighted avg       0.30      0.31      0.30      6075\n",
      "\n",
      "[[1246 1697]\n",
      " [2496  636]]\n",
      "5F-CV: 0.6749133305388579\n",
      "FNA Set F1: 0.3950306722919045\n",
      "FNA Set MCC: -0.24869109070364404\n",
      "FNA Set Recall: 0.4075088879327914\n",
      "FNA Test Set Accuracy: 0.3757680296727207\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.34      0.36     44540\n",
      "           1       0.38      0.41      0.39     44161\n",
      "\n",
      "    accuracy                           0.38     88701\n",
      "   macro avg       0.38      0.38      0.38     88701\n",
      "weighted avg       0.38      0.38      0.38     88701\n",
      "\n",
      "[[15335 29205]\n",
      " [26165 17996]]\n"
     ]
    }
   ],
   "source": [
    "coeff_GBM, TOPfeatures_GBM = GBM_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98e2c8c",
   "metadata": {},
   "source": [
    "### 3.2.4. Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "79af839d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StackingRegressor():\n",
    "    \n",
    "    def __init__(self, learners):\n",
    "        self.level_sizes = []\n",
    "        self.learners = []\n",
    "        \n",
    "        for learning_level in learners:\n",
    "            self.level_sizes.append(len(learning_level))\n",
    "            level_learners = []\n",
    "            \n",
    "            for learner in learning_level:\n",
    "                level_learners.append(deepcopy(learner))\n",
    "            self.learners.append(level_learners)\n",
    "            \n",
    "            \n",
    "    def fit(self, x, y):\n",
    "        \n",
    "        meta_data = [x,x,x]\n",
    "        meta_targets = [y,y,y]\n",
    "        \n",
    "        for i in range(len(self.learners)):\n",
    "            level_size = self.level_sizes[i]\n",
    "            \n",
    "            data_z = np.zeros((level_size, len(x)))\n",
    "            target_z = np.zeros(len(x))\n",
    "            \n",
    "            train_x = meta_data[i]\n",
    "            train_y = meta_targets[i]\n",
    "            \n",
    "            # Define number of folds\n",
    "            num_folds = 5\n",
    "            \n",
    "            # Create the k-fold cross-validation object\n",
    "            KF = KFold(n_splits=num_folds)\n",
    "            m = 0\n",
    "\n",
    "            # Loop over each fold of the cross-validation\n",
    "            for train_indices, test_indices in KF.split(x):\n",
    "                \n",
    "                for j in range(len(self.learners[i])):\n",
    "                    train_x = pd.DataFrame(train_x)\n",
    "                    train_y = pd.DataFrame(train_y)\n",
    "\n",
    "                    learner = self.learners[i][j]\n",
    "                    learner.fit(train_x.iloc[train_indices], train_y.iloc[train_indices])\n",
    "                    p = learner.predict(train_x.iloc[test_indices])\n",
    "                    data_z[j][m: m+len(test_indices) ] = p\n",
    "\n",
    "\n",
    "                train_y = pd.DataFrame(train_y)\n",
    "                train_y_array = (np.array(train_y)).reshape(-1,)\n",
    "                zty_ind = (np.array(train_y.iloc[test_indices])).reshape(-1,)\n",
    "                target_z[m: m+len(test_indices)] = train_y_array[zty_ind]\n",
    "                m += len(test_indices)\n",
    "                \n",
    "\n",
    "            data_z = data_z.transpose()\n",
    "            meta_data.append(data_z)\n",
    "            meta_targets.append(target_z)\n",
    "            \n",
    "            \n",
    "            for learner in self.learners[i]:\n",
    "                train_x = pd.DataFrame(train_x)\n",
    "                train_y = pd.DataFrame(train_y)\n",
    "                learner.fit(train_x, train_y)\n",
    "                \n",
    "                \n",
    "    def predict(self, x):\n",
    "        \n",
    "        meta_data = [x,x,x]\n",
    "        for i in range(len(self.learners)):\n",
    "            \n",
    "            level_size = self.level_sizes[i]\n",
    "            \n",
    "            data_z = np.zeros((level_size, len(x)))\n",
    "            \n",
    "            test_x = meta_data[i]\n",
    "            \n",
    "            for j in range(len(self.learners[i])):\n",
    "                \n",
    "                learner = self.learners[i][j]\n",
    "                predictions = learner.predict(test_x)\n",
    "                data_z[j] = predictions\n",
    "                \n",
    "            \n",
    "            data_z = data_z.transpose()\n",
    "            meta_data.append(data_z)\n",
    "            \n",
    "        return meta_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3fb1ee36",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build stacking Model\n",
    "\n",
    "def Stacking_func(XTrain=X_ingested, XVal=X_val, XTest=X_FNA, XTest2=X_di, yTrain=y_ingested, yVal=y_val, yTest=y_FNA, yTest2=y_di):\n",
    "\n",
    "    base_learners = []\n",
    "\n",
    "    # Define models to use in stacking ensemble\n",
    "    m1 = LogisticRegression(C=0.001, penalty='l1', solver=\"liblinear\", max_iter=5000, random_state=42, class_weight={0:0.9628, 1:1.0402})\n",
    "    base_learners.append(m1)\n",
    "\n",
    "    m2 = LinearSVC(penalty='l2', loss=\"squared_hinge\", C=461, random_state=42, class_weight={0:0.9628, 1:1.0402})\n",
    "    base_learners.append(m2)\n",
    "\n",
    "    m3 = GradientBoostingClassifier(learning_rate=4, n_estimators=50, max_depth=7, min_samples_leaf=4, min_samples_split=30, n_iter_no_change=5, random_state=42)\n",
    "    base_learners.append(m3)\n",
    "\n",
    "    # Define the meta-classifier to use for stacking\n",
    "    #meta_learner = LinearDiscriminantAnalysis()  # 0.90,0.80; 0.75,0.51; 0.65,0.27; 0.64,0.26\n",
    "    #meta_learner = QuadraticDiscriminantAnalysis()  # 0.93,0.86; 0.67,0.39; 0.67,0.15; 0.68,0.20\n",
    "    \n",
    "    #meta_learner = LogisticRegression()  # 0.90,0.79; 0.82,0.65; 0.64,0.24; 0.64;0.27\n",
    "    #meta_learner = LogisticRegression(C=1, penalty='l1', solver=\"liblinear\", max_iter=5000, random_state=42)\n",
    "    ## C=1: 0.90,0.79; 0.82,0.65; 0.65,0.25; 0.65;0.27\n",
    "    #meta_learner = LogisticRegression(C=0.1, penalty='l1', solver=\"liblinear\", max_iter=5000, random_state=42)\n",
    "    ## C=0.1: 0.90,0.79; 0.82,0.65; 0.65,0.25; 0.65;0.28\n",
    "    #meta_learner = LogisticRegression(C=0.01, penalty='l1', solver=\"liblinear\", max_iter=5000, random_state=42)\n",
    "    ## C=0.01: 0.89,0.78; 0.81,0.63; 0.63,0.22; 0.65;0.29\n",
    "    #meta_learner = LogisticRegression(C=0.0075, penalty='l1', solver=\"liblinear\", max_iter=5000, random_state=42)\n",
    "    ## C=0.0075: 0.89,0.77; 0.81,0.63; 0.62,0.20; 0.65;0.29\n",
    "    #meta_learner = LogisticRegression(C=0.005, penalty='l1', solver=\"liblinear\", max_iter=5000, random_state=42)\n",
    "    ## C=0.005: 0.88,0.76; 0.82,0.64; 0.60,0.17; 0.66;0.31\n",
    "    #meta_learner = LogisticRegression(C=0.0025, penalty='l1', solver=\"liblinear\", max_iter=5000, random_state=42)\n",
    "    ## C=0.0025: 0.86,0.72; 0.83,0.66; 0.53,0.02; 0.64;0.31\n",
    "    #meta_learner = LogisticRegression(C=0.0015, penalty='l1', solver=\"liblinear\", max_iter=5000, random_state=42)\n",
    "    ## C=0.0015: 0.85,0.70; 0.80,0.60; 0.55,0.09; 0.64;0.30\n",
    "    #meta_learner = LogisticRegression(C=0.0013, penalty='l1', solver=\"liblinear\", max_iter=5000, random_state=42)\n",
    "    ## C=0.0013: 0.85,0.70; 0.78,0.56; 0.58,0.16; 0.63;0.29\n",
    "    #meta_learner = LogisticRegression(C=0.0012, penalty='l1', solver=\"liblinear\", max_iter=5000, random_state=42)\n",
    "    ## C=0.0012: 0.85,0.69; 0.77,0.52; 0.60,0.22; 0.63;0.27\n",
    "    meta_learner = LogisticRegression(C=0.0011, penalty='l1', solver=\"liblinear\", max_iter=5000, random_state=42)\n",
    "    ## C=0.0011: 0.85,0.69; 0.77,0.51; 0.64,0.30; 0.62;0.25\n",
    "    #meta_learner = LogisticRegression(C=0.001, penalty='l1', solver=\"liblinear\", max_iter=5000, random_state=42)\n",
    "    ## C=0.001: 0.84,0.68; 0.76,0.49; 0.68,0.38; 0.61;0.22\n",
    "    #meta_learner = LogisticRegression(C=0.0005, penalty='l1', solver=\"liblinear\", max_iter=5000, random_state=42)\n",
    "    ## C=0.0005: 0.83,0.66; 0.74,0.45; 0.65,0.37; 0.60;0.18\n",
    "    \n",
    "    #meta_learner = LinearSVC()  # 0.90,0.80; 0.82,0.65; 0.64,0.24; 0.65,0.27\n",
    "    #meta_learner = KNeighborsClassifier()  # 0.98,0.96; 0.65,0.30; 0.68,0.21; 0.52,-0.05\n",
    "    #meta_learner = DecisionTreeClassifier()  # 0.94,0.87; 0.54,0.15; 0.66,0.11; 0.46,-0.11\n",
    "    #meta_learner = RandomForestClassifier()  # 0.98,0.95; 0.54,0.20; 0.66,0.11; 0.49;-0.01\n",
    "    #meta_learner = GradientBoostingClassifier()  # 0.97,0.94; 0.56,0.27; 0.66,0.13; 0.48,-0.09\n",
    "    #meta_learner = AdaBoostClassifier()  # 0.96,0.93; 0.69,0.42; 0.62,0.10; 0.54,0.11\n",
    "    #meta_learner = xgb.XGBClassifier()  # 0.98,0.95; 0.59,0.30; 0.66,0.10; 0.44,-0.12\n",
    "\n",
    "    model_sc = StackingRegressor([[m1, m2, m3], [meta_learner]])\n",
    "    model_sc.fit(XTrain, yTrain)\n",
    "    \n",
    "    #=======================================\n",
    "    \n",
    "    # Training Set\n",
    "    #plt.rcParams[\"figure.figsize\"] = (3,3)\n",
    "    X_train_predictions = model_sc.predict(X_train)[-1]\n",
    "    print(\"Training Set F1:\", f1_score(y_train, model_sc.predict(X_train)[-1], sample_weight=sampleW))\n",
    "    print(\"Training Set MCC:\", matthews_corrcoef(y_train, model_sc.predict(X_train)[-1], sample_weight=sampleW))\n",
    "    print(\"Training Set Accuracy:\", metrics.accuracy_score(y_train, X_train_predictions))\n",
    "    print(classification_report(y_train, X_train_predictions))\n",
    "    print(confusion_matrix(y_train, X_train_predictions))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr, tpr, _ = metrics.roc_curve(y_train, X_train_predictions)\n",
    "    plt.plot(fpr,tpr)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_train.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    # Val set\n",
    "    predictions_val  = model_sc.predict(XVal)[-1]\n",
    "    print(\"Ext Val Set F1:\", f1_score(yVal, model_sc.predict(XVal)[-1], sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set MCC:\", matthews_corrcoef(yVal, model_sc.predict(XVal)[-1], sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set Accuracy:\", metrics.accuracy_score(yVal, predictions_val))\n",
    "    print(classification_report(yVal, predictions_val))\n",
    "    print(confusion_matrix(yVal, predictions_val))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_val, tpr_val, _ = metrics.roc_curve(yVal, predictions_val)\n",
    "    plt.plot(fpr_val,tpr_val)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_test.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    #f1_5_train = cross_val_score(model_sc, XTrain, yTrain, cv = 5, scoring=\"f1\")\n",
    "    #print(\"5F-CV:\", avgScore(f1_5_train, 5))\n",
    "    \n",
    "    # Test set\n",
    "    predictions_FNA = model_sc.predict(XTest)[-1]\n",
    "    print(\"FNA Set F1:\", f1_score(yTest, model_sc.predict(XTest)[-1], sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set MCC:\", matthews_corrcoef(yTest, model_sc.predict(XTest)[-1], sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set Recall:\", recall_score(yTest, model_sc.predict(XTest)[-1]))\n",
    "    print(\"FNA Test Set Accuracy:\", metrics.accuracy_score(yTest, predictions_FNA))\n",
    "    print(classification_report(yTest, predictions_FNA))\n",
    "    print(confusion_matrix(yTest, predictions_FNA))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_FNA, tpr_FNA, _ = metrics.roc_curve(yTest, predictions_FNA)\n",
    "    plt.plot(fpr_FNA,tpr_FNA)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"G:/raMSIn/XGB_Importance2/XGB2_ROC_FNAtest2.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    # Test2 set\n",
    "    predictions_di = model_sc.predict(XTest2)[-1]\n",
    "    print(\"DirectIn Set F1:\", f1_score(yTest2, model_sc.predict(XTest2)[-1], sample_weight=sampleDiW))\n",
    "    print(\"DirectIn Set MCC:\", matthews_corrcoef(yTest2, model_sc.predict(XTest2)[-1], sample_weight=sampleDiW))\n",
    "    print(\"DirectIn Set Recall:\", recall_score(yTest2, model_sc.predict(XTest2)[-1]))\n",
    "    print(\"DirectIn Test Set Accuracy:\", metrics.accuracy_score(yTest2, predictions_di))\n",
    "    print(classification_report(yTest2, predictions_di))\n",
    "    print(confusion_matrix(yTest2, predictions_di))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_di, tpr_di, _ = metrics.roc_curve(yTest2, predictions_di)\n",
    "    plt.plot(fpr_di,tpr_di)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"G:/raMSIn/XGB_Importance2/XGB2_ROC_FNAtest2.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e01c13ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set F1: 0.841512992702823\n",
      "Training Set MCC: 0.6850278433560042\n",
      "Training Set Accuracy: 0.8427550571679859\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.85      0.85     47449\n",
      "           1       0.84      0.84      0.84     43511\n",
      "\n",
      "    accuracy                           0.84     90960\n",
      "   macro avg       0.84      0.84      0.84     90960\n",
      "weighted avg       0.84      0.84      0.84     90960\n",
      "\n",
      "[[40268  7181]\n",
      " [ 7122 36389]]\n",
      "Ext Val Set F1: 0.7699649280543268\n",
      "Ext Val Set MCC: 0.49940411529781636\n",
      "Ext Val Set Accuracy: 0.7461728395061729\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.62      0.70      2943\n",
      "           1       0.71      0.86      0.78      3132\n",
      "\n",
      "    accuracy                           0.75      6075\n",
      "   macro avg       0.76      0.74      0.74      6075\n",
      "weighted avg       0.76      0.75      0.74      6075\n",
      "\n",
      "[[1833 1110]\n",
      " [ 432 2700]]\n",
      "FNA Set F1: 0.7999649183922877\n",
      "FNA Set MCC: 0.6036332629875224\n",
      "FNA Set Recall: 0.7927356717465637\n",
      "FNA Test Set Accuracy: 0.8018060675753373\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80     44540\n",
      "           1       0.81      0.79      0.80     44161\n",
      "\n",
      "    accuracy                           0.80     88701\n",
      "   macro avg       0.80      0.80      0.80     88701\n",
      "weighted avg       0.80      0.80      0.80     88701\n",
      "\n",
      "[[36113  8427]\n",
      " [ 9153 35008]]\n",
      "DirectIn Set F1: 0.5011069035372516\n",
      "DirectIn Set MCC: 0.053996428105464074\n",
      "DirectIn Set Recall: 0.4752475247524752\n",
      "DirectIn Test Set Accuracy: 0.5268284629354466\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.58      0.55      3027\n",
      "           1       0.53      0.48      0.50      3030\n",
      "\n",
      "    accuracy                           0.53      6057\n",
      "   macro avg       0.53      0.53      0.53      6057\n",
      "weighted avg       0.53      0.53      0.53      6057\n",
      "\n",
      "[[1751 1276]\n",
      " [1590 1440]]\n"
     ]
    }
   ],
   "source": [
    "Stacking_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235227fc",
   "metadata": {},
   "source": [
    "### 3.2.5. Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "84be5513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a voting ensemble of models\n",
    "def get_voting():\n",
    "    models = list()\n",
    "    # Define the base models\n",
    "    models.append((\"m1\", LogisticRegression(C=0.001, penalty='l1', solver=\"liblinear\", max_iter=5000, random_state=42, class_weight={0:0.9628, 1:1.0402})))\n",
    "    models.append((\"m2\", LinearSVC(penalty='l2', loss=\"squared_hinge\", C=461, random_state=42, class_weight={0:0.9628, 1:1.0402})))\n",
    "    models.append((\"m3\", GradientBoostingClassifier(learning_rate=4, n_estimators=50, max_depth=7, min_samples_leaf=4, min_samples_split=30, n_iter_no_change=5, random_state=42)))\n",
    "\n",
    "    # define the voting ensemble\n",
    "    ensemble = VotingClassifier(estimators=models, voting='hard')\n",
    "    return ensemble\n",
    "\n",
    "# get a list of models to evaluate\n",
    "def get_models():\n",
    "    models = dict()\n",
    "    models['m1'] = LogisticRegression(C=0.001, penalty='l1', solver=\"liblinear\", max_iter=5000, random_state=42, class_weight={0:0.9628, 1:1.0402})\n",
    "    models['m2'] = LinearSVC(penalty='l2', loss=\"squared_hinge\", C=461, random_state=42, class_weight={0:0.9628, 1:1.0402})\n",
    "    models['m3'] = GradientBoostingClassifier(learning_rate=4, n_estimators=50, max_depth=7, min_samples_leaf=4, min_samples_split=30, n_iter_no_change=5, random_state=42)\n",
    "    models['hard_voting'] = get_voting()\n",
    "    return models\n",
    "\n",
    "\n",
    "# evaluate a give model using cross-validation\n",
    "def evaluate_model(model, XX, yy):\n",
    "    cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=10, random_state=42)\n",
    "    scores = cross_val_score(model, XX, yy, scoring='f1', cv=cv, n_jobs=-1, error_score='raise')\n",
    "    return scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2c7985bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 720x720 with 0 Axes>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from matplotlib.pyplot import figure\n",
    "plt.rcParams['figure.figsize'] = [10, 10]\n",
    "plt.close()\n",
    "figure(figsize=(10, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fab33d50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">m1 0.771 (0.003)\n",
      ">m2 0.886 (0.020)\n",
      ">m3 0.664 (0.143)\n",
      ">hard_voting 0.860 (0.034)\n"
     ]
    }
   ],
   "source": [
    "# get the models to evaluate\n",
    "models = get_models()\n",
    "\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "    scores = evaluate_model(model, XX=X_ingested, yy=y_ingested)\n",
    "    results.append(scores)\n",
    "    names.append(name)\n",
    "    print('>%s %.3f (%.3f)' % (name, np.mean(scores), np.std(scores)))\n",
    "    \n",
    "# plot model performance for comparison\n",
    "plt.subplots(dpi = 600)\n",
    "plt.boxplot(results, labels=names, showmeans=True)\n",
    "plt.ylabel('F1 score')\n",
    "plt.xlabel('Predictive Models')\n",
    "plt.savefig(r\"H:/3_output_raMSIn/3_3_Output_raMSIn_HKU_Ingested4ALL/XGB_ALL/afterModelSelection/cbMSIn_0d1/voting.jpg\", bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6832284f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Voting_func(XTrain=X_ingested, XVal=X_val, XTest=X_FNA, XTest2=X_di, yTrain=y_ingested, yVal=y_val, yTest=y_FNA, yTest2=y_di):\n",
    "\n",
    "    models = get_models()\n",
    "    \n",
    "    ensemble = models[\"hard_voting\"]\n",
    "    ensemble.fit(XTrain, yTrain)\n",
    "    #=======================================\n",
    "\n",
    "    # Training Set\n",
    "    #plt.rcParams[\"figure.figsize\"] = (3,3)\n",
    "    X_train_predictions = ensemble.predict(X_train)\n",
    "    print(\"Training Set F1:\", f1_score(y_train, ensemble.predict(X_train), sample_weight=sampleW))\n",
    "    print(\"Training Set MCC:\", matthews_corrcoef(y_train, ensemble.predict(X_train), sample_weight=sampleW))\n",
    "    print(\"Training Set Accuracy:\", metrics.accuracy_score(y_train, X_train_predictions))\n",
    "    print(classification_report(y_train, X_train_predictions))\n",
    "    print(confusion_matrix(y_train, X_train_predictions))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr, tpr, _ = metrics.roc_curve(y_train, X_train_predictions)\n",
    "    plt.plot(fpr,tpr)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_train.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    # Val set\n",
    "    predictions_val  = ensemble.predict(XVal)\n",
    "    print(\"Ext Val Set F1:\", f1_score(yVal, ensemble.predict(XVal), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set MCC:\", matthews_corrcoef(yVal, ensemble.predict(XVal), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set Accuracy:\", metrics.accuracy_score(yVal, predictions_val))\n",
    "    print(classification_report(yVal, predictions_val))\n",
    "    print(confusion_matrix(yVal, predictions_val))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_val, tpr_val, _ = metrics.roc_curve(yVal, predictions_val)\n",
    "    plt.plot(fpr_val,tpr_val)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_test.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    f1_5_train = cross_val_score(ensemble, XTrain, yTrain, cv = 5, scoring=\"f1\")\n",
    "    print(\"5F-CV:\", avgScore(f1_5_train, 5))\n",
    "\n",
    "    # Test set\n",
    "    predictions_FNA = ensemble.predict(XTest)\n",
    "    print(\"FNA Set F1:\", f1_score(yTest, ensemble.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set MCC:\", matthews_corrcoef(yTest, ensemble.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set Recall:\", recall_score(yTest, ensemble.predict(XTest)))\n",
    "    print(\"FNA Test Set Accuracy:\", metrics.accuracy_score(yTest, predictions_FNA))\n",
    "    print(classification_report(yTest, predictions_FNA))\n",
    "    print(confusion_matrix(yTest, predictions_FNA))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_FNA, tpr_FNA, _ = metrics.roc_curve(yTest, predictions_FNA)\n",
    "    plt.plot(fpr_FNA,tpr_FNA)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"G:/raMSIn/XGB_Importance2/XGB2_ROC_FNAtest2.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    # Test2 set\n",
    "    predictions_di = ensemble.predict(XTest2)\n",
    "    print(\"DirectIn Set F1:\", f1_score(yTest2, ensemble.predict(XTest2), sample_weight=sampleDiW))\n",
    "    print(\"DirectIn Set MCC:\", matthews_corrcoef(yTest2, ensemble.predict(XTest2), sample_weight=sampleDiW))\n",
    "    print(\"DirectIn Set Recall:\", recall_score(yTest2, ensemble.predict(XTest2)))\n",
    "    print(\"DirectIn Test Set Accuracy:\", metrics.accuracy_score(yTest2, predictions_di))\n",
    "    print(classification_report(yTest2, predictions_di))\n",
    "    print(confusion_matrix(yTest2, predictions_di))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_di, tpr_di, _ = metrics.roc_curve(yTest2, predictions_di)\n",
    "    plt.plot(fpr_di,tpr_di)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"G:/raMSIn/XGB_Importance2/XGB2_ROC_FNAtest2.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e3647683",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set F1: 0.8457539849027802\n",
      "Training Set MCC: 0.6927689857504232\n",
      "Training Set Accuracy: 0.8465479331574318\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.85      0.85     47449\n",
      "           1       0.84      0.84      0.84     43511\n",
      "\n",
      "    accuracy                           0.85     90960\n",
      "   macro avg       0.85      0.85      0.85     90960\n",
      "weighted avg       0.85      0.85      0.85     90960\n",
      "\n",
      "[[40351  7098]\n",
      " [ 6860 36651]]\n",
      "Ext Val Set F1: 0.6803762000283127\n",
      "Ext Val Set MCC: 0.3044493313069797\n",
      "Ext Val Set Accuracy: 0.6523456790123456\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.55      0.61      2943\n",
      "           1       0.64      0.75      0.69      3132\n",
      "\n",
      "    accuracy                           0.65      6075\n",
      "   macro avg       0.66      0.65      0.65      6075\n",
      "weighted avg       0.66      0.65      0.65      6075\n",
      "\n",
      "[[1625 1318]\n",
      " [ 794 2338]]\n",
      "5F-CV: 0.7848617768682282\n",
      "FNA Set F1: 0.7220408506086006\n",
      "FNA Set MCC: 0.40556161913180583\n",
      "FNA Set Recall: 0.7785376236951156\n",
      "FNA Test Set Accuracy: 0.6999470129987261\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.62      0.68     44540\n",
      "           1       0.67      0.78      0.72     44161\n",
      "\n",
      "    accuracy                           0.70     88701\n",
      "   macro avg       0.71      0.70      0.70     88701\n",
      "weighted avg       0.71      0.70      0.70     88701\n",
      "\n",
      "[[27705 16835]\n",
      " [ 9780 34381]]\n",
      "DirectIn Set F1: 0.5003245212536693\n",
      "DirectIn Set MCC: -0.06517654968354192\n",
      "DirectIn Set Recall: 0.533003300330033\n",
      "DirectIn Test Set Accuracy: 0.46772329536073964\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.40      0.43      3027\n",
      "           1       0.47      0.53      0.50      3030\n",
      "\n",
      "    accuracy                           0.47      6057\n",
      "   macro avg       0.47      0.47      0.47      6057\n",
      "weighted avg       0.47      0.47      0.47      6057\n",
      "\n",
      "[[1218 1809]\n",
      " [1415 1615]]\n"
     ]
    }
   ],
   "source": [
    "Voting_func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7c6aeb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib as jl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fdfc9ad1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('m1',\n",
       "                              LogisticRegression(C=0.001,\n",
       "                                                 class_weight={0: 0.9628,\n",
       "                                                               1: 1.0402},\n",
       "                                                 max_iter=5000, penalty='l1',\n",
       "                                                 random_state=42,\n",
       "                                                 solver='liblinear')),\n",
       "                             ('m2',\n",
       "                              LinearSVC(C=461,\n",
       "                                        class_weight={0: 0.9628, 1: 1.0402},\n",
       "                                        random_state=42)),\n",
       "                             ('m3',\n",
       "                              GradientBoostingClassifier(learning_rate=4,\n",
       "                                                         max_depth=7,\n",
       "                                                         min_samples_leaf=4,\n",
       "                                                         min_samples_split=30,\n",
       "                                                         n_estimators=50,\n",
       "                                                         n_iter_no_change=5,\n",
       "                                                         random_state=42))])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = get_models()\n",
    "    \n",
    "ensemble = models[\"hard_voting\"]\n",
    "ensemble.fit(X_ingested, y_ingested)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "65d8cb99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['H:\\\\3_output_raMSIn\\\\3_3_Output_raMSIn_HKU_Ingested4ALL\\\\XGB_ALL\\\\afterModelSelection\\\\cbMSIn_0d1\\\\model3to1Voting_cbMSIn0d1.joblib']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelSavePath = r\"H:\\3_output_raMSIn\\3_3_Output_raMSIn_HKU_Ingested4ALL\\XGB_ALL\\afterModelSelection\\cbMSIn_0d1\\model3to1Voting_cbMSIn0d1.joblib\"\n",
    "jl.dump(ensemble, modelSavePath, compress = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f9a9ba",
   "metadata": {},
   "source": [
    "## 3.3 Machine Learning Modeling: Model 1 (Train 6:6, Val 4:4, Test 3:3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49659b18",
   "metadata": {},
   "source": [
    "### 3.3.1. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7bcace0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build Logistic Regression Model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def LogisticRegression_func(XTrain=X_train, XVal=X_val, XTest=X_FNA, yTrain=y_train, yVal=y_val, yTest=y_FNA):\n",
    "    model_lr = LogisticRegression(C=0.001, penalty='l1', solver=\"liblinear\", max_iter=5000, random_state=42, class_weight={0:0.9628, 1:1.0402})  # max_iter=100\n",
    "    model_lr.fit(XTrain,yTrain)\n",
    "    \n",
    "    # Training Set\n",
    "    #plt.rcParams[\"figure.figsize\"] = (3,3)\n",
    "    X_train_predictions = model_lr.predict(X_train)\n",
    "    print(\"Training Set F1:\", f1_score(y_train, model_lr.predict(X_train), sample_weight=sampleW))\n",
    "    print(\"Training Set MCC:\", matthews_corrcoef(y_train, model_lr.predict(X_train), sample_weight=sampleW))\n",
    "    print(\"Training Set Accuracy:\", metrics.accuracy_score(y_train, X_train_predictions))\n",
    "    print(classification_report(y_train, X_train_predictions))\n",
    "    print(confusion_matrix(y_train, X_train_predictions))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr, tpr, _ = metrics.roc_curve(y_train, X_train_predictions)\n",
    "    plt.plot(fpr,tpr)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_train.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    # Val set\n",
    "    predictions_val  = model_lr.predict(XVal)\n",
    "    print(\"Ext Val Set F1:\", f1_score(yVal, model_lr.predict(XVal), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set MCC:\", matthews_corrcoef(yVal, model_lr.predict(XVal), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set Accuracy:\", metrics.accuracy_score(yVal, predictions_val))\n",
    "    print(classification_report(yVal, predictions_val))\n",
    "    print(confusion_matrix(yVal, predictions_val))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_val, tpr_val, _ = metrics.roc_curve(yVal, predictions_val)\n",
    "    plt.plot(fpr_val,tpr_val)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_test.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    f1_5_train = cross_val_score(model_lr, XTrain, yTrain, cv = 5, scoring=\"f1\")\n",
    "    print(\"5F-CV:\", avgScore(f1_5_train, 5))\n",
    "    \n",
    "    # Test set\n",
    "    predictions_FNA = model_lr.predict(XTest)\n",
    "    print(\"FNA Set F1:\", f1_score(yTest, model_lr.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set MCC:\", matthews_corrcoef(yTest, model_lr.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set Recall:\", recall_score(yTest, model_lr.predict(XTest)))\n",
    "    print(\"FNA Test Set Accuracy:\", metrics.accuracy_score(yTest, predictions_FNA))\n",
    "    print(classification_report(yTest, predictions_FNA))\n",
    "    print(confusion_matrix(yTest, predictions_FNA))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_FNA, tpr_FNA, _ = metrics.roc_curve(yTest, predictions_FNA)\n",
    "    plt.plot(fpr_FNA,tpr_FNA)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"G:/raMSIn/XGB_Importance2/XGB2_ROC_FNAtest2.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    # Visualize the importantance of the features\n",
    "    feature_imp = pd.Series(model_lr.coef_[0], index=XTrain.columns).sort_values(ascending=False)\n",
    "    x=feature_imp\n",
    "    y=feature_imp.index\n",
    "    \n",
    "    plt.subplots(dpi = 300)\n",
    "    #plt.rcParams[\"figure.figsize\"] = [4, 6]\n",
    "    #plt.rcParams[\"font.family\"] = \"Arial\"\n",
    "    #plt.rcParams.update({'font.size': 6})\n",
    "    plt.xlabel('Feature Importance Score', fontproperties='Arial', fontsize=17)\n",
    "    plt.ylabel('Features', fontproperties='Arial', fontsize=17)\n",
    "    plt.xticks(fontsize=15)\n",
    "    plt.yticks(fontsize=15)\n",
    "    plt.title(\"Important Molecular Features\", fontproperties='Arial', fontsize=20)\n",
    "    sns.barplot(x=feature_imp, y=feature_imp.index)\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_TopFeatures.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    #feature_importances = model_lr.coef_[0]\n",
    "    #feature_df=pd.DataFrame({'m/z':XTrain.columns,'coef':feature_importances})\n",
    "\n",
    "    #fig = px.bar(feature_df, x='coef', y='m/z')\n",
    "    #fig.show()\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5d284fc7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set F1: 0.8569485297715077\n",
      "Training Set MCC: 0.7121772157313848\n",
      "Training Set Accuracy: 0.8557937554969217\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.85      0.86     47449\n",
      "           1       0.84      0.86      0.85     43511\n",
      "\n",
      "    accuracy                           0.86     90960\n",
      "   macro avg       0.86      0.86      0.86     90960\n",
      "weighted avg       0.86      0.86      0.86     90960\n",
      "\n",
      "[[40326  7123]\n",
      " [ 5994 37517]]\n",
      "Ext Val Set F1: 0.6150514329102017\n",
      "Ext Val Set MCC: 0.17088791678007098\n",
      "Ext Val Set Accuracy: 0.5868312757201646\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.50      0.54      2943\n",
      "           1       0.59      0.66      0.62      3132\n",
      "\n",
      "    accuracy                           0.59      6075\n",
      "   macro avg       0.59      0.58      0.58      6075\n",
      "weighted avg       0.59      0.59      0.58      6075\n",
      "\n",
      "[[1485 1458]\n",
      " [1052 2080]]\n",
      "5F-CV: 0.7364561480445152\n",
      "FNA Set F1: 0.7497707260607065\n",
      "FNA Set MCC: 0.4983187567266692\n",
      "FNA Set Recall: 0.7515907701365458\n",
      "FNA Test Set Accuracy: 0.7491460073730849\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.75      0.75     44540\n",
      "           1       0.75      0.75      0.75     44161\n",
      "\n",
      "    accuracy                           0.75     88701\n",
      "   macro avg       0.75      0.75      0.75     88701\n",
      "weighted avg       0.75      0.75      0.75     88701\n",
      "\n",
      "[[33259 11281]\n",
      " [10970 33191]]\n"
     ]
    }
   ],
   "source": [
    "coeff_LogReg, TOPfeatures_LogReg = LogisticRegression_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e368acdd",
   "metadata": {},
   "source": [
    "### 3.3.2. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "88f68e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build LinearSVC Model\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "def LinearSVC_func(XTrain=X_train, XVal=X_val, XTest=X_FNA, yTrain=y_train, yVal=y_val, yTest=y_FNA):\n",
    "    model_svm = LinearSVC(penalty='l2', loss=\"squared_hinge\", C=461, random_state=42, class_weight={0:0.9628, 1:1.0402})\n",
    "    model_svm.fit(XTrain,yTrain)\n",
    "    \n",
    "    # Training Set\n",
    "    #plt.rcParams[\"figure.figsize\"] = (3,3)\n",
    "    X_train_predictions = model_svm.predict(X_train)\n",
    "    print(\"Training Set F1:\", f1_score(y_train, model_svm.predict(X_train), sample_weight=sampleW))\n",
    "    print(\"Training Set MCC:\", matthews_corrcoef(y_train, model_svm.predict(X_train), sample_weight=sampleW))\n",
    "    print(\"Training Set Accuracy:\", metrics.accuracy_score(y_train, X_train_predictions))\n",
    "    print(classification_report(y_train, X_train_predictions))\n",
    "    print(confusion_matrix(y_train, X_train_predictions))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr, tpr, _ = metrics.roc_curve(y_train, X_train_predictions)\n",
    "    plt.plot(fpr,tpr)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_train.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    # Val set\n",
    "    predictions_val  = model_svm.predict(XVal)\n",
    "    print(\"Ext Val Set F1:\", f1_score(yVal, model_svm.predict(XVal), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set MCC:\", matthews_corrcoef(yVal, model_svm.predict(XVal), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set Accuracy:\", metrics.accuracy_score(yVal, predictions_val))\n",
    "    print(classification_report(yVal, predictions_val))\n",
    "    print(confusion_matrix(yVal, predictions_val))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_val, tpr_val, _ = metrics.roc_curve(yVal, predictions_val)\n",
    "    plt.plot(fpr_val,tpr_val)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_test.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    f1_5_train = cross_val_score(model_svm, XTrain, yTrain, cv = 5, scoring=\"f1\")\n",
    "    print(\"5F-CV:\", avgScore(f1_5_train, 5))\n",
    "    \n",
    "    # Test set\n",
    "    predictions_FNA = model_svm.predict(XTest)\n",
    "    print(\"FNA Set F1:\", f1_score(yTest, model_svm.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set MCC:\", matthews_corrcoef(yTest, model_svm.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set Recall:\", recall_score(yTest, model_svm.predict(XTest)))\n",
    "    print(\"FNA Test Set Accuracy:\", metrics.accuracy_score(yTest, predictions_FNA))\n",
    "    print(classification_report(yTest, predictions_FNA))\n",
    "    print(confusion_matrix(yTest, predictions_FNA))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_FNA, tpr_FNA, _ = metrics.roc_curve(yTest, predictions_FNA)\n",
    "    plt.plot(fpr_FNA,tpr_FNA)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"G:/raMSIn/XGB_Importance2/XGB2_ROC_FNAtest2.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    # Visualize the importantance of the features\n",
    "    feature_imp = pd.Series(model_svm.coef_[0], index=XTrain.columns).sort_values(ascending=False)\n",
    "    x=feature_imp\n",
    "    y=feature_imp.index\n",
    "    \n",
    "    plt.subplots(dpi = 300)\n",
    "    #plt.rcParams[\"figure.figsize\"] = [4, 6]\n",
    "    #plt.rcParams[\"font.family\"] = \"Arial\"\n",
    "    #plt.rcParams.update({'font.size': 6})\n",
    "    plt.xlabel('Feature Importance Score', fontproperties='Arial', fontsize=17)\n",
    "    plt.ylabel('Features', fontproperties='Arial', fontsize=17)\n",
    "    plt.xticks(fontsize=15)\n",
    "    plt.yticks(fontsize=15)\n",
    "    plt.title(\"Important Molecular Features\", fontproperties='Arial', fontsize=20)\n",
    "    sns.barplot(x=feature_imp, y=feature_imp.index)\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_TopFeatures.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    #feature_importances = model_svm.coef_[0]\n",
    "    #feature_df=pd.DataFrame({'m/z':XTrain.columns,'coef':feature_importances})\n",
    "\n",
    "    #fig = px.bar(feature_df, x='coef', y='m/z')\n",
    "    #fig.show()\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "90420725",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set F1: 0.9109933543289993\n",
      "Training Set MCC: 0.8288662702072551\n",
      "Training Set Accuracy: 0.9149846086191733\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92     47449\n",
      "           1       0.94      0.88      0.91     43511\n",
      "\n",
      "    accuracy                           0.91     90960\n",
      "   macro avg       0.92      0.91      0.91     90960\n",
      "weighted avg       0.92      0.91      0.91     90960\n",
      "\n",
      "[[44785  2664]\n",
      " [ 5069 38442]]\n",
      "Ext Val Set F1: 0.2380177560743006\n",
      "Ext Val Set MCC: -0.44191610821732286\n",
      "Ext Val Set Accuracy: 0.27868312757201646\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.34      0.31      2943\n",
      "           1       0.26      0.22      0.24      3132\n",
      "\n",
      "    accuracy                           0.28      6075\n",
      "   macro avg       0.28      0.28      0.28      6075\n",
      "weighted avg       0.28      0.28      0.28      6075\n",
      "\n",
      "[[ 989 1954]\n",
      " [2428  704]]\n",
      "5F-CV: 0.8550142758110824\n",
      "FNA Set F1: 0.5486344047360954\n",
      "FNA Set MCC: 0.11131772049094382\n",
      "FNA Set Recall: 0.5401145807386608\n",
      "FNA Test Set Accuracy: 0.5556983574029605\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.57      0.56     44540\n",
      "           1       0.56      0.54      0.55     44161\n",
      "\n",
      "    accuracy                           0.56     88701\n",
      "   macro avg       0.56      0.56      0.56     88701\n",
      "weighted avg       0.56      0.56      0.56     88701\n",
      "\n",
      "[[25439 19101]\n",
      " [20309 23852]]\n"
     ]
    }
   ],
   "source": [
    "coeff_SVM, TOPfeatures_SVM = LinearSVC_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228ac6cd",
   "metadata": {},
   "source": [
    "### 3.3.3. GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7428a256",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build GBM Model\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "def GBM_func(XTrain=X_train, XVal=X_val, XTest=X_FNA, yTrain=y_train, yVal=y_val, yTest=y_FNA):\n",
    "    model_gbm = GradientBoostingClassifier(learning_rate=4, n_estimators=50, max_depth=7, min_samples_leaf=4, min_samples_split=30, n_iter_no_change=5, random_state=42)\n",
    "    model_gbm.fit(XTrain,yTrain)\n",
    "    \n",
    "    # Training Set\n",
    "    #plt.rcParams[\"figure.figsize\"] = (3,3)\n",
    "    X_train_predictions = model_gbm.predict(X_train)\n",
    "    print(\"Training Set F1:\", f1_score(y_train, model_gbm.predict(X_train), sample_weight=sampleW))\n",
    "    print(\"Training Set MCC:\", matthews_corrcoef(y_train, model_gbm.predict(X_train), sample_weight=sampleW))\n",
    "    print(\"Training Set Accuracy:\", metrics.accuracy_score(y_train, X_train_predictions))\n",
    "    print(classification_report(y_train, X_train_predictions))\n",
    "    print(confusion_matrix(y_train, X_train_predictions))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr, tpr, _ = metrics.roc_curve(y_train, X_train_predictions)\n",
    "    plt.plot(fpr,tpr)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_train.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    # Val set\n",
    "    predictions_val  = model_gbm.predict(XVal)\n",
    "    print(\"Ext Val Set F1:\", f1_score(yVal, model_gbm.predict(XVal), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set MCC:\", matthews_corrcoef(yVal, model_gbm.predict(XVal), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set Accuracy:\", metrics.accuracy_score(yVal, predictions_val))\n",
    "    print(classification_report(yVal, predictions_val))\n",
    "    print(confusion_matrix(yVal, predictions_val))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_val, tpr_val, _ = metrics.roc_curve(yVal, predictions_val)\n",
    "    plt.plot(fpr_val,tpr_val)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_test.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    f1_5_train = cross_val_score(model_gbm, XTrain, yTrain, cv = 5, scoring=\"f1\")\n",
    "    print(\"5F-CV:\", avgScore(f1_5_train, 5))\n",
    "    \n",
    "    # Test set\n",
    "    predictions_FNA = model_gbm.predict(XTest)\n",
    "    print(\"FNA Set F1:\", f1_score(yTest, model_gbm.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set MCC:\", matthews_corrcoef(yTest, model_gbm.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set Recall:\", recall_score(yTest, model_gbm.predict(XTest)))\n",
    "    print(\"FNA Test Set Accuracy:\", metrics.accuracy_score(yTest, predictions_FNA))\n",
    "    print(classification_report(yTest, predictions_FNA))\n",
    "    print(confusion_matrix(yTest, predictions_FNA))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_FNA, tpr_FNA, _ = metrics.roc_curve(yTest, predictions_FNA)\n",
    "    plt.plot(fpr_FNA,tpr_FNA)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"G:/raMSIn/XGB_Importance2/XGB2_ROC_FNAtest2.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    # Visualize the importantance of the features\n",
    "    feature_imp = pd.Series(model_gbm.feature_importances_, index=XTrain.columns).sort_values(ascending=False)\n",
    "    x=feature_imp\n",
    "    y=feature_imp.index\n",
    "    \n",
    "    plt.subplots(dpi = 300)\n",
    "    #plt.rcParams[\"figure.figsize\"] = [4, 6]\n",
    "    #plt.rcParams[\"font.family\"] = \"Arial\"\n",
    "    #plt.rcParams.update({'font.size': 6})\n",
    "    plt.xlabel('Feature Importance Score', fontproperties='Arial', fontsize=17)\n",
    "    plt.ylabel('Features', fontproperties='Arial', fontsize=17)\n",
    "    plt.xticks(fontsize=15)\n",
    "    plt.yticks(fontsize=15)\n",
    "    plt.title(\"Important Molecular Features\", fontproperties='Arial', fontsize=20)\n",
    "    sns.barplot(x=feature_imp, y=feature_imp.index)\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/XGB_TopFeatures.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    # Visualize the boxplot of the important features between the two groups\n",
    "    #fig = px.box(data_frame = df_ROI_for_ML_Opti, x = feature_imp[:10].index,color= 'type')\n",
    "    #fig.show()\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "02a72f17",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set F1: 0.8113686759633589\n",
      "Training Set MCC: 0.6189844161805929\n",
      "Training Set Accuracy: 0.8089819700967458\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.80      0.81     47449\n",
      "           1       0.79      0.82      0.80     43511\n",
      "\n",
      "    accuracy                           0.81     90960\n",
      "   macro avg       0.81      0.81      0.81     90960\n",
      "weighted avg       0.81      0.81      0.81     90960\n",
      "\n",
      "[[37919  9530]\n",
      " [ 7845 35666]]\n",
      "Ext Val Set F1: 0.17594419243837597\n",
      "Ext Val Set MCC: -0.35853111482604305\n",
      "Ext Val Set Accuracy: 0.328559670781893\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.53      0.43      2943\n",
      "           1       0.24      0.14      0.18      3132\n",
      "\n",
      "    accuracy                           0.33      6075\n",
      "   macro avg       0.30      0.33      0.31      6075\n",
      "weighted avg       0.30      0.33      0.30      6075\n",
      "\n",
      "[[1551 1392]\n",
      " [2687  445]]\n",
      "5F-CV: 0.613404446652406\n",
      "FNA Set F1: 0.17822201029834633\n",
      "FNA Set MCC: -0.19172410470192036\n",
      "FNA Set Recall: 0.1251330359366862\n",
      "FNA Test Set Accuracy: 0.42427932041352406\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.72      0.56     44540\n",
      "           1       0.31      0.13      0.18     44161\n",
      "\n",
      "    accuracy                           0.42     88701\n",
      "   macro avg       0.38      0.42      0.37     88701\n",
      "weighted avg       0.38      0.42      0.37     88701\n",
      "\n",
      "[[32108 12432]\n",
      " [38635  5526]]\n"
     ]
    }
   ],
   "source": [
    "coeff_GBM, TOPfeatures_GBM = GBM_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9edf4a32",
   "metadata": {},
   "source": [
    "### 3.3.4. Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9e7e60e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build stacking Model\n",
    "\n",
    "def Stacking_func(XTrain=X_train, XVal=X_val, XTest=X_FNA, XTest2=X_di, yTrain=y_train, yVal=y_val, yTest=y_FNA, yTest2=y_di):\n",
    "\n",
    "    base_learners = []\n",
    "\n",
    "    # Define models to use in stacking ensemble\n",
    "    m1 = LogisticRegression(C=0.001, penalty='l1', solver=\"liblinear\", max_iter=5000, random_state=42, class_weight={0:0.9628, 1:1.0402})\n",
    "    base_learners.append(m1)\n",
    "\n",
    "    m2 = LinearSVC(penalty='l2', loss=\"squared_hinge\", C=461, random_state=42, class_weight={0:0.9628, 1:1.0402})\n",
    "    base_learners.append(m2)\n",
    "\n",
    "    m3 = GradientBoostingClassifier(learning_rate=4, n_estimators=50, max_depth=7, min_samples_leaf=4, min_samples_split=30, n_iter_no_change=5, random_state=42)\n",
    "    base_learners.append(m3)\n",
    "\n",
    "    # Define the meta-classifier to use for stacking\n",
    "    meta_learner = LogisticRegression(C=0.0011, penalty='l1', solver=\"liblinear\", max_iter=5000, random_state=42)\n",
    "\n",
    "    model_sc = StackingRegressor([[m1, m2, m3], [meta_learner]])\n",
    "    model_sc.fit(XTrain, yTrain)\n",
    "    \n",
    "    #=======================================\n",
    "    \n",
    "    # Training Set\n",
    "    #plt.rcParams[\"figure.figsize\"] = (3,3)\n",
    "    X_train_predictions = model_sc.predict(X_train)[-1]\n",
    "    print(\"Training Set F1:\", f1_score(y_train, model_sc.predict(X_train)[-1], sample_weight=sampleW))\n",
    "    print(\"Training Set MCC:\", matthews_corrcoef(y_train, model_sc.predict(X_train)[-1], sample_weight=sampleW))\n",
    "    print(\"Training Set Accuracy:\", metrics.accuracy_score(y_train, X_train_predictions))\n",
    "    print(classification_report(y_train, X_train_predictions))\n",
    "    print(confusion_matrix(y_train, X_train_predictions))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr, tpr, _ = metrics.roc_curve(y_train, X_train_predictions)\n",
    "    plt.plot(fpr,tpr)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_train.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    # Val set\n",
    "    predictions_val  = model_sc.predict(XVal)[-1]\n",
    "    print(\"Ext Val Set F1:\", f1_score(yVal, model_sc.predict(XVal)[-1], sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set MCC:\", matthews_corrcoef(yVal, model_sc.predict(XVal)[-1], sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set Accuracy:\", metrics.accuracy_score(yVal, predictions_val))\n",
    "    print(classification_report(yVal, predictions_val))\n",
    "    print(confusion_matrix(yVal, predictions_val))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_val, tpr_val, _ = metrics.roc_curve(yVal, predictions_val)\n",
    "    plt.plot(fpr_val,tpr_val)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_test.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    #f1_5_train = cross_val_score(model_sc, XTrain, yTrain, cv = 5, scoring=\"f1\")\n",
    "    #print(\"5F-CV:\", avgScore(f1_5_train, 5))\n",
    "    \n",
    "    # Test set\n",
    "    predictions_FNA = model_sc.predict(XTest)[-1]\n",
    "    print(\"FNA Set F1:\", f1_score(yTest, model_sc.predict(XTest)[-1], sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set MCC:\", matthews_corrcoef(yTest, model_sc.predict(XTest)[-1], sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set Recall:\", recall_score(yTest, model_sc.predict(XTest)[-1]))\n",
    "    print(\"FNA Test Set Accuracy:\", metrics.accuracy_score(yTest, predictions_FNA))\n",
    "    print(classification_report(yTest, predictions_FNA))\n",
    "    print(confusion_matrix(yTest, predictions_FNA))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_FNA, tpr_FNA, _ = metrics.roc_curve(yTest, predictions_FNA)\n",
    "    plt.plot(fpr_FNA,tpr_FNA)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"G:/raMSIn/XGB_Importance2/XGB2_ROC_FNAtest2.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    # Test2 set\n",
    "    predictions_di = model_sc.predict(XTest2)[-1]\n",
    "    print(\"DirectIn Set F1:\", f1_score(yTest2, model_sc.predict(XTest2)[-1], sample_weight=sampleDiW))\n",
    "    print(\"DirectIn Set MCC:\", matthews_corrcoef(yTest2, model_sc.predict(XTest2)[-1], sample_weight=sampleDiW))\n",
    "    print(\"DirectIn Set Recall:\", recall_score(yTest2, model_sc.predict(XTest2)[-1]))\n",
    "    print(\"DirectIn Test Set Accuracy:\", metrics.accuracy_score(yTest2, predictions_di))\n",
    "    print(classification_report(yTest2, predictions_di))\n",
    "    print(confusion_matrix(yTest2, predictions_di))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_di, tpr_di, _ = metrics.roc_curve(yTest2, predictions_di)\n",
    "    plt.plot(fpr_di,tpr_di)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"G:/raMSIn/XGB_Importance2/XGB2_ROC_FNAtest2.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "53611a51",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set F1: 0.8581549740450832\n",
      "Training Set MCC: 0.7143628683390962\n",
      "Training Set Accuracy: 0.8568381706244503\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.85      0.86     47449\n",
      "           1       0.84      0.86      0.85     43511\n",
      "\n",
      "    accuracy                           0.86     90960\n",
      "   macro avg       0.86      0.86      0.86     90960\n",
      "weighted avg       0.86      0.86      0.86     90960\n",
      "\n",
      "[[40334  7115]\n",
      " [ 5907 37604]]\n",
      "Ext Val Set F1: 0.5914788118085019\n",
      "Ext Val Set MCC: 0.12710476188572267\n",
      "Ext Val Set Accuracy: 0.5651028806584362\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.49      0.52      2943\n",
      "           1       0.57      0.63      0.60      3132\n",
      "\n",
      "    accuracy                           0.57      6075\n",
      "   macro avg       0.56      0.56      0.56      6075\n",
      "weighted avg       0.56      0.57      0.56      6075\n",
      "\n",
      "[[1451 1492]\n",
      " [1150 1982]]\n",
      "FNA Set F1: 0.7454350055251271\n",
      "FNA Set MCC: 0.4878917286055394\n",
      "FNA Set Recall: 0.749824505785648\n",
      "FNA Test Set Accuracy: 0.743903676395982\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.74      0.74     44540\n",
      "           1       0.74      0.75      0.74     44161\n",
      "\n",
      "    accuracy                           0.74     88701\n",
      "   macro avg       0.74      0.74      0.74     88701\n",
      "weighted avg       0.74      0.74      0.74     88701\n",
      "\n",
      "[[32872 11668]\n",
      " [11048 33113]]\n",
      "DirectIn Set F1: 0.40403452957966274\n",
      "DirectIn Set MCC: -0.17522469683399847\n",
      "DirectIn Set Recall: 0.39834983498349835\n",
      "DirectIn Test Set Accuracy: 0.4124153871553574\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.43      0.42      3027\n",
      "           1       0.41      0.40      0.40      3030\n",
      "\n",
      "    accuracy                           0.41      6057\n",
      "   macro avg       0.41      0.41      0.41      6057\n",
      "weighted avg       0.41      0.41      0.41      6057\n",
      "\n",
      "[[1291 1736]\n",
      " [1823 1207]]\n"
     ]
    }
   ],
   "source": [
    "Stacking_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81113c91",
   "metadata": {},
   "source": [
    "### 3.3.5. Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3de1f12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Voting_func(XTrain=X_train, XVal=X_val, XTest=X_FNA, XTest2=X_di, yTrain=y_train, yVal=y_val, yTest=y_FNA, yTest2=y_di):\n",
    "\n",
    "    models = get_models()\n",
    "    \n",
    "    ensemble = models[\"hard_voting\"]\n",
    "    ensemble.fit(XTrain, yTrain)\n",
    "    #=======================================\n",
    "\n",
    "    # Training Set\n",
    "    #plt.rcParams[\"figure.figsize\"] = (3,3)\n",
    "    X_train_predictions = ensemble.predict(X_train)\n",
    "    print(\"Training Set F1:\", f1_score(y_train, ensemble.predict(X_train), sample_weight=sampleW))\n",
    "    print(\"Training Set MCC:\", matthews_corrcoef(y_train, ensemble.predict(X_train), sample_weight=sampleW))\n",
    "    print(\"Training Set Accuracy:\", metrics.accuracy_score(y_train, X_train_predictions))\n",
    "    print(classification_report(y_train, X_train_predictions))\n",
    "    print(confusion_matrix(y_train, X_train_predictions))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr, tpr, _ = metrics.roc_curve(y_train, X_train_predictions)\n",
    "    plt.plot(fpr,tpr)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_train.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    # Val set\n",
    "    predictions_val  = ensemble.predict(XVal)\n",
    "    print(\"Ext Val Set F1:\", f1_score(yVal, ensemble.predict(XVal), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set MCC:\", matthews_corrcoef(yVal, ensemble.predict(XVal), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set Accuracy:\", metrics.accuracy_score(yVal, predictions_val))\n",
    "    print(classification_report(yVal, predictions_val))\n",
    "    print(confusion_matrix(yVal, predictions_val))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_val, tpr_val, _ = metrics.roc_curve(yVal, predictions_val)\n",
    "    plt.plot(fpr_val,tpr_val)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_test.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    f1_5_train = cross_val_score(ensemble, XTrain, yTrain, cv = 5, scoring=\"f1\")\n",
    "    print(\"5F-CV:\", avgScore(f1_5_train, 5))\n",
    "\n",
    "    # Test set\n",
    "    predictions_FNA = ensemble.predict(XTest)\n",
    "    print(\"FNA Set F1:\", f1_score(yTest, ensemble.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set MCC:\", matthews_corrcoef(yTest, ensemble.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set Recall:\", recall_score(yTest, ensemble.predict(XTest)))\n",
    "    print(\"FNA Test Set Accuracy:\", metrics.accuracy_score(yTest, predictions_FNA))\n",
    "    print(classification_report(yTest, predictions_FNA))\n",
    "    print(confusion_matrix(yTest, predictions_FNA))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_FNA, tpr_FNA, _ = metrics.roc_curve(yTest, predictions_FNA)\n",
    "    plt.plot(fpr_FNA,tpr_FNA)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"G:/raMSIn/XGB_Importance2/XGB2_ROC_FNAtest2.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    # Test2 set\n",
    "    predictions_di = ensemble.predict(XTest2)\n",
    "    print(\"DirectIn Set F1:\", f1_score(yTest2, ensemble.predict(XTest2), sample_weight=sampleDiW))\n",
    "    print(\"DirectIn Set MCC:\", matthews_corrcoef(yTest2, ensemble.predict(XTest2), sample_weight=sampleDiW))\n",
    "    print(\"DirectIn Set Recall:\", recall_score(yTest2, ensemble.predict(XTest2)))\n",
    "    print(\"DirectIn Test Set Accuracy:\", metrics.accuracy_score(yTest2, predictions_di))\n",
    "    print(classification_report(yTest2, predictions_di))\n",
    "    print(confusion_matrix(yTest2, predictions_di))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_di, tpr_di, _ = metrics.roc_curve(yTest2, predictions_di)\n",
    "    plt.plot(fpr_di,tpr_di)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"G:/raMSIn/XGB_Importance2/XGB2_ROC_FNAtest2.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "becdb109",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set F1: 0.9218312799074067\n",
      "Training Set MCC: 0.8471903324479612\n",
      "Training Set Accuracy: 0.9241094986807388\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.93     47449\n",
      "           1       0.93      0.90      0.92     43511\n",
      "\n",
      "    accuracy                           0.92     90960\n",
      "   macro avg       0.92      0.92      0.92     90960\n",
      "weighted avg       0.92      0.92      0.92     90960\n",
      "\n",
      "[[44700  2749]\n",
      " [ 4154 39357]]\n",
      "Ext Val Set F1: 0.26912856862750617\n",
      "Ext Val Set MCC: -0.3291250566775732\n",
      "Ext Val Set Accuracy: 0.3354732510288066\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.43      0.39      2943\n",
      "           1       0.31      0.24      0.27      3132\n",
      "\n",
      "    accuracy                           0.34      6075\n",
      "   macro avg       0.33      0.34      0.33      6075\n",
      "weighted avg       0.33      0.34      0.33      6075\n",
      "\n",
      "[[1275 1668]\n",
      " [2369  763]]\n",
      "5F-CV: 0.8250353689979267\n",
      "FNA Set F1: 0.5642922155848031\n",
      "FNA Set MCC: 0.24552267012628848\n",
      "FNA Set Recall: 0.4936255972464392\n",
      "FNA Test Set Accuracy: 0.6193842234022164\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.74      0.66     44540\n",
      "           1       0.66      0.49      0.56     44161\n",
      "\n",
      "    accuracy                           0.62     88701\n",
      "   macro avg       0.63      0.62      0.61     88701\n",
      "weighted avg       0.63      0.62      0.61     88701\n",
      "\n",
      "[[33141 11399]\n",
      " [22362 21799]]\n",
      "DirectIn Set F1: 0.334103571839503\n",
      "DirectIn Set MCC: -0.19501863453966686\n",
      "DirectIn Set Recall: 0.2986798679867987\n",
      "DirectIn Test Set Accuracy: 0.40465577018325904\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.51      0.46      3027\n",
      "           1       0.38      0.30      0.33      3030\n",
      "\n",
      "    accuracy                           0.40      6057\n",
      "   macro avg       0.40      0.40      0.40      6057\n",
      "weighted avg       0.40      0.40      0.40      6057\n",
      "\n",
      "[[1546 1481]\n",
      " [2125  905]]\n"
     ]
    }
   ],
   "source": [
    "Voting_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08fd62e",
   "metadata": {},
   "source": [
    "## 3.4 Machine Learning Modeling: Model 2 (Train 4:4, Val 6:6, Test 3:3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961246f0",
   "metadata": {},
   "source": [
    "### 3.4.1. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "99086aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build Logistic Regression Model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def LogisticRegression_func(XTrain=X_val, XVal=X_train, XTest=X_FNA, yTrain=y_val, yVal=y_train, yTest=y_FNA):\n",
    "    model_lr = LogisticRegression(C=0.001, penalty='l1', solver=\"liblinear\", max_iter=5000, random_state=42, class_weight={0:0.9628, 1:1.0402})  # max_iter=100\n",
    "    model_lr.fit(XTrain,yTrain)\n",
    "    \n",
    "    # Training Set\n",
    "    #plt.rcParams[\"figure.figsize\"] = (3,3)\n",
    "    X_train_predictions = model_lr.predict(XVal)\n",
    "    print(\"Training Set F1:\", f1_score(yVal, model_lr.predict(XVal), sample_weight=sampleW))\n",
    "    print(\"Training Set MCC:\", matthews_corrcoef(yVal, model_lr.predict(XVal), sample_weight=sampleW))\n",
    "    print(\"Training Set Accuracy:\", metrics.accuracy_score(yVal, X_train_predictions))\n",
    "    print(classification_report(yVal, X_train_predictions))\n",
    "    print(confusion_matrix(yVal, X_train_predictions))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr, tpr, _ = metrics.roc_curve(yVal, X_train_predictions)\n",
    "    plt.plot(fpr,tpr)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_train.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    # Val set\n",
    "    predictions_val  = model_lr.predict(XTrain)\n",
    "    print(\"Ext Val Set F1:\", f1_score(yTrain, model_lr.predict(XTrain), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set MCC:\", matthews_corrcoef(yTrain, model_lr.predict(XTrain), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set Accuracy:\", metrics.accuracy_score(yTrain, predictions_val))\n",
    "    print(classification_report(yTrain, predictions_val))\n",
    "    print(confusion_matrix(yTrain, predictions_val))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_val, tpr_val, _ = metrics.roc_curve(yTrain, predictions_val)\n",
    "    plt.plot(fpr_val,tpr_val)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_test.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    f1_5_train = cross_val_score(model_lr, XTrain, yTrain, cv = 5, scoring=\"f1\")\n",
    "    print(\"5F-CV:\", avgScore(f1_5_train, 5))\n",
    "    \n",
    "    # Test set\n",
    "    predictions_FNA = model_lr.predict(XTest)\n",
    "    print(\"FNA Set F1:\", f1_score(yTest, model_lr.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set MCC:\", matthews_corrcoef(yTest, model_lr.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set Recall:\", recall_score(yTest, model_lr.predict(XTest)))\n",
    "    print(\"FNA Test Set Accuracy:\", metrics.accuracy_score(yTest, predictions_FNA))\n",
    "    print(classification_report(yTest, predictions_FNA))\n",
    "    print(confusion_matrix(yTest, predictions_FNA))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_FNA, tpr_FNA, _ = metrics.roc_curve(yTest, predictions_FNA)\n",
    "    plt.plot(fpr_FNA,tpr_FNA)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"G:/raMSIn/XGB_Importance2/XGB2_ROC_FNAtest2.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    # Visualize the importantance of the features\n",
    "    feature_imp = pd.Series(model_lr.coef_[0], index=XTrain.columns).sort_values(ascending=False)\n",
    "    x=feature_imp\n",
    "    y=feature_imp.index\n",
    "    \n",
    "    plt.subplots(dpi = 300)\n",
    "    #plt.rcParams[\"figure.figsize\"] = [4, 6]\n",
    "    #plt.rcParams[\"font.family\"] = \"Arial\"\n",
    "    #plt.rcParams.update({'font.size': 6})\n",
    "    plt.xlabel('Feature Importance Score', fontproperties='Arial', fontsize=17)\n",
    "    plt.ylabel('Features', fontproperties='Arial', fontsize=17)\n",
    "    plt.xticks(fontsize=15)\n",
    "    plt.yticks(fontsize=15)\n",
    "    plt.title(\"Important Molecular Features\", fontproperties='Arial', fontsize=20)\n",
    "    sns.barplot(x=feature_imp, y=feature_imp.index)\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_TopFeatures.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    #feature_importances = model_lr.coef_[0]\n",
    "    #feature_df=pd.DataFrame({'m/z':XTrain.columns,'coef':feature_importances})\n",
    "\n",
    "    #fig = px.bar(feature_df, x='coef', y='m/z')\n",
    "    #fig.show()\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ff504fe8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set F1: 0.0\n",
      "Training Set MCC: 0.0\n",
      "Training Set Accuracy: 0.5216468777484609\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      1.00      0.69     47449\n",
      "           1       0.00      0.00      0.00     43511\n",
      "\n",
      "    accuracy                           0.52     90960\n",
      "   macro avg       0.26      0.50      0.34     90960\n",
      "weighted avg       0.27      0.52      0.36     90960\n",
      "\n",
      "[[47449     0]\n",
      " [43511     0]]\n",
      "Ext Val Set F1: 0.0\n",
      "Ext Val Set MCC: 0.0\n",
      "Ext Val Set Accuracy: 0.48444444444444446\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      1.00      0.65      2943\n",
      "           1       0.00      0.00      0.00      3132\n",
      "\n",
      "    accuracy                           0.48      6075\n",
      "   macro avg       0.24      0.50      0.33      6075\n",
      "weighted avg       0.23      0.48      0.32      6075\n",
      "\n",
      "[[2943    0]\n",
      " [3132    0]]\n",
      "5F-CV: 0.0\n",
      "FNA Set F1: 0.0\n",
      "FNA Set MCC: 0.0\n",
      "FNA Set Recall: 0.0\n",
      "FNA Test Set Accuracy: 0.5021363907960451\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67     44540\n",
      "           1       0.00      0.00      0.00     44161\n",
      "\n",
      "    accuracy                           0.50     88701\n",
      "   macro avg       0.25      0.50      0.33     88701\n",
      "weighted avg       0.25      0.50      0.34     88701\n",
      "\n",
      "[[44540     0]\n",
      " [44161     0]]\n"
     ]
    }
   ],
   "source": [
    "coeff_LogReg, TOPfeatures_LogReg = LogisticRegression_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a040e5",
   "metadata": {},
   "source": [
    "### 3.4.2. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ae3652ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build LinearSVC Model\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "def LinearSVC_func(XTrain=X_val, XVal=X_train, XTest=X_FNA, yTrain=y_val, yVal=y_train, yTest=y_FNA):\n",
    "    model_svm = LinearSVC(penalty='l2', loss=\"squared_hinge\", C=461, random_state=42, class_weight={0:0.9628, 1:1.0402})\n",
    "    model_svm.fit(XTrain,yTrain)\n",
    "    \n",
    "    # Training Set\n",
    "    #plt.rcParams[\"figure.figsize\"] = (3,3)\n",
    "    X_train_predictions = model_svm.predict(XVal)\n",
    "    print(\"Training Set F1:\", f1_score(yVal, model_svm.predict(XVal), sample_weight=sampleW))\n",
    "    print(\"Training Set MCC:\", matthews_corrcoef(yVal, model_svm.predict(XVal), sample_weight=sampleW))\n",
    "    print(\"Training Set Accuracy:\", metrics.accuracy_score(yVal, X_train_predictions))\n",
    "    print(classification_report(yVal, X_train_predictions))\n",
    "    print(confusion_matrix(yVal, X_train_predictions))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr, tpr, _ = metrics.roc_curve(yVal, X_train_predictions)\n",
    "    plt.plot(fpr,tpr)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_train.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    # Val set\n",
    "    predictions_val  = model_svm.predict(XTrain)\n",
    "    print(\"Ext Val Set F1:\", f1_score(yTrain, model_svm.predict(XTrain), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set MCC:\", matthews_corrcoef(yTrain, model_svm.predict(XTrain), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set Accuracy:\", metrics.accuracy_score(yTrain, predictions_val))\n",
    "    print(classification_report(yTrain, predictions_val))\n",
    "    print(confusion_matrix(yTrain, predictions_val))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_val, tpr_val, _ = metrics.roc_curve(yTrain, predictions_val)\n",
    "    plt.plot(fpr_val,tpr_val)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_test.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    f1_5_train = cross_val_score(model_svm, XTrain, yTrain, cv = 5, scoring=\"f1\")\n",
    "    print(\"5F-CV:\", avgScore(f1_5_train, 5))\n",
    "    \n",
    "    # Test set\n",
    "    predictions_FNA = model_svm.predict(XTest)\n",
    "    print(\"FNA Set F1:\", f1_score(yTest, model_svm.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set MCC:\", matthews_corrcoef(yTest, model_svm.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set Recall:\", recall_score(yTest, model_svm.predict(XTest)))\n",
    "    print(\"FNA Test Set Accuracy:\", metrics.accuracy_score(yTest, predictions_FNA))\n",
    "    print(classification_report(yTest, predictions_FNA))\n",
    "    print(confusion_matrix(yTest, predictions_FNA))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_FNA, tpr_FNA, _ = metrics.roc_curve(yTest, predictions_FNA)\n",
    "    plt.plot(fpr_FNA,tpr_FNA)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"G:/raMSIn/XGB_Importance2/XGB2_ROC_FNAtest2.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    # Visualize the importantance of the features\n",
    "    feature_imp = pd.Series(model_svm.coef_[0], index=XTrain.columns).sort_values(ascending=False)\n",
    "    x=feature_imp\n",
    "    y=feature_imp.index\n",
    "    \n",
    "    plt.subplots(dpi = 300)\n",
    "    #plt.rcParams[\"figure.figsize\"] = [4, 6]\n",
    "    #plt.rcParams[\"font.family\"] = \"Arial\"\n",
    "    #plt.rcParams.update({'font.size': 6})\n",
    "    plt.xlabel('Feature Importance Score', fontproperties='Arial', fontsize=17)\n",
    "    plt.ylabel('Features', fontproperties='Arial', fontsize=17)\n",
    "    plt.xticks(fontsize=15)\n",
    "    plt.yticks(fontsize=15)\n",
    "    plt.title(\"Important Molecular Features\", fontproperties='Arial', fontsize=20)\n",
    "    sns.barplot(x=feature_imp, y=feature_imp.index)\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_TopFeatures.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    #feature_importances = model_svm.coef_[0]\n",
    "    #feature_df=pd.DataFrame({'m/z':XTrain.columns,'coef':feature_importances})\n",
    "\n",
    "    #fig = px.bar(feature_df, x='coef', y='m/z')\n",
    "    #fig.show()\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8936e108",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set F1: 0.822060296453499\n",
      "Training Set MCC: 0.6471318805689714\n",
      "Training Set Accuracy: 0.8238786279683378\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83     47449\n",
      "           1       0.82      0.82      0.82     43511\n",
      "\n",
      "    accuracy                           0.82     90960\n",
      "   macro avg       0.82      0.82      0.82     90960\n",
      "weighted avg       0.82      0.82      0.82     90960\n",
      "\n",
      "[[39466  7983]\n",
      " [ 8037 35474]]\n",
      "Ext Val Set F1: 0.9496782743961818\n",
      "Ext Val Set MCC: 0.9012093799913425\n",
      "Ext Val Set Accuracy: 0.9499588477366255\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95      2943\n",
      "           1       0.97      0.94      0.95      3132\n",
      "\n",
      "    accuracy                           0.95      6075\n",
      "   macro avg       0.95      0.95      0.95      6075\n",
      "weighted avg       0.95      0.95      0.95      6075\n",
      "\n",
      "[[2840  103]\n",
      " [ 201 2931]]\n",
      "5F-CV: 0.8823789778869807\n",
      "FNA Set F1: 0.6746413925803055\n",
      "FNA Set MCC: 0.37312466969846503\n",
      "FNA Set Recall: 0.6508684133058581\n",
      "FNA Test Set Accuracy: 0.686249309477909\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.72      0.70     44540\n",
      "           1       0.70      0.65      0.67     44161\n",
      "\n",
      "    accuracy                           0.69     88701\n",
      "   macro avg       0.69      0.69      0.69     88701\n",
      "weighted avg       0.69      0.69      0.69     88701\n",
      "\n",
      "[[32128 12412]\n",
      " [15418 28743]]\n"
     ]
    }
   ],
   "source": [
    "coeff_SVM, TOPfeatures_SVM = LinearSVC_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d25a8aa",
   "metadata": {},
   "source": [
    "### 3.4.3. GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0bf777fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build GBM Model\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "def GBM_func(XTrain=X_val, XVal=X_train, XTest=X_FNA, yTrain=y_val, yVal=y_train, yTest=y_FNA):\n",
    "    model_gbm = GradientBoostingClassifier(learning_rate=4, n_estimators=50, max_depth=7, min_samples_leaf=4, min_samples_split=30, n_iter_no_change=5, random_state=42)\n",
    "    model_gbm.fit(XTrain,yTrain)\n",
    "    \n",
    "    # Training Set\n",
    "    #plt.rcParams[\"figure.figsize\"] = (3,3)\n",
    "    X_train_predictions = model_gbm.predict(XVal)\n",
    "    print(\"Training Set F1:\", f1_score(yVal, model_gbm.predict(XVal), sample_weight=sampleW))\n",
    "    print(\"Training Set MCC:\", matthews_corrcoef(yVal, model_gbm.predict(XVal), sample_weight=sampleW))\n",
    "    print(\"Training Set Accuracy:\", metrics.accuracy_score(yVal, X_train_predictions))\n",
    "    print(classification_report(yVal, X_train_predictions))\n",
    "    print(confusion_matrix(yVal, X_train_predictions))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr, tpr, _ = metrics.roc_curve(yVal, X_train_predictions)\n",
    "    plt.plot(fpr,tpr)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_train.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    # Val set\n",
    "    predictions_val  = model_gbm.predict(XTrain)\n",
    "    print(\"Ext Val Set F1:\", f1_score(yTrain, model_gbm.predict(XTrain), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set MCC:\", matthews_corrcoef(yTrain, model_gbm.predict(XTrain), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set Accuracy:\", metrics.accuracy_score(yTrain, predictions_val))\n",
    "    print(classification_report(yTrain, predictions_val))\n",
    "    print(confusion_matrix(yTrain, predictions_val))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_val, tpr_val, _ = metrics.roc_curve(yTrain, predictions_val)\n",
    "    plt.plot(fpr_val,tpr_val)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_test.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    f1_5_train = cross_val_score(model_gbm, XTrain, yTrain, cv = 5, scoring=\"f1\")\n",
    "    print(\"5F-CV:\", avgScore(f1_5_train, 5))\n",
    "    \n",
    "    # Test set\n",
    "    predictions_FNA = model_gbm.predict(XTest)\n",
    "    print(\"FNA Set F1:\", f1_score(yTest, model_gbm.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set MCC:\", matthews_corrcoef(yTest, model_gbm.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set Recall:\", recall_score(yTest, model_gbm.predict(XTest)))\n",
    "    print(\"FNA Test Set Accuracy:\", metrics.accuracy_score(yTest, predictions_FNA))\n",
    "    print(classification_report(yTest, predictions_FNA))\n",
    "    print(confusion_matrix(yTest, predictions_FNA))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_FNA, tpr_FNA, _ = metrics.roc_curve(yTest, predictions_FNA)\n",
    "    plt.plot(fpr_FNA,tpr_FNA)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"G:/raMSIn/XGB_Importance2/XGB2_ROC_FNAtest2.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    # Visualize the importantance of the features\n",
    "    feature_imp = pd.Series(model_gbm.feature_importances_, index=XTrain.columns).sort_values(ascending=False)\n",
    "    x=feature_imp\n",
    "    y=feature_imp.index\n",
    "    \n",
    "    plt.subplots(dpi = 300)\n",
    "    #plt.rcParams[\"figure.figsize\"] = [4, 6]\n",
    "    #plt.rcParams[\"font.family\"] = \"Arial\"\n",
    "    #plt.rcParams.update({'font.size': 6})\n",
    "    plt.xlabel('Feature Importance Score', fontproperties='Arial', fontsize=17)\n",
    "    plt.ylabel('Features', fontproperties='Arial', fontsize=17)\n",
    "    plt.xticks(fontsize=15)\n",
    "    plt.yticks(fontsize=15)\n",
    "    plt.title(\"Important Molecular Features\", fontproperties='Arial', fontsize=20)\n",
    "    sns.barplot(x=feature_imp, y=feature_imp.index)\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/XGB_TopFeatures.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    # Visualize the boxplot of the important features between the two groups\n",
    "    #fig = px.box(data_frame = df_ROI_for_ML_Opti, x = feature_imp[:10].index,color= 'type')\n",
    "    #fig.show()\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "58c5dcd8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set F1: 0.5414647738806154\n",
      "Training Set MCC: 0.2041944147732082\n",
      "Training Set Accuracy: 0.6042656112576957\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.72      0.66     47449\n",
      "           1       0.61      0.47      0.53     43511\n",
      "\n",
      "    accuracy                           0.60     90960\n",
      "   macro avg       0.61      0.60      0.60     90960\n",
      "weighted avg       0.61      0.60      0.60     90960\n",
      "\n",
      "[[34353 13096]\n",
      " [22900 20611]]\n",
      "Ext Val Set F1: 0.6055917548901529\n",
      "Ext Val Set MCC: 0.2326140950798751\n",
      "Ext Val Set Accuracy: 0.6153086419753087\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.64      0.62      2943\n",
      "           1       0.64      0.59      0.61      3132\n",
      "\n",
      "    accuracy                           0.62      6075\n",
      "   macro avg       0.62      0.62      0.62      6075\n",
      "weighted avg       0.62      0.62      0.62      6075\n",
      "\n",
      "[[1892 1051]\n",
      " [1286 1846]]\n",
      "5F-CV: 0.6467367938622762\n",
      "FNA Set F1: 0.559634571140626\n",
      "FNA Set MCC: 0.08145229780581788\n",
      "FNA Set Recall: 0.5838409456307602\n",
      "FNA Test Set Accuracy: 0.5403884961838086\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.50      0.52     44540\n",
      "           1       0.54      0.58      0.56     44161\n",
      "\n",
      "    accuracy                           0.54     88701\n",
      "   macro avg       0.54      0.54      0.54     88701\n",
      "weighted avg       0.54      0.54      0.54     88701\n",
      "\n",
      "[[22150 22390]\n",
      " [18378 25783]]\n"
     ]
    }
   ],
   "source": [
    "coeff_GBM, TOPfeatures_GBM = GBM_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c276f472",
   "metadata": {},
   "source": [
    "### 3.4.4. Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b940433a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build stacking Model\n",
    "\n",
    "def Stacking_func(XTrain=X_val, XVal=X_train, XTest=X_FNA, XTest2=X_di, yTrain=y_val, yVal=y_train, yTest=y_FNA, yTest2=y_di):\n",
    "\n",
    "    base_learners = []\n",
    "\n",
    "    # Define models to use in stacking ensemble\n",
    "    m1 = LogisticRegression(C=0.001, penalty='l1', solver=\"liblinear\", max_iter=5000, random_state=42, class_weight={0:0.9628, 1:1.0402})\n",
    "    base_learners.append(m1)\n",
    "\n",
    "    m2 = LinearSVC(penalty='l2', loss=\"squared_hinge\", C=461, random_state=42, class_weight={0:0.9628, 1:1.0402})\n",
    "    base_learners.append(m2)\n",
    "\n",
    "    m3 = GradientBoostingClassifier(learning_rate=4, n_estimators=50, max_depth=7, min_samples_leaf=4, min_samples_split=30, n_iter_no_change=5, random_state=42)\n",
    "    base_learners.append(m3)\n",
    "\n",
    "    # Define the meta-classifier to use for stacking\n",
    "    meta_learner = LogisticRegression(C=0.0011, penalty='l1', solver=\"liblinear\", max_iter=5000, random_state=42)\n",
    "\n",
    "    model_sc = StackingRegressor([[m1, m2, m3], [meta_learner]])\n",
    "    model_sc.fit(XTrain, yTrain)\n",
    "    \n",
    "    #=======================================\n",
    "    \n",
    "    # Training Set\n",
    "    #plt.rcParams[\"figure.figsize\"] = (3,3)\n",
    "    X_train_predictions = model_sc.predict(XVal)[-1]\n",
    "    print(\"Training Set F1:\", f1_score(yVal, model_sc.predict(XVal)[-1], sample_weight=sampleW))\n",
    "    print(\"Training Set MCC:\", matthews_corrcoef(yVal, model_sc.predict(XVal)[-1], sample_weight=sampleW))\n",
    "    print(\"Training Set Accuracy:\", metrics.accuracy_score(yVal, X_train_predictions))\n",
    "    print(classification_report(yVal, X_train_predictions))\n",
    "    print(confusion_matrix(yVal, X_train_predictions))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr, tpr, _ = metrics.roc_curve(yVal, X_train_predictions)\n",
    "    plt.plot(fpr,tpr)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_train.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    # Val set\n",
    "    predictions_val  = model_sc.predict(XTrain)[-1]\n",
    "    print(\"Ext Val Set F1:\", f1_score(yTrain, model_sc.predict(XTrain)[-1], sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set MCC:\", matthews_corrcoef(yTrain, model_sc.predict(XTrain)[-1], sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set Accuracy:\", metrics.accuracy_score(yTrain, predictions_val))\n",
    "    print(classification_report(yTrain, predictions_val))\n",
    "    print(confusion_matrix(yTrain, predictions_val))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_val, tpr_val, _ = metrics.roc_curve(yTrain, predictions_val)\n",
    "    plt.plot(fpr_val,tpr_val)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_test.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    #f1_5_train = cross_val_score(model_sc, XTrain, yTrain, cv = 5, scoring=\"f1\")\n",
    "    #print(\"5F-CV:\", avgScore(f1_5_train, 5))\n",
    "    \n",
    "    # Test set\n",
    "    predictions_FNA = model_sc.predict(XTest)[-1]\n",
    "    print(\"FNA Set F1:\", f1_score(yTest, model_sc.predict(XTest)[-1], sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set MCC:\", matthews_corrcoef(yTest, model_sc.predict(XTest)[-1], sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set Recall:\", recall_score(yTest, model_sc.predict(XTest)[-1]))\n",
    "    print(\"FNA Test Set Accuracy:\", metrics.accuracy_score(yTest, predictions_FNA))\n",
    "    print(classification_report(yTest, predictions_FNA))\n",
    "    print(confusion_matrix(yTest, predictions_FNA))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_FNA, tpr_FNA, _ = metrics.roc_curve(yTest, predictions_FNA)\n",
    "    plt.plot(fpr_FNA,tpr_FNA)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"G:/raMSIn/XGB_Importance2/XGB2_ROC_FNAtest2.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    # Test2 set\n",
    "    predictions_di = model_sc.predict(XTest2)[-1]\n",
    "    print(\"DirectIn Set F1:\", f1_score(yTest2, model_sc.predict(XTest2)[-1], sample_weight=sampleDiW))\n",
    "    print(\"DirectIn Set MCC:\", matthews_corrcoef(yTest2, model_sc.predict(XTest2)[-1], sample_weight=sampleDiW))\n",
    "    print(\"DirectIn Set Recall:\", recall_score(yTest2, model_sc.predict(XTest2)[-1]))\n",
    "    print(\"DirectIn Test Set Accuracy:\", metrics.accuracy_score(yTest2, predictions_di))\n",
    "    print(classification_report(yTest2, predictions_di))\n",
    "    print(confusion_matrix(yTest2, predictions_di))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_di, tpr_di, _ = metrics.roc_curve(yTest2, predictions_di)\n",
    "    plt.plot(fpr_di,tpr_di)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"G:/raMSIn/XGB_Importance2/XGB2_ROC_FNAtest2.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "74cbb345",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set F1: 0.0\n",
      "Training Set MCC: 0.0\n",
      "Training Set Accuracy: 0.5216468777484609\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      1.00      0.69     47449\n",
      "           1       0.00      0.00      0.00     43511\n",
      "\n",
      "    accuracy                           0.52     90960\n",
      "   macro avg       0.26      0.50      0.34     90960\n",
      "weighted avg       0.27      0.52      0.36     90960\n",
      "\n",
      "[[47449     0]\n",
      " [43511     0]]\n",
      "Ext Val Set F1: 0.0\n",
      "Ext Val Set MCC: 0.0\n",
      "Ext Val Set Accuracy: 0.48444444444444446\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      1.00      0.65      2943\n",
      "           1       0.00      0.00      0.00      3132\n",
      "\n",
      "    accuracy                           0.48      6075\n",
      "   macro avg       0.24      0.50      0.33      6075\n",
      "weighted avg       0.23      0.48      0.32      6075\n",
      "\n",
      "[[2943    0]\n",
      " [3132    0]]\n",
      "FNA Set F1: 0.0\n",
      "FNA Set MCC: 0.0\n",
      "FNA Set Recall: 0.0\n",
      "FNA Test Set Accuracy: 0.5021363907960451\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67     44540\n",
      "           1       0.00      0.00      0.00     44161\n",
      "\n",
      "    accuracy                           0.50     88701\n",
      "   macro avg       0.25      0.50      0.33     88701\n",
      "weighted avg       0.25      0.50      0.34     88701\n",
      "\n",
      "[[44540     0]\n",
      " [44161     0]]\n",
      "DirectIn Set F1: 0.0\n",
      "DirectIn Set MCC: 0.0\n",
      "DirectIn Set Recall: 0.0\n",
      "DirectIn Test Set Accuracy: 0.49975235264982665\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67      3027\n",
      "           1       0.00      0.00      0.00      3030\n",
      "\n",
      "    accuracy                           0.50      6057\n",
      "   macro avg       0.25      0.50      0.33      6057\n",
      "weighted avg       0.25      0.50      0.33      6057\n",
      "\n",
      "[[3027    0]\n",
      " [3030    0]]\n"
     ]
    }
   ],
   "source": [
    "Stacking_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b896917b",
   "metadata": {},
   "source": [
    "### 3.4.5. Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d03a0a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Voting_func(XTrain=X_val, XVal=X_train, XTest=X_FNA, XTest2=X_di, yTrain=y_val, yVal=y_train, yTest=y_FNA, yTest2=y_di):\n",
    "\n",
    "    models = get_models()\n",
    "    \n",
    "    ensemble = models[\"hard_voting\"]\n",
    "    ensemble.fit(XTrain, yTrain)\n",
    "    #=======================================\n",
    "\n",
    "    # Training Set\n",
    "    #plt.rcParams[\"figure.figsize\"] = (3,3)\n",
    "    X_train_predictions = ensemble.predict(XVal)\n",
    "    print(\"Training Set F1:\", f1_score(yVal, ensemble.predict(XVal), sample_weight=sampleW))\n",
    "    print(\"Training Set MCC:\", matthews_corrcoef(yVal, ensemble.predict(XVal), sample_weight=sampleW))\n",
    "    print(\"Training Set Accuracy:\", metrics.accuracy_score(yVal, X_train_predictions))\n",
    "    print(classification_report(yVal, X_train_predictions))\n",
    "    print(confusion_matrix(yVal, X_train_predictions))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr, tpr, _ = metrics.roc_curve(yVal, X_train_predictions)\n",
    "    plt.plot(fpr,tpr)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_train.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    # Val set\n",
    "    predictions_val  = ensemble.predict(XTrain)\n",
    "    print(\"Ext Val Set F1:\", f1_score(yTrain, ensemble.predict(XTrain), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set MCC:\", matthews_corrcoef(yTrain, ensemble.predict(XTrain), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set Accuracy:\", metrics.accuracy_score(yTrain, predictions_val))\n",
    "    print(classification_report(yTrain, predictions_val))\n",
    "    print(confusion_matrix(yTrain, predictions_val))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_val, tpr_val, _ = metrics.roc_curve(yTrain, predictions_val)\n",
    "    plt.plot(fpr_val,tpr_val)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_test.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    f1_5_train = cross_val_score(ensemble, XTrain, yTrain, cv = 5, scoring=\"f1\")\n",
    "    print(\"5F-CV:\", avgScore(f1_5_train, 5))\n",
    "\n",
    "    # Test set\n",
    "    predictions_FNA = ensemble.predict(XTest)\n",
    "    print(\"FNA Set F1:\", f1_score(yTest, ensemble.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set MCC:\", matthews_corrcoef(yTest, ensemble.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set Recall:\", recall_score(yTest, ensemble.predict(XTest)))\n",
    "    print(\"FNA Test Set Accuracy:\", metrics.accuracy_score(yTest, predictions_FNA))\n",
    "    print(classification_report(yTest, predictions_FNA))\n",
    "    print(confusion_matrix(yTest, predictions_FNA))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_FNA, tpr_FNA, _ = metrics.roc_curve(yTest, predictions_FNA)\n",
    "    plt.plot(fpr_FNA,tpr_FNA)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"G:/raMSIn/XGB_Importance2/XGB2_ROC_FNAtest2.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    # Test2 set\n",
    "    predictions_di = ensemble.predict(XTest2)\n",
    "    print(\"DirectIn Set F1:\", f1_score(yTest2, ensemble.predict(XTest2), sample_weight=sampleDiW))\n",
    "    print(\"DirectIn Set MCC:\", matthews_corrcoef(yTest2, ensemble.predict(XTest2), sample_weight=sampleDiW))\n",
    "    print(\"DirectIn Set Recall:\", recall_score(yTest2, ensemble.predict(XTest2)))\n",
    "    print(\"DirectIn Test Set Accuracy:\", metrics.accuracy_score(yTest2, predictions_di))\n",
    "    print(classification_report(yTest2, predictions_di))\n",
    "    print(confusion_matrix(yTest2, predictions_di))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_di, tpr_di, _ = metrics.roc_curve(yTest2, predictions_di)\n",
    "    plt.plot(fpr_di,tpr_di)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"G:/raMSIn/XGB_Importance2/XGB2_ROC_FNAtest2.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2e1865ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set F1: 0.5408562261624528\n",
      "Training Set MCC: 0.396732768206014\n",
      "Training Set Accuracy: 0.6780123131046614\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.94      0.75     47449\n",
      "           1       0.86      0.39      0.54     43511\n",
      "\n",
      "    accuracy                           0.68     90960\n",
      "   macro avg       0.74      0.67      0.65     90960\n",
      "weighted avg       0.74      0.68      0.65     90960\n",
      "\n",
      "[[44563  2886]\n",
      " [26402 17109]]\n",
      "Ext Val Set F1: 0.7015330614851787\n",
      "Ext Val Set MCC: 0.5949849771903635\n",
      "Ext Val Set Accuracy: 0.7603292181069958\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.99      0.80      2943\n",
      "           1       0.98      0.55      0.70      3132\n",
      "\n",
      "    accuracy                           0.76      6075\n",
      "   macro avg       0.83      0.77      0.75      6075\n",
      "weighted avg       0.83      0.76      0.75      6075\n",
      "\n",
      "[[2905   38]\n",
      " [1418 1714]]\n",
      "5F-CV: 0.7339920624288725\n",
      "FNA Set F1: 0.550187545521609\n",
      "FNA Set MCC: 0.31266324267641066\n",
      "FNA Set Recall: 0.43721836009148346\n",
      "FNA Test Set Accuracy: 0.6434200290864815\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.85      0.70     44540\n",
      "           1       0.74      0.44      0.55     44161\n",
      "\n",
      "    accuracy                           0.64     88701\n",
      "   macro avg       0.67      0.64      0.63     88701\n",
      "weighted avg       0.67      0.64      0.63     88701\n",
      "\n",
      "[[37764  6776]\n",
      " [24853 19308]]\n",
      "DirectIn Set F1: 0.34602008537924833\n",
      "DirectIn Set MCC: -0.05353856925506891\n",
      "DirectIn Set Recall: 0.27755775577557756\n",
      "DirectIn Test Set Accuracy: 0.4753178140993891\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.67      0.56      3027\n",
      "           1       0.46      0.28      0.35      3030\n",
      "\n",
      "    accuracy                           0.48      6057\n",
      "   macro avg       0.47      0.48      0.45      6057\n",
      "weighted avg       0.47      0.48      0.45      6057\n",
      "\n",
      "[[2038  989]\n",
      " [2189  841]]\n"
     ]
    }
   ],
   "source": [
    "Voting_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a613c4",
   "metadata": {},
   "source": [
    "# 4. Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5cafba",
   "metadata": {},
   "source": [
    "## 4.1 Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0ab74741",
   "metadata": {},
   "outputs": [],
   "source": [
    "## deploy models for training set ##\n",
    "model_voting = jl.load(r\"H:\\3_output_raMSIn\\3_3_Output_raMSIn_HKU_Ingested4ALL\\XGB_ALL\\afterModelSelection\\cbMSIn_0d1\\model3to1Voting_cbMSIn0d1.joblib\")\n",
    "#\n",
    "## deploy model ##\n",
    "predicted0n1_train = model_voting.predict(X_train)\n",
    "#predicted0n1_trainProba = model_voting.predict_proba(X_train)         \n",
    "trainDEFSDf[\"predicted0n1\"] = predicted0n1_train\n",
    "T_ = []\n",
    "F_ = []\n",
    "for i in range(len(trainDEFSDf)):\n",
    "    if trainDEFSDf.iloc[i][\"predicted0n1\"] == 1:\n",
    "        T_.append(1)\n",
    "        F_.append(0)\n",
    "    elif trainDEFSDf.iloc[i][\"predicted0n1\"] == 0:\n",
    "        F_.append(1)\n",
    "        T_.append(0)\n",
    "trainDEFSDf[\"T\"] = T_\n",
    "trainDEFSDf[\"F\"] = F_\n",
    "#\n",
    "## save ##, ouputing trainSet df\n",
    "savePath = r\"H:\\3_output_raMSIn\\3_3_Output_raMSIn_HKU_Ingested4ALL\\XGB_ALL\\afterModelSelection\\cbMSIn_0d1\\df_train_cbMSIn0d1_norm_0n1.csv\"\n",
    "trainDEFSDf.to_csv(savePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "76d7c323",
   "metadata": {},
   "outputs": [],
   "source": [
    "## deploy models for Ext Val set ##\n",
    "model_voting = jl.load(r\"H:\\3_output_raMSIn\\3_3_Output_raMSIn_HKU_Ingested4ALL\\XGB_ALL\\afterModelSelection\\cbMSIn_0d1\\model3to1Voting_cbMSIn0d1.joblib\")\n",
    "#\n",
    "## deploy model ##\n",
    "predicted0n1_ext = model_voting.predict(X_val)\n",
    "extDEFSDf[\"predicted0n1\"] = predicted0n1_ext\n",
    "T_ = []\n",
    "F_ = []\n",
    "for i in range(len(extDEFSDf)):\n",
    "    if extDEFSDf.iloc[i][\"predicted0n1\"] == 1:\n",
    "        T_.append(1)\n",
    "        F_.append(0)\n",
    "    elif extDEFSDf.iloc[i][\"predicted0n1\"] == 0:\n",
    "        F_.append(1)\n",
    "        T_.append(0)\n",
    "extDEFSDf[\"T\"] = T_\n",
    "extDEFSDf[\"F\"] = F_\n",
    "#\n",
    "## save ##, ouputing extSet df\n",
    "savePath = r\"H:\\3_output_raMSIn\\3_3_Output_raMSIn_HKU_Ingested4ALL\\XGB_ALL\\afterModelSelection\\cbMSIn_0d1\\df_ext_cbMSIn0d1_norm_0n1.csv\"\n",
    "extDEFSDf.to_csv(savePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3a327944",
   "metadata": {},
   "outputs": [],
   "source": [
    "## deploy models for FNA set ##\n",
    "model_voting = jl.load(r\"H:\\3_output_raMSIn\\3_3_Output_raMSIn_HKU_Ingested4ALL\\XGB_ALL\\afterModelSelection\\cbMSIn_0d1\\model3to1Voting_cbMSIn0d1.joblib\")\n",
    "#\n",
    "## deploy model ##\n",
    "predicted0n1_FNA = model_voting.predict(X_FNA)\n",
    "fnaDEFSDf[\"predicted0n1\"] = predicted0n1_FNA\n",
    "T_ = []\n",
    "F_ = []\n",
    "for i in range(len(fnaDEFSDf)):\n",
    "    if fnaDEFSDf.iloc[i][\"predicted0n1\"] == 1:\n",
    "        T_.append(1)\n",
    "        F_.append(0)\n",
    "    elif fnaDEFSDf.iloc[i][\"predicted0n1\"] == 0:\n",
    "        F_.append(1)\n",
    "        T_.append(0)\n",
    "fnaDEFSDf[\"T\"] = T_\n",
    "fnaDEFSDf[\"F\"] = F_\n",
    "#\n",
    "## save ##, ouputing extSet df\n",
    "savePath = r\"H:\\3_output_raMSIn\\3_3_Output_raMSIn_HKU_Ingested4ALL\\XGB_ALL\\afterModelSelection\\cbMSIn_0d1\\df_FNA_cbMSIn0d1_norm_0n1.csv\"\n",
    "fnaDEFSDf.to_csv(savePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e771a1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "## deploy models for DirectInfusion set ##\n",
    "model_voting = jl.load(r\"H:\\3_output_raMSIn\\3_3_Output_raMSIn_HKU_Ingested4ALL\\XGB_ALL\\afterModelSelection\\cbMSIn_0d1\\model3to1Voting_cbMSIn0d1.joblib\")\n",
    "#\n",
    "## deploy model ##\n",
    "predicted0n1_Di = model_voting.predict(X_di)\n",
    "diDEFSDf[\"predicted0n1\"] = predicted0n1_Di\n",
    "T_ = []\n",
    "F_ = []\n",
    "for i in range(len(diDEFSDf)):\n",
    "    if diDEFSDf.iloc[i][\"predicted0n1\"] == 1:\n",
    "        T_.append(1)\n",
    "        F_.append(0)\n",
    "    elif diDEFSDf.iloc[i][\"predicted0n1\"] == 0:\n",
    "        F_.append(1)\n",
    "        T_.append(0)\n",
    "diDEFSDf[\"T\"] = T_\n",
    "diDEFSDf[\"F\"] = F_\n",
    "#\n",
    "## save ##, ouputing extSet df\n",
    "savePath = r\"H:\\3_output_raMSIn\\3_3_Output_raMSIn_HKU_Ingested4ALL\\XGB_ALL\\afterModelSelection\\cbMSIn_0d1\\df_Di_cbMSIn0d1_norm_0n1.csv\"\n",
    "diDEFSDf.to_csv(savePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3082152",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
