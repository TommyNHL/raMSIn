{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b137a905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\Users\\\\user\\\\anaconda3\\\\lib\\\\site-packages\\\\config']\n",
      "2.12.0-dev20221107\n",
      "2.12.0\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import glob\n",
    "import xlwings as xw\n",
    "import math\n",
    "from pathlib import Path\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "from matplotlib import cm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mclr\n",
    "import plotly.express as px\n",
    "import statsmodels.api as sm\n",
    "import pylab as py\n",
    "import os, cv2, glob, tempfile\n",
    "import joblib\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "import sklearn\n",
    "from sklearn import datasets\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "make_scorer = sklearn.metrics.make_scorer\n",
    "f1 = make_scorer(f1_score, pos_label=1, average=\"binary\")\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate, KFold\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import BatchNormalization, Conv2D, MaxPooling2D, Activation, Dropout, Flatten, Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras import utils as np_utils\n",
    "from keras import models\n",
    "import keras_tuner as kt\n",
    "from scipy import signal\n",
    "\n",
    "import config as config\n",
    "print(config.__path__)\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import to_categorical\n",
    "from keras import backend as K\n",
    "\n",
    "import argparse\n",
    "# from sklearn.utils import class_weight\n",
    "print(tf.__version__)\n",
    "print(keras.__version__)\n",
    "\n",
    "import shutil\n",
    "import xlwings as xw\n",
    "\n",
    "%matplotlib inline\n",
    "mpl.use(\"Agg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5c8a718",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build XGBoost Model\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statsmodels.graphics.tsaplots import plot_acf,plot_pacf\n",
    "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV,train_test_split\n",
    "from skopt import BayesSearchCV\n",
    "from sklearn.metrics import accuracy_score,f1_score,roc_auc_score,confusion_matrix,roc_curve\n",
    "import xgboost as xgb\n",
    "import time\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30868f12",
   "metadata": {},
   "source": [
    "# 1. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "daf38283",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDEFSDf = pd.read_csv(r\"H:\\\\3_output_raMSIn\\\\3_3_Output_raMSIn_HKU_Ingested4ALL\\\\XGB_ALL\\\\df_train_dbMSIn5ppm4nonInDI_norm.csv\")\n",
    "diDEFSDf = pd.read_csv(r\"H:\\\\3_output_raMSIn\\\\3_3_Output_raMSIn_HKU_Ingested4ALL\\\\XGB_ALL\\\\df_nonInDI_dbMSIn5ppm4nonInDI_norm.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36740c29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel_id</th>\n",
       "      <th>311.1684</th>\n",
       "      <th>269.2486</th>\n",
       "      <th>215.0328</th>\n",
       "      <th>295.2278</th>\n",
       "      <th>883.533</th>\n",
       "      <th>309.1725</th>\n",
       "      <th>738.5057</th>\n",
       "      <th>435.2965</th>\n",
       "      <th>280.2361</th>\n",
       "      <th>241.2173</th>\n",
       "      <th>311.2228</th>\n",
       "      <th>339.1996</th>\n",
       "      <th>353.2004</th>\n",
       "      <th>325.1842</th>\n",
       "      <th>250.1449</th>\n",
       "      <th>514.2846</th>\n",
       "      <th>265.1478</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HKULiver_Post29wk_HCCAMCLiver_Left_Mice03_Slid...</td>\n",
       "      <td>0.318763</td>\n",
       "      <td>0.150470</td>\n",
       "      <td>-0.119121</td>\n",
       "      <td>-0.067072</td>\n",
       "      <td>-0.071854</td>\n",
       "      <td>0.384412</td>\n",
       "      <td>-0.143360</td>\n",
       "      <td>0.118134</td>\n",
       "      <td>-0.082548</td>\n",
       "      <td>0.226547</td>\n",
       "      <td>-0.006497</td>\n",
       "      <td>0.230776</td>\n",
       "      <td>0.249742</td>\n",
       "      <td>0.293674</td>\n",
       "      <td>0.126164</td>\n",
       "      <td>-0.040567</td>\n",
       "      <td>0.322933</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HKULiver_Post29wk_HCCAMCLiver_Left_Mice03_Slid...</td>\n",
       "      <td>0.440853</td>\n",
       "      <td>0.394966</td>\n",
       "      <td>-0.038289</td>\n",
       "      <td>-0.067072</td>\n",
       "      <td>0.017921</td>\n",
       "      <td>0.479880</td>\n",
       "      <td>-0.160340</td>\n",
       "      <td>0.058233</td>\n",
       "      <td>-0.102401</td>\n",
       "      <td>0.292198</td>\n",
       "      <td>-0.006497</td>\n",
       "      <td>0.312503</td>\n",
       "      <td>0.313633</td>\n",
       "      <td>0.399218</td>\n",
       "      <td>0.300476</td>\n",
       "      <td>-0.040567</td>\n",
       "      <td>0.392722</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HKULiver_Post29wk_HCCAMCLiver_Left_Mice03_Slid...</td>\n",
       "      <td>0.297858</td>\n",
       "      <td>0.166363</td>\n",
       "      <td>-0.083697</td>\n",
       "      <td>-0.067072</td>\n",
       "      <td>-0.069362</td>\n",
       "      <td>0.317106</td>\n",
       "      <td>-0.150742</td>\n",
       "      <td>-0.029448</td>\n",
       "      <td>-0.088097</td>\n",
       "      <td>0.210543</td>\n",
       "      <td>-0.006497</td>\n",
       "      <td>0.229695</td>\n",
       "      <td>0.257632</td>\n",
       "      <td>0.267805</td>\n",
       "      <td>0.208799</td>\n",
       "      <td>-0.040567</td>\n",
       "      <td>0.315268</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HKULiver_Post29wk_HCCAMCLiver_Left_Mice03_Slid...</td>\n",
       "      <td>0.276322</td>\n",
       "      <td>0.115277</td>\n",
       "      <td>-0.042454</td>\n",
       "      <td>-0.067072</td>\n",
       "      <td>-0.054074</td>\n",
       "      <td>0.299065</td>\n",
       "      <td>-0.143111</td>\n",
       "      <td>-0.018081</td>\n",
       "      <td>-0.106709</td>\n",
       "      <td>0.272757</td>\n",
       "      <td>-0.006497</td>\n",
       "      <td>0.221038</td>\n",
       "      <td>0.208418</td>\n",
       "      <td>0.247311</td>\n",
       "      <td>0.187170</td>\n",
       "      <td>-0.040567</td>\n",
       "      <td>0.303836</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HKULiver_Post29wk_HCCAMCLiver_Left_Mice03_Slid...</td>\n",
       "      <td>0.172632</td>\n",
       "      <td>0.200346</td>\n",
       "      <td>-0.131919</td>\n",
       "      <td>-0.067072</td>\n",
       "      <td>-0.052373</td>\n",
       "      <td>0.219220</td>\n",
       "      <td>-0.146138</td>\n",
       "      <td>0.140049</td>\n",
       "      <td>-0.064402</td>\n",
       "      <td>0.166744</td>\n",
       "      <td>-0.006497</td>\n",
       "      <td>0.138928</td>\n",
       "      <td>0.194134</td>\n",
       "      <td>0.151399</td>\n",
       "      <td>0.094790</td>\n",
       "      <td>-0.040567</td>\n",
       "      <td>0.213324</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90955</th>\n",
       "      <td>HKULiver_Post29wk_HCCLiver_Left_Mice12_Slide4F...</td>\n",
       "      <td>0.035493</td>\n",
       "      <td>-0.272607</td>\n",
       "      <td>0.004148</td>\n",
       "      <td>-0.067072</td>\n",
       "      <td>-0.142422</td>\n",
       "      <td>0.062967</td>\n",
       "      <td>-0.200362</td>\n",
       "      <td>0.242729</td>\n",
       "      <td>-0.173635</td>\n",
       "      <td>-0.248759</td>\n",
       "      <td>-0.006497</td>\n",
       "      <td>0.042836</td>\n",
       "      <td>0.066402</td>\n",
       "      <td>0.035222</td>\n",
       "      <td>0.038175</td>\n",
       "      <td>0.212752</td>\n",
       "      <td>0.036053</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90956</th>\n",
       "      <td>HKULiver_Post29wk_HCCLiver_Left_Mice12_Slide4F...</td>\n",
       "      <td>0.021826</td>\n",
       "      <td>-0.272607</td>\n",
       "      <td>-0.091252</td>\n",
       "      <td>-0.067072</td>\n",
       "      <td>-0.062065</td>\n",
       "      <td>0.074304</td>\n",
       "      <td>-0.191751</td>\n",
       "      <td>0.300467</td>\n",
       "      <td>-0.195074</td>\n",
       "      <td>0.152673</td>\n",
       "      <td>-0.006497</td>\n",
       "      <td>0.050344</td>\n",
       "      <td>0.070289</td>\n",
       "      <td>0.037014</td>\n",
       "      <td>0.210629</td>\n",
       "      <td>-0.040567</td>\n",
       "      <td>0.018591</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90957</th>\n",
       "      <td>HKULiver_Post29wk_HCCLiver_Left_Mice12_Slide4F...</td>\n",
       "      <td>0.030907</td>\n",
       "      <td>0.332829</td>\n",
       "      <td>-0.093406</td>\n",
       "      <td>-0.067072</td>\n",
       "      <td>-0.090889</td>\n",
       "      <td>0.044570</td>\n",
       "      <td>-0.114260</td>\n",
       "      <td>0.195776</td>\n",
       "      <td>-0.156608</td>\n",
       "      <td>-0.248759</td>\n",
       "      <td>-0.006497</td>\n",
       "      <td>0.046817</td>\n",
       "      <td>0.103054</td>\n",
       "      <td>0.037404</td>\n",
       "      <td>0.143302</td>\n",
       "      <td>-0.040567</td>\n",
       "      <td>-0.052554</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90958</th>\n",
       "      <td>HKULiver_Post29wk_HCCLiver_Left_Mice12_Slide4F...</td>\n",
       "      <td>0.045524</td>\n",
       "      <td>-0.272607</td>\n",
       "      <td>-0.122689</td>\n",
       "      <td>-0.067072</td>\n",
       "      <td>-0.163137</td>\n",
       "      <td>0.059988</td>\n",
       "      <td>-0.138465</td>\n",
       "      <td>0.149654</td>\n",
       "      <td>-0.163002</td>\n",
       "      <td>-0.248759</td>\n",
       "      <td>-0.006497</td>\n",
       "      <td>0.033911</td>\n",
       "      <td>-0.067550</td>\n",
       "      <td>0.036384</td>\n",
       "      <td>0.189038</td>\n",
       "      <td>-0.040567</td>\n",
       "      <td>0.048043</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90959</th>\n",
       "      <td>HKULiver_Post29wk_HCCLiver_Left_Mice12_Slide4F...</td>\n",
       "      <td>0.017845</td>\n",
       "      <td>-0.272607</td>\n",
       "      <td>-0.120920</td>\n",
       "      <td>-0.067072</td>\n",
       "      <td>-0.392345</td>\n",
       "      <td>0.049505</td>\n",
       "      <td>-0.112366</td>\n",
       "      <td>0.101809</td>\n",
       "      <td>-0.231187</td>\n",
       "      <td>-0.248759</td>\n",
       "      <td>-0.006497</td>\n",
       "      <td>0.041777</td>\n",
       "      <td>-0.067550</td>\n",
       "      <td>0.028761</td>\n",
       "      <td>0.177671</td>\n",
       "      <td>-0.040567</td>\n",
       "      <td>0.035269</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90960 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                pixel_id  311.1684  269.2486  \\\n",
       "0      HKULiver_Post29wk_HCCAMCLiver_Left_Mice03_Slid...  0.318763  0.150470   \n",
       "1      HKULiver_Post29wk_HCCAMCLiver_Left_Mice03_Slid...  0.440853  0.394966   \n",
       "2      HKULiver_Post29wk_HCCAMCLiver_Left_Mice03_Slid...  0.297858  0.166363   \n",
       "3      HKULiver_Post29wk_HCCAMCLiver_Left_Mice03_Slid...  0.276322  0.115277   \n",
       "4      HKULiver_Post29wk_HCCAMCLiver_Left_Mice03_Slid...  0.172632  0.200346   \n",
       "...                                                  ...       ...       ...   \n",
       "90955  HKULiver_Post29wk_HCCLiver_Left_Mice12_Slide4F...  0.035493 -0.272607   \n",
       "90956  HKULiver_Post29wk_HCCLiver_Left_Mice12_Slide4F...  0.021826 -0.272607   \n",
       "90957  HKULiver_Post29wk_HCCLiver_Left_Mice12_Slide4F...  0.030907  0.332829   \n",
       "90958  HKULiver_Post29wk_HCCLiver_Left_Mice12_Slide4F...  0.045524 -0.272607   \n",
       "90959  HKULiver_Post29wk_HCCLiver_Left_Mice12_Slide4F...  0.017845 -0.272607   \n",
       "\n",
       "       215.0328  295.2278   883.533  309.1725  738.5057  435.2965  280.2361  \\\n",
       "0     -0.119121 -0.067072 -0.071854  0.384412 -0.143360  0.118134 -0.082548   \n",
       "1     -0.038289 -0.067072  0.017921  0.479880 -0.160340  0.058233 -0.102401   \n",
       "2     -0.083697 -0.067072 -0.069362  0.317106 -0.150742 -0.029448 -0.088097   \n",
       "3     -0.042454 -0.067072 -0.054074  0.299065 -0.143111 -0.018081 -0.106709   \n",
       "4     -0.131919 -0.067072 -0.052373  0.219220 -0.146138  0.140049 -0.064402   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "90955  0.004148 -0.067072 -0.142422  0.062967 -0.200362  0.242729 -0.173635   \n",
       "90956 -0.091252 -0.067072 -0.062065  0.074304 -0.191751  0.300467 -0.195074   \n",
       "90957 -0.093406 -0.067072 -0.090889  0.044570 -0.114260  0.195776 -0.156608   \n",
       "90958 -0.122689 -0.067072 -0.163137  0.059988 -0.138465  0.149654 -0.163002   \n",
       "90959 -0.120920 -0.067072 -0.392345  0.049505 -0.112366  0.101809 -0.231187   \n",
       "\n",
       "       241.2173  311.2228  339.1996  353.2004  325.1842  250.1449  514.2846  \\\n",
       "0      0.226547 -0.006497  0.230776  0.249742  0.293674  0.126164 -0.040567   \n",
       "1      0.292198 -0.006497  0.312503  0.313633  0.399218  0.300476 -0.040567   \n",
       "2      0.210543 -0.006497  0.229695  0.257632  0.267805  0.208799 -0.040567   \n",
       "3      0.272757 -0.006497  0.221038  0.208418  0.247311  0.187170 -0.040567   \n",
       "4      0.166744 -0.006497  0.138928  0.194134  0.151399  0.094790 -0.040567   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "90955 -0.248759 -0.006497  0.042836  0.066402  0.035222  0.038175  0.212752   \n",
       "90956  0.152673 -0.006497  0.050344  0.070289  0.037014  0.210629 -0.040567   \n",
       "90957 -0.248759 -0.006497  0.046817  0.103054  0.037404  0.143302 -0.040567   \n",
       "90958 -0.248759 -0.006497  0.033911 -0.067550  0.036384  0.189038 -0.040567   \n",
       "90959 -0.248759 -0.006497  0.041777 -0.067550  0.028761  0.177671 -0.040567   \n",
       "\n",
       "       265.1478  type  \n",
       "0      0.322933     0  \n",
       "1      0.392722     0  \n",
       "2      0.315268     0  \n",
       "3      0.303836     0  \n",
       "4      0.213324     0  \n",
       "...         ...   ...  \n",
       "90955  0.036053     1  \n",
       "90956  0.018591     1  \n",
       "90957 -0.052554     1  \n",
       "90958  0.048043     1  \n",
       "90959  0.035269     1  \n",
       "\n",
       "[90960 rows x 19 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDEFSDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "558c10c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "can = []\n",
    "for i in list(range(0,9)) + list(range(15,17)) + [len(list(trainDEFSDf.columns))-1]:\n",
    "    can.append(list(trainDEFSDf.columns)[i])\n",
    "\n",
    "dican = []\n",
    "for i in list(range(0,9)) + list(range(15,17)) + [len(list(diDEFSDf.columns))-1]:\n",
    "    dican.append(list(diDEFSDf.columns)[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85c654ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pixel_id',\n",
       " '311.1684',\n",
       " '269.2486',\n",
       " '215.0328',\n",
       " '295.2278',\n",
       " '883.533',\n",
       " '309.1725',\n",
       " '738.5057',\n",
       " '435.2965',\n",
       " '250.1449',\n",
       " '514.2846',\n",
       " 'type']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "can"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c5daef9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pixel_id',\n",
       " '311.169',\n",
       " '269.2486',\n",
       " '215.032',\n",
       " '295.2279',\n",
       " '883.5375',\n",
       " '309.1728',\n",
       " '738.5084',\n",
       " '435.2966',\n",
       " '250.145',\n",
       " '514.2844',\n",
       " 'type']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dican"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d2530f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## input training set ## 90960 x 20 df\n",
    "trainDEFSDf = pd.read_csv(r\"H:\\\\3_output_raMSIn\\\\3_3_Output_raMSIn_HKU_Ingested4ALL\\\\XGB_ALL\\\\df_train_dbMSIn5ppm4nonInDI_norm.csv\")\n",
    "#trainDEFSDf[trainDEFSDf.type .== 1, :]\n",
    "## calculate weight ## 0: 47449, 1: 43511\n",
    "trainDEFSDf = trainDEFSDf[can]\n",
    "Yy_train = trainDEFSDf[\"type\"]  # 0.9585; 1.0453\n",
    "sampleW = []\n",
    "for w in Yy_train:\n",
    "    if w == 0:\n",
    "        sampleW.append(0.9585)\n",
    "    elif w == 1:\n",
    "        sampleW.append(1.0453) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26f6b926",
   "metadata": {},
   "outputs": [],
   "source": [
    "## input ext val set ## 6075 x 20 df\n",
    "extDEFSDf = pd.read_csv(r\"H:\\\\3_output_raMSIn\\\\3_3_Output_raMSIn_HKU_Ingested4ALL\\\\XGB_ALL\\\\df_ext_dbMSIn5ppm4nonInDI_norm.csv\")\n",
    "#extDEFSDf[extDEFSDf.type .== 1, :]\n",
    "## calculate weight ## 0: 2943, 1: 3132\n",
    "extDEFSDf = extDEFSDf[can]\n",
    "Yy_ext = extDEFSDf[\"type\"]  # 1.0321; 0.9698\n",
    "sampleExtW = []\n",
    "for w in Yy_ext:\n",
    "    if w == 0:\n",
    "        sampleExtW.append(1.0321)\n",
    "    elif w == 1:\n",
    "        sampleExtW.append(0.9698) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f13b3818",
   "metadata": {},
   "outputs": [],
   "source": [
    "## input ingested set ## 97035 x 20 df\n",
    "ingestedDEFSDf = pd.read_csv(r\"H:\\\\3_output_raMSIn\\\\3_3_Output_raMSIn_HKU_Ingested4ALL\\\\XGB_ALL\\\\df_ingested_dbMSIn5ppm4nonInDI_norm.csv\")\n",
    "#ingestedDEFSDf[extDEFSDf.type .== 1, :]\n",
    "## calculate weight ## 0: 50392, 1: 46643\n",
    "ingestedDEFSDf = ingestedDEFSDf[can]\n",
    "Yy_ingested = ingestedDEFSDf[\"type\"]  # 0.9628; 1.0402\n",
    "sampleIngestedW = []\n",
    "for w in Yy_ingested:\n",
    "    if w == 0:\n",
    "        sampleIngestedW.append(0.9628)\n",
    "    elif w == 1:\n",
    "        sampleIngestedW.append(1.0402)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a884cb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "## input FNA set ## 88701 x 20 df\n",
    "fnaDEFSDf = pd.read_csv(r\"H:\\\\3_output_raMSIn\\\\3_3_Output_raMSIn_HKU_Ingested4ALL\\\\XGB_ALL\\\\df_FNA_dbMSIn5ppm4nonInDI_norm.csv\")\n",
    "#fnaDEFSDf[fnaDEFSDf.type .== 1, :]\n",
    "## calculate weight ##  0: 44540, 1: 44161\n",
    "fnaDEFSDf = fnaDEFSDf[can]\n",
    "Yy_FNA = fnaDEFSDf[\"type\"]  # 0.9957; 1.0043\n",
    "sampleFNAW = []\n",
    "for w in Yy_FNA:\n",
    "    if w == 0:\n",
    "        sampleFNAW.append(0.9957)\n",
    "    elif w == 1:\n",
    "        sampleFNAW.append(1.0043)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b2cfbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## input DirectIn set ## 88701 x 20 df\n",
    "diDEFSDf = pd.read_csv(r\"H:\\\\3_output_raMSIn\\\\3_3_Output_raMSIn_HKU_Ingested4ALL\\\\XGB_ALL\\\\df_nonInDI_dbMSIn5ppm4nonInDI_norm.csv\")\n",
    "#diDEFSDf[diDEFSDf.type .== 1, :]\n",
    "## calculate weight ## 0: 3027, 1: 3030\n",
    "diDEFSDf = diDEFSDf[dican]\n",
    "diDEFSDf = diDEFSDf.rename(columns={\"311.169\": \"311.1684\", \"215.032\":\"215.0328\", \"295.2279\":\"295.2278\", \"883.5375\":\"883.533\", \n",
    "                                    \"309.1728\":\"309.1725\", \"738.5084\":\"738.5057\", \"435.2966\":\"435.2965\", \"280.2364\":\"280.2361\", \"241.217\":\"241.2173\", \n",
    "                                    \"311.2224\":\"311.2228\", \"339.1999\":\"339.1996\", \"353.1996\":\"353.2004\", \"325.1844\":\"325.1842\", \"250.145\":\"250.1449\", \n",
    "                                    \"514.2844\":\"514.2846\", \"265.1479\":\"265.1478\"})\n",
    "Yy_DI = diDEFSDf[\"type\"]  # 1.0005; 0.9995\n",
    "sampleDiW = []\n",
    "for w in Yy_DI:\n",
    "    if w == 0:\n",
    "        sampleDiW.append(1.0005)\n",
    "    elif w == 1:\n",
    "        sampleDiW.append(0.9995)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95558b9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel_id</th>\n",
       "      <th>311.1684</th>\n",
       "      <th>269.2486</th>\n",
       "      <th>215.0328</th>\n",
       "      <th>295.2278</th>\n",
       "      <th>883.533</th>\n",
       "      <th>309.1725</th>\n",
       "      <th>738.5057</th>\n",
       "      <th>435.2965</th>\n",
       "      <th>250.1449</th>\n",
       "      <th>514.2846</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HKULiver_Post29wk_HCCAMCLiver_DirectIn_MiceNL_...</td>\n",
       "      <td>0.005233</td>\n",
       "      <td>0.142288</td>\n",
       "      <td>0.041727</td>\n",
       "      <td>0.003879</td>\n",
       "      <td>0.078180</td>\n",
       "      <td>0.211155</td>\n",
       "      <td>0.061859</td>\n",
       "      <td>0.125898</td>\n",
       "      <td>0.467350</td>\n",
       "      <td>0.036498</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HKULiver_Post29wk_HCCAMCLiver_DirectIn_MiceNL_...</td>\n",
       "      <td>0.089591</td>\n",
       "      <td>0.156412</td>\n",
       "      <td>0.177387</td>\n",
       "      <td>0.001265</td>\n",
       "      <td>0.167206</td>\n",
       "      <td>0.317443</td>\n",
       "      <td>0.128000</td>\n",
       "      <td>0.145558</td>\n",
       "      <td>0.583306</td>\n",
       "      <td>0.099618</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HKULiver_Post29wk_HCCAMCLiver_DirectIn_MiceNL_...</td>\n",
       "      <td>0.032985</td>\n",
       "      <td>0.134206</td>\n",
       "      <td>0.036969</td>\n",
       "      <td>-0.069655</td>\n",
       "      <td>0.122163</td>\n",
       "      <td>0.212954</td>\n",
       "      <td>0.028988</td>\n",
       "      <td>0.076856</td>\n",
       "      <td>0.465193</td>\n",
       "      <td>0.056825</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HKULiver_Post29wk_HCCAMCLiver_DirectIn_MiceNL_...</td>\n",
       "      <td>0.081001</td>\n",
       "      <td>0.235152</td>\n",
       "      <td>0.064473</td>\n",
       "      <td>0.057514</td>\n",
       "      <td>0.129276</td>\n",
       "      <td>0.303459</td>\n",
       "      <td>0.108118</td>\n",
       "      <td>0.193038</td>\n",
       "      <td>0.550698</td>\n",
       "      <td>0.090339</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HKULiver_Post29wk_HCCAMCLiver_DirectIn_MiceNL_...</td>\n",
       "      <td>0.132548</td>\n",
       "      <td>0.236938</td>\n",
       "      <td>0.155154</td>\n",
       "      <td>0.080273</td>\n",
       "      <td>0.239452</td>\n",
       "      <td>0.394214</td>\n",
       "      <td>0.236248</td>\n",
       "      <td>0.204588</td>\n",
       "      <td>0.645501</td>\n",
       "      <td>0.147333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6052</th>\n",
       "      <td>HKULiver_Post29wk_HCCLiver_DirectIn_MiceHCC_S1...</td>\n",
       "      <td>-0.002046</td>\n",
       "      <td>-0.209455</td>\n",
       "      <td>0.129981</td>\n",
       "      <td>-0.039157</td>\n",
       "      <td>-0.042339</td>\n",
       "      <td>-0.056631</td>\n",
       "      <td>0.023269</td>\n",
       "      <td>0.147197</td>\n",
       "      <td>-0.089365</td>\n",
       "      <td>0.163267</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6053</th>\n",
       "      <td>HKULiver_Post29wk_HCCLiver_DirectIn_MiceHCC_S1...</td>\n",
       "      <td>-0.313188</td>\n",
       "      <td>-0.217983</td>\n",
       "      <td>-0.306250</td>\n",
       "      <td>-0.299289</td>\n",
       "      <td>-0.272830</td>\n",
       "      <td>-0.303023</td>\n",
       "      <td>-0.280528</td>\n",
       "      <td>-0.277815</td>\n",
       "      <td>-0.025231</td>\n",
       "      <td>-0.251944</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6054</th>\n",
       "      <td>HKULiver_Post29wk_HCCLiver_DirectIn_MiceHCC_S1...</td>\n",
       "      <td>-0.158181</td>\n",
       "      <td>-0.037213</td>\n",
       "      <td>0.001807</td>\n",
       "      <td>-0.048526</td>\n",
       "      <td>-0.044929</td>\n",
       "      <td>-0.153125</td>\n",
       "      <td>-0.084889</td>\n",
       "      <td>-0.039383</td>\n",
       "      <td>-0.089365</td>\n",
       "      <td>0.091528</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6055</th>\n",
       "      <td>HKULiver_Post29wk_HCCLiver_DirectIn_MiceHCC_S1...</td>\n",
       "      <td>-0.130111</td>\n",
       "      <td>-0.100314</td>\n",
       "      <td>0.068308</td>\n",
       "      <td>-0.107947</td>\n",
       "      <td>-0.006630</td>\n",
       "      <td>-0.127231</td>\n",
       "      <td>-0.068977</td>\n",
       "      <td>-0.070617</td>\n",
       "      <td>-0.010167</td>\n",
       "      <td>-0.018040</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6056</th>\n",
       "      <td>HKULiver_Post29wk_HCCLiver_DirectIn_MiceHCC_S1...</td>\n",
       "      <td>-0.375053</td>\n",
       "      <td>-0.421196</td>\n",
       "      <td>-0.306250</td>\n",
       "      <td>-0.382957</td>\n",
       "      <td>-0.272830</td>\n",
       "      <td>-0.362289</td>\n",
       "      <td>-0.280528</td>\n",
       "      <td>-0.277815</td>\n",
       "      <td>-0.025757</td>\n",
       "      <td>-0.312439</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6057 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               pixel_id  311.1684  269.2486  \\\n",
       "0     HKULiver_Post29wk_HCCAMCLiver_DirectIn_MiceNL_...  0.005233  0.142288   \n",
       "1     HKULiver_Post29wk_HCCAMCLiver_DirectIn_MiceNL_...  0.089591  0.156412   \n",
       "2     HKULiver_Post29wk_HCCAMCLiver_DirectIn_MiceNL_...  0.032985  0.134206   \n",
       "3     HKULiver_Post29wk_HCCAMCLiver_DirectIn_MiceNL_...  0.081001  0.235152   \n",
       "4     HKULiver_Post29wk_HCCAMCLiver_DirectIn_MiceNL_...  0.132548  0.236938   \n",
       "...                                                 ...       ...       ...   \n",
       "6052  HKULiver_Post29wk_HCCLiver_DirectIn_MiceHCC_S1... -0.002046 -0.209455   \n",
       "6053  HKULiver_Post29wk_HCCLiver_DirectIn_MiceHCC_S1... -0.313188 -0.217983   \n",
       "6054  HKULiver_Post29wk_HCCLiver_DirectIn_MiceHCC_S1... -0.158181 -0.037213   \n",
       "6055  HKULiver_Post29wk_HCCLiver_DirectIn_MiceHCC_S1... -0.130111 -0.100314   \n",
       "6056  HKULiver_Post29wk_HCCLiver_DirectIn_MiceHCC_S1... -0.375053 -0.421196   \n",
       "\n",
       "      215.0328  295.2278   883.533  309.1725  738.5057  435.2965  250.1449  \\\n",
       "0     0.041727  0.003879  0.078180  0.211155  0.061859  0.125898  0.467350   \n",
       "1     0.177387  0.001265  0.167206  0.317443  0.128000  0.145558  0.583306   \n",
       "2     0.036969 -0.069655  0.122163  0.212954  0.028988  0.076856  0.465193   \n",
       "3     0.064473  0.057514  0.129276  0.303459  0.108118  0.193038  0.550698   \n",
       "4     0.155154  0.080273  0.239452  0.394214  0.236248  0.204588  0.645501   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "6052  0.129981 -0.039157 -0.042339 -0.056631  0.023269  0.147197 -0.089365   \n",
       "6053 -0.306250 -0.299289 -0.272830 -0.303023 -0.280528 -0.277815 -0.025231   \n",
       "6054  0.001807 -0.048526 -0.044929 -0.153125 -0.084889 -0.039383 -0.089365   \n",
       "6055  0.068308 -0.107947 -0.006630 -0.127231 -0.068977 -0.070617 -0.010167   \n",
       "6056 -0.306250 -0.382957 -0.272830 -0.362289 -0.280528 -0.277815 -0.025757   \n",
       "\n",
       "      514.2846  type  \n",
       "0     0.036498     0  \n",
       "1     0.099618     0  \n",
       "2     0.056825     0  \n",
       "3     0.090339     0  \n",
       "4     0.147333     0  \n",
       "...        ...   ...  \n",
       "6052  0.163267     1  \n",
       "6053 -0.251944     1  \n",
       "6054  0.091528     1  \n",
       "6055 -0.018040     1  \n",
       "6056 -0.312439     1  \n",
       "\n",
       "[6057 rows x 12 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diDEFSDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca171d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "## define functions for performace evaluation ##\n",
    "\n",
    "# Average score\n",
    "def avgScore(arrAcc, cv):\n",
    "    sumAcc = 0\n",
    "    for acc in arrAcc:\n",
    "        sumAcc += acc\n",
    "    return sumAcc / cv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ccef0bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>311.1684</th>\n",
       "      <th>269.2486</th>\n",
       "      <th>215.0328</th>\n",
       "      <th>295.2278</th>\n",
       "      <th>883.533</th>\n",
       "      <th>309.1725</th>\n",
       "      <th>738.5057</th>\n",
       "      <th>435.2965</th>\n",
       "      <th>250.1449</th>\n",
       "      <th>514.2846</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.318763</td>\n",
       "      <td>0.150470</td>\n",
       "      <td>-0.119121</td>\n",
       "      <td>-0.067072</td>\n",
       "      <td>-0.071854</td>\n",
       "      <td>0.384412</td>\n",
       "      <td>-0.143360</td>\n",
       "      <td>0.118134</td>\n",
       "      <td>0.126164</td>\n",
       "      <td>-0.040567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.440853</td>\n",
       "      <td>0.394966</td>\n",
       "      <td>-0.038289</td>\n",
       "      <td>-0.067072</td>\n",
       "      <td>0.017921</td>\n",
       "      <td>0.479880</td>\n",
       "      <td>-0.160340</td>\n",
       "      <td>0.058233</td>\n",
       "      <td>0.300476</td>\n",
       "      <td>-0.040567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.297858</td>\n",
       "      <td>0.166363</td>\n",
       "      <td>-0.083697</td>\n",
       "      <td>-0.067072</td>\n",
       "      <td>-0.069362</td>\n",
       "      <td>0.317106</td>\n",
       "      <td>-0.150742</td>\n",
       "      <td>-0.029448</td>\n",
       "      <td>0.208799</td>\n",
       "      <td>-0.040567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.276322</td>\n",
       "      <td>0.115277</td>\n",
       "      <td>-0.042454</td>\n",
       "      <td>-0.067072</td>\n",
       "      <td>-0.054074</td>\n",
       "      <td>0.299065</td>\n",
       "      <td>-0.143111</td>\n",
       "      <td>-0.018081</td>\n",
       "      <td>0.187170</td>\n",
       "      <td>-0.040567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.172632</td>\n",
       "      <td>0.200346</td>\n",
       "      <td>-0.131919</td>\n",
       "      <td>-0.067072</td>\n",
       "      <td>-0.052373</td>\n",
       "      <td>0.219220</td>\n",
       "      <td>-0.146138</td>\n",
       "      <td>0.140049</td>\n",
       "      <td>0.094790</td>\n",
       "      <td>-0.040567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90955</th>\n",
       "      <td>0.035493</td>\n",
       "      <td>-0.272607</td>\n",
       "      <td>0.004148</td>\n",
       "      <td>-0.067072</td>\n",
       "      <td>-0.142422</td>\n",
       "      <td>0.062967</td>\n",
       "      <td>-0.200362</td>\n",
       "      <td>0.242729</td>\n",
       "      <td>0.038175</td>\n",
       "      <td>0.212752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90956</th>\n",
       "      <td>0.021826</td>\n",
       "      <td>-0.272607</td>\n",
       "      <td>-0.091252</td>\n",
       "      <td>-0.067072</td>\n",
       "      <td>-0.062065</td>\n",
       "      <td>0.074304</td>\n",
       "      <td>-0.191751</td>\n",
       "      <td>0.300467</td>\n",
       "      <td>0.210629</td>\n",
       "      <td>-0.040567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90957</th>\n",
       "      <td>0.030907</td>\n",
       "      <td>0.332829</td>\n",
       "      <td>-0.093406</td>\n",
       "      <td>-0.067072</td>\n",
       "      <td>-0.090889</td>\n",
       "      <td>0.044570</td>\n",
       "      <td>-0.114260</td>\n",
       "      <td>0.195776</td>\n",
       "      <td>0.143302</td>\n",
       "      <td>-0.040567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90958</th>\n",
       "      <td>0.045524</td>\n",
       "      <td>-0.272607</td>\n",
       "      <td>-0.122689</td>\n",
       "      <td>-0.067072</td>\n",
       "      <td>-0.163137</td>\n",
       "      <td>0.059988</td>\n",
       "      <td>-0.138465</td>\n",
       "      <td>0.149654</td>\n",
       "      <td>0.189038</td>\n",
       "      <td>-0.040567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90959</th>\n",
       "      <td>0.017845</td>\n",
       "      <td>-0.272607</td>\n",
       "      <td>-0.120920</td>\n",
       "      <td>-0.067072</td>\n",
       "      <td>-0.392345</td>\n",
       "      <td>0.049505</td>\n",
       "      <td>-0.112366</td>\n",
       "      <td>0.101809</td>\n",
       "      <td>0.177671</td>\n",
       "      <td>-0.040567</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90960 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       311.1684  269.2486  215.0328  295.2278   883.533  309.1725  738.5057  \\\n",
       "0      0.318763  0.150470 -0.119121 -0.067072 -0.071854  0.384412 -0.143360   \n",
       "1      0.440853  0.394966 -0.038289 -0.067072  0.017921  0.479880 -0.160340   \n",
       "2      0.297858  0.166363 -0.083697 -0.067072 -0.069362  0.317106 -0.150742   \n",
       "3      0.276322  0.115277 -0.042454 -0.067072 -0.054074  0.299065 -0.143111   \n",
       "4      0.172632  0.200346 -0.131919 -0.067072 -0.052373  0.219220 -0.146138   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "90955  0.035493 -0.272607  0.004148 -0.067072 -0.142422  0.062967 -0.200362   \n",
       "90956  0.021826 -0.272607 -0.091252 -0.067072 -0.062065  0.074304 -0.191751   \n",
       "90957  0.030907  0.332829 -0.093406 -0.067072 -0.090889  0.044570 -0.114260   \n",
       "90958  0.045524 -0.272607 -0.122689 -0.067072 -0.163137  0.059988 -0.138465   \n",
       "90959  0.017845 -0.272607 -0.120920 -0.067072 -0.392345  0.049505 -0.112366   \n",
       "\n",
       "       435.2965  250.1449  514.2846  \n",
       "0      0.118134  0.126164 -0.040567  \n",
       "1      0.058233  0.300476 -0.040567  \n",
       "2     -0.029448  0.208799 -0.040567  \n",
       "3     -0.018081  0.187170 -0.040567  \n",
       "4      0.140049  0.094790 -0.040567  \n",
       "...         ...       ...       ...  \n",
       "90955  0.242729  0.038175  0.212752  \n",
       "90956  0.300467  0.210629 -0.040567  \n",
       "90957  0.195776  0.143302 -0.040567  \n",
       "90958  0.149654  0.189038 -0.040567  \n",
       "90959  0.101809  0.177671 -0.040567  \n",
       "\n",
       "[90960 rows x 10 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDEFSDf[trainDEFSDf.columns[1:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ff9f9ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c56eae",
   "metadata": {},
   "source": [
    "# 2. Unsupervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8049959",
   "metadata": {},
   "source": [
    "## 2.1. Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "56926254",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 720x720 with 0 Axes>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from matplotlib.pyplot import figure\n",
    "plt.rcParams['figure.figsize'] = [10, 10]\n",
    "plt.grid(visible=None)\n",
    "plt.close()\n",
    "figure(figsize=(10, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "62a3d9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ROI_for_ML_Opti = pd.concat([trainDEFSDf, extDEFSDf, fnaDEFSDf, diDEFSDf]).set_index('pixel_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e9061d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ROI_for_ML_Opti_ingested = ingestedDEFSDf.set_index('pixel_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7d1ef236",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ROI_for_ML_Opti_train = trainDEFSDf.set_index('pixel_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f9f05550",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ROI_for_ML_Opti_ext = extDEFSDf.set_index('pixel_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0dfe922b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ROI_for_ML_Opti_FNA = fnaDEFSDf.set_index('pixel_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f17e49c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ROI_for_ML_Opti_di = diDEFSDf.set_index('pixel_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9c15f5e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>311.1684</th>\n",
       "      <th>269.2486</th>\n",
       "      <th>215.0328</th>\n",
       "      <th>295.2278</th>\n",
       "      <th>883.533</th>\n",
       "      <th>309.1725</th>\n",
       "      <th>738.5057</th>\n",
       "      <th>435.2965</th>\n",
       "      <th>250.1449</th>\n",
       "      <th>514.2846</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6.057000e+03</td>\n",
       "      <td>6.057000e+03</td>\n",
       "      <td>6.057000e+03</td>\n",
       "      <td>6.057000e+03</td>\n",
       "      <td>6.057000e+03</td>\n",
       "      <td>6.057000e+03</td>\n",
       "      <td>6.057000e+03</td>\n",
       "      <td>6.057000e+03</td>\n",
       "      <td>6.057000e+03</td>\n",
       "      <td>6.057000e+03</td>\n",
       "      <td>6057.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.786097e-18</td>\n",
       "      <td>6.620646e-17</td>\n",
       "      <td>2.832104e-16</td>\n",
       "      <td>-1.438873e-18</td>\n",
       "      <td>-4.755611e-16</td>\n",
       "      <td>9.102472e-17</td>\n",
       "      <td>1.235597e-16</td>\n",
       "      <td>-4.213514e-16</td>\n",
       "      <td>-4.598716e-15</td>\n",
       "      <td>-7.857894e-17</td>\n",
       "      <td>0.500248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.259709e-01</td>\n",
       "      <td>1.439456e-01</td>\n",
       "      <td>1.644526e-01</td>\n",
       "      <td>1.354221e-01</td>\n",
       "      <td>1.816907e-01</td>\n",
       "      <td>1.711848e-01</td>\n",
       "      <td>1.276984e-01</td>\n",
       "      <td>2.074127e-01</td>\n",
       "      <td>1.914162e-01</td>\n",
       "      <td>1.330110e-01</td>\n",
       "      <td>0.500041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-3.936976e-01</td>\n",
       "      <td>-4.211962e-01</td>\n",
       "      <td>-3.062504e-01</td>\n",
       "      <td>-4.545066e-01</td>\n",
       "      <td>-2.728296e-01</td>\n",
       "      <td>-3.622890e-01</td>\n",
       "      <td>-2.805282e-01</td>\n",
       "      <td>-2.778148e-01</td>\n",
       "      <td>-8.936520e-02</td>\n",
       "      <td>-3.327803e-01</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-7.672668e-02</td>\n",
       "      <td>-6.810890e-02</td>\n",
       "      <td>-9.448816e-02</td>\n",
       "      <td>-6.188994e-02</td>\n",
       "      <td>-1.079244e-01</td>\n",
       "      <td>-8.982515e-02</td>\n",
       "      <td>-5.994488e-02</td>\n",
       "      <td>-2.778148e-01</td>\n",
       "      <td>-8.936520e-02</td>\n",
       "      <td>-6.633725e-02</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.552356e-03</td>\n",
       "      <td>-6.986512e-03</td>\n",
       "      <td>1.676521e-02</td>\n",
       "      <td>1.774746e-02</td>\n",
       "      <td>3.107505e-02</td>\n",
       "      <td>-3.331810e-02</td>\n",
       "      <td>1.461270e-02</td>\n",
       "      <td>6.133792e-03</td>\n",
       "      <td>-8.936520e-02</td>\n",
       "      <td>-1.853303e-02</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.000432e-02</td>\n",
       "      <td>5.958404e-02</td>\n",
       "      <td>1.127828e-01</td>\n",
       "      <td>7.451773e-02</td>\n",
       "      <td>1.306204e-01</td>\n",
       "      <td>3.533862e-02</td>\n",
       "      <td>6.957675e-02</td>\n",
       "      <td>1.666052e-01</td>\n",
       "      <td>-1.214997e-03</td>\n",
       "      <td>8.938771e-02</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.063024e-01</td>\n",
       "      <td>5.788038e-01</td>\n",
       "      <td>6.937496e-01</td>\n",
       "      <td>5.454934e-01</td>\n",
       "      <td>7.271704e-01</td>\n",
       "      <td>6.377110e-01</td>\n",
       "      <td>7.194718e-01</td>\n",
       "      <td>7.221852e-01</td>\n",
       "      <td>9.106348e-01</td>\n",
       "      <td>6.672197e-01</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           311.1684      269.2486      215.0328      295.2278       883.533  \\\n",
       "count  6.057000e+03  6.057000e+03  6.057000e+03  6.057000e+03  6.057000e+03   \n",
       "mean   2.786097e-18  6.620646e-17  2.832104e-16 -1.438873e-18 -4.755611e-16   \n",
       "std    1.259709e-01  1.439456e-01  1.644526e-01  1.354221e-01  1.816907e-01   \n",
       "min   -3.936976e-01 -4.211962e-01 -3.062504e-01 -4.545066e-01 -2.728296e-01   \n",
       "25%   -7.672668e-02 -6.810890e-02 -9.448816e-02 -6.188994e-02 -1.079244e-01   \n",
       "50%    9.552356e-03 -6.986512e-03  1.676521e-02  1.774746e-02  3.107505e-02   \n",
       "75%    9.000432e-02  5.958404e-02  1.127828e-01  7.451773e-02  1.306204e-01   \n",
       "max    6.063024e-01  5.788038e-01  6.937496e-01  5.454934e-01  7.271704e-01   \n",
       "\n",
       "           309.1725      738.5057      435.2965      250.1449      514.2846  \\\n",
       "count  6.057000e+03  6.057000e+03  6.057000e+03  6.057000e+03  6.057000e+03   \n",
       "mean   9.102472e-17  1.235597e-16 -4.213514e-16 -4.598716e-15 -7.857894e-17   \n",
       "std    1.711848e-01  1.276984e-01  2.074127e-01  1.914162e-01  1.330110e-01   \n",
       "min   -3.622890e-01 -2.805282e-01 -2.778148e-01 -8.936520e-02 -3.327803e-01   \n",
       "25%   -8.982515e-02 -5.994488e-02 -2.778148e-01 -8.936520e-02 -6.633725e-02   \n",
       "50%   -3.331810e-02  1.461270e-02  6.133792e-03 -8.936520e-02 -1.853303e-02   \n",
       "75%    3.533862e-02  6.957675e-02  1.666052e-01 -1.214997e-03  8.938771e-02   \n",
       "max    6.377110e-01  7.194718e-01  7.221852e-01  9.106348e-01  6.672197e-01   \n",
       "\n",
       "              type  \n",
       "count  6057.000000  \n",
       "mean      0.500248  \n",
       "std       0.500041  \n",
       "min       0.000000  \n",
       "25%       0.000000  \n",
       "50%       1.000000  \n",
       "75%       1.000000  \n",
       "max       1.000000  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ROI_for_ML_Opti_di.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c25aab6",
   "metadata": {},
   "source": [
    "## 2.2. PCA Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e9735181",
   "metadata": {},
   "outputs": [],
   "source": [
    "## PCA Analysis\n",
    "\n",
    "def pca_visual(df=df_ROI_for_ML_Opti_di):\n",
    "\n",
    "    pca = PCA(n_components=3)\n",
    "    raMSI_ML_mz_df = df.drop(\"type\", axis = 1)\n",
    "    pca.fit(raMSI_ML_mz_df)\n",
    "    result = pd.DataFrame(pca.transform(raMSI_ML_mz_df), columns=['PCA%i' % i for i in range(3)], index=df_ROI_for_ML_Opti_di.index)\n",
    "    \n",
    "    plt.subplots(dpi = 300)\n",
    "    plt.scatter(result['PCA1'], result['PCA2'], c = df['type'], s=1)\n",
    "    plt.xlabel('PC1', size=20)\n",
    "    plt.ylabel('PC2', size=20)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    plt.savefig(r\"H:/3_output_raMSIn/3_3_Output_raMSIn_HKU_Ingested4ALL/XGB_ALL/afterModelSelection/dbMSIn_5ppm/PCA_di.tif\", bbox_inches = 'tight')\n",
    "\n",
    "    components = pca.fit_transform(raMSI_ML_mz_df)\n",
    "    total_var = pca.explained_variance_ratio_.sum() * 100\n",
    "    fig = px.scatter_3d(\n",
    "        components, x=0, y=1, z=2, color=df['type'],\n",
    "        title = f'Total Explained Variance: {total_var:.2f}%',\n",
    "        labels = {'0': 'PC 1', '1': 'PC 2', '2': 'PC 3'}\n",
    "    )\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5636f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_visual()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a0c5f5",
   "metadata": {},
   "source": [
    "# 3. Supervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cdf76b0",
   "metadata": {},
   "source": [
    "## 3.1. Preparation of training and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a9518fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(df=df_ROI_for_ML_Opti_ingested):\n",
    "    raMSI_ML_NoType = df.drop(\"type\", axis = 1)\n",
    "    raMSI_ML_Type=df[['type']]\n",
    "    X_train,X_test,y_train,y_test=train_test_split(raMSI_ML_NoType,raMSI_ML_Type,test_size=0.2,random_state=42)\n",
    "    return X_train,X_test,y_train,y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7a5146",
   "metadata": {},
   "source": [
    "X_train,X_test,y_train,y_test=split_dataset(df=df_ROI_for_ML_Opti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "92b9ff22",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ingested = df_ROI_for_ML_Opti_ingested[df_ROI_for_ML_Opti_ingested.columns[:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "071b9d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ingested = df_ROI_for_ML_Opti_ingested[df_ROI_for_ML_Opti_ingested.columns[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "78235c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_ROI_for_ML_Opti_train[df_ROI_for_ML_Opti_train.columns[:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "226a001d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_ROI_for_ML_Opti_train[df_ROI_for_ML_Opti_train.columns[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "21066a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = df_ROI_for_ML_Opti_ext[df_ROI_for_ML_Opti_ext.columns[:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "375fd7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val = df_ROI_for_ML_Opti_ext[df_ROI_for_ML_Opti_ext.columns[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "460faa79",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_FNA = df_ROI_for_ML_Opti_FNA[df_ROI_for_ML_Opti_FNA.columns[:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dd2eede7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_FNA = df_ROI_for_ML_Opti_FNA[df_ROI_for_ML_Opti_FNA.columns[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c1e0ca85",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_di = df_ROI_for_ML_Opti_di[df_ROI_for_ML_Opti_di.columns[:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3529c5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_di = df_ROI_for_ML_Opti_di[df_ROI_for_ML_Opti_di.columns[-1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02cd4f6d",
   "metadata": {},
   "source": [
    "## 3.2 Machine Learning Modeling: Model 1+2 (Train 10:10, Val 4:4, Test 3:3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6d458bee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 720x720 with 0 Axes>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from matplotlib.pyplot import figure\n",
    "plt.rcParams['figure.figsize'] = [10, 10]\n",
    "plt.grid(visible=None)\n",
    "plt.close()\n",
    "figure(figsize=(10, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462143af",
   "metadata": {},
   "source": [
    "### 3.2.1. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2bdf27e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build Logistic Regression Model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def LogisticRegression_func(XTrain=X_ingested, XVal=X_val, XTest=X_FNA, yTrain=y_ingested, yVal=y_val, yTest=y_FNA):\n",
    "    model_lr = LogisticRegression(C=0.001, penalty='l1', solver=\"liblinear\", max_iter=5000, random_state=42, class_weight={0:0.9628, 1:1.0402})  # max_iter=100\n",
    "    model_lr.fit(XTrain,yTrain)\n",
    "    \n",
    "    # Training Set\n",
    "    #plt.rcParams[\"figure.figsize\"] = (3,3)\n",
    "    X_train_predictions = model_lr.predict(X_train)\n",
    "    print(\"Training Set F1:\", f1_score(y_train, model_lr.predict(X_train), sample_weight=sampleW))\n",
    "    print(\"Training Set MCC:\", matthews_corrcoef(y_train, model_lr.predict(X_train), sample_weight=sampleW))\n",
    "    print(\"Training Set Accuracy:\", metrics.accuracy_score(y_train, X_train_predictions))\n",
    "    print(classification_report(y_train, X_train_predictions))\n",
    "    print(confusion_matrix(y_train, X_train_predictions))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr, tpr, _ = metrics.roc_curve(y_train, X_train_predictions)\n",
    "    plt.plot(fpr,tpr)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_train.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    # Val set\n",
    "    predictions_val  = model_lr.predict(XVal)\n",
    "    print(\"Ext Val Set F1:\", f1_score(yVal, model_lr.predict(XVal), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set MCC:\", matthews_corrcoef(yVal, model_lr.predict(XVal), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set Accuracy:\", metrics.accuracy_score(yVal, predictions_val))\n",
    "    print(classification_report(yVal, predictions_val))\n",
    "    print(confusion_matrix(yVal, predictions_val))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_val, tpr_val, _ = metrics.roc_curve(yVal, predictions_val)\n",
    "    plt.plot(fpr_val,tpr_val)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_test.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    f1_5_train = cross_val_score(model_lr, XTrain, yTrain, cv = 5, scoring=\"f1\")\n",
    "    print(\"5F-CV:\", avgScore(f1_5_train, 5))\n",
    "    \n",
    "    # Test set\n",
    "    predictions_FNA = model_lr.predict(XTest)\n",
    "    print(\"FNA Set F1:\", f1_score(yTest, model_lr.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set MCC:\", matthews_corrcoef(yTest, model_lr.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set Recall:\", recall_score(yTest, model_lr.predict(XTest)))\n",
    "    print(\"FNA Test Set Accuracy:\", metrics.accuracy_score(yTest, predictions_FNA))\n",
    "    print(classification_report(yTest, predictions_FNA))\n",
    "    print(confusion_matrix(yTest, predictions_FNA))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_FNA, tpr_FNA, _ = metrics.roc_curve(yTest, predictions_FNA)\n",
    "    plt.plot(fpr_FNA,tpr_FNA)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"G:/raMSIn/XGB_Importance2/XGB2_ROC_FNAtest2.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    # Visualize the importantance of the features\n",
    "    feature_imp = pd.Series(model_lr.coef_[0], index=XTrain.columns).sort_values(ascending=False)\n",
    "    x=feature_imp\n",
    "    y=feature_imp.index\n",
    "    \n",
    "    plt.subplots(dpi = 300)\n",
    "    #plt.rcParams[\"figure.figsize\"] = [4, 6]\n",
    "    #plt.rcParams[\"font.family\"] = \"Arial\"\n",
    "    #plt.rcParams.update({'font.size': 6})\n",
    "    plt.xlabel('Feature Importance Score', fontproperties='Arial', fontsize=17)\n",
    "    plt.ylabel('Features', fontproperties='Arial', fontsize=17)\n",
    "    plt.xticks(fontsize=15)\n",
    "    plt.yticks(fontsize=15)\n",
    "    plt.title(\"Important Molecular Features\", fontproperties='Arial', fontsize=20)\n",
    "    sns.barplot(x=feature_imp, y=feature_imp.index)\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_TopFeatures.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    #feature_importances = model_lr.coef_[0]\n",
    "    #feature_df=pd.DataFrame({'m/z':XTrain.columns,'coef':feature_importances})\n",
    "\n",
    "    #fig = px.bar(feature_df, x='coef', y='m/z')\n",
    "    #fig.show()\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e4810838",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set F1: 0.8406548865609851\n",
      "Training Set MCC: 0.6813608572119455\n",
      "Training Set Accuracy: 0.8406882145998241\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.84      0.85     47449\n",
      "           1       0.83      0.84      0.83     43511\n",
      "\n",
      "    accuracy                           0.84     90960\n",
      "   macro avg       0.84      0.84      0.84     90960\n",
      "weighted avg       0.84      0.84      0.84     90960\n",
      "\n",
      "[[39898  7551]\n",
      " [ 6940 36571]]\n",
      "Ext Val Set F1: 0.8152216111756206\n",
      "Ext Val Set MCC: 0.6040424643656963\n",
      "Ext Val Set Accuracy: 0.7973662551440329\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.68      0.76      2943\n",
      "           1       0.75      0.91      0.82      3132\n",
      "\n",
      "    accuracy                           0.80      6075\n",
      "   macro avg       0.81      0.79      0.79      6075\n",
      "weighted avg       0.81      0.80      0.79      6075\n",
      "\n",
      "[[1994  949]\n",
      " [ 282 2850]]\n",
      "5F-CV: 0.6279461455926231\n",
      "FNA Set F1: 0.746655739208128\n",
      "FNA Set MCC: 0.4947357776811647\n",
      "FNA Set Recall: 0.7445483571477095\n",
      "FNA Test Set Accuracy: 0.747376016053934\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.75      0.75     44540\n",
      "           1       0.75      0.74      0.75     44161\n",
      "\n",
      "    accuracy                           0.75     88701\n",
      "   macro avg       0.75      0.75      0.75     88701\n",
      "weighted avg       0.75      0.75      0.75     88701\n",
      "\n",
      "[[33413 11127]\n",
      " [11281 32880]]\n"
     ]
    }
   ],
   "source": [
    "coeff_LogReg, TOPfeatures_LogReg = LogisticRegression_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b7a08c",
   "metadata": {},
   "source": [
    "### 3.2.2. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "aab84224",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build LinearSVC Model\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "def LinearSVC_func(XTrain=X_ingested, XVal=X_val, XTest=X_FNA, yTrain=y_ingested, yVal=y_val, yTest=y_FNA):\n",
    "    model_svm = LinearSVC(penalty='l2', loss=\"squared_hinge\", C=461, random_state=42, class_weight={0:0.9628, 1:1.0402})\n",
    "    model_svm.fit(XTrain,yTrain)\n",
    "    \n",
    "    # Training Set\n",
    "    #plt.rcParams[\"figure.figsize\"] = (3,3)\n",
    "    X_train_predictions = model_svm.predict(X_train)\n",
    "    print(\"Training Set F1:\", f1_score(y_train, model_svm.predict(X_train), sample_weight=sampleW))\n",
    "    print(\"Training Set MCC:\", matthews_corrcoef(y_train, model_svm.predict(X_train), sample_weight=sampleW))\n",
    "    print(\"Training Set Accuracy:\", metrics.accuracy_score(y_train, X_train_predictions))\n",
    "    print(classification_report(y_train, X_train_predictions))\n",
    "    print(confusion_matrix(y_train, X_train_predictions))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr, tpr, _ = metrics.roc_curve(y_train, X_train_predictions)\n",
    "    plt.plot(fpr,tpr)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_train.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    # Val set\n",
    "    predictions_val  = model_svm.predict(XVal)\n",
    "    print(\"Ext Val Set F1:\", f1_score(yVal, model_svm.predict(XVal), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set MCC:\", matthews_corrcoef(yVal, model_svm.predict(XVal), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set Accuracy:\", metrics.accuracy_score(yVal, predictions_val))\n",
    "    print(classification_report(yVal, predictions_val))\n",
    "    print(confusion_matrix(yVal, predictions_val))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_val, tpr_val, _ = metrics.roc_curve(yVal, predictions_val)\n",
    "    plt.plot(fpr_val,tpr_val)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_test.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    f1_5_train = cross_val_score(model_svm, XTrain, yTrain, cv = 5, scoring=\"f1\")\n",
    "    print(\"5F-CV:\", avgScore(f1_5_train, 5))\n",
    "    \n",
    "    # Test set\n",
    "    predictions_FNA = model_svm.predict(XTest)\n",
    "    print(\"FNA Set F1:\", f1_score(yTest, model_svm.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set MCC:\", matthews_corrcoef(yTest, model_svm.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set Recall:\", recall_score(yTest, model_svm.predict(XTest)))\n",
    "    print(\"FNA Test Set Accuracy:\", metrics.accuracy_score(yTest, predictions_FNA))\n",
    "    print(classification_report(yTest, predictions_FNA))\n",
    "    print(confusion_matrix(yTest, predictions_FNA))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_FNA, tpr_FNA, _ = metrics.roc_curve(yTest, predictions_FNA)\n",
    "    plt.plot(fpr_FNA,tpr_FNA)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"G:/raMSIn/XGB_Importance2/XGB2_ROC_FNAtest2.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    # Visualize the importantance of the features\n",
    "    feature_imp = pd.Series(model_svm.coef_[0], index=XTrain.columns).sort_values(ascending=False)\n",
    "    x=feature_imp\n",
    "    y=feature_imp.index\n",
    "    \n",
    "    plt.subplots(dpi = 300)\n",
    "    #plt.rcParams[\"figure.figsize\"] = [4, 6]\n",
    "    #plt.rcParams[\"font.family\"] = \"Arial\"\n",
    "    #plt.rcParams.update({'font.size': 6})\n",
    "    plt.xlabel('Feature Importance Score', fontproperties='Arial', fontsize=17)\n",
    "    plt.ylabel('Features', fontproperties='Arial', fontsize=17)\n",
    "    plt.xticks(fontsize=15)\n",
    "    plt.yticks(fontsize=15)\n",
    "    plt.title(\"Important Molecular Features\", fontproperties='Arial', fontsize=20)\n",
    "    sns.barplot(x=feature_imp, y=feature_imp.index)\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_TopFeatures.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    #feature_importances = model_svm.coef_[0]\n",
    "    #feature_df=pd.DataFrame({'m/z':XTrain.columns,'coef':feature_importances})\n",
    "\n",
    "    #fig = px.bar(feature_df, x='coef', y='m/z')\n",
    "    #fig.show()\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "78a85b62",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set F1: 0.8847064904390333\n",
      "Training Set MCC: 0.7647722222645835\n",
      "Training Set Accuracy: 0.880914687774846\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.86      0.88     47449\n",
      "           1       0.85      0.91      0.88     43511\n",
      "\n",
      "    accuracy                           0.88     90960\n",
      "   macro avg       0.88      0.88      0.88     90960\n",
      "weighted avg       0.88      0.88      0.88     90960\n",
      "\n",
      "[[40714  6735]\n",
      " [ 4097 39414]]\n",
      "Ext Val Set F1: 0.8287434038066259\n",
      "Ext Val Set MCC: 0.6468450640451637\n",
      "Ext Val Set Accuracy: 0.8237037037037037\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.79      0.81      2943\n",
      "           1       0.81      0.86      0.83      3132\n",
      "\n",
      "    accuracy                           0.82      6075\n",
      "   macro avg       0.83      0.82      0.82      6075\n",
      "weighted avg       0.82      0.82      0.82      6075\n",
      "\n",
      "[[2315  628]\n",
      " [ 443 2689]]\n",
      "5F-CV: 0.9159689638386391\n",
      "FNA Set F1: 0.6505794800746774\n",
      "FNA Set MCC: 0.24001662814455524\n",
      "FNA Set Recall: 0.7114195783609972\n",
      "FNA Test Set Accuracy: 0.6174902199524245\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.52      0.58     44540\n",
      "           1       0.60      0.71      0.65     44161\n",
      "\n",
      "    accuracy                           0.62     88701\n",
      "   macro avg       0.62      0.62      0.61     88701\n",
      "weighted avg       0.62      0.62      0.61     88701\n",
      "\n",
      "[[23355 21185]\n",
      " [12744 31417]]\n"
     ]
    }
   ],
   "source": [
    "coeff_SVM, TOPfeatures_SVM = LinearSVC_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e84218",
   "metadata": {},
   "source": [
    "### 3.2.3. GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "44b76c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build GBM Model\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "def GBM_func(XTrain=X_ingested, XVal=X_val, XTest=X_FNA, yTrain=y_ingested, yVal=y_val, yTest=y_FNA):\n",
    "    model_gbm = GradientBoostingClassifier(learning_rate=4, n_estimators=50, max_depth=7, min_samples_leaf=4, min_samples_split=30, n_iter_no_change=5, random_state=42)\n",
    "    model_gbm.fit(XTrain,yTrain)\n",
    "    \n",
    "    # Training Set\n",
    "    #plt.rcParams[\"figure.figsize\"] = (3,3)\n",
    "    X_train_predictions = model_gbm.predict(X_train)\n",
    "    print(\"Training Set F1:\", f1_score(y_train, model_gbm.predict(X_train), sample_weight=sampleW))\n",
    "    print(\"Training Set MCC:\", matthews_corrcoef(y_train, model_gbm.predict(X_train), sample_weight=sampleW))\n",
    "    print(\"Training Set Accuracy:\", metrics.accuracy_score(y_train, X_train_predictions))\n",
    "    print(classification_report(y_train, X_train_predictions))\n",
    "    print(confusion_matrix(y_train, X_train_predictions))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr, tpr, _ = metrics.roc_curve(y_train, X_train_predictions)\n",
    "    plt.plot(fpr,tpr)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_train.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    # Val set\n",
    "    predictions_val  = model_gbm.predict(XVal)\n",
    "    print(\"Ext Val Set F1:\", f1_score(yVal, model_gbm.predict(XVal), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set MCC:\", matthews_corrcoef(yVal, model_gbm.predict(XVal), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set Accuracy:\", metrics.accuracy_score(yVal, predictions_val))\n",
    "    print(classification_report(yVal, predictions_val))\n",
    "    print(confusion_matrix(yVal, predictions_val))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_val, tpr_val, _ = metrics.roc_curve(yVal, predictions_val)\n",
    "    plt.plot(fpr_val,tpr_val)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_test.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    f1_5_train = cross_val_score(model_gbm, XTrain, yTrain, cv = 5, scoring=\"f1\")\n",
    "    print(\"5F-CV:\", avgScore(f1_5_train, 5))\n",
    "    \n",
    "    # Test set\n",
    "    predictions_FNA = model_gbm.predict(XTest)\n",
    "    print(\"FNA Set F1:\", f1_score(yTest, model_gbm.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set MCC:\", matthews_corrcoef(yTest, model_gbm.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set Recall:\", recall_score(yTest, model_gbm.predict(XTest)))\n",
    "    print(\"FNA Test Set Accuracy:\", metrics.accuracy_score(yTest, predictions_FNA))\n",
    "    print(classification_report(yTest, predictions_FNA))\n",
    "    print(confusion_matrix(yTest, predictions_FNA))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_FNA, tpr_FNA, _ = metrics.roc_curve(yTest, predictions_FNA)\n",
    "    plt.plot(fpr_FNA,tpr_FNA)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"G:/raMSIn/XGB_Importance2/XGB2_ROC_FNAtest2.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    # Visualize the importantance of the features\n",
    "    feature_imp = pd.Series(model_gbm.feature_importances_, index=XTrain.columns).sort_values(ascending=False)\n",
    "    x=feature_imp\n",
    "    y=feature_imp.index\n",
    "    \n",
    "    plt.subplots(dpi = 300)\n",
    "    #plt.rcParams[\"figure.figsize\"] = [4, 6]\n",
    "    #plt.rcParams[\"font.family\"] = \"Arial\"\n",
    "    #plt.rcParams.update({'font.size': 6})\n",
    "    plt.xlabel('Feature Importance Score', fontproperties='Arial', fontsize=17)\n",
    "    plt.ylabel('Features', fontproperties='Arial', fontsize=17)\n",
    "    plt.xticks(fontsize=15)\n",
    "    plt.yticks(fontsize=15)\n",
    "    plt.title(\"Important Molecular Features\", fontproperties='Arial', fontsize=20)\n",
    "    sns.barplot(x=feature_imp, y=feature_imp.index)\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/XGB_TopFeatures.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    # Visualize the boxplot of the important features between the two groups\n",
    "    #fig = px.box(data_frame = df_ROI_for_ML_Opti, x = feature_imp[:10].index,color= 'type')\n",
    "    #fig.show()\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2dcef352",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set F1: 0.44491498896790316\n",
      "Training Set MCC: 0.3058405860365625\n",
      "Training Set Accuracy: 0.6326517150395778\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.93      0.73     47449\n",
      "           1       0.81      0.31      0.44     43511\n",
      "\n",
      "    accuracy                           0.63     90960\n",
      "   macro avg       0.70      0.62      0.58     90960\n",
      "weighted avg       0.70      0.63      0.59     90960\n",
      "\n",
      "[[44261  3188]\n",
      " [30226 13285]]\n",
      "Ext Val Set F1: 0.36669374228601226\n",
      "Ext Val Set MCC: -0.08672126955572901\n",
      "Ext Val Set Accuracy: 0.4539917695473251\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.60      0.52      2943\n",
      "           1       0.46      0.31      0.37      3132\n",
      "\n",
      "    accuracy                           0.45      6075\n",
      "   macro avg       0.45      0.46      0.44      6075\n",
      "weighted avg       0.45      0.45      0.44      6075\n",
      "\n",
      "[[1776 1167]\n",
      " [2150  982]]\n",
      "5F-CV: 0.6032422440438727\n",
      "FNA Set F1: 0.42159802760103754\n",
      "FNA Set MCC: -0.01077828493819004\n",
      "FNA Set Recall: 0.36824347274744684\n",
      "FNA Test Set Accuracy: 0.4953269974408406\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.62      0.55     44540\n",
      "           1       0.49      0.37      0.42     44161\n",
      "\n",
      "    accuracy                           0.50     88701\n",
      "   macro avg       0.49      0.49      0.49     88701\n",
      "weighted avg       0.49      0.50      0.49     88701\n",
      "\n",
      "[[27674 16866]\n",
      " [27899 16262]]\n"
     ]
    }
   ],
   "source": [
    "coeff_GBM, TOPfeatures_GBM = GBM_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98e2c8c",
   "metadata": {},
   "source": [
    "### 3.2.4. Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "79af839d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StackingRegressor():\n",
    "    \n",
    "    def __init__(self, learners):\n",
    "        self.level_sizes = []\n",
    "        self.learners = []\n",
    "        \n",
    "        for learning_level in learners:\n",
    "            self.level_sizes.append(len(learning_level))\n",
    "            level_learners = []\n",
    "            \n",
    "            for learner in learning_level:\n",
    "                level_learners.append(deepcopy(learner))\n",
    "            self.learners.append(level_learners)\n",
    "            \n",
    "            \n",
    "    def fit(self, x, y):\n",
    "        \n",
    "        meta_data = [x,x,x]\n",
    "        meta_targets = [y,y,y]\n",
    "        \n",
    "        for i in range(len(self.learners)):\n",
    "            level_size = self.level_sizes[i]\n",
    "            \n",
    "            data_z = np.zeros((level_size, len(x)))\n",
    "            target_z = np.zeros(len(x))\n",
    "            \n",
    "            train_x = meta_data[i]\n",
    "            train_y = meta_targets[i]\n",
    "            \n",
    "            # Define number of folds\n",
    "            num_folds = 5\n",
    "            \n",
    "            # Create the k-fold cross-validation object\n",
    "            KF = KFold(n_splits=num_folds)\n",
    "            m = 0\n",
    "\n",
    "            # Loop over each fold of the cross-validation\n",
    "            for train_indices, test_indices in KF.split(x):\n",
    "                \n",
    "                for j in range(len(self.learners[i])):\n",
    "                    train_x = pd.DataFrame(train_x)\n",
    "                    train_y = pd.DataFrame(train_y)\n",
    "\n",
    "                    learner = self.learners[i][j]\n",
    "                    learner.fit(train_x.iloc[train_indices], train_y.iloc[train_indices])\n",
    "                    p = learner.predict(train_x.iloc[test_indices])\n",
    "                    data_z[j][m: m+len(test_indices) ] = p\n",
    "\n",
    "\n",
    "                train_y = pd.DataFrame(train_y)\n",
    "                train_y_array = (np.array(train_y)).reshape(-1,)\n",
    "                zty_ind = (np.array(train_y.iloc[test_indices])).reshape(-1,)\n",
    "                target_z[m: m+len(test_indices)] = train_y_array[zty_ind]\n",
    "                m += len(test_indices)\n",
    "                \n",
    "\n",
    "            data_z = data_z.transpose()\n",
    "            meta_data.append(data_z)\n",
    "            meta_targets.append(target_z)\n",
    "            \n",
    "            \n",
    "            for learner in self.learners[i]:\n",
    "                train_x = pd.DataFrame(train_x)\n",
    "                train_y = pd.DataFrame(train_y)\n",
    "                learner.fit(train_x, train_y)\n",
    "                \n",
    "                \n",
    "    def predict(self, x):\n",
    "        \n",
    "        meta_data = [x,x,x]\n",
    "        for i in range(len(self.learners)):\n",
    "            \n",
    "            level_size = self.level_sizes[i]\n",
    "            \n",
    "            data_z = np.zeros((level_size, len(x)))\n",
    "            \n",
    "            test_x = meta_data[i]\n",
    "            \n",
    "            for j in range(len(self.learners[i])):\n",
    "                \n",
    "                learner = self.learners[i][j]\n",
    "                predictions = learner.predict(test_x)\n",
    "                data_z[j] = predictions\n",
    "                \n",
    "            \n",
    "            data_z = data_z.transpose()\n",
    "            meta_data.append(data_z)\n",
    "            \n",
    "        return meta_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3fb1ee36",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build stacking Model\n",
    "\n",
    "def Stacking_func(XTrain=X_ingested, XVal=X_val, XTest=X_FNA, XTest2=X_di, yTrain=y_ingested, yVal=y_val, yTest=y_FNA, yTest2=y_di):\n",
    "\n",
    "    base_learners = []\n",
    "\n",
    "    # Define models to use in stacking ensemble\n",
    "    m1 = LogisticRegression(C=0.001, penalty='l1', solver=\"liblinear\", max_iter=5000, random_state=42, class_weight={0:0.9628, 1:1.0402})\n",
    "    base_learners.append(m1)\n",
    "\n",
    "    m2 = LinearSVC(penalty='l2', loss=\"squared_hinge\", C=461, random_state=42, class_weight={0:0.9628, 1:1.0402})\n",
    "    base_learners.append(m2)\n",
    "\n",
    "    m3 = GradientBoostingClassifier(learning_rate=4, n_estimators=50, max_depth=7, min_samples_leaf=4, min_samples_split=30, n_iter_no_change=5, random_state=42)\n",
    "    base_learners.append(m3)\n",
    "\n",
    "    # Define the meta-classifier to use for stacking\n",
    "    #meta_learner = LinearDiscriminantAnalysis()  # 0.90,0.80; 0.75,0.51; 0.65,0.27; 0.64,0.26\n",
    "    #meta_learner = QuadraticDiscriminantAnalysis()  # 0.93,0.86; 0.67,0.39; 0.67,0.15; 0.68,0.20\n",
    "    \n",
    "    #meta_learner = LogisticRegression()  # 0.90,0.79; 0.82,0.65; 0.64,0.24; 0.64;0.27\n",
    "    #meta_learner = LogisticRegression(C=1, penalty='l1', solver=\"liblinear\", max_iter=5000, random_state=42)\n",
    "    ## C=1: 0.90,0.79; 0.82,0.65; 0.65,0.25; 0.65;0.27\n",
    "    #meta_learner = LogisticRegression(C=0.1, penalty='l1', solver=\"liblinear\", max_iter=5000, random_state=42)\n",
    "    ## C=0.1: 0.90,0.79; 0.82,0.65; 0.65,0.25; 0.65;0.28\n",
    "    #meta_learner = LogisticRegression(C=0.01, penalty='l1', solver=\"liblinear\", max_iter=5000, random_state=42)\n",
    "    ## C=0.01: 0.89,0.78; 0.81,0.63; 0.63,0.22; 0.65;0.29\n",
    "    #meta_learner = LogisticRegression(C=0.0075, penalty='l1', solver=\"liblinear\", max_iter=5000, random_state=42)\n",
    "    ## C=0.0075: 0.89,0.77; 0.81,0.63; 0.62,0.20; 0.65;0.29\n",
    "    #meta_learner = LogisticRegression(C=0.005, penalty='l1', solver=\"liblinear\", max_iter=5000, random_state=42)\n",
    "    ## C=0.005: 0.88,0.76; 0.82,0.64; 0.60,0.17; 0.66;0.31\n",
    "    #meta_learner = LogisticRegression(C=0.0025, penalty='l1', solver=\"liblinear\", max_iter=5000, random_state=42)\n",
    "    ## C=0.0025: 0.86,0.72; 0.83,0.66; 0.53,0.02; 0.64;0.31\n",
    "    #meta_learner = LogisticRegression(C=0.0015, penalty='l1', solver=\"liblinear\", max_iter=5000, random_state=42)\n",
    "    ## C=0.0015: 0.85,0.70; 0.80,0.60; 0.55,0.09; 0.64;0.30\n",
    "    #meta_learner = LogisticRegression(C=0.0013, penalty='l1', solver=\"liblinear\", max_iter=5000, random_state=42)\n",
    "    ## C=0.0013: 0.85,0.70; 0.78,0.56; 0.58,0.16; 0.63;0.29\n",
    "    #meta_learner = LogisticRegression(C=0.0012, penalty='l1', solver=\"liblinear\", max_iter=5000, random_state=42)\n",
    "    ## C=0.0012: 0.85,0.69; 0.77,0.52; 0.60,0.22; 0.63;0.27\n",
    "    meta_learner = LogisticRegression(C=0.0011, penalty='l1', solver=\"liblinear\", max_iter=5000, random_state=42)\n",
    "    ## C=0.0011: 0.85,0.69; 0.77,0.51; 0.64,0.30; 0.62;0.25\n",
    "    #meta_learner = LogisticRegression(C=0.001, penalty='l1', solver=\"liblinear\", max_iter=5000, random_state=42)\n",
    "    ## C=0.001: 0.84,0.68; 0.76,0.49; 0.68,0.38; 0.61;0.22\n",
    "    #meta_learner = LogisticRegression(C=0.0005, penalty='l1', solver=\"liblinear\", max_iter=5000, random_state=42)\n",
    "    ## C=0.0005: 0.83,0.66; 0.74,0.45; 0.65,0.37; 0.60;0.18\n",
    "    \n",
    "    #meta_learner = LinearSVC()  # 0.90,0.80; 0.82,0.65; 0.64,0.24; 0.65,0.27\n",
    "    #meta_learner = KNeighborsClassifier()  # 0.98,0.96; 0.65,0.30; 0.68,0.21; 0.52,-0.05\n",
    "    #meta_learner = DecisionTreeClassifier()  # 0.94,0.87; 0.54,0.15; 0.66,0.11; 0.46,-0.11\n",
    "    #meta_learner = RandomForestClassifier()  # 0.98,0.95; 0.54,0.20; 0.66,0.11; 0.49;-0.01\n",
    "    #meta_learner = GradientBoostingClassifier()  # 0.97,0.94; 0.56,0.27; 0.66,0.13; 0.48,-0.09\n",
    "    #meta_learner = AdaBoostClassifier()  # 0.96,0.93; 0.69,0.42; 0.62,0.10; 0.54,0.11\n",
    "    #meta_learner = xgb.XGBClassifier()  # 0.98,0.95; 0.59,0.30; 0.66,0.10; 0.44,-0.12\n",
    "\n",
    "    model_sc = StackingRegressor([[m1, m2, m3], [meta_learner]])\n",
    "    model_sc.fit(XTrain, yTrain)\n",
    "    \n",
    "    #=======================================\n",
    "    \n",
    "    # Training Set\n",
    "    #plt.rcParams[\"figure.figsize\"] = (3,3)\n",
    "    X_train_predictions = model_sc.predict(X_train)[-1]\n",
    "    print(\"Training Set F1:\", f1_score(y_train, model_sc.predict(X_train)[-1], sample_weight=sampleW))\n",
    "    print(\"Training Set MCC:\", matthews_corrcoef(y_train, model_sc.predict(X_train)[-1], sample_weight=sampleW))\n",
    "    print(\"Training Set Accuracy:\", metrics.accuracy_score(y_train, X_train_predictions))\n",
    "    print(classification_report(y_train, X_train_predictions))\n",
    "    print(confusion_matrix(y_train, X_train_predictions))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr, tpr, _ = metrics.roc_curve(y_train, X_train_predictions)\n",
    "    plt.plot(fpr,tpr)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_train.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    # Val set\n",
    "    predictions_val  = model_sc.predict(XVal)[-1]\n",
    "    print(\"Ext Val Set F1:\", f1_score(yVal, model_sc.predict(XVal)[-1], sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set MCC:\", matthews_corrcoef(yVal, model_sc.predict(XVal)[-1], sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set Accuracy:\", metrics.accuracy_score(yVal, predictions_val))\n",
    "    print(classification_report(yVal, predictions_val))\n",
    "    print(confusion_matrix(yVal, predictions_val))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_val, tpr_val, _ = metrics.roc_curve(yVal, predictions_val)\n",
    "    plt.plot(fpr_val,tpr_val)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_test.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    #f1_5_train = cross_val_score(model_sc, XTrain, yTrain, cv = 5, scoring=\"f1\")\n",
    "    #print(\"5F-CV:\", avgScore(f1_5_train, 5))\n",
    "    \n",
    "    # Test set\n",
    "    predictions_FNA = model_sc.predict(XTest)[-1]\n",
    "    print(\"FNA Set F1:\", f1_score(yTest, model_sc.predict(XTest)[-1], sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set MCC:\", matthews_corrcoef(yTest, model_sc.predict(XTest)[-1], sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set Recall:\", recall_score(yTest, model_sc.predict(XTest)[-1]))\n",
    "    print(\"FNA Test Set Accuracy:\", metrics.accuracy_score(yTest, predictions_FNA))\n",
    "    print(classification_report(yTest, predictions_FNA))\n",
    "    print(confusion_matrix(yTest, predictions_FNA))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_FNA, tpr_FNA, _ = metrics.roc_curve(yTest, predictions_FNA)\n",
    "    plt.plot(fpr_FNA,tpr_FNA)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"G:/raMSIn/XGB_Importance2/XGB2_ROC_FNAtest2.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    # Test2 set\n",
    "    predictions_di = model_sc.predict(XTest2)[-1]\n",
    "    print(\"DirectIn Set F1:\", f1_score(yTest2, model_sc.predict(XTest2)[-1], sample_weight=sampleDiW))\n",
    "    print(\"DirectIn Set MCC:\", matthews_corrcoef(yTest2, model_sc.predict(XTest2)[-1], sample_weight=sampleDiW))\n",
    "    print(\"DirectIn Set Recall:\", recall_score(yTest2, model_sc.predict(XTest2)[-1]))\n",
    "    print(\"DirectIn Test Set Accuracy:\", metrics.accuracy_score(yTest2, predictions_di))\n",
    "    print(classification_report(yTest2, predictions_di))\n",
    "    print(confusion_matrix(yTest2, predictions_di))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_di, tpr_di, _ = metrics.roc_curve(yTest2, predictions_di)\n",
    "    plt.plot(fpr_di,tpr_di)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"G:/raMSIn/XGB_Importance2/XGB2_ROC_FNAtest2.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e01c13ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set F1: 0.8423672428013455\n",
      "Training Set MCC: 0.6846344917985415\n",
      "Training Set Accuracy: 0.8423043095866315\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.84      0.85     47449\n",
      "           1       0.83      0.84      0.84     43511\n",
      "\n",
      "    accuracy                           0.84     90960\n",
      "   macro avg       0.84      0.84      0.84     90960\n",
      "weighted avg       0.84      0.84      0.84     90960\n",
      "\n",
      "[[39953  7496]\n",
      " [ 6848 36663]]\n",
      "Ext Val Set F1: 0.832634364655037\n",
      "Ext Val Set MCC: 0.644872636681615\n",
      "Ext Val Set Accuracy: 0.8190946502057613\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.72      0.79      2943\n",
      "           1       0.77      0.92      0.84      3132\n",
      "\n",
      "    accuracy                           0.82      6075\n",
      "   macro avg       0.83      0.82      0.82      6075\n",
      "weighted avg       0.83      0.82      0.82      6075\n",
      "\n",
      "[[2109  834]\n",
      " [ 265 2867]]\n",
      "FNA Set F1: 0.7108418398555316\n",
      "FNA Set MCC: 0.4392628452832895\n",
      "FNA Set Recall: 0.6901338284912026\n",
      "FNA Test Set Accuracy: 0.7193830960192106\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.75      0.73     44540\n",
      "           1       0.73      0.69      0.71     44161\n",
      "\n",
      "    accuracy                           0.72     88701\n",
      "   macro avg       0.72      0.72      0.72     88701\n",
      "weighted avg       0.72      0.72      0.72     88701\n",
      "\n",
      "[[33333 11207]\n",
      " [13684 30477]]\n",
      "DirectIn Set F1: 0.6750282767703342\n",
      "DirectIn Set MCC: 0.35822032785092695\n",
      "DirectIn Set Recall: 0.6666666666666666\n",
      "DirectIn Test Set Accuracy: 0.6790490341753344\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.69      0.68      3027\n",
      "           1       0.68      0.67      0.68      3030\n",
      "\n",
      "    accuracy                           0.68      6057\n",
      "   macro avg       0.68      0.68      0.68      6057\n",
      "weighted avg       0.68      0.68      0.68      6057\n",
      "\n",
      "[[2093  934]\n",
      " [1010 2020]]\n"
     ]
    }
   ],
   "source": [
    "Stacking_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235227fc",
   "metadata": {},
   "source": [
    "### 3.2.5. Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "84be5513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a voting ensemble of models\n",
    "def get_voting():\n",
    "    models = list()\n",
    "    # Define the base models\n",
    "    models.append((\"m1\", LogisticRegression(C=0.001, penalty='l1', solver=\"liblinear\", max_iter=5000, random_state=42, class_weight={0:0.9628, 1:1.0402})))\n",
    "    models.append((\"m2\", LinearSVC(penalty='l2', loss=\"squared_hinge\", C=461, random_state=42, class_weight={0:0.9628, 1:1.0402})))\n",
    "    models.append((\"m3\", GradientBoostingClassifier(learning_rate=4, n_estimators=50, max_depth=7, min_samples_leaf=4, min_samples_split=30, n_iter_no_change=5, random_state=42)))\n",
    "\n",
    "    # define the voting ensemble\n",
    "    ensemble = VotingClassifier(estimators=models, voting='hard')\n",
    "    return ensemble\n",
    "\n",
    "# get a list of models to evaluate\n",
    "def get_models():\n",
    "    models = dict()\n",
    "    models['m1'] = LogisticRegression(C=0.001, penalty='l1', solver=\"liblinear\", max_iter=5000, random_state=42, class_weight={0:0.9628, 1:1.0402})\n",
    "    models['m2'] = LinearSVC(penalty='l2', loss=\"squared_hinge\", C=461, random_state=42, class_weight={0:0.9628, 1:1.0402})\n",
    "    models['m3'] = GradientBoostingClassifier(learning_rate=4, n_estimators=50, max_depth=7, min_samples_leaf=4, min_samples_split=30, n_iter_no_change=5, random_state=42)\n",
    "    models['hard_voting'] = get_voting()\n",
    "    return models\n",
    "\n",
    "\n",
    "# evaluate a give model using cross-validation\n",
    "def evaluate_model(model, XX, yy):\n",
    "    cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=10, random_state=42)\n",
    "    scores = cross_val_score(model, XX, yy, scoring='f1', cv=cv, n_jobs=-1, error_score='raise')\n",
    "    return scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2c7985bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 720x720 with 0 Axes>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from matplotlib.pyplot import figure\n",
    "plt.rcParams['figure.figsize'] = [10, 10]\n",
    "plt.close()\n",
    "figure(figsize=(10, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fab33d50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">m1 0.811 (0.003)\n",
      ">m2 0.933 (0.009)\n",
      ">m3 0.671 (0.144)\n",
      ">hard_voting 0.902 (0.022)\n"
     ]
    }
   ],
   "source": [
    "# get the models to evaluate\n",
    "models = get_models()\n",
    "\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "    scores = evaluate_model(model, XX=X_ingested, yy=y_ingested)\n",
    "    results.append(scores)\n",
    "    names.append(name)\n",
    "    print('>%s %.3f (%.3f)' % (name, np.mean(scores), np.std(scores)))\n",
    "    \n",
    "# plot model performance for comparison\n",
    "plt.subplots(dpi = 600)\n",
    "plt.boxplot(results, labels=names, showmeans=True)\n",
    "plt.ylabel('F1 score')\n",
    "plt.xlabel('Predictive Models')\n",
    "plt.savefig(r\"H:/3_output_raMSIn/3_3_Output_raMSIn_HKU_Ingested4ALL/XGB_ALL/afterModelSelection/dbMSIn_5ppm/voting.jpg\", bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6832284f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Voting_func(XTrain=X_ingested, XVal=X_val, XTest=X_FNA, XTest2=X_di, yTrain=y_ingested, yVal=y_val, yTest=y_FNA, yTest2=y_di):\n",
    "\n",
    "    models = get_models()\n",
    "    \n",
    "    ensemble = models[\"hard_voting\"]\n",
    "    ensemble.fit(XTrain, yTrain)\n",
    "    #=======================================\n",
    "\n",
    "    # Training Set\n",
    "    #plt.rcParams[\"figure.figsize\"] = (3,3)\n",
    "    X_train_predictions = ensemble.predict(X_train)\n",
    "    print(\"Training Set F1:\", f1_score(y_train, ensemble.predict(X_train), sample_weight=sampleW))\n",
    "    print(\"Training Set MCC:\", matthews_corrcoef(y_train, ensemble.predict(X_train), sample_weight=sampleW))\n",
    "    print(\"Training Set Accuracy:\", metrics.accuracy_score(y_train, X_train_predictions))\n",
    "    print(classification_report(y_train, X_train_predictions))\n",
    "    print(confusion_matrix(y_train, X_train_predictions))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr, tpr, _ = metrics.roc_curve(y_train, X_train_predictions)\n",
    "    plt.plot(fpr,tpr)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_train.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    # Val set\n",
    "    predictions_val  = ensemble.predict(XVal)\n",
    "    print(\"Ext Val Set F1:\", f1_score(yVal, ensemble.predict(XVal), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set MCC:\", matthews_corrcoef(yVal, ensemble.predict(XVal), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set Accuracy:\", metrics.accuracy_score(yVal, predictions_val))\n",
    "    print(classification_report(yVal, predictions_val))\n",
    "    print(confusion_matrix(yVal, predictions_val))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_val, tpr_val, _ = metrics.roc_curve(yVal, predictions_val)\n",
    "    plt.plot(fpr_val,tpr_val)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_test.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    f1_5_train = cross_val_score(ensemble, XTrain, yTrain, cv = 5, scoring=\"f1\")\n",
    "    print(\"5F-CV:\", avgScore(f1_5_train, 5))\n",
    "\n",
    "    # Test set\n",
    "    predictions_FNA = ensemble.predict(XTest)\n",
    "    print(\"FNA Set F1:\", f1_score(yTest, ensemble.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set MCC:\", matthews_corrcoef(yTest, ensemble.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set Recall:\", recall_score(yTest, ensemble.predict(XTest)))\n",
    "    print(\"FNA Test Set Accuracy:\", metrics.accuracy_score(yTest, predictions_FNA))\n",
    "    print(classification_report(yTest, predictions_FNA))\n",
    "    print(confusion_matrix(yTest, predictions_FNA))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_FNA, tpr_FNA, _ = metrics.roc_curve(yTest, predictions_FNA)\n",
    "    plt.plot(fpr_FNA,tpr_FNA)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"G:/raMSIn/XGB_Importance2/XGB2_ROC_FNAtest2.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    # Test2 set\n",
    "    predictions_di = ensemble.predict(XTest2)\n",
    "    print(\"DirectIn Set F1:\", f1_score(yTest2, ensemble.predict(XTest2), sample_weight=sampleDiW))\n",
    "    print(\"DirectIn Set MCC:\", matthews_corrcoef(yTest2, ensemble.predict(XTest2), sample_weight=sampleDiW))\n",
    "    print(\"DirectIn Set Recall:\", recall_score(yTest2, ensemble.predict(XTest2)))\n",
    "    print(\"DirectIn Test Set Accuracy:\", metrics.accuracy_score(yTest2, predictions_di))\n",
    "    print(classification_report(yTest2, predictions_di))\n",
    "    print(confusion_matrix(yTest2, predictions_di))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_di, tpr_di, _ = metrics.roc_curve(yTest2, predictions_di)\n",
    "    plt.plot(fpr_di,tpr_di)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"G:/raMSIn/XGB_Importance2/XGB2_ROC_FNAtest2.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e3647683",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set F1: 0.8833318637005201\n",
      "Training Set MCC: 0.7616614513328519\n",
      "Training Set Accuracy: 0.8792106420404573\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.85      0.88     47449\n",
      "           1       0.85      0.91      0.88     43511\n",
      "\n",
      "    accuracy                           0.88     90960\n",
      "   macro avg       0.88      0.88      0.88     90960\n",
      "weighted avg       0.88      0.88      0.88     90960\n",
      "\n",
      "[[40549  6900]\n",
      " [ 4087 39424]]\n",
      "Ext Val Set F1: 0.864749296675819\n",
      "Ext Val Set MCC: 0.7228694161043941\n",
      "Ext Val Set Accuracy: 0.8617283950617284\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.83      0.85      2943\n",
      "           1       0.85      0.89      0.87      3132\n",
      "\n",
      "    accuracy                           0.86      6075\n",
      "   macro avg       0.86      0.86      0.86      6075\n",
      "weighted avg       0.86      0.86      0.86      6075\n",
      "\n",
      "[[2448  495]\n",
      " [ 345 2787]]\n",
      "5F-CV: 0.8109135421047764\n",
      "FNA Set F1: 0.7203888994797493\n",
      "FNA Set MCC: 0.4213683696974928\n",
      "FNA Set Recall: 0.7468354430379747\n",
      "FNA Test Set Accuracy: 0.7099581740904838\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.67      0.70     44540\n",
      "           1       0.69      0.75      0.72     44161\n",
      "\n",
      "    accuracy                           0.71     88701\n",
      "   macro avg       0.71      0.71      0.71     88701\n",
      "weighted avg       0.71      0.71      0.71     88701\n",
      "\n",
      "[[29993 14547]\n",
      " [11180 32981]]\n",
      "DirectIn Set F1: 0.6098345161344518\n",
      "DirectIn Set MCC: 0.23887199358627015\n",
      "DirectIn Set Recall: 0.595049504950495\n",
      "DirectIn Test Set Accuracy: 0.6192834736668318\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.64      0.63      3027\n",
      "           1       0.63      0.60      0.61      3030\n",
      "\n",
      "    accuracy                           0.62      6057\n",
      "   macro avg       0.62      0.62      0.62      6057\n",
      "weighted avg       0.62      0.62      0.62      6057\n",
      "\n",
      "[[1948 1079]\n",
      " [1227 1803]]\n"
     ]
    }
   ],
   "source": [
    "Voting_func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7c6aeb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib as jl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fdfc9ad1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('m1',\n",
       "                              LogisticRegression(C=0.001,\n",
       "                                                 class_weight={0: 0.9628,\n",
       "                                                               1: 1.0402},\n",
       "                                                 max_iter=5000, penalty='l1',\n",
       "                                                 random_state=42,\n",
       "                                                 solver='liblinear')),\n",
       "                             ('m2',\n",
       "                              LinearSVC(C=461,\n",
       "                                        class_weight={0: 0.9628, 1: 1.0402},\n",
       "                                        random_state=42)),\n",
       "                             ('m3',\n",
       "                              GradientBoostingClassifier(learning_rate=4,\n",
       "                                                         max_depth=7,\n",
       "                                                         min_samples_leaf=4,\n",
       "                                                         min_samples_split=30,\n",
       "                                                         n_estimators=50,\n",
       "                                                         n_iter_no_change=5,\n",
       "                                                         random_state=42))])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = get_models()\n",
    "    \n",
    "ensemble = models[\"hard_voting\"]\n",
    "ensemble.fit(X_ingested, y_ingested)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "65d8cb99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['H:\\\\3_output_raMSIn\\\\3_3_Output_raMSIn_HKU_Ingested4ALL\\\\XGB_ALL\\\\afterModelSelection\\\\dbMSIn_5ppm\\\\model3to1Voting_dbMSIn5ppm.joblib']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelSavePath = r\"H:\\3_output_raMSIn\\3_3_Output_raMSIn_HKU_Ingested4ALL\\XGB_ALL\\afterModelSelection\\dbMSIn_5ppm\\model3to1Voting_dbMSIn5ppm.joblib\"\n",
    "jl.dump(ensemble, modelSavePath, compress = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f9a9ba",
   "metadata": {},
   "source": [
    "## 3.3 Machine Learning Modeling: Model 1 (Train 6:6, Val 4:4, Test 3:3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49659b18",
   "metadata": {},
   "source": [
    "### 3.3.1. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7bcace0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build Logistic Regression Model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def LogisticRegression_func(XTrain=X_train, XVal=X_val, XTest=X_FNA, yTrain=y_train, yVal=y_val, yTest=y_FNA):\n",
    "    model_lr = LogisticRegression(C=0.001, penalty='l1', solver=\"liblinear\", max_iter=5000, random_state=42, class_weight={0:0.9628, 1:1.0402})  # max_iter=100\n",
    "    model_lr.fit(XTrain,yTrain)\n",
    "    \n",
    "    # Training Set\n",
    "    #plt.rcParams[\"figure.figsize\"] = (3,3)\n",
    "    X_train_predictions = model_lr.predict(X_train)\n",
    "    print(\"Training Set F1:\", f1_score(y_train, model_lr.predict(X_train), sample_weight=sampleW))\n",
    "    print(\"Training Set MCC:\", matthews_corrcoef(y_train, model_lr.predict(X_train), sample_weight=sampleW))\n",
    "    print(\"Training Set Accuracy:\", metrics.accuracy_score(y_train, X_train_predictions))\n",
    "    print(classification_report(y_train, X_train_predictions))\n",
    "    print(confusion_matrix(y_train, X_train_predictions))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr, tpr, _ = metrics.roc_curve(y_train, X_train_predictions)\n",
    "    plt.plot(fpr,tpr)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_train.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    # Val set\n",
    "    predictions_val  = model_lr.predict(XVal)\n",
    "    print(\"Ext Val Set F1:\", f1_score(yVal, model_lr.predict(XVal), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set MCC:\", matthews_corrcoef(yVal, model_lr.predict(XVal), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set Accuracy:\", metrics.accuracy_score(yVal, predictions_val))\n",
    "    print(classification_report(yVal, predictions_val))\n",
    "    print(confusion_matrix(yVal, predictions_val))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_val, tpr_val, _ = metrics.roc_curve(yVal, predictions_val)\n",
    "    plt.plot(fpr_val,tpr_val)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_test.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    f1_5_train = cross_val_score(model_lr, XTrain, yTrain, cv = 5, scoring=\"f1\")\n",
    "    print(\"5F-CV:\", avgScore(f1_5_train, 5))\n",
    "    \n",
    "    # Test set\n",
    "    predictions_FNA = model_lr.predict(XTest)\n",
    "    print(\"FNA Set F1:\", f1_score(yTest, model_lr.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set MCC:\", matthews_corrcoef(yTest, model_lr.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set Recall:\", recall_score(yTest, model_lr.predict(XTest)))\n",
    "    print(\"FNA Test Set Accuracy:\", metrics.accuracy_score(yTest, predictions_FNA))\n",
    "    print(classification_report(yTest, predictions_FNA))\n",
    "    print(confusion_matrix(yTest, predictions_FNA))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_FNA, tpr_FNA, _ = metrics.roc_curve(yTest, predictions_FNA)\n",
    "    plt.plot(fpr_FNA,tpr_FNA)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"G:/raMSIn/XGB_Importance2/XGB2_ROC_FNAtest2.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    # Visualize the importantance of the features\n",
    "    feature_imp = pd.Series(model_lr.coef_[0], index=XTrain.columns).sort_values(ascending=False)\n",
    "    x=feature_imp\n",
    "    y=feature_imp.index\n",
    "    \n",
    "    plt.subplots(dpi = 300)\n",
    "    #plt.rcParams[\"figure.figsize\"] = [4, 6]\n",
    "    #plt.rcParams[\"font.family\"] = \"Arial\"\n",
    "    #plt.rcParams.update({'font.size': 6})\n",
    "    plt.xlabel('Feature Importance Score', fontproperties='Arial', fontsize=17)\n",
    "    plt.ylabel('Features', fontproperties='Arial', fontsize=17)\n",
    "    plt.xticks(fontsize=15)\n",
    "    plt.yticks(fontsize=15)\n",
    "    plt.title(\"Important Molecular Features\", fontproperties='Arial', fontsize=20)\n",
    "    sns.barplot(x=feature_imp, y=feature_imp.index)\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_TopFeatures.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    #feature_importances = model_lr.coef_[0]\n",
    "    #feature_df=pd.DataFrame({'m/z':XTrain.columns,'coef':feature_importances})\n",
    "\n",
    "    #fig = px.bar(feature_df, x='coef', y='m/z')\n",
    "    #fig.show()\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5d284fc7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set F1: 0.8607786920989818\n",
      "Training Set MCC: 0.7177102858667281\n",
      "Training Set Accuracy: 0.8580474934036939\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.84      0.86     47449\n",
      "           1       0.84      0.87      0.85     43511\n",
      "\n",
      "    accuracy                           0.86     90960\n",
      "   macro avg       0.86      0.86      0.86     90960\n",
      "weighted avg       0.86      0.86      0.86     90960\n",
      "\n",
      "[[40035  7414]\n",
      " [ 5498 38013]]\n",
      "Ext Val Set F1: 0.7455915678272023\n",
      "Ext Val Set MCC: 0.45450778489828036\n",
      "Ext Val Set Accuracy: 0.7265843621399177\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.64      0.69      2943\n",
      "           1       0.70      0.81      0.75      3132\n",
      "\n",
      "    accuracy                           0.73      6075\n",
      "   macro avg       0.73      0.72      0.72      6075\n",
      "weighted avg       0.73      0.73      0.72      6075\n",
      "\n",
      "[[1880 1063]\n",
      " [ 598 2534]]\n",
      "5F-CV: 0.7458898574536084\n",
      "FNA Set F1: 0.5255329612418614\n",
      "FNA Set MCC: 0.024460726890852616\n",
      "FNA Set Recall: 0.5402730916419465\n",
      "FNA Test Set Accuracy: 0.5120911827375114\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.48      0.50     44540\n",
      "           1       0.51      0.54      0.52     44161\n",
      "\n",
      "    accuracy                           0.51     88701\n",
      "   macro avg       0.51      0.51      0.51     88701\n",
      "weighted avg       0.51      0.51      0.51     88701\n",
      "\n",
      "[[21564 22976]\n",
      " [20302 23859]]\n"
     ]
    }
   ],
   "source": [
    "coeff_LogReg, TOPfeatures_LogReg = LogisticRegression_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e368acdd",
   "metadata": {},
   "source": [
    "### 3.3.2. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "88f68e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build LinearSVC Model\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "def LinearSVC_func(XTrain=X_train, XVal=X_val, XTest=X_FNA, yTrain=y_train, yVal=y_val, yTest=y_FNA):\n",
    "    model_svm = LinearSVC(penalty='l2', loss=\"squared_hinge\", C=461, random_state=42, class_weight={0:0.9628, 1:1.0402})\n",
    "    model_svm.fit(XTrain,yTrain)\n",
    "    \n",
    "    # Training Set\n",
    "    #plt.rcParams[\"figure.figsize\"] = (3,3)\n",
    "    X_train_predictions = model_svm.predict(X_train)\n",
    "    print(\"Training Set F1:\", f1_score(y_train, model_svm.predict(X_train), sample_weight=sampleW))\n",
    "    print(\"Training Set MCC:\", matthews_corrcoef(y_train, model_svm.predict(X_train), sample_weight=sampleW))\n",
    "    print(\"Training Set Accuracy:\", metrics.accuracy_score(y_train, X_train_predictions))\n",
    "    print(classification_report(y_train, X_train_predictions))\n",
    "    print(confusion_matrix(y_train, X_train_predictions))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr, tpr, _ = metrics.roc_curve(y_train, X_train_predictions)\n",
    "    plt.plot(fpr,tpr)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_train.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    # Val set\n",
    "    predictions_val  = model_svm.predict(XVal)\n",
    "    print(\"Ext Val Set F1:\", f1_score(yVal, model_svm.predict(XVal), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set MCC:\", matthews_corrcoef(yVal, model_svm.predict(XVal), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set Accuracy:\", metrics.accuracy_score(yVal, predictions_val))\n",
    "    print(classification_report(yVal, predictions_val))\n",
    "    print(confusion_matrix(yVal, predictions_val))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_val, tpr_val, _ = metrics.roc_curve(yVal, predictions_val)\n",
    "    plt.plot(fpr_val,tpr_val)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_test.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    f1_5_train = cross_val_score(model_svm, XTrain, yTrain, cv = 5, scoring=\"f1\")\n",
    "    print(\"5F-CV:\", avgScore(f1_5_train, 5))\n",
    "    \n",
    "    # Test set\n",
    "    predictions_FNA = model_svm.predict(XTest)\n",
    "    print(\"FNA Set F1:\", f1_score(yTest, model_svm.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set MCC:\", matthews_corrcoef(yTest, model_svm.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set Recall:\", recall_score(yTest, model_svm.predict(XTest)))\n",
    "    print(\"FNA Test Set Accuracy:\", metrics.accuracy_score(yTest, predictions_FNA))\n",
    "    print(classification_report(yTest, predictions_FNA))\n",
    "    print(confusion_matrix(yTest, predictions_FNA))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_FNA, tpr_FNA, _ = metrics.roc_curve(yTest, predictions_FNA)\n",
    "    plt.plot(fpr_FNA,tpr_FNA)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"G:/raMSIn/XGB_Importance2/XGB2_ROC_FNAtest2.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    # Visualize the importantance of the features\n",
    "    feature_imp = pd.Series(model_svm.coef_[0], index=XTrain.columns).sort_values(ascending=False)\n",
    "    x=feature_imp\n",
    "    y=feature_imp.index\n",
    "    \n",
    "    plt.subplots(dpi = 300)\n",
    "    #plt.rcParams[\"figure.figsize\"] = [4, 6]\n",
    "    #plt.rcParams[\"font.family\"] = \"Arial\"\n",
    "    #plt.rcParams.update({'font.size': 6})\n",
    "    plt.xlabel('Feature Importance Score', fontproperties='Arial', fontsize=17)\n",
    "    plt.ylabel('Features', fontproperties='Arial', fontsize=17)\n",
    "    plt.xticks(fontsize=15)\n",
    "    plt.yticks(fontsize=15)\n",
    "    plt.title(\"Important Molecular Features\", fontproperties='Arial', fontsize=20)\n",
    "    sns.barplot(x=feature_imp, y=feature_imp.index)\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_TopFeatures.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    #feature_importances = model_svm.coef_[0]\n",
    "    #feature_df=pd.DataFrame({'m/z':XTrain.columns,'coef':feature_importances})\n",
    "\n",
    "    #fig = px.bar(feature_df, x='coef', y='m/z')\n",
    "    #fig.show()\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "90420725",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set F1: 0.9247348950913382\n",
      "Training Set MCC: 0.8467684201619845\n",
      "Training Set Accuracy: 0.9171943711521547\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.86      0.92     47449\n",
      "           1       0.86      0.98      0.92     43511\n",
      "\n",
      "    accuracy                           0.92     90960\n",
      "   macro avg       0.92      0.92      0.92     90960\n",
      "weighted avg       0.93      0.92      0.92     90960\n",
      "\n",
      "[[40634  6815]\n",
      " [  717 42794]]\n",
      "Ext Val Set F1: 0.6054244661836908\n",
      "Ext Val Set MCC: 0.03454573263286213\n",
      "Ext Val Set Accuracy: 0.5224691358024691\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.29      0.37      2943\n",
      "           1       0.53      0.74      0.62      3132\n",
      "\n",
      "    accuracy                           0.52      6075\n",
      "   macro avg       0.52      0.52      0.49      6075\n",
      "weighted avg       0.52      0.52      0.50      6075\n",
      "\n",
      "[[ 845 2098]\n",
      " [ 803 2329]]\n",
      "5F-CV: 0.9201916500472332\n",
      "FNA Set F1: 0.707011263554752\n",
      "FNA Set MCC: 0.29855599545762734\n",
      "FNA Set Recall: 0.9159439324290664\n",
      "FNA Test Set Accuracy: 0.6191474729709925\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.32      0.46     44540\n",
      "           1       0.57      0.92      0.71     44161\n",
      "\n",
      "    accuracy                           0.62     88701\n",
      "   macro avg       0.68      0.62      0.58     88701\n",
      "weighted avg       0.69      0.62      0.58     88701\n",
      "\n",
      "[[14470 30070]\n",
      " [ 3712 40449]]\n"
     ]
    }
   ],
   "source": [
    "coeff_SVM, TOPfeatures_SVM = LinearSVC_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228ac6cd",
   "metadata": {},
   "source": [
    "### 3.3.3. GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7428a256",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build GBM Model\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "def GBM_func(XTrain=X_train, XVal=X_val, XTest=X_FNA, yTrain=y_train, yVal=y_val, yTest=y_FNA):\n",
    "    model_gbm = GradientBoostingClassifier(learning_rate=4, n_estimators=50, max_depth=7, min_samples_leaf=4, min_samples_split=30, n_iter_no_change=5, random_state=42)\n",
    "    model_gbm.fit(XTrain,yTrain)\n",
    "    \n",
    "    # Training Set\n",
    "    #plt.rcParams[\"figure.figsize\"] = (3,3)\n",
    "    X_train_predictions = model_gbm.predict(X_train)\n",
    "    print(\"Training Set F1:\", f1_score(y_train, model_gbm.predict(X_train), sample_weight=sampleW))\n",
    "    print(\"Training Set MCC:\", matthews_corrcoef(y_train, model_gbm.predict(X_train), sample_weight=sampleW))\n",
    "    print(\"Training Set Accuracy:\", metrics.accuracy_score(y_train, X_train_predictions))\n",
    "    print(classification_report(y_train, X_train_predictions))\n",
    "    print(confusion_matrix(y_train, X_train_predictions))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr, tpr, _ = metrics.roc_curve(y_train, X_train_predictions)\n",
    "    plt.plot(fpr,tpr)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_train.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    # Val set\n",
    "    predictions_val  = model_gbm.predict(XVal)\n",
    "    print(\"Ext Val Set F1:\", f1_score(yVal, model_gbm.predict(XVal), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set MCC:\", matthews_corrcoef(yVal, model_gbm.predict(XVal), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set Accuracy:\", metrics.accuracy_score(yVal, predictions_val))\n",
    "    print(classification_report(yVal, predictions_val))\n",
    "    print(confusion_matrix(yVal, predictions_val))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_val, tpr_val, _ = metrics.roc_curve(yVal, predictions_val)\n",
    "    plt.plot(fpr_val,tpr_val)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_test.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    f1_5_train = cross_val_score(model_gbm, XTrain, yTrain, cv = 5, scoring=\"f1\")\n",
    "    print(\"5F-CV:\", avgScore(f1_5_train, 5))\n",
    "    \n",
    "    # Test set\n",
    "    predictions_FNA = model_gbm.predict(XTest)\n",
    "    print(\"FNA Set F1:\", f1_score(yTest, model_gbm.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set MCC:\", matthews_corrcoef(yTest, model_gbm.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set Recall:\", recall_score(yTest, model_gbm.predict(XTest)))\n",
    "    print(\"FNA Test Set Accuracy:\", metrics.accuracy_score(yTest, predictions_FNA))\n",
    "    print(classification_report(yTest, predictions_FNA))\n",
    "    print(confusion_matrix(yTest, predictions_FNA))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_FNA, tpr_FNA, _ = metrics.roc_curve(yTest, predictions_FNA)\n",
    "    plt.plot(fpr_FNA,tpr_FNA)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"G:/raMSIn/XGB_Importance2/XGB2_ROC_FNAtest2.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    # Visualize the importantance of the features\n",
    "    feature_imp = pd.Series(model_gbm.feature_importances_, index=XTrain.columns).sort_values(ascending=False)\n",
    "    x=feature_imp\n",
    "    y=feature_imp.index\n",
    "    \n",
    "    plt.subplots(dpi = 300)\n",
    "    #plt.rcParams[\"figure.figsize\"] = [4, 6]\n",
    "    #plt.rcParams[\"font.family\"] = \"Arial\"\n",
    "    #plt.rcParams.update({'font.size': 6})\n",
    "    plt.xlabel('Feature Importance Score', fontproperties='Arial', fontsize=17)\n",
    "    plt.ylabel('Features', fontproperties='Arial', fontsize=17)\n",
    "    plt.xticks(fontsize=15)\n",
    "    plt.yticks(fontsize=15)\n",
    "    plt.title(\"Important Molecular Features\", fontproperties='Arial', fontsize=20)\n",
    "    sns.barplot(x=feature_imp, y=feature_imp.index)\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/XGB_TopFeatures.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    # Visualize the boxplot of the important features between the two groups\n",
    "    #fig = px.box(data_frame = df_ROI_for_ML_Opti, x = feature_imp[:10].index,color= 'type')\n",
    "    #fig.show()\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "02a72f17",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set F1: 0.9116094669891098\n",
      "Training Set MCC: 0.8264573962800329\n",
      "Training Set Accuracy: 0.9137093227792437\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92     47449\n",
      "           1       0.92      0.90      0.91     43511\n",
      "\n",
      "    accuracy                           0.91     90960\n",
      "   macro avg       0.91      0.91      0.91     90960\n",
      "weighted avg       0.91      0.91      0.91     90960\n",
      "\n",
      "[[44079  3370]\n",
      " [ 4479 39032]]\n",
      "Ext Val Set F1: 0.5429447705283154\n",
      "Ext Val Set MCC: -0.10022450676481336\n",
      "Ext Val Set Accuracy: 0.459917695473251\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.26      0.32      2943\n",
      "           1       0.48      0.65      0.55      3132\n",
      "\n",
      "    accuracy                           0.46      6075\n",
      "   macro avg       0.45      0.45      0.44      6075\n",
      "weighted avg       0.45      0.46      0.44      6075\n",
      "\n",
      "[[ 762 2181]\n",
      " [1100 2032]]\n",
      "5F-CV: 0.7011533620526068\n",
      "FNA Set F1: 0.5383865680391124\n",
      "FNA Set MCC: -0.1043884615145006\n",
      "FNA Set Recall: 0.6395462059283078\n",
      "FNA Test Set Accuracy: 0.45082919020078693\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.26      0.33     44540\n",
      "           1       0.46      0.64      0.54     44161\n",
      "\n",
      "    accuracy                           0.45     88701\n",
      "   macro avg       0.44      0.45      0.43     88701\n",
      "weighted avg       0.44      0.45      0.43     88701\n",
      "\n",
      "[[11746 32794]\n",
      " [15918 28243]]\n"
     ]
    }
   ],
   "source": [
    "coeff_GBM, TOPfeatures_GBM = GBM_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9edf4a32",
   "metadata": {},
   "source": [
    "### 3.3.4. Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9e7e60e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build stacking Model\n",
    "\n",
    "def Stacking_func(XTrain=X_train, XVal=X_val, XTest=X_FNA, XTest2=X_di, yTrain=y_train, yVal=y_val, yTest=y_FNA, yTest2=y_di):\n",
    "\n",
    "    base_learners = []\n",
    "\n",
    "    # Define models to use in stacking ensemble\n",
    "    m1 = LogisticRegression(C=0.001, penalty='l1', solver=\"liblinear\", max_iter=5000, random_state=42, class_weight={0:0.9628, 1:1.0402})\n",
    "    base_learners.append(m1)\n",
    "\n",
    "    m2 = LinearSVC(penalty='l2', loss=\"squared_hinge\", C=461, random_state=42, class_weight={0:0.9628, 1:1.0402})\n",
    "    base_learners.append(m2)\n",
    "\n",
    "    m3 = GradientBoostingClassifier(learning_rate=4, n_estimators=50, max_depth=7, min_samples_leaf=4, min_samples_split=30, n_iter_no_change=5, random_state=42)\n",
    "    base_learners.append(m3)\n",
    "\n",
    "    # Define the meta-classifier to use for stacking\n",
    "    meta_learner = LogisticRegression(C=0.0011, penalty='l1', solver=\"liblinear\", max_iter=5000, random_state=42)\n",
    "\n",
    "    model_sc = StackingRegressor([[m1, m2, m3], [meta_learner]])\n",
    "    model_sc.fit(XTrain, yTrain)\n",
    "    \n",
    "    #=======================================\n",
    "    \n",
    "    # Training Set\n",
    "    #plt.rcParams[\"figure.figsize\"] = (3,3)\n",
    "    X_train_predictions = model_sc.predict(X_train)[-1]\n",
    "    print(\"Training Set F1:\", f1_score(y_train, model_sc.predict(X_train)[-1], sample_weight=sampleW))\n",
    "    print(\"Training Set MCC:\", matthews_corrcoef(y_train, model_sc.predict(X_train)[-1], sample_weight=sampleW))\n",
    "    print(\"Training Set Accuracy:\", metrics.accuracy_score(y_train, X_train_predictions))\n",
    "    print(classification_report(y_train, X_train_predictions))\n",
    "    print(confusion_matrix(y_train, X_train_predictions))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr, tpr, _ = metrics.roc_curve(y_train, X_train_predictions)\n",
    "    plt.plot(fpr,tpr)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_train.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    # Val set\n",
    "    predictions_val  = model_sc.predict(XVal)[-1]\n",
    "    print(\"Ext Val Set F1:\", f1_score(yVal, model_sc.predict(XVal)[-1], sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set MCC:\", matthews_corrcoef(yVal, model_sc.predict(XVal)[-1], sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set Accuracy:\", metrics.accuracy_score(yVal, predictions_val))\n",
    "    print(classification_report(yVal, predictions_val))\n",
    "    print(confusion_matrix(yVal, predictions_val))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_val, tpr_val, _ = metrics.roc_curve(yVal, predictions_val)\n",
    "    plt.plot(fpr_val,tpr_val)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_test.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    #f1_5_train = cross_val_score(model_sc, XTrain, yTrain, cv = 5, scoring=\"f1\")\n",
    "    #print(\"5F-CV:\", avgScore(f1_5_train, 5))\n",
    "    \n",
    "    # Test set\n",
    "    predictions_FNA = model_sc.predict(XTest)[-1]\n",
    "    print(\"FNA Set F1:\", f1_score(yTest, model_sc.predict(XTest)[-1], sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set MCC:\", matthews_corrcoef(yTest, model_sc.predict(XTest)[-1], sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set Recall:\", recall_score(yTest, model_sc.predict(XTest)[-1]))\n",
    "    print(\"FNA Test Set Accuracy:\", metrics.accuracy_score(yTest, predictions_FNA))\n",
    "    print(classification_report(yTest, predictions_FNA))\n",
    "    print(confusion_matrix(yTest, predictions_FNA))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_FNA, tpr_FNA, _ = metrics.roc_curve(yTest, predictions_FNA)\n",
    "    plt.plot(fpr_FNA,tpr_FNA)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"G:/raMSIn/XGB_Importance2/XGB2_ROC_FNAtest2.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    # Test2 set\n",
    "    predictions_di = model_sc.predict(XTest2)[-1]\n",
    "    print(\"DirectIn Set F1:\", f1_score(yTest2, model_sc.predict(XTest2)[-1], sample_weight=sampleDiW))\n",
    "    print(\"DirectIn Set MCC:\", matthews_corrcoef(yTest2, model_sc.predict(XTest2)[-1], sample_weight=sampleDiW))\n",
    "    print(\"DirectIn Set Recall:\", recall_score(yTest2, model_sc.predict(XTest2)[-1]))\n",
    "    print(\"DirectIn Test Set Accuracy:\", metrics.accuracy_score(yTest2, predictions_di))\n",
    "    print(classification_report(yTest2, predictions_di))\n",
    "    print(confusion_matrix(yTest2, predictions_di))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_di, tpr_di, _ = metrics.roc_curve(yTest2, predictions_di)\n",
    "    plt.plot(fpr_di,tpr_di)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"G:/raMSIn/XGB_Importance2/XGB2_ROC_FNAtest2.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "53611a51",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set F1: 0.8679743714574002\n",
      "Training Set MCC: 0.7325277019110886\n",
      "Training Set Accuracy: 0.8655123131046614\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.85      0.87     47449\n",
      "           1       0.85      0.88      0.86     43511\n",
      "\n",
      "    accuracy                           0.87     90960\n",
      "   macro avg       0.87      0.87      0.87     90960\n",
      "weighted avg       0.87      0.87      0.87     90960\n",
      "\n",
      "[[40431  7018]\n",
      " [ 5215 38296]]\n",
      "Ext Val Set F1: 0.7513333464863904\n",
      "Ext Val Set MCC: 0.4810438528738775\n",
      "Ext Val Set Accuracy: 0.7409053497942387\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.69      0.72      2943\n",
      "           1       0.73      0.79      0.76      3132\n",
      "\n",
      "    accuracy                           0.74      6075\n",
      "   macro avg       0.74      0.74      0.74      6075\n",
      "weighted avg       0.74      0.74      0.74      6075\n",
      "\n",
      "[[2035  908]\n",
      " [ 666 2466]]\n",
      "FNA Set F1: 0.504465432926685\n",
      "FNA Set MCC: -0.019348083916839443\n",
      "FNA Set Recall: 0.5188288308688662\n",
      "FNA Test Set Accuracy: 0.49021995242443717\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.46      0.48     44540\n",
      "           1       0.49      0.52      0.50     44161\n",
      "\n",
      "    accuracy                           0.49     88701\n",
      "   macro avg       0.49      0.49      0.49     88701\n",
      "weighted avg       0.49      0.49      0.49     88701\n",
      "\n",
      "[[20571 23969]\n",
      " [21249 22912]]\n",
      "DirectIn Set F1: 0.6059184027198463\n",
      "DirectIn Set MCC: 0.2322921953419782\n",
      "DirectIn Set Recall: 0.5904290429042904\n",
      "DirectIn Test Set Accuracy: 0.6159815089978538\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.64      0.63      3027\n",
      "           1       0.62      0.59      0.61      3030\n",
      "\n",
      "    accuracy                           0.62      6057\n",
      "   macro avg       0.62      0.62      0.62      6057\n",
      "weighted avg       0.62      0.62      0.62      6057\n",
      "\n",
      "[[1942 1085]\n",
      " [1241 1789]]\n"
     ]
    }
   ],
   "source": [
    "Stacking_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81113c91",
   "metadata": {},
   "source": [
    "### 3.3.5. Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3de1f12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Voting_func(XTrain=X_train, XVal=X_val, XTest=X_FNA, XTest2=X_di, yTrain=y_train, yVal=y_val, yTest=y_FNA, yTest2=y_di):\n",
    "\n",
    "    models = get_models()\n",
    "    \n",
    "    ensemble = models[\"hard_voting\"]\n",
    "    ensemble.fit(XTrain, yTrain)\n",
    "    #=======================================\n",
    "\n",
    "    # Training Set\n",
    "    #plt.rcParams[\"figure.figsize\"] = (3,3)\n",
    "    X_train_predictions = ensemble.predict(X_train)\n",
    "    print(\"Training Set F1:\", f1_score(y_train, ensemble.predict(X_train), sample_weight=sampleW))\n",
    "    print(\"Training Set MCC:\", matthews_corrcoef(y_train, ensemble.predict(X_train), sample_weight=sampleW))\n",
    "    print(\"Training Set Accuracy:\", metrics.accuracy_score(y_train, X_train_predictions))\n",
    "    print(classification_report(y_train, X_train_predictions))\n",
    "    print(confusion_matrix(y_train, X_train_predictions))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr, tpr, _ = metrics.roc_curve(y_train, X_train_predictions)\n",
    "    plt.plot(fpr,tpr)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_train.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    # Val set\n",
    "    predictions_val  = ensemble.predict(XVal)\n",
    "    print(\"Ext Val Set F1:\", f1_score(yVal, ensemble.predict(XVal), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set MCC:\", matthews_corrcoef(yVal, ensemble.predict(XVal), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set Accuracy:\", metrics.accuracy_score(yVal, predictions_val))\n",
    "    print(classification_report(yVal, predictions_val))\n",
    "    print(confusion_matrix(yVal, predictions_val))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_val, tpr_val, _ = metrics.roc_curve(yVal, predictions_val)\n",
    "    plt.plot(fpr_val,tpr_val)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_test.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    f1_5_train = cross_val_score(ensemble, XTrain, yTrain, cv = 5, scoring=\"f1\")\n",
    "    print(\"5F-CV:\", avgScore(f1_5_train, 5))\n",
    "\n",
    "    # Test set\n",
    "    predictions_FNA = ensemble.predict(XTest)\n",
    "    print(\"FNA Set F1:\", f1_score(yTest, ensemble.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set MCC:\", matthews_corrcoef(yTest, ensemble.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set Recall:\", recall_score(yTest, ensemble.predict(XTest)))\n",
    "    print(\"FNA Test Set Accuracy:\", metrics.accuracy_score(yTest, predictions_FNA))\n",
    "    print(classification_report(yTest, predictions_FNA))\n",
    "    print(confusion_matrix(yTest, predictions_FNA))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_FNA, tpr_FNA, _ = metrics.roc_curve(yTest, predictions_FNA)\n",
    "    plt.plot(fpr_FNA,tpr_FNA)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"G:/raMSIn/XGB_Importance2/XGB2_ROC_FNAtest2.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    # Test2 set\n",
    "    predictions_di = ensemble.predict(XTest2)\n",
    "    print(\"DirectIn Set F1:\", f1_score(yTest2, ensemble.predict(XTest2), sample_weight=sampleDiW))\n",
    "    print(\"DirectIn Set MCC:\", matthews_corrcoef(yTest2, ensemble.predict(XTest2), sample_weight=sampleDiW))\n",
    "    print(\"DirectIn Set Recall:\", recall_score(yTest2, ensemble.predict(XTest2)))\n",
    "    print(\"DirectIn Test Set Accuracy:\", metrics.accuracy_score(yTest2, predictions_di))\n",
    "    print(classification_report(yTest2, predictions_di))\n",
    "    print(confusion_matrix(yTest2, predictions_di))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_di, tpr_di, _ = metrics.roc_curve(yTest2, predictions_di)\n",
    "    plt.plot(fpr_di,tpr_di)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"G:/raMSIn/XGB_Importance2/XGB2_ROC_FNAtest2.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "becdb109",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set F1: 0.9355460815781772\n",
      "Training Set MCC: 0.8691645398438659\n",
      "Training Set Accuracy: 0.933311345646438\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.91      0.93     47449\n",
      "           1       0.91      0.95      0.93     43511\n",
      "\n",
      "    accuracy                           0.93     90960\n",
      "   macro avg       0.93      0.93      0.93     90960\n",
      "weighted avg       0.93      0.93      0.93     90960\n",
      "\n",
      "[[43344  4105]\n",
      " [ 1961 41550]]\n",
      "Ext Val Set F1: 0.6556326378591221\n",
      "Ext Val Set MCC: 0.13720601034775723\n",
      "Ext Val Set Accuracy: 0.5649382716049383\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.27      0.37      2943\n",
      "           1       0.55      0.85      0.67      3132\n",
      "\n",
      "    accuracy                           0.56      6075\n",
      "   macro avg       0.58      0.56      0.52      6075\n",
      "weighted avg       0.58      0.56      0.52      6075\n",
      "\n",
      "[[ 784 2159]\n",
      " [ 484 2648]]\n",
      "5F-CV: 0.8703850133423877\n",
      "FNA Set F1: 0.6041353313042247\n",
      "FNA Set MCC: 0.07539270771473425\n",
      "FNA Set Recall: 0.7090872036412219\n",
      "FNA Test Set Accuracy: 0.534605021363908\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.36      0.44     44540\n",
      "           1       0.52      0.71      0.60     44161\n",
      "\n",
      "    accuracy                           0.53     88701\n",
      "   macro avg       0.54      0.54      0.52     88701\n",
      "weighted avg       0.54      0.53      0.52     88701\n",
      "\n",
      "[[16106 28434]\n",
      " [12847 31314]]\n",
      "DirectIn Set F1: 0.612250565281374\n",
      "DirectIn Set MCC: 0.1942378261990255\n",
      "DirectIn Set Recall: 0.6366336633663366\n",
      "DirectIn Test Set Accuracy: 0.5968301139177811\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.56      0.58      3027\n",
      "           1       0.59      0.64      0.61      3030\n",
      "\n",
      "    accuracy                           0.60      6057\n",
      "   macro avg       0.60      0.60      0.60      6057\n",
      "weighted avg       0.60      0.60      0.60      6057\n",
      "\n",
      "[[1686 1341]\n",
      " [1101 1929]]\n"
     ]
    }
   ],
   "source": [
    "Voting_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08fd62e",
   "metadata": {},
   "source": [
    "## 3.4 Machine Learning Modeling: Model 2 (Train 4:4, Val 6:6, Test 3:3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961246f0",
   "metadata": {},
   "source": [
    "### 3.4.1. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "99086aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build Logistic Regression Model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def LogisticRegression_func(XTrain=X_val, XVal=X_train, XTest=X_FNA, yTrain=y_val, yVal=y_train, yTest=y_FNA):\n",
    "    model_lr = LogisticRegression(C=0.001, penalty='l1', solver=\"liblinear\", max_iter=5000, random_state=42, class_weight={0:0.9628, 1:1.0402})  # max_iter=100\n",
    "    model_lr.fit(XTrain,yTrain)\n",
    "    \n",
    "    # Training Set\n",
    "    #plt.rcParams[\"figure.figsize\"] = (3,3)\n",
    "    X_train_predictions = model_lr.predict(XVal)\n",
    "    print(\"Training Set F1:\", f1_score(yVal, model_lr.predict(XVal), sample_weight=sampleW))\n",
    "    print(\"Training Set MCC:\", matthews_corrcoef(yVal, model_lr.predict(XVal), sample_weight=sampleW))\n",
    "    print(\"Training Set Accuracy:\", metrics.accuracy_score(yVal, X_train_predictions))\n",
    "    print(classification_report(yVal, X_train_predictions))\n",
    "    print(confusion_matrix(yVal, X_train_predictions))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr, tpr, _ = metrics.roc_curve(yVal, X_train_predictions)\n",
    "    plt.plot(fpr,tpr)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_train.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    # Val set\n",
    "    predictions_val  = model_lr.predict(XTrain)\n",
    "    print(\"Ext Val Set F1:\", f1_score(yTrain, model_lr.predict(XTrain), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set MCC:\", matthews_corrcoef(yTrain, model_lr.predict(XTrain), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set Accuracy:\", metrics.accuracy_score(yTrain, predictions_val))\n",
    "    print(classification_report(yTrain, predictions_val))\n",
    "    print(confusion_matrix(yTrain, predictions_val))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_val, tpr_val, _ = metrics.roc_curve(yTrain, predictions_val)\n",
    "    plt.plot(fpr_val,tpr_val)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_test.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    f1_5_train = cross_val_score(model_lr, XTrain, yTrain, cv = 5, scoring=\"f1\")\n",
    "    print(\"5F-CV:\", avgScore(f1_5_train, 5))\n",
    "    \n",
    "    # Test set\n",
    "    predictions_FNA = model_lr.predict(XTest)\n",
    "    print(\"FNA Set F1:\", f1_score(yTest, model_lr.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set MCC:\", matthews_corrcoef(yTest, model_lr.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set Recall:\", recall_score(yTest, model_lr.predict(XTest)))\n",
    "    print(\"FNA Test Set Accuracy:\", metrics.accuracy_score(yTest, predictions_FNA))\n",
    "    print(classification_report(yTest, predictions_FNA))\n",
    "    print(confusion_matrix(yTest, predictions_FNA))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_FNA, tpr_FNA, _ = metrics.roc_curve(yTest, predictions_FNA)\n",
    "    plt.plot(fpr_FNA,tpr_FNA)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"G:/raMSIn/XGB_Importance2/XGB2_ROC_FNAtest2.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    # Visualize the importantance of the features\n",
    "    feature_imp = pd.Series(model_lr.coef_[0], index=XTrain.columns).sort_values(ascending=False)\n",
    "    x=feature_imp\n",
    "    y=feature_imp.index\n",
    "    \n",
    "    plt.subplots(dpi = 300)\n",
    "    #plt.rcParams[\"figure.figsize\"] = [4, 6]\n",
    "    #plt.rcParams[\"font.family\"] = \"Arial\"\n",
    "    #plt.rcParams.update({'font.size': 6})\n",
    "    plt.xlabel('Feature Importance Score', fontproperties='Arial', fontsize=17)\n",
    "    plt.ylabel('Features', fontproperties='Arial', fontsize=17)\n",
    "    plt.xticks(fontsize=15)\n",
    "    plt.yticks(fontsize=15)\n",
    "    plt.title(\"Important Molecular Features\", fontproperties='Arial', fontsize=20)\n",
    "    sns.barplot(x=feature_imp, y=feature_imp.index)\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_TopFeatures.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    #feature_importances = model_lr.coef_[0]\n",
    "    #feature_df=pd.DataFrame({'m/z':XTrain.columns,'coef':feature_importances})\n",
    "\n",
    "    #fig = px.bar(feature_df, x='coef', y='m/z')\n",
    "    #fig.show()\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ff504fe8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set F1: 0.0\n",
      "Training Set MCC: 0.0\n",
      "Training Set Accuracy: 0.5216468777484609\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      1.00      0.69     47449\n",
      "           1       0.00      0.00      0.00     43511\n",
      "\n",
      "    accuracy                           0.52     90960\n",
      "   macro avg       0.26      0.50      0.34     90960\n",
      "weighted avg       0.27      0.52      0.36     90960\n",
      "\n",
      "[[47449     0]\n",
      " [43511     0]]\n",
      "Ext Val Set F1: 0.0\n",
      "Ext Val Set MCC: 0.0\n",
      "Ext Val Set Accuracy: 0.48444444444444446\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      1.00      0.65      2943\n",
      "           1       0.00      0.00      0.00      3132\n",
      "\n",
      "    accuracy                           0.48      6075\n",
      "   macro avg       0.24      0.50      0.33      6075\n",
      "weighted avg       0.23      0.48      0.32      6075\n",
      "\n",
      "[[2943    0]\n",
      " [3132    0]]\n",
      "5F-CV: 0.0\n",
      "FNA Set F1: 0.0\n",
      "FNA Set MCC: 0.0\n",
      "FNA Set Recall: 0.0\n",
      "FNA Test Set Accuracy: 0.5021363907960451\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67     44540\n",
      "           1       0.00      0.00      0.00     44161\n",
      "\n",
      "    accuracy                           0.50     88701\n",
      "   macro avg       0.25      0.50      0.33     88701\n",
      "weighted avg       0.25      0.50      0.34     88701\n",
      "\n",
      "[[44540     0]\n",
      " [44161     0]]\n"
     ]
    }
   ],
   "source": [
    "coeff_LogReg, TOPfeatures_LogReg = LogisticRegression_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a040e5",
   "metadata": {},
   "source": [
    "### 3.4.2. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ae3652ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build LinearSVC Model\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "def LinearSVC_func(XTrain=X_val, XVal=X_train, XTest=X_FNA, yTrain=y_val, yVal=y_train, yTest=y_FNA):\n",
    "    model_svm = LinearSVC(penalty='l2', loss=\"squared_hinge\", C=461, random_state=42, class_weight={0:0.9628, 1:1.0402})\n",
    "    model_svm.fit(XTrain,yTrain)\n",
    "    \n",
    "    # Training Set\n",
    "    #plt.rcParams[\"figure.figsize\"] = (3,3)\n",
    "    X_train_predictions = model_svm.predict(XVal)\n",
    "    print(\"Training Set F1:\", f1_score(yVal, model_svm.predict(XVal), sample_weight=sampleW))\n",
    "    print(\"Training Set MCC:\", matthews_corrcoef(yVal, model_svm.predict(XVal), sample_weight=sampleW))\n",
    "    print(\"Training Set Accuracy:\", metrics.accuracy_score(yVal, X_train_predictions))\n",
    "    print(classification_report(yVal, X_train_predictions))\n",
    "    print(confusion_matrix(yVal, X_train_predictions))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr, tpr, _ = metrics.roc_curve(yVal, X_train_predictions)\n",
    "    plt.plot(fpr,tpr)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_train.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    # Val set\n",
    "    predictions_val  = model_svm.predict(XTrain)\n",
    "    print(\"Ext Val Set F1:\", f1_score(yTrain, model_svm.predict(XTrain), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set MCC:\", matthews_corrcoef(yTrain, model_svm.predict(XTrain), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set Accuracy:\", metrics.accuracy_score(yTrain, predictions_val))\n",
    "    print(classification_report(yTrain, predictions_val))\n",
    "    print(confusion_matrix(yTrain, predictions_val))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_val, tpr_val, _ = metrics.roc_curve(yTrain, predictions_val)\n",
    "    plt.plot(fpr_val,tpr_val)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_test.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    f1_5_train = cross_val_score(model_svm, XTrain, yTrain, cv = 5, scoring=\"f1\")\n",
    "    print(\"5F-CV:\", avgScore(f1_5_train, 5))\n",
    "    \n",
    "    # Test set\n",
    "    predictions_FNA = model_svm.predict(XTest)\n",
    "    print(\"FNA Set F1:\", f1_score(yTest, model_svm.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set MCC:\", matthews_corrcoef(yTest, model_svm.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set Recall:\", recall_score(yTest, model_svm.predict(XTest)))\n",
    "    print(\"FNA Test Set Accuracy:\", metrics.accuracy_score(yTest, predictions_FNA))\n",
    "    print(classification_report(yTest, predictions_FNA))\n",
    "    print(confusion_matrix(yTest, predictions_FNA))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_FNA, tpr_FNA, _ = metrics.roc_curve(yTest, predictions_FNA)\n",
    "    plt.plot(fpr_FNA,tpr_FNA)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"G:/raMSIn/XGB_Importance2/XGB2_ROC_FNAtest2.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    # Visualize the importantance of the features\n",
    "    feature_imp = pd.Series(model_svm.coef_[0], index=XTrain.columns).sort_values(ascending=False)\n",
    "    x=feature_imp\n",
    "    y=feature_imp.index\n",
    "    \n",
    "    plt.subplots(dpi = 300)\n",
    "    #plt.rcParams[\"figure.figsize\"] = [4, 6]\n",
    "    #plt.rcParams[\"font.family\"] = \"Arial\"\n",
    "    #plt.rcParams.update({'font.size': 6})\n",
    "    plt.xlabel('Feature Importance Score', fontproperties='Arial', fontsize=17)\n",
    "    plt.ylabel('Features', fontproperties='Arial', fontsize=17)\n",
    "    plt.xticks(fontsize=15)\n",
    "    plt.yticks(fontsize=15)\n",
    "    plt.title(\"Important Molecular Features\", fontproperties='Arial', fontsize=20)\n",
    "    sns.barplot(x=feature_imp, y=feature_imp.index)\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_TopFeatures.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    #feature_importances = model_svm.coef_[0]\n",
    "    #feature_df=pd.DataFrame({'m/z':XTrain.columns,'coef':feature_importances})\n",
    "\n",
    "    #fig = px.bar(feature_df, x='coef', y='m/z')\n",
    "    #fig.show()\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8936e108",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set F1: 0.5866180873263486\n",
      "Training Set MCC: 0.06628913385384579\n",
      "Training Set Accuracy: 0.5262423043095866\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.40      0.47     47449\n",
      "           1       0.50      0.66      0.57     43511\n",
      "\n",
      "    accuracy                           0.53     90960\n",
      "   macro avg       0.53      0.53      0.52     90960\n",
      "weighted avg       0.54      0.53      0.52     90960\n",
      "\n",
      "[[18969 28480]\n",
      " [14613 28898]]\n",
      "Ext Val Set F1: 0.951638273857085\n",
      "Ext Val Set MCC: 0.9071510023599009\n",
      "Ext Val Set Accuracy: 0.9520987654320988\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.95      2943\n",
      "           1       0.98      0.93      0.95      3132\n",
      "\n",
      "    accuracy                           0.95      6075\n",
      "   macro avg       0.95      0.95      0.95      6075\n",
      "weighted avg       0.95      0.95      0.95      6075\n",
      "\n",
      "[[2883   60]\n",
      " [ 231 2901]]\n",
      "5F-CV: 0.8891078535936563\n",
      "FNA Set F1: 0.4526933824725116\n",
      "FNA Set MCC: -0.1964564182796874\n",
      "FNA Set Recall: 0.49346708634315345\n",
      "FNA Test Set Accuracy: 0.40299432926348067\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.31      0.35     44540\n",
      "           1       0.42      0.49      0.45     44161\n",
      "\n",
      "    accuracy                           0.40     88701\n",
      "   macro avg       0.40      0.40      0.40     88701\n",
      "weighted avg       0.40      0.40      0.40     88701\n",
      "\n",
      "[[13954 30586]\n",
      " [22369 21792]]\n"
     ]
    }
   ],
   "source": [
    "coeff_SVM, TOPfeatures_SVM = LinearSVC_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d25a8aa",
   "metadata": {},
   "source": [
    "### 3.4.3. GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0bf777fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build GBM Model\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "def GBM_func(XTrain=X_val, XVal=X_train, XTest=X_FNA, yTrain=y_val, yVal=y_train, yTest=y_FNA):\n",
    "    model_gbm = GradientBoostingClassifier(learning_rate=4, n_estimators=50, max_depth=7, min_samples_leaf=4, min_samples_split=30, n_iter_no_change=5, random_state=42)\n",
    "    model_gbm.fit(XTrain,yTrain)\n",
    "    \n",
    "    # Training Set\n",
    "    #plt.rcParams[\"figure.figsize\"] = (3,3)\n",
    "    X_train_predictions = model_gbm.predict(XVal)\n",
    "    print(\"Training Set F1:\", f1_score(yVal, model_gbm.predict(XVal), sample_weight=sampleW))\n",
    "    print(\"Training Set MCC:\", matthews_corrcoef(yVal, model_gbm.predict(XVal), sample_weight=sampleW))\n",
    "    print(\"Training Set Accuracy:\", metrics.accuracy_score(yVal, X_train_predictions))\n",
    "    print(classification_report(yVal, X_train_predictions))\n",
    "    print(confusion_matrix(yVal, X_train_predictions))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr, tpr, _ = metrics.roc_curve(yVal, X_train_predictions)\n",
    "    plt.plot(fpr,tpr)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_train.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    # Val set\n",
    "    predictions_val  = model_gbm.predict(XTrain)\n",
    "    print(\"Ext Val Set F1:\", f1_score(yTrain, model_gbm.predict(XTrain), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set MCC:\", matthews_corrcoef(yTrain, model_gbm.predict(XTrain), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set Accuracy:\", metrics.accuracy_score(yTrain, predictions_val))\n",
    "    print(classification_report(yTrain, predictions_val))\n",
    "    print(confusion_matrix(yTrain, predictions_val))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_val, tpr_val, _ = metrics.roc_curve(yTrain, predictions_val)\n",
    "    plt.plot(fpr_val,tpr_val)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_test.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    f1_5_train = cross_val_score(model_gbm, XTrain, yTrain, cv = 5, scoring=\"f1\")\n",
    "    print(\"5F-CV:\", avgScore(f1_5_train, 5))\n",
    "    \n",
    "    # Test set\n",
    "    predictions_FNA = model_gbm.predict(XTest)\n",
    "    print(\"FNA Set F1:\", f1_score(yTest, model_gbm.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set MCC:\", matthews_corrcoef(yTest, model_gbm.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set Recall:\", recall_score(yTest, model_gbm.predict(XTest)))\n",
    "    print(\"FNA Test Set Accuracy:\", metrics.accuracy_score(yTest, predictions_FNA))\n",
    "    print(classification_report(yTest, predictions_FNA))\n",
    "    print(confusion_matrix(yTest, predictions_FNA))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_FNA, tpr_FNA, _ = metrics.roc_curve(yTest, predictions_FNA)\n",
    "    plt.plot(fpr_FNA,tpr_FNA)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"G:/raMSIn/XGB_Importance2/XGB2_ROC_FNAtest2.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    # Visualize the importantance of the features\n",
    "    feature_imp = pd.Series(model_gbm.feature_importances_, index=XTrain.columns).sort_values(ascending=False)\n",
    "    x=feature_imp\n",
    "    y=feature_imp.index\n",
    "    \n",
    "    plt.subplots(dpi = 300)\n",
    "    #plt.rcParams[\"figure.figsize\"] = [4, 6]\n",
    "    #plt.rcParams[\"font.family\"] = \"Arial\"\n",
    "    #plt.rcParams.update({'font.size': 6})\n",
    "    plt.xlabel('Feature Importance Score', fontproperties='Arial', fontsize=17)\n",
    "    plt.ylabel('Features', fontproperties='Arial', fontsize=17)\n",
    "    plt.xticks(fontsize=15)\n",
    "    plt.yticks(fontsize=15)\n",
    "    plt.title(\"Important Molecular Features\", fontproperties='Arial', fontsize=20)\n",
    "    sns.barplot(x=feature_imp, y=feature_imp.index)\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/XGB_TopFeatures.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    # Visualize the boxplot of the important features between the two groups\n",
    "    #fig = px.box(data_frame = df_ROI_for_ML_Opti, x = feature_imp[:10].index,color= 'type')\n",
    "    #fig.show()\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "58c5dcd8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set F1: 0.7040687007871267\n",
      "Training Set MCC: 0.3693306154115578\n",
      "Training Set Accuracy: 0.6796174142480211\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.61      0.67     47449\n",
      "           1       0.64      0.75      0.69     43511\n",
      "\n",
      "    accuracy                           0.68     90960\n",
      "   macro avg       0.69      0.68      0.68     90960\n",
      "weighted avg       0.69      0.68      0.68     90960\n",
      "\n",
      "[[28976 18473]\n",
      " [10669 32842]]\n",
      "Ext Val Set F1: 0.8843151945524823\n",
      "Ext Val Set MCC: 0.7602080949794748\n",
      "Ext Val Set Accuracy: 0.8791769547325103\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.82      0.87      2943\n",
      "           1       0.84      0.94      0.89      3132\n",
      "\n",
      "    accuracy                           0.88      6075\n",
      "   macro avg       0.89      0.88      0.88      6075\n",
      "weighted avg       0.88      0.88      0.88      6075\n",
      "\n",
      "[[2403  540]\n",
      " [ 194 2938]]\n",
      "5F-CV: 0.6155215625599894\n",
      "FNA Set F1: 0.6301864421122367\n",
      "FNA Set MCC: 0.21064271579608243\n",
      "FNA Set Recall: 0.6743053825773873\n",
      "FNA Test Set Accuracy: 0.6039841715425982\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.53      0.58     44540\n",
      "           1       0.59      0.67      0.63     44161\n",
      "\n",
      "    accuracy                           0.60     88701\n",
      "   macro avg       0.61      0.60      0.60     88701\n",
      "weighted avg       0.61      0.60      0.60     88701\n",
      "\n",
      "[[23796 20744]\n",
      " [14383 29778]]\n"
     ]
    }
   ],
   "source": [
    "coeff_GBM, TOPfeatures_GBM = GBM_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c276f472",
   "metadata": {},
   "source": [
    "### 3.4.4. Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b940433a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build stacking Model\n",
    "\n",
    "def Stacking_func(XTrain=X_val, XVal=X_train, XTest=X_FNA, XTest2=X_di, yTrain=y_val, yVal=y_train, yTest=y_FNA, yTest2=y_di):\n",
    "\n",
    "    base_learners = []\n",
    "\n",
    "    # Define models to use in stacking ensemble\n",
    "    m1 = LogisticRegression(C=0.001, penalty='l1', solver=\"liblinear\", max_iter=5000, random_state=42, class_weight={0:0.9628, 1:1.0402})\n",
    "    base_learners.append(m1)\n",
    "\n",
    "    m2 = LinearSVC(penalty='l2', loss=\"squared_hinge\", C=461, random_state=42, class_weight={0:0.9628, 1:1.0402})\n",
    "    base_learners.append(m2)\n",
    "\n",
    "    m3 = GradientBoostingClassifier(learning_rate=4, n_estimators=50, max_depth=7, min_samples_leaf=4, min_samples_split=30, n_iter_no_change=5, random_state=42)\n",
    "    base_learners.append(m3)\n",
    "\n",
    "    # Define the meta-classifier to use for stacking\n",
    "    meta_learner = LogisticRegression(C=0.0011, penalty='l1', solver=\"liblinear\", max_iter=5000, random_state=42)\n",
    "\n",
    "    model_sc = StackingRegressor([[m1, m2, m3], [meta_learner]])\n",
    "    model_sc.fit(XTrain, yTrain)\n",
    "    \n",
    "    #=======================================\n",
    "    \n",
    "    # Training Set\n",
    "    #plt.rcParams[\"figure.figsize\"] = (3,3)\n",
    "    X_train_predictions = model_sc.predict(XVal)[-1]\n",
    "    print(\"Training Set F1:\", f1_score(yVal, model_sc.predict(XVal)[-1], sample_weight=sampleW))\n",
    "    print(\"Training Set MCC:\", matthews_corrcoef(yVal, model_sc.predict(XVal)[-1], sample_weight=sampleW))\n",
    "    print(\"Training Set Accuracy:\", metrics.accuracy_score(yVal, X_train_predictions))\n",
    "    print(classification_report(yVal, X_train_predictions))\n",
    "    print(confusion_matrix(yVal, X_train_predictions))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr, tpr, _ = metrics.roc_curve(yVal, X_train_predictions)\n",
    "    plt.plot(fpr,tpr)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_train.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    # Val set\n",
    "    predictions_val  = model_sc.predict(XTrain)[-1]\n",
    "    print(\"Ext Val Set F1:\", f1_score(yTrain, model_sc.predict(XTrain)[-1], sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set MCC:\", matthews_corrcoef(yTrain, model_sc.predict(XTrain)[-1], sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set Accuracy:\", metrics.accuracy_score(yTrain, predictions_val))\n",
    "    print(classification_report(yTrain, predictions_val))\n",
    "    print(confusion_matrix(yTrain, predictions_val))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_val, tpr_val, _ = metrics.roc_curve(yTrain, predictions_val)\n",
    "    plt.plot(fpr_val,tpr_val)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_test.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    #f1_5_train = cross_val_score(model_sc, XTrain, yTrain, cv = 5, scoring=\"f1\")\n",
    "    #print(\"5F-CV:\", avgScore(f1_5_train, 5))\n",
    "    \n",
    "    # Test set\n",
    "    predictions_FNA = model_sc.predict(XTest)[-1]\n",
    "    print(\"FNA Set F1:\", f1_score(yTest, model_sc.predict(XTest)[-1], sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set MCC:\", matthews_corrcoef(yTest, model_sc.predict(XTest)[-1], sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set Recall:\", recall_score(yTest, model_sc.predict(XTest)[-1]))\n",
    "    print(\"FNA Test Set Accuracy:\", metrics.accuracy_score(yTest, predictions_FNA))\n",
    "    print(classification_report(yTest, predictions_FNA))\n",
    "    print(confusion_matrix(yTest, predictions_FNA))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_FNA, tpr_FNA, _ = metrics.roc_curve(yTest, predictions_FNA)\n",
    "    plt.plot(fpr_FNA,tpr_FNA)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"G:/raMSIn/XGB_Importance2/XGB2_ROC_FNAtest2.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    # Test2 set\n",
    "    predictions_di = model_sc.predict(XTest2)[-1]\n",
    "    print(\"DirectIn Set F1:\", f1_score(yTest2, model_sc.predict(XTest2)[-1], sample_weight=sampleDiW))\n",
    "    print(\"DirectIn Set MCC:\", matthews_corrcoef(yTest2, model_sc.predict(XTest2)[-1], sample_weight=sampleDiW))\n",
    "    print(\"DirectIn Set Recall:\", recall_score(yTest2, model_sc.predict(XTest2)[-1]))\n",
    "    print(\"DirectIn Test Set Accuracy:\", metrics.accuracy_score(yTest2, predictions_di))\n",
    "    print(classification_report(yTest2, predictions_di))\n",
    "    print(confusion_matrix(yTest2, predictions_di))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_di, tpr_di, _ = metrics.roc_curve(yTest2, predictions_di)\n",
    "    plt.plot(fpr_di,tpr_di)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"G:/raMSIn/XGB_Importance2/XGB2_ROC_FNAtest2.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "74cbb345",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set F1: 0.0\n",
      "Training Set MCC: 0.0\n",
      "Training Set Accuracy: 0.5216468777484609\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      1.00      0.69     47449\n",
      "           1       0.00      0.00      0.00     43511\n",
      "\n",
      "    accuracy                           0.52     90960\n",
      "   macro avg       0.26      0.50      0.34     90960\n",
      "weighted avg       0.27      0.52      0.36     90960\n",
      "\n",
      "[[47449     0]\n",
      " [43511     0]]\n",
      "Ext Val Set F1: 0.0\n",
      "Ext Val Set MCC: 0.0\n",
      "Ext Val Set Accuracy: 0.48444444444444446\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      1.00      0.65      2943\n",
      "           1       0.00      0.00      0.00      3132\n",
      "\n",
      "    accuracy                           0.48      6075\n",
      "   macro avg       0.24      0.50      0.33      6075\n",
      "weighted avg       0.23      0.48      0.32      6075\n",
      "\n",
      "[[2943    0]\n",
      " [3132    0]]\n",
      "FNA Set F1: 0.0\n",
      "FNA Set MCC: 0.0\n",
      "FNA Set Recall: 0.0\n",
      "FNA Test Set Accuracy: 0.5021363907960451\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67     44540\n",
      "           1       0.00      0.00      0.00     44161\n",
      "\n",
      "    accuracy                           0.50     88701\n",
      "   macro avg       0.25      0.50      0.33     88701\n",
      "weighted avg       0.25      0.50      0.34     88701\n",
      "\n",
      "[[44540     0]\n",
      " [44161     0]]\n",
      "DirectIn Set F1: 0.0\n",
      "DirectIn Set MCC: 0.0\n",
      "DirectIn Set Recall: 0.0\n",
      "DirectIn Test Set Accuracy: 0.49975235264982665\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67      3027\n",
      "           1       0.00      0.00      0.00      3030\n",
      "\n",
      "    accuracy                           0.50      6057\n",
      "   macro avg       0.25      0.50      0.33      6057\n",
      "weighted avg       0.25      0.50      0.33      6057\n",
      "\n",
      "[[3027    0]\n",
      " [3030    0]]\n"
     ]
    }
   ],
   "source": [
    "Stacking_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b896917b",
   "metadata": {},
   "source": [
    "### 3.4.5. Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d03a0a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Voting_func(XTrain=X_val, XVal=X_train, XTest=X_FNA, XTest2=X_di, yTrain=y_val, yVal=y_train, yTest=y_FNA, yTest2=y_di):\n",
    "\n",
    "    models = get_models()\n",
    "    \n",
    "    ensemble = models[\"hard_voting\"]\n",
    "    ensemble.fit(XTrain, yTrain)\n",
    "    #=======================================\n",
    "\n",
    "    # Training Set\n",
    "    #plt.rcParams[\"figure.figsize\"] = (3,3)\n",
    "    X_train_predictions = ensemble.predict(XVal)\n",
    "    print(\"Training Set F1:\", f1_score(yVal, ensemble.predict(XVal), sample_weight=sampleW))\n",
    "    print(\"Training Set MCC:\", matthews_corrcoef(yVal, ensemble.predict(XVal), sample_weight=sampleW))\n",
    "    print(\"Training Set Accuracy:\", metrics.accuracy_score(yVal, X_train_predictions))\n",
    "    print(classification_report(yVal, X_train_predictions))\n",
    "    print(confusion_matrix(yVal, X_train_predictions))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr, tpr, _ = metrics.roc_curve(yVal, X_train_predictions)\n",
    "    plt.plot(fpr,tpr)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_train.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    # Val set\n",
    "    predictions_val  = ensemble.predict(XTrain)\n",
    "    print(\"Ext Val Set F1:\", f1_score(yTrain, ensemble.predict(XTrain), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set MCC:\", matthews_corrcoef(yTrain, ensemble.predict(XTrain), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set Accuracy:\", metrics.accuracy_score(yTrain, predictions_val))\n",
    "    print(classification_report(yTrain, predictions_val))\n",
    "    print(confusion_matrix(yTrain, predictions_val))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_val, tpr_val, _ = metrics.roc_curve(yTrain, predictions_val)\n",
    "    plt.plot(fpr_val,tpr_val)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_test.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    f1_5_train = cross_val_score(ensemble, XTrain, yTrain, cv = 5, scoring=\"f1\")\n",
    "    print(\"5F-CV:\", avgScore(f1_5_train, 5))\n",
    "\n",
    "    # Test set\n",
    "    predictions_FNA = ensemble.predict(XTest)\n",
    "    print(\"FNA Set F1:\", f1_score(yTest, ensemble.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set MCC:\", matthews_corrcoef(yTest, ensemble.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set Recall:\", recall_score(yTest, ensemble.predict(XTest)))\n",
    "    print(\"FNA Test Set Accuracy:\", metrics.accuracy_score(yTest, predictions_FNA))\n",
    "    print(classification_report(yTest, predictions_FNA))\n",
    "    print(confusion_matrix(yTest, predictions_FNA))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_FNA, tpr_FNA, _ = metrics.roc_curve(yTest, predictions_FNA)\n",
    "    plt.plot(fpr_FNA,tpr_FNA)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"G:/raMSIn/XGB_Importance2/XGB2_ROC_FNAtest2.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    # Test2 set\n",
    "    predictions_di = ensemble.predict(XTest2)\n",
    "    print(\"DirectIn Set F1:\", f1_score(yTest2, ensemble.predict(XTest2), sample_weight=sampleDiW))\n",
    "    print(\"DirectIn Set MCC:\", matthews_corrcoef(yTest2, ensemble.predict(XTest2), sample_weight=sampleDiW))\n",
    "    print(\"DirectIn Set Recall:\", recall_score(yTest2, ensemble.predict(XTest2)))\n",
    "    print(\"DirectIn Test Set Accuracy:\", metrics.accuracy_score(yTest2, predictions_di))\n",
    "    print(classification_report(yTest2, predictions_di))\n",
    "    print(confusion_matrix(yTest2, predictions_di))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_di, tpr_di, _ = metrics.roc_curve(yTest2, predictions_di)\n",
    "    plt.plot(fpr_di,tpr_di)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"G:/raMSIn/XGB_Importance2/XGB2_ROC_FNAtest2.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2e1865ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set F1: 0.5785390636495318\n",
      "Training Set MCC: 0.2721761428655857\n",
      "Training Set Accuracy: 0.6371481970096746\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.76      0.69     47449\n",
      "           1       0.66      0.51      0.57     43511\n",
      "\n",
      "    accuracy                           0.64     90960\n",
      "   macro avg       0.64      0.63      0.63     90960\n",
      "weighted avg       0.64      0.64      0.63     90960\n",
      "\n",
      "[[35957 11492]\n",
      " [21513 21998]]\n",
      "Ext Val Set F1: 0.9310661601937893\n",
      "Ext Val Set MCC: 0.8752227341100146\n",
      "Ext Val Set Accuracy: 0.9331687242798354\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.93      2943\n",
      "           1       0.99      0.88      0.93      3132\n",
      "\n",
      "    accuracy                           0.93      6075\n",
      "   macro avg       0.94      0.93      0.93      6075\n",
      "weighted avg       0.94      0.93      0.93      6075\n",
      "\n",
      "[[2915   28]\n",
      " [ 378 2754]]\n",
      "5F-CV: 0.6234347986181539\n",
      "FNA Set F1: 0.4585361994802933\n",
      "FNA Set MCC: 0.09089681935783171\n",
      "FNA Set Recall: 0.3868571816761396\n",
      "FNA Test Set Accuracy: 0.5438382881816439\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.70      0.61     44540\n",
      "           1       0.56      0.39      0.46     44161\n",
      "\n",
      "    accuracy                           0.54     88701\n",
      "   macro avg       0.55      0.54      0.53     88701\n",
      "weighted avg       0.55      0.54      0.53     88701\n",
      "\n",
      "[[31155 13385]\n",
      " [27077 17084]]\n",
      "DirectIn Set F1: 0.5417367359850558\n",
      "DirectIn Set MCC: 0.23314766068444623\n",
      "DirectIn Set Recall: 0.45973597359735974\n",
      "DirectIn Test Set Accuracy: 0.6110285619943867\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.76      0.66      3027\n",
      "           1       0.66      0.46      0.54      3030\n",
      "\n",
      "    accuracy                           0.61      6057\n",
      "   macro avg       0.62      0.61      0.60      6057\n",
      "weighted avg       0.62      0.61      0.60      6057\n",
      "\n",
      "[[2308  719]\n",
      " [1637 1393]]\n"
     ]
    }
   ],
   "source": [
    "Voting_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a613c4",
   "metadata": {},
   "source": [
    "# 4. Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5cafba",
   "metadata": {},
   "source": [
    "## 4.1 Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0ab74741",
   "metadata": {},
   "outputs": [],
   "source": [
    "## deploy models for training set ##\n",
    "model_voting = jl.load(r\"H:\\3_output_raMSIn\\3_3_Output_raMSIn_HKU_Ingested4ALL\\XGB_ALL\\afterModelSelection\\dbMSIn_5ppm\\model3to1Voting_dbMSIn5ppm.joblib\")\n",
    "#\n",
    "## deploy model ##\n",
    "predicted0n1_train = model_voting.predict(X_train)\n",
    "#predicted0n1_trainProba = model_voting.predict_proba(X_train)         \n",
    "trainDEFSDf[\"predicted0n1\"] = predicted0n1_train\n",
    "T_ = []\n",
    "F_ = []\n",
    "for i in range(len(trainDEFSDf)):\n",
    "    if trainDEFSDf.iloc[i][\"predicted0n1\"] == 1:\n",
    "        T_.append(1)\n",
    "        F_.append(0)\n",
    "    elif trainDEFSDf.iloc[i][\"predicted0n1\"] == 0:\n",
    "        F_.append(1)\n",
    "        T_.append(0)\n",
    "trainDEFSDf[\"T\"] = T_\n",
    "trainDEFSDf[\"F\"] = F_\n",
    "#\n",
    "## save ##, ouputing trainSet df\n",
    "savePath = r\"H:\\3_output_raMSIn\\3_3_Output_raMSIn_HKU_Ingested4ALL\\XGB_ALL\\afterModelSelection\\dbMSIn_5ppm\\df_train_dbMSIn5ppm_norm_0n1.csv\"\n",
    "trainDEFSDf.to_csv(savePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "76d7c323",
   "metadata": {},
   "outputs": [],
   "source": [
    "## deploy models for Ext Val set ##\n",
    "model_voting = jl.load(r\"H:\\3_output_raMSIn\\3_3_Output_raMSIn_HKU_Ingested4ALL\\XGB_ALL\\afterModelSelection\\dbMSIn_5ppm\\model3to1Voting_dbMSIn5ppm.joblib\")\n",
    "#\n",
    "## deploy model ##\n",
    "predicted0n1_ext = model_voting.predict(X_val)\n",
    "extDEFSDf[\"predicted0n1\"] = predicted0n1_ext\n",
    "T_ = []\n",
    "F_ = []\n",
    "for i in range(len(extDEFSDf)):\n",
    "    if extDEFSDf.iloc[i][\"predicted0n1\"] == 1:\n",
    "        T_.append(1)\n",
    "        F_.append(0)\n",
    "    elif extDEFSDf.iloc[i][\"predicted0n1\"] == 0:\n",
    "        F_.append(1)\n",
    "        T_.append(0)\n",
    "extDEFSDf[\"T\"] = T_\n",
    "extDEFSDf[\"F\"] = F_\n",
    "#\n",
    "## save ##, ouputing extSet df\n",
    "savePath = r\"H:\\3_output_raMSIn\\3_3_Output_raMSIn_HKU_Ingested4ALL\\XGB_ALL\\afterModelSelection\\dbMSIn_5ppm\\df_ext_dbMSIn5ppm_norm_0n1.csv\"\n",
    "extDEFSDf.to_csv(savePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3a327944",
   "metadata": {},
   "outputs": [],
   "source": [
    "## deploy models for FNA set ##\n",
    "model_voting = jl.load(r\"H:\\3_output_raMSIn\\3_3_Output_raMSIn_HKU_Ingested4ALL\\XGB_ALL\\afterModelSelection\\dbMSIn_5ppm\\model3to1Voting_dbMSIn5ppm.joblib\")\n",
    "#\n",
    "## deploy model ##\n",
    "predicted0n1_FNA = model_voting.predict(X_FNA)\n",
    "fnaDEFSDf[\"predicted0n1\"] = predicted0n1_FNA\n",
    "T_ = []\n",
    "F_ = []\n",
    "for i in range(len(fnaDEFSDf)):\n",
    "    if fnaDEFSDf.iloc[i][\"predicted0n1\"] == 1:\n",
    "        T_.append(1)\n",
    "        F_.append(0)\n",
    "    elif fnaDEFSDf.iloc[i][\"predicted0n1\"] == 0:\n",
    "        F_.append(1)\n",
    "        T_.append(0)\n",
    "fnaDEFSDf[\"T\"] = T_\n",
    "fnaDEFSDf[\"F\"] = F_\n",
    "#\n",
    "## save ##, ouputing extSet df\n",
    "savePath = r\"H:\\3_output_raMSIn\\3_3_Output_raMSIn_HKU_Ingested4ALL\\XGB_ALL\\afterModelSelection\\dbMSIn_5ppm\\df_FNA_dbMSIn5ppm_norm_0n1.csv\"\n",
    "fnaDEFSDf.to_csv(savePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e771a1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "## deploy models for DirectInfusion set ##\n",
    "model_voting = jl.load(r\"H:\\3_output_raMSIn\\3_3_Output_raMSIn_HKU_Ingested4ALL\\XGB_ALL\\afterModelSelection\\dbMSIn_5ppm\\model3to1Voting_dbMSIn5ppm.joblib\")\n",
    "#\n",
    "## deploy model ##\n",
    "predicted0n1_Di = model_voting.predict(X_di)\n",
    "diDEFSDf[\"predicted0n1\"] = predicted0n1_Di\n",
    "T_ = []\n",
    "F_ = []\n",
    "for i in range(len(diDEFSDf)):\n",
    "    if diDEFSDf.iloc[i][\"predicted0n1\"] == 1:\n",
    "        T_.append(1)\n",
    "        F_.append(0)\n",
    "    elif diDEFSDf.iloc[i][\"predicted0n1\"] == 0:\n",
    "        F_.append(1)\n",
    "        T_.append(0)\n",
    "diDEFSDf[\"T\"] = T_\n",
    "diDEFSDf[\"F\"] = F_\n",
    "#\n",
    "## save ##, ouputing extSet df\n",
    "savePath = r\"H:\\3_output_raMSIn\\3_3_Output_raMSIn_HKU_Ingested4ALL\\XGB_ALL\\afterModelSelection\\dbMSIn_5ppm\\df_Di_dbMSIn5ppm_norm_0n1.csv\"\n",
    "diDEFSDf.to_csv(savePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3082152",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
