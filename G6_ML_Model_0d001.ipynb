{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b137a905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\Users\\\\user\\\\anaconda3\\\\lib\\\\site-packages\\\\config']\n",
      "2.12.0-dev20221107\n",
      "2.12.0\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import glob\n",
    "import xlwings as xw\n",
    "import math\n",
    "from pathlib import Path\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "from matplotlib import cm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mclr\n",
    "import plotly.express as px\n",
    "import statsmodels.api as sm\n",
    "import pylab as py\n",
    "import os, cv2, glob, tempfile\n",
    "import joblib\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "import sklearn\n",
    "from sklearn import datasets\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "make_scorer = sklearn.metrics.make_scorer\n",
    "f1 = make_scorer(f1_score, pos_label=1, average=\"binary\")\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate, KFold\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import BatchNormalization, Conv2D, MaxPooling2D, Activation, Dropout, Flatten, Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras import utils as np_utils\n",
    "from keras import models\n",
    "import keras_tuner as kt\n",
    "from scipy import signal\n",
    "\n",
    "import config as config\n",
    "print(config.__path__)\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import to_categorical\n",
    "from keras import backend as K\n",
    "\n",
    "import argparse\n",
    "# from sklearn.utils import class_weight\n",
    "print(tf.__version__)\n",
    "print(keras.__version__)\n",
    "\n",
    "import shutil\n",
    "import xlwings as xw\n",
    "\n",
    "%matplotlib inline\n",
    "mpl.use(\"Agg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5c8a718",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build XGBoost Model\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statsmodels.graphics.tsaplots import plot_acf,plot_pacf\n",
    "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV,train_test_split\n",
    "from skopt import BayesSearchCV\n",
    "from sklearn.metrics import accuracy_score,f1_score,roc_auc_score,confusion_matrix,roc_curve\n",
    "import xgboost as xgb\n",
    "import time\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30868f12",
   "metadata": {},
   "source": [
    "# 1. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "daf38283",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDEFSDf = pd.read_csv(r\"H:\\\\3_output_raMSIn\\\\3_3_Output_raMSIn_HKU_Ingested4ALL\\\\XGB_ALL\\\\df_train_cbMSIn0d0014nonInDI_norm.csv\")\n",
    "diDEFSDf = pd.read_csv(r\"H:\\\\3_output_raMSIn\\\\3_3_Output_raMSIn_HKU_Ingested4ALL\\\\XGB_ALL\\\\df_nonInDI_cbMSIn0d0014nonInDI_norm.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36740c29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel_id</th>\n",
       "      <th>311.168</th>\n",
       "      <th>269.249</th>\n",
       "      <th>215.033</th>\n",
       "      <th>295.227</th>\n",
       "      <th>883.533</th>\n",
       "      <th>309.172</th>\n",
       "      <th>738.505</th>\n",
       "      <th>435.296</th>\n",
       "      <th>280.236</th>\n",
       "      <th>241.217</th>\n",
       "      <th>311.223</th>\n",
       "      <th>339.2</th>\n",
       "      <th>353.201</th>\n",
       "      <th>325.184</th>\n",
       "      <th>250.145</th>\n",
       "      <th>514.284</th>\n",
       "      <th>265.148</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HKULiver_Post29wk_HCCAMCLiver_Left_Mice03_Slid...</td>\n",
       "      <td>0.318766</td>\n",
       "      <td>0.166427</td>\n",
       "      <td>-0.119110</td>\n",
       "      <td>-0.066937</td>\n",
       "      <td>-0.070112</td>\n",
       "      <td>0.384434</td>\n",
       "      <td>-0.143208</td>\n",
       "      <td>0.118236</td>\n",
       "      <td>-0.082543</td>\n",
       "      <td>0.226676</td>\n",
       "      <td>-0.001238</td>\n",
       "      <td>0.230791</td>\n",
       "      <td>0.249851</td>\n",
       "      <td>0.293677</td>\n",
       "      <td>0.126166</td>\n",
       "      <td>-0.040413</td>\n",
       "      <td>0.322943</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HKULiver_Post29wk_HCCAMCLiver_Left_Mice03_Slid...</td>\n",
       "      <td>0.440857</td>\n",
       "      <td>0.435660</td>\n",
       "      <td>-0.038277</td>\n",
       "      <td>-0.066937</td>\n",
       "      <td>-0.037918</td>\n",
       "      <td>0.479902</td>\n",
       "      <td>-0.160188</td>\n",
       "      <td>0.058335</td>\n",
       "      <td>-0.102396</td>\n",
       "      <td>0.292328</td>\n",
       "      <td>-0.001238</td>\n",
       "      <td>0.312519</td>\n",
       "      <td>0.313742</td>\n",
       "      <td>0.399221</td>\n",
       "      <td>0.300477</td>\n",
       "      <td>-0.040413</td>\n",
       "      <td>0.392732</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HKULiver_Post29wk_HCCAMCLiver_Left_Mice03_Slid...</td>\n",
       "      <td>0.297861</td>\n",
       "      <td>0.183927</td>\n",
       "      <td>-0.083686</td>\n",
       "      <td>-0.066937</td>\n",
       "      <td>-0.067620</td>\n",
       "      <td>0.317128</td>\n",
       "      <td>-0.150589</td>\n",
       "      <td>-0.029346</td>\n",
       "      <td>-0.088092</td>\n",
       "      <td>0.210673</td>\n",
       "      <td>-0.001238</td>\n",
       "      <td>0.229711</td>\n",
       "      <td>0.257741</td>\n",
       "      <td>0.267807</td>\n",
       "      <td>0.208800</td>\n",
       "      <td>-0.040413</td>\n",
       "      <td>0.315278</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HKULiver_Post29wk_HCCAMCLiver_Left_Mice03_Slid...</td>\n",
       "      <td>0.276325</td>\n",
       "      <td>0.127673</td>\n",
       "      <td>-0.042443</td>\n",
       "      <td>-0.066937</td>\n",
       "      <td>-0.052332</td>\n",
       "      <td>0.299088</td>\n",
       "      <td>-0.142959</td>\n",
       "      <td>-0.017979</td>\n",
       "      <td>-0.106704</td>\n",
       "      <td>0.272887</td>\n",
       "      <td>-0.001238</td>\n",
       "      <td>0.221054</td>\n",
       "      <td>0.208527</td>\n",
       "      <td>0.247314</td>\n",
       "      <td>0.187171</td>\n",
       "      <td>-0.040413</td>\n",
       "      <td>0.303845</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HKULiver_Post29wk_HCCAMCLiver_Left_Mice03_Slid...</td>\n",
       "      <td>0.172636</td>\n",
       "      <td>0.221349</td>\n",
       "      <td>-0.131908</td>\n",
       "      <td>-0.066937</td>\n",
       "      <td>-0.050631</td>\n",
       "      <td>0.219242</td>\n",
       "      <td>-0.145985</td>\n",
       "      <td>0.140151</td>\n",
       "      <td>-0.064397</td>\n",
       "      <td>0.166874</td>\n",
       "      <td>-0.001238</td>\n",
       "      <td>0.138944</td>\n",
       "      <td>0.194243</td>\n",
       "      <td>0.151402</td>\n",
       "      <td>0.094791</td>\n",
       "      <td>-0.040413</td>\n",
       "      <td>0.213334</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90955</th>\n",
       "      <td>HKULiver_Post29wk_HCCLiver_Left_Mice12_Slide4F...</td>\n",
       "      <td>0.035497</td>\n",
       "      <td>-0.299458</td>\n",
       "      <td>0.004159</td>\n",
       "      <td>-0.066937</td>\n",
       "      <td>-0.140680</td>\n",
       "      <td>0.062989</td>\n",
       "      <td>-0.200210</td>\n",
       "      <td>0.242831</td>\n",
       "      <td>-0.173629</td>\n",
       "      <td>-0.248629</td>\n",
       "      <td>-0.001238</td>\n",
       "      <td>0.042851</td>\n",
       "      <td>0.066512</td>\n",
       "      <td>0.035224</td>\n",
       "      <td>0.038177</td>\n",
       "      <td>0.212906</td>\n",
       "      <td>0.036063</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90956</th>\n",
       "      <td>HKULiver_Post29wk_HCCLiver_Left_Mice12_Slide4F...</td>\n",
       "      <td>0.021830</td>\n",
       "      <td>-0.299458</td>\n",
       "      <td>-0.091240</td>\n",
       "      <td>-0.066937</td>\n",
       "      <td>-0.060323</td>\n",
       "      <td>0.074326</td>\n",
       "      <td>-0.191599</td>\n",
       "      <td>0.300569</td>\n",
       "      <td>-0.195069</td>\n",
       "      <td>0.152803</td>\n",
       "      <td>-0.001238</td>\n",
       "      <td>0.050360</td>\n",
       "      <td>0.070399</td>\n",
       "      <td>0.037017</td>\n",
       "      <td>0.210630</td>\n",
       "      <td>-0.040413</td>\n",
       "      <td>0.018601</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90957</th>\n",
       "      <td>HKULiver_Post29wk_HCCLiver_Left_Mice12_Slide4F...</td>\n",
       "      <td>0.030910</td>\n",
       "      <td>0.367236</td>\n",
       "      <td>-0.093395</td>\n",
       "      <td>-0.066937</td>\n",
       "      <td>-0.089147</td>\n",
       "      <td>0.044593</td>\n",
       "      <td>-0.114107</td>\n",
       "      <td>0.195878</td>\n",
       "      <td>-0.156602</td>\n",
       "      <td>-0.248629</td>\n",
       "      <td>-0.001238</td>\n",
       "      <td>0.046832</td>\n",
       "      <td>0.103164</td>\n",
       "      <td>0.037407</td>\n",
       "      <td>0.143304</td>\n",
       "      <td>-0.040413</td>\n",
       "      <td>-0.052544</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90958</th>\n",
       "      <td>HKULiver_Post29wk_HCCLiver_Left_Mice12_Slide4F...</td>\n",
       "      <td>0.045528</td>\n",
       "      <td>-0.299458</td>\n",
       "      <td>-0.122677</td>\n",
       "      <td>-0.066937</td>\n",
       "      <td>-0.161395</td>\n",
       "      <td>0.060010</td>\n",
       "      <td>-0.138312</td>\n",
       "      <td>0.149756</td>\n",
       "      <td>-0.162997</td>\n",
       "      <td>-0.248629</td>\n",
       "      <td>-0.001238</td>\n",
       "      <td>0.033926</td>\n",
       "      <td>-0.067441</td>\n",
       "      <td>0.036386</td>\n",
       "      <td>0.189039</td>\n",
       "      <td>-0.040413</td>\n",
       "      <td>0.048053</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90959</th>\n",
       "      <td>HKULiver_Post29wk_HCCLiver_Left_Mice12_Slide4F...</td>\n",
       "      <td>0.017849</td>\n",
       "      <td>-0.299458</td>\n",
       "      <td>-0.120909</td>\n",
       "      <td>-0.066937</td>\n",
       "      <td>-0.390603</td>\n",
       "      <td>0.049527</td>\n",
       "      <td>-0.112213</td>\n",
       "      <td>0.101911</td>\n",
       "      <td>-0.231182</td>\n",
       "      <td>-0.248629</td>\n",
       "      <td>-0.001238</td>\n",
       "      <td>0.041793</td>\n",
       "      <td>-0.067441</td>\n",
       "      <td>0.028764</td>\n",
       "      <td>0.177673</td>\n",
       "      <td>-0.040413</td>\n",
       "      <td>0.035278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90960 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                pixel_id   311.168   269.249  \\\n",
       "0      HKULiver_Post29wk_HCCAMCLiver_Left_Mice03_Slid...  0.318766  0.166427   \n",
       "1      HKULiver_Post29wk_HCCAMCLiver_Left_Mice03_Slid...  0.440857  0.435660   \n",
       "2      HKULiver_Post29wk_HCCAMCLiver_Left_Mice03_Slid...  0.297861  0.183927   \n",
       "3      HKULiver_Post29wk_HCCAMCLiver_Left_Mice03_Slid...  0.276325  0.127673   \n",
       "4      HKULiver_Post29wk_HCCAMCLiver_Left_Mice03_Slid...  0.172636  0.221349   \n",
       "...                                                  ...       ...       ...   \n",
       "90955  HKULiver_Post29wk_HCCLiver_Left_Mice12_Slide4F...  0.035497 -0.299458   \n",
       "90956  HKULiver_Post29wk_HCCLiver_Left_Mice12_Slide4F...  0.021830 -0.299458   \n",
       "90957  HKULiver_Post29wk_HCCLiver_Left_Mice12_Slide4F...  0.030910  0.367236   \n",
       "90958  HKULiver_Post29wk_HCCLiver_Left_Mice12_Slide4F...  0.045528 -0.299458   \n",
       "90959  HKULiver_Post29wk_HCCLiver_Left_Mice12_Slide4F...  0.017849 -0.299458   \n",
       "\n",
       "        215.033   295.227   883.533   309.172   738.505   435.296   280.236  \\\n",
       "0     -0.119110 -0.066937 -0.070112  0.384434 -0.143208  0.118236 -0.082543   \n",
       "1     -0.038277 -0.066937 -0.037918  0.479902 -0.160188  0.058335 -0.102396   \n",
       "2     -0.083686 -0.066937 -0.067620  0.317128 -0.150589 -0.029346 -0.088092   \n",
       "3     -0.042443 -0.066937 -0.052332  0.299088 -0.142959 -0.017979 -0.106704   \n",
       "4     -0.131908 -0.066937 -0.050631  0.219242 -0.145985  0.140151 -0.064397   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "90955  0.004159 -0.066937 -0.140680  0.062989 -0.200210  0.242831 -0.173629   \n",
       "90956 -0.091240 -0.066937 -0.060323  0.074326 -0.191599  0.300569 -0.195069   \n",
       "90957 -0.093395 -0.066937 -0.089147  0.044593 -0.114107  0.195878 -0.156602   \n",
       "90958 -0.122677 -0.066937 -0.161395  0.060010 -0.138312  0.149756 -0.162997   \n",
       "90959 -0.120909 -0.066937 -0.390603  0.049527 -0.112213  0.101911 -0.231182   \n",
       "\n",
       "        241.217   311.223     339.2   353.201   325.184   250.145   514.284  \\\n",
       "0      0.226676 -0.001238  0.230791  0.249851  0.293677  0.126166 -0.040413   \n",
       "1      0.292328 -0.001238  0.312519  0.313742  0.399221  0.300477 -0.040413   \n",
       "2      0.210673 -0.001238  0.229711  0.257741  0.267807  0.208800 -0.040413   \n",
       "3      0.272887 -0.001238  0.221054  0.208527  0.247314  0.187171 -0.040413   \n",
       "4      0.166874 -0.001238  0.138944  0.194243  0.151402  0.094791 -0.040413   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "90955 -0.248629 -0.001238  0.042851  0.066512  0.035224  0.038177  0.212906   \n",
       "90956  0.152803 -0.001238  0.050360  0.070399  0.037017  0.210630 -0.040413   \n",
       "90957 -0.248629 -0.001238  0.046832  0.103164  0.037407  0.143304 -0.040413   \n",
       "90958 -0.248629 -0.001238  0.033926 -0.067441  0.036386  0.189039 -0.040413   \n",
       "90959 -0.248629 -0.001238  0.041793 -0.067441  0.028764  0.177673 -0.040413   \n",
       "\n",
       "        265.148  type  \n",
       "0      0.322943     0  \n",
       "1      0.392732     0  \n",
       "2      0.315278     0  \n",
       "3      0.303845     0  \n",
       "4      0.213334     0  \n",
       "...         ...   ...  \n",
       "90955  0.036063     1  \n",
       "90956  0.018601     1  \n",
       "90957 -0.052544     1  \n",
       "90958  0.048053     1  \n",
       "90959  0.035278     1  \n",
       "\n",
       "[90960 rows x 19 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDEFSDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "558c10c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "can = []\n",
    "for i in list(range(0,9)) + list(range(15,17)) + [len(list(trainDEFSDf.columns))-1]:\n",
    "    can.append(list(trainDEFSDf.columns)[i])\n",
    "\n",
    "dican = []\n",
    "for i in list(range(0,9)) + list(range(15,17)) + [len(list(diDEFSDf.columns))-1]:\n",
    "    dican.append(list(diDEFSDf.columns)[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85c654ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pixel_id',\n",
       " '311.168',\n",
       " '269.249',\n",
       " '215.033',\n",
       " '295.227',\n",
       " '883.533',\n",
       " '309.172',\n",
       " '738.505',\n",
       " '435.296',\n",
       " '250.145',\n",
       " '514.284',\n",
       " 'type']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "can"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c5daef9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pixel_id',\n",
       " '311.169',\n",
       " '269.249',\n",
       " '215.032',\n",
       " '295.228',\n",
       " '883.538',\n",
       " '309.17',\n",
       " '738.508',\n",
       " '435.297',\n",
       " '250.145',\n",
       " '514.284',\n",
       " 'type']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dican"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d2530f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## input training set ## 90960 x 20 df\n",
    "trainDEFSDf = pd.read_csv(r\"H:\\\\3_output_raMSIn\\\\3_3_Output_raMSIn_HKU_Ingested4ALL\\\\XGB_ALL\\\\df_train_cbMSIn0d0014nonInDI_norm.csv\")\n",
    "#trainDEFSDf[trainDEFSDf.type .== 1, :]\n",
    "## calculate weight ## 0: 47449, 1: 43511\n",
    "trainDEFSDf = trainDEFSDf[can]\n",
    "Yy_train = trainDEFSDf[\"type\"]  # 0.9585; 1.0453\n",
    "sampleW = []\n",
    "for w in Yy_train:\n",
    "    if w == 0:\n",
    "        sampleW.append(0.9585)\n",
    "    elif w == 1:\n",
    "        sampleW.append(1.0453) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26f6b926",
   "metadata": {},
   "outputs": [],
   "source": [
    "## input ext val set ## 6075 x 20 df\n",
    "extDEFSDf = pd.read_csv(r\"H:\\\\3_output_raMSIn\\\\3_3_Output_raMSIn_HKU_Ingested4ALL\\\\XGB_ALL\\\\df_ext_cbMSIn0d0014nonInDI_norm.csv\")\n",
    "#extDEFSDf[extDEFSDf.type .== 1, :]\n",
    "## calculate weight ## 0: 2943, 1: 3132\n",
    "extDEFSDf = extDEFSDf[can]\n",
    "Yy_ext = extDEFSDf[\"type\"]  # 1.0321; 0.9698\n",
    "sampleExtW = []\n",
    "for w in Yy_ext:\n",
    "    if w == 0:\n",
    "        sampleExtW.append(1.0321)\n",
    "    elif w == 1:\n",
    "        sampleExtW.append(0.9698) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f13b3818",
   "metadata": {},
   "outputs": [],
   "source": [
    "## input ingested set ## 97035 x 20 df\n",
    "ingestedDEFSDf = pd.read_csv(r\"H:\\\\3_output_raMSIn\\\\3_3_Output_raMSIn_HKU_Ingested4ALL\\\\XGB_ALL\\\\df_ingested_cbMSIn0d0014nonInDI_norm.csv\")\n",
    "#ingestedDEFSDf[extDEFSDf.type .== 1, :]\n",
    "## calculate weight ## 0: 50392, 1: 46643\n",
    "ingestedDEFSDf = ingestedDEFSDf[can]\n",
    "Yy_ingested = ingestedDEFSDf[\"type\"]  # 0.9628; 1.0402\n",
    "sampleIngestedW = []\n",
    "for w in Yy_ingested:\n",
    "    if w == 0:\n",
    "        sampleIngestedW.append(0.9628)\n",
    "    elif w == 1:\n",
    "        sampleIngestedW.append(1.0402)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a884cb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "## input FNA set ## 88701 x 20 df\n",
    "fnaDEFSDf = pd.read_csv(r\"H:\\\\3_output_raMSIn\\\\3_3_Output_raMSIn_HKU_Ingested4ALL\\\\XGB_ALL\\\\df_FNA_cbMSIn0d0014nonInDI_norm.csv\")\n",
    "#fnaDEFSDf[fnaDEFSDf.type .== 1, :]\n",
    "## calculate weight ##  0: 44540, 1: 44161\n",
    "fnaDEFSDf = fnaDEFSDf[can]\n",
    "Yy_FNA = fnaDEFSDf[\"type\"]  # 0.9957; 1.0043\n",
    "sampleFNAW = []\n",
    "for w in Yy_FNA:\n",
    "    if w == 0:\n",
    "        sampleFNAW.append(0.9957)\n",
    "    elif w == 1:\n",
    "        sampleFNAW.append(1.0043)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b2cfbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## input DirectIn set ## 88701 x 20 df\n",
    "diDEFSDf = pd.read_csv(r\"H:\\\\3_output_raMSIn\\\\3_3_Output_raMSIn_HKU_Ingested4ALL\\\\XGB_ALL\\\\df_nonInDI_cbMSIn0d0014nonInDI_norm.csv\")\n",
    "#diDEFSDf[diDEFSDf.type .== 1, :]\n",
    "## calculate weight ## 0: 3027, 1: 3030\n",
    "diDEFSDf = diDEFSDf[dican]\n",
    "diDEFSDf = diDEFSDf.rename(columns={\"311.169\": \"311.168\", \"215.032\":\"215.033\", \"295.228\":\"295.227\", \"883.538\":\"883.533\", \n",
    "                                    \"309.17\":\"309.172\", \"738.508\":\"738.505\", \"435.297\":\"435.296\", \"311.222\":\"311.223\"})\n",
    "Yy_DI = diDEFSDf[\"type\"]  # 1.0005; 0.9995\n",
    "sampleDiW = []\n",
    "for w in Yy_DI:\n",
    "    if w == 0:\n",
    "        sampleDiW.append(1.0005)\n",
    "    elif w == 1:\n",
    "        sampleDiW.append(0.9995)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95558b9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel_id</th>\n",
       "      <th>311.168</th>\n",
       "      <th>269.249</th>\n",
       "      <th>215.033</th>\n",
       "      <th>295.227</th>\n",
       "      <th>883.533</th>\n",
       "      <th>309.172</th>\n",
       "      <th>738.505</th>\n",
       "      <th>435.296</th>\n",
       "      <th>250.145</th>\n",
       "      <th>514.284</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HKULiver_Post29wk_HCCAMCLiver_DirectIn_MiceNL_...</td>\n",
       "      <td>0.005233</td>\n",
       "      <td>0.142288</td>\n",
       "      <td>0.041741</td>\n",
       "      <td>0.003879</td>\n",
       "      <td>0.080422</td>\n",
       "      <td>-0.001508</td>\n",
       "      <td>0.061910</td>\n",
       "      <td>0.126365</td>\n",
       "      <td>0.467350</td>\n",
       "      <td>0.036504</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HKULiver_Post29wk_HCCAMCLiver_DirectIn_MiceNL_...</td>\n",
       "      <td>0.089591</td>\n",
       "      <td>0.156412</td>\n",
       "      <td>0.177400</td>\n",
       "      <td>0.001265</td>\n",
       "      <td>0.169447</td>\n",
       "      <td>-0.001508</td>\n",
       "      <td>0.128052</td>\n",
       "      <td>0.146025</td>\n",
       "      <td>0.583306</td>\n",
       "      <td>0.099624</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HKULiver_Post29wk_HCCAMCLiver_DirectIn_MiceNL_...</td>\n",
       "      <td>0.032985</td>\n",
       "      <td>0.134206</td>\n",
       "      <td>0.036982</td>\n",
       "      <td>-0.069655</td>\n",
       "      <td>0.124404</td>\n",
       "      <td>-0.001508</td>\n",
       "      <td>0.029039</td>\n",
       "      <td>0.077323</td>\n",
       "      <td>0.465193</td>\n",
       "      <td>0.056832</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HKULiver_Post29wk_HCCAMCLiver_DirectIn_MiceNL_...</td>\n",
       "      <td>0.081001</td>\n",
       "      <td>0.235152</td>\n",
       "      <td>0.064486</td>\n",
       "      <td>0.057514</td>\n",
       "      <td>0.131518</td>\n",
       "      <td>-0.001508</td>\n",
       "      <td>0.108169</td>\n",
       "      <td>0.193505</td>\n",
       "      <td>0.550698</td>\n",
       "      <td>0.090345</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HKULiver_Post29wk_HCCAMCLiver_DirectIn_MiceNL_...</td>\n",
       "      <td>0.132548</td>\n",
       "      <td>0.236938</td>\n",
       "      <td>0.155168</td>\n",
       "      <td>0.080273</td>\n",
       "      <td>0.241694</td>\n",
       "      <td>-0.001508</td>\n",
       "      <td>0.236299</td>\n",
       "      <td>0.205055</td>\n",
       "      <td>0.645501</td>\n",
       "      <td>0.147339</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6052</th>\n",
       "      <td>HKULiver_Post29wk_HCCLiver_DirectIn_MiceHCC_S1...</td>\n",
       "      <td>-0.002046</td>\n",
       "      <td>-0.209455</td>\n",
       "      <td>0.129994</td>\n",
       "      <td>-0.039157</td>\n",
       "      <td>-0.040097</td>\n",
       "      <td>-0.001508</td>\n",
       "      <td>0.023320</td>\n",
       "      <td>0.147663</td>\n",
       "      <td>-0.089365</td>\n",
       "      <td>0.163274</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6053</th>\n",
       "      <td>HKULiver_Post29wk_HCCLiver_DirectIn_MiceHCC_S1...</td>\n",
       "      <td>-0.313188</td>\n",
       "      <td>-0.217983</td>\n",
       "      <td>-0.306237</td>\n",
       "      <td>-0.299289</td>\n",
       "      <td>-0.270588</td>\n",
       "      <td>-0.001508</td>\n",
       "      <td>-0.280477</td>\n",
       "      <td>-0.277348</td>\n",
       "      <td>-0.025231</td>\n",
       "      <td>-0.251938</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6054</th>\n",
       "      <td>HKULiver_Post29wk_HCCLiver_DirectIn_MiceHCC_S1...</td>\n",
       "      <td>-0.158181</td>\n",
       "      <td>-0.037213</td>\n",
       "      <td>0.001820</td>\n",
       "      <td>-0.048526</td>\n",
       "      <td>-0.042687</td>\n",
       "      <td>-0.001508</td>\n",
       "      <td>-0.084838</td>\n",
       "      <td>-0.038916</td>\n",
       "      <td>-0.089365</td>\n",
       "      <td>0.091535</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6055</th>\n",
       "      <td>HKULiver_Post29wk_HCCLiver_DirectIn_MiceHCC_S1...</td>\n",
       "      <td>-0.130111</td>\n",
       "      <td>-0.100314</td>\n",
       "      <td>0.068322</td>\n",
       "      <td>-0.107947</td>\n",
       "      <td>-0.004388</td>\n",
       "      <td>-0.001508</td>\n",
       "      <td>-0.068925</td>\n",
       "      <td>-0.070150</td>\n",
       "      <td>-0.010167</td>\n",
       "      <td>-0.018033</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6056</th>\n",
       "      <td>HKULiver_Post29wk_HCCLiver_DirectIn_MiceHCC_S1...</td>\n",
       "      <td>-0.375053</td>\n",
       "      <td>-0.421196</td>\n",
       "      <td>-0.306237</td>\n",
       "      <td>-0.382957</td>\n",
       "      <td>-0.270588</td>\n",
       "      <td>-0.001508</td>\n",
       "      <td>-0.280477</td>\n",
       "      <td>-0.277348</td>\n",
       "      <td>-0.025757</td>\n",
       "      <td>-0.312433</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6057 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               pixel_id   311.168   269.249  \\\n",
       "0     HKULiver_Post29wk_HCCAMCLiver_DirectIn_MiceNL_...  0.005233  0.142288   \n",
       "1     HKULiver_Post29wk_HCCAMCLiver_DirectIn_MiceNL_...  0.089591  0.156412   \n",
       "2     HKULiver_Post29wk_HCCAMCLiver_DirectIn_MiceNL_...  0.032985  0.134206   \n",
       "3     HKULiver_Post29wk_HCCAMCLiver_DirectIn_MiceNL_...  0.081001  0.235152   \n",
       "4     HKULiver_Post29wk_HCCAMCLiver_DirectIn_MiceNL_...  0.132548  0.236938   \n",
       "...                                                 ...       ...       ...   \n",
       "6052  HKULiver_Post29wk_HCCLiver_DirectIn_MiceHCC_S1... -0.002046 -0.209455   \n",
       "6053  HKULiver_Post29wk_HCCLiver_DirectIn_MiceHCC_S1... -0.313188 -0.217983   \n",
       "6054  HKULiver_Post29wk_HCCLiver_DirectIn_MiceHCC_S1... -0.158181 -0.037213   \n",
       "6055  HKULiver_Post29wk_HCCLiver_DirectIn_MiceHCC_S1... -0.130111 -0.100314   \n",
       "6056  HKULiver_Post29wk_HCCLiver_DirectIn_MiceHCC_S1... -0.375053 -0.421196   \n",
       "\n",
       "       215.033   295.227   883.533   309.172   738.505   435.296   250.145  \\\n",
       "0     0.041741  0.003879  0.080422 -0.001508  0.061910  0.126365  0.467350   \n",
       "1     0.177400  0.001265  0.169447 -0.001508  0.128052  0.146025  0.583306   \n",
       "2     0.036982 -0.069655  0.124404 -0.001508  0.029039  0.077323  0.465193   \n",
       "3     0.064486  0.057514  0.131518 -0.001508  0.108169  0.193505  0.550698   \n",
       "4     0.155168  0.080273  0.241694 -0.001508  0.236299  0.205055  0.645501   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "6052  0.129994 -0.039157 -0.040097 -0.001508  0.023320  0.147663 -0.089365   \n",
       "6053 -0.306237 -0.299289 -0.270588 -0.001508 -0.280477 -0.277348 -0.025231   \n",
       "6054  0.001820 -0.048526 -0.042687 -0.001508 -0.084838 -0.038916 -0.089365   \n",
       "6055  0.068322 -0.107947 -0.004388 -0.001508 -0.068925 -0.070150 -0.010167   \n",
       "6056 -0.306237 -0.382957 -0.270588 -0.001508 -0.280477 -0.277348 -0.025757   \n",
       "\n",
       "       514.284  type  \n",
       "0     0.036504     0  \n",
       "1     0.099624     0  \n",
       "2     0.056832     0  \n",
       "3     0.090345     0  \n",
       "4     0.147339     0  \n",
       "...        ...   ...  \n",
       "6052  0.163274     1  \n",
       "6053 -0.251938     1  \n",
       "6054  0.091535     1  \n",
       "6055 -0.018033     1  \n",
       "6056 -0.312433     1  \n",
       "\n",
       "[6057 rows x 12 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diDEFSDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca171d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "## define functions for performace evaluation ##\n",
    "\n",
    "# Average score\n",
    "def avgScore(arrAcc, cv):\n",
    "    sumAcc = 0\n",
    "    for acc in arrAcc:\n",
    "        sumAcc += acc\n",
    "    return sumAcc / cv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ccef0bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>311.168</th>\n",
       "      <th>269.249</th>\n",
       "      <th>215.033</th>\n",
       "      <th>295.227</th>\n",
       "      <th>883.533</th>\n",
       "      <th>309.172</th>\n",
       "      <th>738.505</th>\n",
       "      <th>435.296</th>\n",
       "      <th>250.145</th>\n",
       "      <th>514.284</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.318766</td>\n",
       "      <td>0.166427</td>\n",
       "      <td>-0.119110</td>\n",
       "      <td>-0.066937</td>\n",
       "      <td>-0.070112</td>\n",
       "      <td>0.384434</td>\n",
       "      <td>-0.143208</td>\n",
       "      <td>0.118236</td>\n",
       "      <td>0.126166</td>\n",
       "      <td>-0.040413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.440857</td>\n",
       "      <td>0.435660</td>\n",
       "      <td>-0.038277</td>\n",
       "      <td>-0.066937</td>\n",
       "      <td>-0.037918</td>\n",
       "      <td>0.479902</td>\n",
       "      <td>-0.160188</td>\n",
       "      <td>0.058335</td>\n",
       "      <td>0.300477</td>\n",
       "      <td>-0.040413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.297861</td>\n",
       "      <td>0.183927</td>\n",
       "      <td>-0.083686</td>\n",
       "      <td>-0.066937</td>\n",
       "      <td>-0.067620</td>\n",
       "      <td>0.317128</td>\n",
       "      <td>-0.150589</td>\n",
       "      <td>-0.029346</td>\n",
       "      <td>0.208800</td>\n",
       "      <td>-0.040413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.276325</td>\n",
       "      <td>0.127673</td>\n",
       "      <td>-0.042443</td>\n",
       "      <td>-0.066937</td>\n",
       "      <td>-0.052332</td>\n",
       "      <td>0.299088</td>\n",
       "      <td>-0.142959</td>\n",
       "      <td>-0.017979</td>\n",
       "      <td>0.187171</td>\n",
       "      <td>-0.040413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.172636</td>\n",
       "      <td>0.221349</td>\n",
       "      <td>-0.131908</td>\n",
       "      <td>-0.066937</td>\n",
       "      <td>-0.050631</td>\n",
       "      <td>0.219242</td>\n",
       "      <td>-0.145985</td>\n",
       "      <td>0.140151</td>\n",
       "      <td>0.094791</td>\n",
       "      <td>-0.040413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90955</th>\n",
       "      <td>0.035497</td>\n",
       "      <td>-0.299458</td>\n",
       "      <td>0.004159</td>\n",
       "      <td>-0.066937</td>\n",
       "      <td>-0.140680</td>\n",
       "      <td>0.062989</td>\n",
       "      <td>-0.200210</td>\n",
       "      <td>0.242831</td>\n",
       "      <td>0.038177</td>\n",
       "      <td>0.212906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90956</th>\n",
       "      <td>0.021830</td>\n",
       "      <td>-0.299458</td>\n",
       "      <td>-0.091240</td>\n",
       "      <td>-0.066937</td>\n",
       "      <td>-0.060323</td>\n",
       "      <td>0.074326</td>\n",
       "      <td>-0.191599</td>\n",
       "      <td>0.300569</td>\n",
       "      <td>0.210630</td>\n",
       "      <td>-0.040413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90957</th>\n",
       "      <td>0.030910</td>\n",
       "      <td>0.367236</td>\n",
       "      <td>-0.093395</td>\n",
       "      <td>-0.066937</td>\n",
       "      <td>-0.089147</td>\n",
       "      <td>0.044593</td>\n",
       "      <td>-0.114107</td>\n",
       "      <td>0.195878</td>\n",
       "      <td>0.143304</td>\n",
       "      <td>-0.040413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90958</th>\n",
       "      <td>0.045528</td>\n",
       "      <td>-0.299458</td>\n",
       "      <td>-0.122677</td>\n",
       "      <td>-0.066937</td>\n",
       "      <td>-0.161395</td>\n",
       "      <td>0.060010</td>\n",
       "      <td>-0.138312</td>\n",
       "      <td>0.149756</td>\n",
       "      <td>0.189039</td>\n",
       "      <td>-0.040413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90959</th>\n",
       "      <td>0.017849</td>\n",
       "      <td>-0.299458</td>\n",
       "      <td>-0.120909</td>\n",
       "      <td>-0.066937</td>\n",
       "      <td>-0.390603</td>\n",
       "      <td>0.049527</td>\n",
       "      <td>-0.112213</td>\n",
       "      <td>0.101911</td>\n",
       "      <td>0.177673</td>\n",
       "      <td>-0.040413</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90960 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        311.168   269.249   215.033   295.227   883.533   309.172   738.505  \\\n",
       "0      0.318766  0.166427 -0.119110 -0.066937 -0.070112  0.384434 -0.143208   \n",
       "1      0.440857  0.435660 -0.038277 -0.066937 -0.037918  0.479902 -0.160188   \n",
       "2      0.297861  0.183927 -0.083686 -0.066937 -0.067620  0.317128 -0.150589   \n",
       "3      0.276325  0.127673 -0.042443 -0.066937 -0.052332  0.299088 -0.142959   \n",
       "4      0.172636  0.221349 -0.131908 -0.066937 -0.050631  0.219242 -0.145985   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "90955  0.035497 -0.299458  0.004159 -0.066937 -0.140680  0.062989 -0.200210   \n",
       "90956  0.021830 -0.299458 -0.091240 -0.066937 -0.060323  0.074326 -0.191599   \n",
       "90957  0.030910  0.367236 -0.093395 -0.066937 -0.089147  0.044593 -0.114107   \n",
       "90958  0.045528 -0.299458 -0.122677 -0.066937 -0.161395  0.060010 -0.138312   \n",
       "90959  0.017849 -0.299458 -0.120909 -0.066937 -0.390603  0.049527 -0.112213   \n",
       "\n",
       "        435.296   250.145   514.284  \n",
       "0      0.118236  0.126166 -0.040413  \n",
       "1      0.058335  0.300477 -0.040413  \n",
       "2     -0.029346  0.208800 -0.040413  \n",
       "3     -0.017979  0.187171 -0.040413  \n",
       "4      0.140151  0.094791 -0.040413  \n",
       "...         ...       ...       ...  \n",
       "90955  0.242831  0.038177  0.212906  \n",
       "90956  0.300569  0.210630 -0.040413  \n",
       "90957  0.195878  0.143304 -0.040413  \n",
       "90958  0.149756  0.189039 -0.040413  \n",
       "90959  0.101911  0.177673 -0.040413  \n",
       "\n",
       "[90960 rows x 10 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDEFSDf[trainDEFSDf.columns[1:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ff9f9ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c56eae",
   "metadata": {},
   "source": [
    "# 2. Unsupervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8049959",
   "metadata": {},
   "source": [
    "## 2.1. Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "56926254",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 720x720 with 0 Axes>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from matplotlib.pyplot import figure\n",
    "plt.rcParams['figure.figsize'] = [10, 10]\n",
    "plt.grid(visible=None)\n",
    "plt.close()\n",
    "figure(figsize=(10, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "62a3d9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ROI_for_ML_Opti = pd.concat([trainDEFSDf, extDEFSDf, fnaDEFSDf, diDEFSDf]).set_index('pixel_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e9061d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ROI_for_ML_Opti_ingested = ingestedDEFSDf.set_index('pixel_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7d1ef236",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ROI_for_ML_Opti_train = trainDEFSDf.set_index('pixel_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f9f05550",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ROI_for_ML_Opti_ext = extDEFSDf.set_index('pixel_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0dfe922b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ROI_for_ML_Opti_FNA = fnaDEFSDf.set_index('pixel_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f17e49c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ROI_for_ML_Opti_di = diDEFSDf.set_index('pixel_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9c15f5e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>311.168</th>\n",
       "      <th>269.249</th>\n",
       "      <th>215.033</th>\n",
       "      <th>295.227</th>\n",
       "      <th>883.533</th>\n",
       "      <th>309.172</th>\n",
       "      <th>738.505</th>\n",
       "      <th>435.296</th>\n",
       "      <th>250.145</th>\n",
       "      <th>514.284</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6.057000e+03</td>\n",
       "      <td>6.057000e+03</td>\n",
       "      <td>6.057000e+03</td>\n",
       "      <td>6.057000e+03</td>\n",
       "      <td>6.057000e+03</td>\n",
       "      <td>6.057000e+03</td>\n",
       "      <td>6.057000e+03</td>\n",
       "      <td>6.057000e+03</td>\n",
       "      <td>6.057000e+03</td>\n",
       "      <td>6.057000e+03</td>\n",
       "      <td>6057.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.786097e-18</td>\n",
       "      <td>6.620646e-17</td>\n",
       "      <td>-1.434290e-17</td>\n",
       "      <td>-1.438873e-18</td>\n",
       "      <td>4.710337e-16</td>\n",
       "      <td>-5.057534e-18</td>\n",
       "      <td>1.524563e-16</td>\n",
       "      <td>7.979419e-16</td>\n",
       "      <td>-4.598716e-15</td>\n",
       "      <td>2.271036e-17</td>\n",
       "      <td>0.500248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.259709e-01</td>\n",
       "      <td>1.439456e-01</td>\n",
       "      <td>1.644742e-01</td>\n",
       "      <td>1.354221e-01</td>\n",
       "      <td>1.830145e-01</td>\n",
       "      <td>3.246305e-02</td>\n",
       "      <td>1.277902e-01</td>\n",
       "      <td>2.078016e-01</td>\n",
       "      <td>1.914162e-01</td>\n",
       "      <td>1.330269e-01</td>\n",
       "      <td>0.500041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-3.936976e-01</td>\n",
       "      <td>-4.211962e-01</td>\n",
       "      <td>-3.062371e-01</td>\n",
       "      <td>-4.545066e-01</td>\n",
       "      <td>-2.705880e-01</td>\n",
       "      <td>-1.508251e-03</td>\n",
       "      <td>-2.804766e-01</td>\n",
       "      <td>-2.773479e-01</td>\n",
       "      <td>-8.936520e-02</td>\n",
       "      <td>-3.327737e-01</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-7.672668e-02</td>\n",
       "      <td>-6.810890e-02</td>\n",
       "      <td>-9.447482e-02</td>\n",
       "      <td>-6.188994e-02</td>\n",
       "      <td>-1.155605e-01</td>\n",
       "      <td>-1.508251e-03</td>\n",
       "      <td>-5.989332e-02</td>\n",
       "      <td>-2.773479e-01</td>\n",
       "      <td>-8.936520e-02</td>\n",
       "      <td>-6.633072e-02</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.552356e-03</td>\n",
       "      <td>-6.986512e-03</td>\n",
       "      <td>1.677855e-02</td>\n",
       "      <td>1.774746e-02</td>\n",
       "      <td>3.213359e-02</td>\n",
       "      <td>-1.508251e-03</td>\n",
       "      <td>1.466426e-02</td>\n",
       "      <td>6.586256e-03</td>\n",
       "      <td>-8.936520e-02</td>\n",
       "      <td>-1.852649e-02</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.000432e-02</td>\n",
       "      <td>5.958404e-02</td>\n",
       "      <td>1.127961e-01</td>\n",
       "      <td>7.451773e-02</td>\n",
       "      <td>1.324455e-01</td>\n",
       "      <td>-1.508251e-03</td>\n",
       "      <td>6.962831e-02</td>\n",
       "      <td>1.670720e-01</td>\n",
       "      <td>-1.214997e-03</td>\n",
       "      <td>8.939424e-02</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.063024e-01</td>\n",
       "      <td>5.788038e-01</td>\n",
       "      <td>6.937629e-01</td>\n",
       "      <td>5.454934e-01</td>\n",
       "      <td>7.294120e-01</td>\n",
       "      <td>9.984917e-01</td>\n",
       "      <td>7.195234e-01</td>\n",
       "      <td>7.226521e-01</td>\n",
       "      <td>9.106348e-01</td>\n",
       "      <td>6.672263e-01</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            311.168       269.249       215.033       295.227       883.533  \\\n",
       "count  6.057000e+03  6.057000e+03  6.057000e+03  6.057000e+03  6.057000e+03   \n",
       "mean   2.786097e-18  6.620646e-17 -1.434290e-17 -1.438873e-18  4.710337e-16   \n",
       "std    1.259709e-01  1.439456e-01  1.644742e-01  1.354221e-01  1.830145e-01   \n",
       "min   -3.936976e-01 -4.211962e-01 -3.062371e-01 -4.545066e-01 -2.705880e-01   \n",
       "25%   -7.672668e-02 -6.810890e-02 -9.447482e-02 -6.188994e-02 -1.155605e-01   \n",
       "50%    9.552356e-03 -6.986512e-03  1.677855e-02  1.774746e-02  3.213359e-02   \n",
       "75%    9.000432e-02  5.958404e-02  1.127961e-01  7.451773e-02  1.324455e-01   \n",
       "max    6.063024e-01  5.788038e-01  6.937629e-01  5.454934e-01  7.294120e-01   \n",
       "\n",
       "            309.172       738.505       435.296       250.145       514.284  \\\n",
       "count  6.057000e+03  6.057000e+03  6.057000e+03  6.057000e+03  6.057000e+03   \n",
       "mean  -5.057534e-18  1.524563e-16  7.979419e-16 -4.598716e-15  2.271036e-17   \n",
       "std    3.246305e-02  1.277902e-01  2.078016e-01  1.914162e-01  1.330269e-01   \n",
       "min   -1.508251e-03 -2.804766e-01 -2.773479e-01 -8.936520e-02 -3.327737e-01   \n",
       "25%   -1.508251e-03 -5.989332e-02 -2.773479e-01 -8.936520e-02 -6.633072e-02   \n",
       "50%   -1.508251e-03  1.466426e-02  6.586256e-03 -8.936520e-02 -1.852649e-02   \n",
       "75%   -1.508251e-03  6.962831e-02  1.670720e-01 -1.214997e-03  8.939424e-02   \n",
       "max    9.984917e-01  7.195234e-01  7.226521e-01  9.106348e-01  6.672263e-01   \n",
       "\n",
       "              type  \n",
       "count  6057.000000  \n",
       "mean      0.500248  \n",
       "std       0.500041  \n",
       "min       0.000000  \n",
       "25%       0.000000  \n",
       "50%       1.000000  \n",
       "75%       1.000000  \n",
       "max       1.000000  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ROI_for_ML_Opti_di.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c25aab6",
   "metadata": {},
   "source": [
    "## 2.2. PCA Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e9735181",
   "metadata": {},
   "outputs": [],
   "source": [
    "## PCA Analysis\n",
    "\n",
    "def pca_visual(df=df_ROI_for_ML_Opti_di):\n",
    "\n",
    "    pca = PCA(n_components=3)\n",
    "    raMSI_ML_mz_df = df.drop(\"type\", axis = 1)\n",
    "    pca.fit(raMSI_ML_mz_df)\n",
    "    result = pd.DataFrame(pca.transform(raMSI_ML_mz_df), columns=['PCA%i' % i for i in range(3)], index=df_ROI_for_ML_Opti_di.index)\n",
    "    \n",
    "    plt.subplots(dpi = 300)\n",
    "    plt.scatter(result['PCA1'], result['PCA2'], c = df['type'], s=1)\n",
    "    plt.xlabel('PC1', size=20)\n",
    "    plt.ylabel('PC2', size=20)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    plt.savefig(r\"H:/3_output_raMSIn/3_3_Output_raMSIn_HKU_Ingested4ALL/XGB_ALL/afterModelSelection/cbMSIn_0d001/PCA_di.tif\", bbox_inches = 'tight')\n",
    "\n",
    "    components = pca.fit_transform(raMSI_ML_mz_df)\n",
    "    total_var = pca.explained_variance_ratio_.sum() * 100\n",
    "    fig = px.scatter_3d(\n",
    "        components, x=0, y=1, z=2, color=df['type'],\n",
    "        title = f'Total Explained Variance: {total_var:.2f}%',\n",
    "        labels = {'0': 'PC 1', '1': 'PC 2', '2': 'PC 3'}\n",
    "    )\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a507a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_visual()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a0c5f5",
   "metadata": {},
   "source": [
    "# 3. Supervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cdf76b0",
   "metadata": {},
   "source": [
    "## 3.1. Preparation of training and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a9518fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(df=df_ROI_for_ML_Opti_ingested):\n",
    "    raMSI_ML_NoType = df.drop(\"type\", axis = 1)\n",
    "    raMSI_ML_Type=df[['type']]\n",
    "    X_train,X_test,y_train,y_test=train_test_split(raMSI_ML_NoType,raMSI_ML_Type,test_size=0.2,random_state=42)\n",
    "    return X_train,X_test,y_train,y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7a5146",
   "metadata": {},
   "source": [
    "X_train,X_test,y_train,y_test=split_dataset(df=df_ROI_for_ML_Opti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "92b9ff22",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ingested = df_ROI_for_ML_Opti_ingested[df_ROI_for_ML_Opti_ingested.columns[:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "071b9d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ingested = df_ROI_for_ML_Opti_ingested[df_ROI_for_ML_Opti_ingested.columns[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "78235c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_ROI_for_ML_Opti_train[df_ROI_for_ML_Opti_train.columns[:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "226a001d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_ROI_for_ML_Opti_train[df_ROI_for_ML_Opti_train.columns[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "21066a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = df_ROI_for_ML_Opti_ext[df_ROI_for_ML_Opti_ext.columns[:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "375fd7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val = df_ROI_for_ML_Opti_ext[df_ROI_for_ML_Opti_ext.columns[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "460faa79",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_FNA = df_ROI_for_ML_Opti_FNA[df_ROI_for_ML_Opti_FNA.columns[:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "dd2eede7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_FNA = df_ROI_for_ML_Opti_FNA[df_ROI_for_ML_Opti_FNA.columns[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c1e0ca85",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_di = df_ROI_for_ML_Opti_di[df_ROI_for_ML_Opti_di.columns[:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3529c5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_di = df_ROI_for_ML_Opti_di[df_ROI_for_ML_Opti_di.columns[-1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02cd4f6d",
   "metadata": {},
   "source": [
    "## 3.2 Machine Learning Modeling: Model 1+2 (Train 10:10, Val 4:4, Test 3:3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6d458bee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 720x720 with 0 Axes>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from matplotlib.pyplot import figure\n",
    "plt.rcParams['figure.figsize'] = [10, 10]\n",
    "plt.grid(visible=None)\n",
    "plt.close()\n",
    "figure(figsize=(10, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462143af",
   "metadata": {},
   "source": [
    "### 3.2.1. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2bdf27e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build Logistic Regression Model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def LogisticRegression_func(XTrain=X_ingested, XVal=X_val, XTest=X_FNA, yTrain=y_ingested, yVal=y_val, yTest=y_FNA):\n",
    "    model_lr = LogisticRegression(C=0.001, penalty='l1', solver=\"liblinear\", max_iter=5000, random_state=42, class_weight={0:0.9628, 1:1.0402})  # max_iter=100\n",
    "    model_lr.fit(XTrain,yTrain)\n",
    "    \n",
    "    # Training Set\n",
    "    #plt.rcParams[\"figure.figsize\"] = (3,3)\n",
    "    X_train_predictions = model_lr.predict(X_train)\n",
    "    print(\"Training Set F1:\", f1_score(y_train, model_lr.predict(X_train), sample_weight=sampleW))\n",
    "    print(\"Training Set MCC:\", matthews_corrcoef(y_train, model_lr.predict(X_train), sample_weight=sampleW))\n",
    "    print(\"Training Set Accuracy:\", metrics.accuracy_score(y_train, X_train_predictions))\n",
    "    print(classification_report(y_train, X_train_predictions))\n",
    "    print(confusion_matrix(y_train, X_train_predictions))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr, tpr, _ = metrics.roc_curve(y_train, X_train_predictions)\n",
    "    plt.plot(fpr,tpr)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_train.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    # Val set\n",
    "    predictions_val  = model_lr.predict(XVal)\n",
    "    print(\"Ext Val Set F1:\", f1_score(yVal, model_lr.predict(XVal), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set MCC:\", matthews_corrcoef(yVal, model_lr.predict(XVal), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set Accuracy:\", metrics.accuracy_score(yVal, predictions_val))\n",
    "    print(classification_report(yVal, predictions_val))\n",
    "    print(confusion_matrix(yVal, predictions_val))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_val, tpr_val, _ = metrics.roc_curve(yVal, predictions_val)\n",
    "    plt.plot(fpr_val,tpr_val)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_test.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    f1_5_train = cross_val_score(model_lr, XTrain, yTrain, cv = 5, scoring=\"f1\")\n",
    "    print(\"5F-CV:\", avgScore(f1_5_train, 5))\n",
    "    \n",
    "    # Test set\n",
    "    predictions_FNA = model_lr.predict(XTest)\n",
    "    print(\"FNA Set F1:\", f1_score(yTest, model_lr.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set MCC:\", matthews_corrcoef(yTest, model_lr.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set Recall:\", recall_score(yTest, model_lr.predict(XTest)))\n",
    "    print(\"FNA Test Set Accuracy:\", metrics.accuracy_score(yTest, predictions_FNA))\n",
    "    print(classification_report(yTest, predictions_FNA))\n",
    "    print(confusion_matrix(yTest, predictions_FNA))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_FNA, tpr_FNA, _ = metrics.roc_curve(yTest, predictions_FNA)\n",
    "    plt.plot(fpr_FNA,tpr_FNA)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"G:/raMSIn/XGB_Importance2/XGB2_ROC_FNAtest2.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    # Visualize the importantance of the features\n",
    "    feature_imp = pd.Series(model_lr.coef_[0], index=XTrain.columns).sort_values(ascending=False)\n",
    "    x=feature_imp\n",
    "    y=feature_imp.index\n",
    "    \n",
    "    plt.subplots(dpi = 300)\n",
    "    #plt.rcParams[\"figure.figsize\"] = [4, 6]\n",
    "    #plt.rcParams[\"font.family\"] = \"Arial\"\n",
    "    #plt.rcParams.update({'font.size': 6})\n",
    "    plt.xlabel('Feature Importance Score', fontproperties='Arial', fontsize=17)\n",
    "    plt.ylabel('Features', fontproperties='Arial', fontsize=17)\n",
    "    plt.xticks(fontsize=15)\n",
    "    plt.yticks(fontsize=15)\n",
    "    plt.title(\"Important Molecular Features\", fontproperties='Arial', fontsize=20)\n",
    "    sns.barplot(x=feature_imp, y=feature_imp.index)\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_TopFeatures.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    #feature_importances = model_lr.coef_[0]\n",
    "    #feature_df=pd.DataFrame({'m/z':XTrain.columns,'coef':feature_importances})\n",
    "\n",
    "    #fig = px.bar(feature_df, x='coef', y='m/z')\n",
    "    #fig.show()\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e4810838",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set F1: 0.8390982668238988\n",
      "Training Set MCC: 0.6791888928889686\n",
      "Training Set Accuracy: 0.8397207563764292\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.84      0.85     47449\n",
      "           1       0.83      0.84      0.83     43511\n",
      "\n",
      "    accuracy                           0.84     90960\n",
      "   macro avg       0.84      0.84      0.84     90960\n",
      "weighted avg       0.84      0.84      0.84     90960\n",
      "\n",
      "[[39983  7466]\n",
      " [ 7113 36398]]\n",
      "Ext Val Set F1: 0.8155151465528109\n",
      "Ext Val Set MCC: 0.6047170472841887\n",
      "Ext Val Set Accuracy: 0.7976954732510289\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.68      0.76      2943\n",
      "           1       0.75      0.91      0.82      3132\n",
      "\n",
      "    accuracy                           0.80      6075\n",
      "   macro avg       0.81      0.79      0.79      6075\n",
      "weighted avg       0.81      0.80      0.79      6075\n",
      "\n",
      "[[1995  948]\n",
      " [ 281 2851]]\n",
      "5F-CV: 0.628095702338524\n",
      "FNA Set F1: 0.74656967408123\n",
      "FNA Set MCC: 0.49464513815727446\n",
      "FNA Set Recall: 0.7443445574149136\n",
      "FNA Test Set Accuracy: 0.7473309207337009\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.75      0.75     44540\n",
      "           1       0.75      0.74      0.75     44161\n",
      "\n",
      "    accuracy                           0.75     88701\n",
      "   macro avg       0.75      0.75      0.75     88701\n",
      "weighted avg       0.75      0.75      0.75     88701\n",
      "\n",
      "[[33418 11122]\n",
      " [11290 32871]]\n"
     ]
    }
   ],
   "source": [
    "coeff_LogReg, TOPfeatures_LogReg = LogisticRegression_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b7a08c",
   "metadata": {},
   "source": [
    "### 3.2.2. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "aab84224",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build LinearSVC Model\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "def LinearSVC_func(XTrain=X_ingested, XVal=X_val, XTest=X_FNA, yTrain=y_ingested, yVal=y_val, yTest=y_FNA):\n",
    "    model_svm = LinearSVC(penalty='l2', loss=\"squared_hinge\", C=461, random_state=42, class_weight={0:0.9628, 1:1.0402})\n",
    "    model_svm.fit(XTrain,yTrain)\n",
    "    \n",
    "    # Training Set\n",
    "    #plt.rcParams[\"figure.figsize\"] = (3,3)\n",
    "    X_train_predictions = model_svm.predict(X_train)\n",
    "    print(\"Training Set F1:\", f1_score(y_train, model_svm.predict(X_train), sample_weight=sampleW))\n",
    "    print(\"Training Set MCC:\", matthews_corrcoef(y_train, model_svm.predict(X_train), sample_weight=sampleW))\n",
    "    print(\"Training Set Accuracy:\", metrics.accuracy_score(y_train, X_train_predictions))\n",
    "    print(classification_report(y_train, X_train_predictions))\n",
    "    print(confusion_matrix(y_train, X_train_predictions))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr, tpr, _ = metrics.roc_curve(y_train, X_train_predictions)\n",
    "    plt.plot(fpr,tpr)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_train.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    # Val set\n",
    "    predictions_val  = model_svm.predict(XVal)\n",
    "    print(\"Ext Val Set F1:\", f1_score(yVal, model_svm.predict(XVal), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set MCC:\", matthews_corrcoef(yVal, model_svm.predict(XVal), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set Accuracy:\", metrics.accuracy_score(yVal, predictions_val))\n",
    "    print(classification_report(yVal, predictions_val))\n",
    "    print(confusion_matrix(yVal, predictions_val))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_val, tpr_val, _ = metrics.roc_curve(yVal, predictions_val)\n",
    "    plt.plot(fpr_val,tpr_val)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_test.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    f1_5_train = cross_val_score(model_svm, XTrain, yTrain, cv = 5, scoring=\"f1\")\n",
    "    print(\"5F-CV:\", avgScore(f1_5_train, 5))\n",
    "    \n",
    "    # Test set\n",
    "    predictions_FNA = model_svm.predict(XTest)\n",
    "    print(\"FNA Set F1:\", f1_score(yTest, model_svm.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set MCC:\", matthews_corrcoef(yTest, model_svm.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set Recall:\", recall_score(yTest, model_svm.predict(XTest)))\n",
    "    print(\"FNA Test Set Accuracy:\", metrics.accuracy_score(yTest, predictions_FNA))\n",
    "    print(classification_report(yTest, predictions_FNA))\n",
    "    print(confusion_matrix(yTest, predictions_FNA))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_FNA, tpr_FNA, _ = metrics.roc_curve(yTest, predictions_FNA)\n",
    "    plt.plot(fpr_FNA,tpr_FNA)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"G:/raMSIn/XGB_Importance2/XGB2_ROC_FNAtest2.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    # Visualize the importantance of the features\n",
    "    feature_imp = pd.Series(model_svm.coef_[0], index=XTrain.columns).sort_values(ascending=False)\n",
    "    x=feature_imp\n",
    "    y=feature_imp.index\n",
    "    \n",
    "    plt.subplots(dpi = 300)\n",
    "    #plt.rcParams[\"figure.figsize\"] = [4, 6]\n",
    "    #plt.rcParams[\"font.family\"] = \"Arial\"\n",
    "    #plt.rcParams.update({'font.size': 6})\n",
    "    plt.xlabel('Feature Importance Score', fontproperties='Arial', fontsize=17)\n",
    "    plt.ylabel('Features', fontproperties='Arial', fontsize=17)\n",
    "    plt.xticks(fontsize=15)\n",
    "    plt.yticks(fontsize=15)\n",
    "    plt.title(\"Important Molecular Features\", fontproperties='Arial', fontsize=20)\n",
    "    sns.barplot(x=feature_imp, y=feature_imp.index)\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_TopFeatures.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    #feature_importances = model_svm.coef_[0]\n",
    "    #feature_df=pd.DataFrame({'m/z':XTrain.columns,'coef':feature_importances})\n",
    "\n",
    "    #fig = px.bar(feature_df, x='coef', y='m/z')\n",
    "    #fig.show()\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "78a85b62",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set F1: 0.8797283533548552\n",
      "Training Set MCC: 0.7565608917496852\n",
      "Training Set Accuracy: 0.8775835532102023\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.87      0.88     47449\n",
      "           1       0.86      0.89      0.87     43511\n",
      "\n",
      "    accuracy                           0.88     90960\n",
      "   macro avg       0.88      0.88      0.88     90960\n",
      "weighted avg       0.88      0.88      0.88     90960\n",
      "\n",
      "[[41046  6403]\n",
      " [ 4732 38779]]\n",
      "Ext Val Set F1: 0.8277768644493677\n",
      "Ext Val Set MCC: 0.6533037808217003\n",
      "Ext Val Set Accuracy: 0.8268312757201646\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      2943\n",
      "           1       0.83      0.83      0.83      3132\n",
      "\n",
      "    accuracy                           0.83      6075\n",
      "   macro avg       0.83      0.83      0.83      6075\n",
      "weighted avg       0.83      0.83      0.83      6075\n",
      "\n",
      "[[2413  530]\n",
      " [ 522 2610]]\n",
      "5F-CV: 0.9077546357959191\n",
      "FNA Set F1: 0.6315512601979377\n",
      "FNA Set MCC: 0.22368244328813516\n",
      "FNA Set Recall: 0.6664930594868775\n",
      "FNA Test Set Accuracy: 0.6109175770284438\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.56      0.59     44540\n",
      "           1       0.60      0.67      0.63     44161\n",
      "\n",
      "    accuracy                           0.61     88701\n",
      "   macro avg       0.61      0.61      0.61     88701\n",
      "weighted avg       0.61      0.61      0.61     88701\n",
      "\n",
      "[[24756 19784]\n",
      " [14728 29433]]\n"
     ]
    }
   ],
   "source": [
    "coeff_SVM, TOPfeatures_SVM = LinearSVC_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e84218",
   "metadata": {},
   "source": [
    "### 3.2.3. GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "44b76c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build GBM Model\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "def GBM_func(XTrain=X_ingested, XVal=X_val, XTest=X_FNA, yTrain=y_ingested, yVal=y_val, yTest=y_FNA):\n",
    "    model_gbm = GradientBoostingClassifier(learning_rate=4, n_estimators=50, max_depth=7, min_samples_leaf=4, min_samples_split=30, n_iter_no_change=5, random_state=42)\n",
    "    model_gbm.fit(XTrain,yTrain)\n",
    "    \n",
    "    # Training Set\n",
    "    #plt.rcParams[\"figure.figsize\"] = (3,3)\n",
    "    X_train_predictions = model_gbm.predict(X_train)\n",
    "    print(\"Training Set F1:\", f1_score(y_train, model_gbm.predict(X_train), sample_weight=sampleW))\n",
    "    print(\"Training Set MCC:\", matthews_corrcoef(y_train, model_gbm.predict(X_train), sample_weight=sampleW))\n",
    "    print(\"Training Set Accuracy:\", metrics.accuracy_score(y_train, X_train_predictions))\n",
    "    print(classification_report(y_train, X_train_predictions))\n",
    "    print(confusion_matrix(y_train, X_train_predictions))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr, tpr, _ = metrics.roc_curve(y_train, X_train_predictions)\n",
    "    plt.plot(fpr,tpr)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_train.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    # Val set\n",
    "    predictions_val  = model_gbm.predict(XVal)\n",
    "    print(\"Ext Val Set F1:\", f1_score(yVal, model_gbm.predict(XVal), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set MCC:\", matthews_corrcoef(yVal, model_gbm.predict(XVal), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set Accuracy:\", metrics.accuracy_score(yVal, predictions_val))\n",
    "    print(classification_report(yVal, predictions_val))\n",
    "    print(confusion_matrix(yVal, predictions_val))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_val, tpr_val, _ = metrics.roc_curve(yVal, predictions_val)\n",
    "    plt.plot(fpr_val,tpr_val)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_test.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    f1_5_train = cross_val_score(model_gbm, XTrain, yTrain, cv = 5, scoring=\"f1\")\n",
    "    print(\"5F-CV:\", avgScore(f1_5_train, 5))\n",
    "    \n",
    "    # Test set\n",
    "    predictions_FNA = model_gbm.predict(XTest)\n",
    "    print(\"FNA Set F1:\", f1_score(yTest, model_gbm.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set MCC:\", matthews_corrcoef(yTest, model_gbm.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set Recall:\", recall_score(yTest, model_gbm.predict(XTest)))\n",
    "    print(\"FNA Test Set Accuracy:\", metrics.accuracy_score(yTest, predictions_FNA))\n",
    "    print(classification_report(yTest, predictions_FNA))\n",
    "    print(confusion_matrix(yTest, predictions_FNA))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_FNA, tpr_FNA, _ = metrics.roc_curve(yTest, predictions_FNA)\n",
    "    plt.plot(fpr_FNA,tpr_FNA)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"G:/raMSIn/XGB_Importance2/XGB2_ROC_FNAtest2.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    # Visualize the importantance of the features\n",
    "    feature_imp = pd.Series(model_gbm.feature_importances_, index=XTrain.columns).sort_values(ascending=False)\n",
    "    x=feature_imp\n",
    "    y=feature_imp.index\n",
    "    \n",
    "    plt.subplots(dpi = 300)\n",
    "    #plt.rcParams[\"figure.figsize\"] = [4, 6]\n",
    "    #plt.rcParams[\"font.family\"] = \"Arial\"\n",
    "    #plt.rcParams.update({'font.size': 6})\n",
    "    plt.xlabel('Feature Importance Score', fontproperties='Arial', fontsize=17)\n",
    "    plt.ylabel('Features', fontproperties='Arial', fontsize=17)\n",
    "    plt.xticks(fontsize=15)\n",
    "    plt.yticks(fontsize=15)\n",
    "    plt.title(\"Important Molecular Features\", fontproperties='Arial', fontsize=20)\n",
    "    sns.barplot(x=feature_imp, y=feature_imp.index)\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/XGB_TopFeatures.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    # Visualize the boxplot of the important features between the two groups\n",
    "    #fig = px.box(data_frame = df_ROI_for_ML_Opti, x = feature_imp[:10].index,color= 'type')\n",
    "    #fig.show()\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2dcef352",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set F1: 0.3387704774653022\n",
      "Training Set MCC: 0.10187904349252903\n",
      "Training Set Accuracy: 0.5535729991204925\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.85      0.66     47449\n",
      "           1       0.58      0.24      0.34     43511\n",
      "\n",
      "    accuracy                           0.55     90960\n",
      "   macro avg       0.56      0.54      0.50     90960\n",
      "weighted avg       0.56      0.55      0.51     90960\n",
      "\n",
      "[[40107  7342]\n",
      " [33265 10246]]\n",
      "Ext Val Set F1: 0.19208499371408716\n",
      "Ext Val Set MCC: -0.11284184526582608\n",
      "Ext Val Set Accuracy: 0.44724279835390945\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.79      0.58      2943\n",
      "           1       0.39      0.13      0.19      3132\n",
      "\n",
      "    accuracy                           0.45      6075\n",
      "   macro avg       0.42      0.46      0.39      6075\n",
      "weighted avg       0.42      0.45      0.38      6075\n",
      "\n",
      "[[2313  630]\n",
      " [2728  404]]\n",
      "5F-CV: 0.6475279700575391\n",
      "FNA Set F1: 0.45777786179352775\n",
      "FNA Set MCC: 0.0669081452881185\n",
      "FNA Set Recall: 0.3949638821584656\n",
      "FNA Test Set Accuracy: 0.5327561132343491\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.67      0.59     44540\n",
      "           1       0.54      0.39      0.46     44161\n",
      "\n",
      "    accuracy                           0.53     88701\n",
      "   macro avg       0.53      0.53      0.52     88701\n",
      "weighted avg       0.53      0.53      0.52     88701\n",
      "\n",
      "[[29814 14726]\n",
      " [26719 17442]]\n"
     ]
    }
   ],
   "source": [
    "coeff_GBM, TOPfeatures_GBM = GBM_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98e2c8c",
   "metadata": {},
   "source": [
    "### 3.2.4. Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "79af839d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StackingRegressor():\n",
    "    \n",
    "    def __init__(self, learners):\n",
    "        self.level_sizes = []\n",
    "        self.learners = []\n",
    "        \n",
    "        for learning_level in learners:\n",
    "            self.level_sizes.append(len(learning_level))\n",
    "            level_learners = []\n",
    "            \n",
    "            for learner in learning_level:\n",
    "                level_learners.append(deepcopy(learner))\n",
    "            self.learners.append(level_learners)\n",
    "            \n",
    "            \n",
    "    def fit(self, x, y):\n",
    "        \n",
    "        meta_data = [x,x,x]\n",
    "        meta_targets = [y,y,y]\n",
    "        \n",
    "        for i in range(len(self.learners)):\n",
    "            level_size = self.level_sizes[i]\n",
    "            \n",
    "            data_z = np.zeros((level_size, len(x)))\n",
    "            target_z = np.zeros(len(x))\n",
    "            \n",
    "            train_x = meta_data[i]\n",
    "            train_y = meta_targets[i]\n",
    "            \n",
    "            # Define number of folds\n",
    "            num_folds = 5\n",
    "            \n",
    "            # Create the k-fold cross-validation object\n",
    "            KF = KFold(n_splits=num_folds)\n",
    "            m = 0\n",
    "\n",
    "            # Loop over each fold of the cross-validation\n",
    "            for train_indices, test_indices in KF.split(x):\n",
    "                \n",
    "                for j in range(len(self.learners[i])):\n",
    "                    train_x = pd.DataFrame(train_x)\n",
    "                    train_y = pd.DataFrame(train_y)\n",
    "\n",
    "                    learner = self.learners[i][j]\n",
    "                    learner.fit(train_x.iloc[train_indices], train_y.iloc[train_indices])\n",
    "                    p = learner.predict(train_x.iloc[test_indices])\n",
    "                    data_z[j][m: m+len(test_indices) ] = p\n",
    "\n",
    "\n",
    "                train_y = pd.DataFrame(train_y)\n",
    "                train_y_array = (np.array(train_y)).reshape(-1,)\n",
    "                zty_ind = (np.array(train_y.iloc[test_indices])).reshape(-1,)\n",
    "                target_z[m: m+len(test_indices)] = train_y_array[zty_ind]\n",
    "                m += len(test_indices)\n",
    "                \n",
    "\n",
    "            data_z = data_z.transpose()\n",
    "            meta_data.append(data_z)\n",
    "            meta_targets.append(target_z)\n",
    "            \n",
    "            \n",
    "            for learner in self.learners[i]:\n",
    "                train_x = pd.DataFrame(train_x)\n",
    "                train_y = pd.DataFrame(train_y)\n",
    "                learner.fit(train_x, train_y)\n",
    "                \n",
    "                \n",
    "    def predict(self, x):\n",
    "        \n",
    "        meta_data = [x,x,x]\n",
    "        for i in range(len(self.learners)):\n",
    "            \n",
    "            level_size = self.level_sizes[i]\n",
    "            \n",
    "            data_z = np.zeros((level_size, len(x)))\n",
    "            \n",
    "            test_x = meta_data[i]\n",
    "            \n",
    "            for j in range(len(self.learners[i])):\n",
    "                \n",
    "                learner = self.learners[i][j]\n",
    "                predictions = learner.predict(test_x)\n",
    "                data_z[j] = predictions\n",
    "                \n",
    "            \n",
    "            data_z = data_z.transpose()\n",
    "            meta_data.append(data_z)\n",
    "            \n",
    "        return meta_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3fb1ee36",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build stacking Model\n",
    "\n",
    "def Stacking_func(XTrain=X_ingested, XVal=X_val, XTest=X_FNA, XTest2=X_di, yTrain=y_ingested, yVal=y_val, yTest=y_FNA, yTest2=y_di):\n",
    "\n",
    "    base_learners = []\n",
    "\n",
    "    # Define models to use in stacking ensemble\n",
    "    m1 = LogisticRegression(C=0.001, penalty='l1', solver=\"liblinear\", max_iter=5000, random_state=42, class_weight={0:0.9628, 1:1.0402})\n",
    "    base_learners.append(m1)\n",
    "\n",
    "    m2 = LinearSVC(penalty='l2', loss=\"squared_hinge\", C=461, random_state=42, class_weight={0:0.9628, 1:1.0402})\n",
    "    base_learners.append(m2)\n",
    "\n",
    "    m3 = GradientBoostingClassifier(learning_rate=4, n_estimators=50, max_depth=7, min_samples_leaf=4, min_samples_split=30, n_iter_no_change=5, random_state=42)\n",
    "    base_learners.append(m3)\n",
    "\n",
    "    # Define the meta-classifier to use for stacking\n",
    "    #meta_learner = LinearDiscriminantAnalysis()  # 0.90,0.80; 0.75,0.51; 0.65,0.27; 0.64,0.26\n",
    "    #meta_learner = QuadraticDiscriminantAnalysis()  # 0.93,0.86; 0.67,0.39; 0.67,0.15; 0.68,0.20\n",
    "    \n",
    "    #meta_learner = LogisticRegression()  # 0.90,0.79; 0.82,0.65; 0.64,0.24; 0.64;0.27\n",
    "    #meta_learner = LogisticRegression(C=1, penalty='l1', solver=\"liblinear\", max_iter=5000, random_state=42)\n",
    "    ## C=1: 0.90,0.79; 0.82,0.65; 0.65,0.25; 0.65;0.27\n",
    "    #meta_learner = LogisticRegression(C=0.1, penalty='l1', solver=\"liblinear\", max_iter=5000, random_state=42)\n",
    "    ## C=0.1: 0.90,0.79; 0.82,0.65; 0.65,0.25; 0.65;0.28\n",
    "    #meta_learner = LogisticRegression(C=0.01, penalty='l1', solver=\"liblinear\", max_iter=5000, random_state=42)\n",
    "    ## C=0.01: 0.89,0.78; 0.81,0.63; 0.63,0.22; 0.65;0.29\n",
    "    #meta_learner = LogisticRegression(C=0.0075, penalty='l1', solver=\"liblinear\", max_iter=5000, random_state=42)\n",
    "    ## C=0.0075: 0.89,0.77; 0.81,0.63; 0.62,0.20; 0.65;0.29\n",
    "    #meta_learner = LogisticRegression(C=0.005, penalty='l1', solver=\"liblinear\", max_iter=5000, random_state=42)\n",
    "    ## C=0.005: 0.88,0.76; 0.82,0.64; 0.60,0.17; 0.66;0.31\n",
    "    #meta_learner = LogisticRegression(C=0.0025, penalty='l1', solver=\"liblinear\", max_iter=5000, random_state=42)\n",
    "    ## C=0.0025: 0.86,0.72; 0.83,0.66; 0.53,0.02; 0.64;0.31\n",
    "    #meta_learner = LogisticRegression(C=0.0015, penalty='l1', solver=\"liblinear\", max_iter=5000, random_state=42)\n",
    "    ## C=0.0015: 0.85,0.70; 0.80,0.60; 0.55,0.09; 0.64;0.30\n",
    "    #meta_learner = LogisticRegression(C=0.0013, penalty='l1', solver=\"liblinear\", max_iter=5000, random_state=42)\n",
    "    ## C=0.0013: 0.85,0.70; 0.78,0.56; 0.58,0.16; 0.63;0.29\n",
    "    #meta_learner = LogisticRegression(C=0.0012, penalty='l1', solver=\"liblinear\", max_iter=5000, random_state=42)\n",
    "    ## C=0.0012: 0.85,0.69; 0.77,0.52; 0.60,0.22; 0.63;0.27\n",
    "    meta_learner = LogisticRegression(C=0.0011, penalty='l1', solver=\"liblinear\", max_iter=5000, random_state=42)\n",
    "    ## C=0.0011: 0.85,0.69; 0.77,0.51; 0.64,0.30; 0.62;0.25\n",
    "    #meta_learner = LogisticRegression(C=0.001, penalty='l1', solver=\"liblinear\", max_iter=5000, random_state=42)\n",
    "    ## C=0.001: 0.84,0.68; 0.76,0.49; 0.68,0.38; 0.61;0.22\n",
    "    #meta_learner = LogisticRegression(C=0.0005, penalty='l1', solver=\"liblinear\", max_iter=5000, random_state=42)\n",
    "    ## C=0.0005: 0.83,0.66; 0.74,0.45; 0.65,0.37; 0.60;0.18\n",
    "    \n",
    "    #meta_learner = LinearSVC()  # 0.90,0.80; 0.82,0.65; 0.64,0.24; 0.65,0.27\n",
    "    #meta_learner = KNeighborsClassifier()  # 0.98,0.96; 0.65,0.30; 0.68,0.21; 0.52,-0.05\n",
    "    #meta_learner = DecisionTreeClassifier()  # 0.94,0.87; 0.54,0.15; 0.66,0.11; 0.46,-0.11\n",
    "    #meta_learner = RandomForestClassifier()  # 0.98,0.95; 0.54,0.20; 0.66,0.11; 0.49;-0.01\n",
    "    #meta_learner = GradientBoostingClassifier()  # 0.97,0.94; 0.56,0.27; 0.66,0.13; 0.48,-0.09\n",
    "    #meta_learner = AdaBoostClassifier()  # 0.96,0.93; 0.69,0.42; 0.62,0.10; 0.54,0.11\n",
    "    #meta_learner = xgb.XGBClassifier()  # 0.98,0.95; 0.59,0.30; 0.66,0.10; 0.44,-0.12\n",
    "\n",
    "    model_sc = StackingRegressor([[m1, m2, m3], [meta_learner]])\n",
    "    model_sc.fit(XTrain, yTrain)\n",
    "    \n",
    "    #=======================================\n",
    "    \n",
    "    # Training Set\n",
    "    #plt.rcParams[\"figure.figsize\"] = (3,3)\n",
    "    X_train_predictions = model_sc.predict(X_train)[-1]\n",
    "    print(\"Training Set F1:\", f1_score(y_train, model_sc.predict(X_train)[-1], sample_weight=sampleW))\n",
    "    print(\"Training Set MCC:\", matthews_corrcoef(y_train, model_sc.predict(X_train)[-1], sample_weight=sampleW))\n",
    "    print(\"Training Set Accuracy:\", metrics.accuracy_score(y_train, X_train_predictions))\n",
    "    print(classification_report(y_train, X_train_predictions))\n",
    "    print(confusion_matrix(y_train, X_train_predictions))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr, tpr, _ = metrics.roc_curve(y_train, X_train_predictions)\n",
    "    plt.plot(fpr,tpr)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_train.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    # Val set\n",
    "    predictions_val  = model_sc.predict(XVal)[-1]\n",
    "    print(\"Ext Val Set F1:\", f1_score(yVal, model_sc.predict(XVal)[-1], sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set MCC:\", matthews_corrcoef(yVal, model_sc.predict(XVal)[-1], sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set Accuracy:\", metrics.accuracy_score(yVal, predictions_val))\n",
    "    print(classification_report(yVal, predictions_val))\n",
    "    print(confusion_matrix(yVal, predictions_val))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_val, tpr_val, _ = metrics.roc_curve(yVal, predictions_val)\n",
    "    plt.plot(fpr_val,tpr_val)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_test.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    #f1_5_train = cross_val_score(model_sc, XTrain, yTrain, cv = 5, scoring=\"f1\")\n",
    "    #print(\"5F-CV:\", avgScore(f1_5_train, 5))\n",
    "    \n",
    "    # Test set\n",
    "    predictions_FNA = model_sc.predict(XTest)[-1]\n",
    "    print(\"FNA Set F1:\", f1_score(yTest, model_sc.predict(XTest)[-1], sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set MCC:\", matthews_corrcoef(yTest, model_sc.predict(XTest)[-1], sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set Recall:\", recall_score(yTest, model_sc.predict(XTest)[-1]))\n",
    "    print(\"FNA Test Set Accuracy:\", metrics.accuracy_score(yTest, predictions_FNA))\n",
    "    print(classification_report(yTest, predictions_FNA))\n",
    "    print(confusion_matrix(yTest, predictions_FNA))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_FNA, tpr_FNA, _ = metrics.roc_curve(yTest, predictions_FNA)\n",
    "    plt.plot(fpr_FNA,tpr_FNA)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"G:/raMSIn/XGB_Importance2/XGB2_ROC_FNAtest2.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    # Test2 set\n",
    "    predictions_di = model_sc.predict(XTest2)[-1]\n",
    "    print(\"DirectIn Set F1:\", f1_score(yTest2, model_sc.predict(XTest2)[-1], sample_weight=sampleDiW))\n",
    "    print(\"DirectIn Set MCC:\", matthews_corrcoef(yTest2, model_sc.predict(XTest2)[-1], sample_weight=sampleDiW))\n",
    "    print(\"DirectIn Set Recall:\", recall_score(yTest2, model_sc.predict(XTest2)[-1]))\n",
    "    print(\"DirectIn Test Set Accuracy:\", metrics.accuracy_score(yTest2, predictions_di))\n",
    "    print(classification_report(yTest2, predictions_di))\n",
    "    print(confusion_matrix(yTest2, predictions_di))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_di, tpr_di, _ = metrics.roc_curve(yTest2, predictions_di)\n",
    "    plt.plot(fpr_di,tpr_di)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"G:/raMSIn/XGB_Importance2/XGB2_ROC_FNAtest2.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e01c13ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set F1: 0.8406163945092073\n",
      "Training Set MCC: 0.682009460263964\n",
      "Training Set Accuracy: 0.8411059806508355\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.84      0.85     47449\n",
      "           1       0.83      0.84      0.83     43511\n",
      "\n",
      "    accuracy                           0.84     90960\n",
      "   macro avg       0.84      0.84      0.84     90960\n",
      "weighted avg       0.84      0.84      0.84     90960\n",
      "\n",
      "[[40020  7429]\n",
      " [ 7024 36487]]\n",
      "Ext Val Set F1: 0.832423918527915\n",
      "Ext Val Set MCC: 0.6444376315589516\n",
      "Ext Val Set Accuracy: 0.8189300411522634\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.72      0.79      2943\n",
      "           1       0.77      0.91      0.84      3132\n",
      "\n",
      "    accuracy                           0.82      6075\n",
      "   macro avg       0.83      0.82      0.82      6075\n",
      "weighted avg       0.83      0.82      0.82      6075\n",
      "\n",
      "[[2110  833]\n",
      " [ 267 2865]]\n",
      "FNA Set F1: 0.7107423761966096\n",
      "FNA Set MCC: 0.4393255235974306\n",
      "FNA Set Recall: 0.689748873440366\n",
      "FNA Test Set Accuracy: 0.7194056436793271\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.75      0.73     44540\n",
      "           1       0.73      0.69      0.71     44161\n",
      "\n",
      "    accuracy                           0.72     88701\n",
      "   macro avg       0.72      0.72      0.72     88701\n",
      "weighted avg       0.72      0.72      0.72     88701\n",
      "\n",
      "[[33352 11188]\n",
      " [13701 30460]]\n",
      "DirectIn Set F1: 0.6751367242530236\n",
      "DirectIn Set MCC: 0.3582142135650891\n",
      "DirectIn Set Recall: 0.666996699669967\n",
      "DirectIn Test Set Accuracy: 0.6790490341753344\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.69      0.68      3027\n",
      "           1       0.68      0.67      0.68      3030\n",
      "\n",
      "    accuracy                           0.68      6057\n",
      "   macro avg       0.68      0.68      0.68      6057\n",
      "weighted avg       0.68      0.68      0.68      6057\n",
      "\n",
      "[[2092  935]\n",
      " [1009 2021]]\n"
     ]
    }
   ],
   "source": [
    "Stacking_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235227fc",
   "metadata": {},
   "source": [
    "### 3.2.5. Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "84be5513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a voting ensemble of models\n",
    "def get_voting():\n",
    "    models = list()\n",
    "    # Define the base models\n",
    "    models.append((\"m1\", LogisticRegression(C=0.001, penalty='l1', solver=\"liblinear\", max_iter=5000, random_state=42, class_weight={0:0.9628, 1:1.0402})))\n",
    "    models.append((\"m2\", LinearSVC(penalty='l2', loss=\"squared_hinge\", C=461, random_state=42, class_weight={0:0.9628, 1:1.0402})))\n",
    "    models.append((\"m3\", GradientBoostingClassifier(learning_rate=4, n_estimators=50, max_depth=7, min_samples_leaf=4, min_samples_split=30, n_iter_no_change=5, random_state=42)))\n",
    "\n",
    "    # define the voting ensemble\n",
    "    ensemble = VotingClassifier(estimators=models, voting='hard')\n",
    "    return ensemble\n",
    "\n",
    "# get a list of models to evaluate\n",
    "def get_models():\n",
    "    models = dict()\n",
    "    models['m1'] = LogisticRegression(C=0.001, penalty='l1', solver=\"liblinear\", max_iter=5000, random_state=42, class_weight={0:0.9628, 1:1.0402})\n",
    "    models['m2'] = LinearSVC(penalty='l2', loss=\"squared_hinge\", C=461, random_state=42, class_weight={0:0.9628, 1:1.0402})\n",
    "    models['m3'] = GradientBoostingClassifier(learning_rate=4, n_estimators=50, max_depth=7, min_samples_leaf=4, min_samples_split=30, n_iter_no_change=5, random_state=42)\n",
    "    models['hard_voting'] = get_voting()\n",
    "    return models\n",
    "\n",
    "\n",
    "# evaluate a give model using cross-validation\n",
    "def evaluate_model(model, XX, yy):\n",
    "    cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=10, random_state=42)\n",
    "    scores = cross_val_score(model, XX, yy, scoring='f1', cv=cv, n_jobs=-1, error_score='raise')\n",
    "    return scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2c7985bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 720x720 with 0 Axes>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from matplotlib.pyplot import figure\n",
    "plt.rcParams['figure.figsize'] = [10, 10]\n",
    "plt.close()\n",
    "figure(figsize=(10, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fab33d50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">m1 0.812 (0.003)\n",
      ">m2 0.935 (0.007)\n",
      ">m3 0.676 (0.127)\n",
      ">hard_voting 0.904 (0.019)\n"
     ]
    }
   ],
   "source": [
    "# get the models to evaluate\n",
    "models = get_models()\n",
    "\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "    scores = evaluate_model(model, XX=X_ingested, yy=y_ingested)\n",
    "    results.append(scores)\n",
    "    names.append(name)\n",
    "    print('>%s %.3f (%.3f)' % (name, np.mean(scores), np.std(scores)))\n",
    "    \n",
    "# plot model performance for comparison\n",
    "plt.subplots(dpi = 600)\n",
    "plt.boxplot(results, labels=names, showmeans=True)\n",
    "plt.ylabel('F1 score')\n",
    "plt.xlabel('Predictive Models')\n",
    "plt.savefig(r\"H:/3_output_raMSIn/3_3_Output_raMSIn_HKU_Ingested4ALL/XGB_ALL/afterModelSelection/cbMSIn_0d001/voting.jpg\", bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6832284f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Voting_func(XTrain=X_ingested, XVal=X_val, XTest=X_FNA, XTest2=X_di, yTrain=y_ingested, yVal=y_val, yTest=y_FNA, yTest2=y_di):\n",
    "\n",
    "    models = get_models()\n",
    "    \n",
    "    ensemble = models[\"hard_voting\"]\n",
    "    ensemble.fit(XTrain, yTrain)\n",
    "    #=======================================\n",
    "\n",
    "    # Training Set\n",
    "    #plt.rcParams[\"figure.figsize\"] = (3,3)\n",
    "    X_train_predictions = ensemble.predict(X_train)\n",
    "    print(\"Training Set F1:\", f1_score(y_train, ensemble.predict(X_train), sample_weight=sampleW))\n",
    "    print(\"Training Set MCC:\", matthews_corrcoef(y_train, ensemble.predict(X_train), sample_weight=sampleW))\n",
    "    print(\"Training Set Accuracy:\", metrics.accuracy_score(y_train, X_train_predictions))\n",
    "    print(classification_report(y_train, X_train_predictions))\n",
    "    print(confusion_matrix(y_train, X_train_predictions))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr, tpr, _ = metrics.roc_curve(y_train, X_train_predictions)\n",
    "    plt.plot(fpr,tpr)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_train.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    # Val set\n",
    "    predictions_val  = ensemble.predict(XVal)\n",
    "    print(\"Ext Val Set F1:\", f1_score(yVal, ensemble.predict(XVal), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set MCC:\", matthews_corrcoef(yVal, ensemble.predict(XVal), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set Accuracy:\", metrics.accuracy_score(yVal, predictions_val))\n",
    "    print(classification_report(yVal, predictions_val))\n",
    "    print(confusion_matrix(yVal, predictions_val))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_val, tpr_val, _ = metrics.roc_curve(yVal, predictions_val)\n",
    "    plt.plot(fpr_val,tpr_val)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_test.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    f1_5_train = cross_val_score(ensemble, XTrain, yTrain, cv = 5, scoring=\"f1\")\n",
    "    print(\"5F-CV:\", avgScore(f1_5_train, 5))\n",
    "\n",
    "    # Test set\n",
    "    predictions_FNA = ensemble.predict(XTest)\n",
    "    print(\"FNA Set F1:\", f1_score(yTest, ensemble.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set MCC:\", matthews_corrcoef(yTest, ensemble.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set Recall:\", recall_score(yTest, ensemble.predict(XTest)))\n",
    "    print(\"FNA Test Set Accuracy:\", metrics.accuracy_score(yTest, predictions_FNA))\n",
    "    print(classification_report(yTest, predictions_FNA))\n",
    "    print(confusion_matrix(yTest, predictions_FNA))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_FNA, tpr_FNA, _ = metrics.roc_curve(yTest, predictions_FNA)\n",
    "    plt.plot(fpr_FNA,tpr_FNA)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"G:/raMSIn/XGB_Importance2/XGB2_ROC_FNAtest2.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    # Test2 set\n",
    "    predictions_di = ensemble.predict(XTest2)\n",
    "    print(\"DirectIn Set F1:\", f1_score(yTest2, ensemble.predict(XTest2), sample_weight=sampleDiW))\n",
    "    print(\"DirectIn Set MCC:\", matthews_corrcoef(yTest2, ensemble.predict(XTest2), sample_weight=sampleDiW))\n",
    "    print(\"DirectIn Set Recall:\", recall_score(yTest2, ensemble.predict(XTest2)))\n",
    "    print(\"DirectIn Test Set Accuracy:\", metrics.accuracy_score(yTest2, predictions_di))\n",
    "    print(classification_report(yTest2, predictions_di))\n",
    "    print(confusion_matrix(yTest2, predictions_di))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_di, tpr_di, _ = metrics.roc_curve(yTest2, predictions_di)\n",
    "    plt.plot(fpr_di,tpr_di)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"G:/raMSIn/XGB_Importance2/XGB2_ROC_FNAtest2.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e3647683",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set F1: 0.8621242268490743\n",
      "Training Set MCC: 0.7249109771465304\n",
      "Training Set Accuracy: 0.8625549692172384\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.86      0.87     47449\n",
      "           1       0.85      0.86      0.86     43511\n",
      "\n",
      "    accuracy                           0.86     90960\n",
      "   macro avg       0.86      0.86      0.86     90960\n",
      "weighted avg       0.86      0.86      0.86     90960\n",
      "\n",
      "[[41036  6413]\n",
      " [ 6089 37422]]\n",
      "Ext Val Set F1: 0.8259854700197835\n",
      "Ext Val Set MCC: 0.6607549001846557\n",
      "Ext Val Set Accuracy: 0.8293004115226338\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.85      0.83      2943\n",
      "           1       0.85      0.81      0.83      3132\n",
      "\n",
      "    accuracy                           0.83      6075\n",
      "   macro avg       0.83      0.83      0.83      6075\n",
      "weighted avg       0.83      0.83      0.83      6075\n",
      "\n",
      "[[2511  432]\n",
      " [ 605 2527]]\n",
      "5F-CV: 0.8551381473771457\n",
      "FNA Set F1: 0.7068452106249302\n",
      "FNA Set MCC: 0.4057148563829135\n",
      "FNA Set Recall: 0.7166277937546705\n",
      "FNA Test Set Accuracy: 0.7027203751930643\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.69      0.70     44540\n",
      "           1       0.70      0.72      0.71     44161\n",
      "\n",
      "    accuracy                           0.70     88701\n",
      "   macro avg       0.70      0.70      0.70     88701\n",
      "weighted avg       0.70      0.70      0.70     88701\n",
      "\n",
      "[[30685 13855]\n",
      " [12514 31647]]\n",
      "DirectIn Set F1: 0.46475254038964925\n",
      "DirectIn Set MCC: 0.1600285258344838\n",
      "DirectIn Set Recall: 0.3706270627062706\n",
      "DirectIn Test Set Accuracy: 0.5730559683011391\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.78      0.64      3027\n",
      "           1       0.62      0.37      0.46      3030\n",
      "\n",
      "    accuracy                           0.57      6057\n",
      "   macro avg       0.59      0.57      0.55      6057\n",
      "weighted avg       0.59      0.57      0.55      6057\n",
      "\n",
      "[[2348  679]\n",
      " [1907 1123]]\n"
     ]
    }
   ],
   "source": [
    "Voting_func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7c6aeb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib as jl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "fdfc9ad1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('m1',\n",
       "                              LogisticRegression(C=0.001,\n",
       "                                                 class_weight={0: 0.9628,\n",
       "                                                               1: 1.0402},\n",
       "                                                 max_iter=5000, penalty='l1',\n",
       "                                                 random_state=42,\n",
       "                                                 solver='liblinear')),\n",
       "                             ('m2',\n",
       "                              LinearSVC(C=461,\n",
       "                                        class_weight={0: 0.9628, 1: 1.0402},\n",
       "                                        random_state=42)),\n",
       "                             ('m3',\n",
       "                              GradientBoostingClassifier(learning_rate=4,\n",
       "                                                         max_depth=7,\n",
       "                                                         min_samples_leaf=4,\n",
       "                                                         min_samples_split=30,\n",
       "                                                         n_estimators=50,\n",
       "                                                         n_iter_no_change=5,\n",
       "                                                         random_state=42))])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = get_models()\n",
    "    \n",
    "ensemble = models[\"hard_voting\"]\n",
    "ensemble.fit(X_ingested, y_ingested)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "65d8cb99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['H:\\\\3_output_raMSIn\\\\3_3_Output_raMSIn_HKU_Ingested4ALL\\\\XGB_ALL\\\\afterModelSelection\\\\cbMSIn_0d001\\\\model3to1Voting_cbMSIn0d001.joblib']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelSavePath = r\"H:\\3_output_raMSIn\\3_3_Output_raMSIn_HKU_Ingested4ALL\\XGB_ALL\\afterModelSelection\\cbMSIn_0d001\\model3to1Voting_cbMSIn0d001.joblib\"\n",
    "jl.dump(ensemble, modelSavePath, compress = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f9a9ba",
   "metadata": {},
   "source": [
    "## 3.3 Machine Learning Modeling: Model 1 (Train 6:6, Val 4:4, Test 3:3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49659b18",
   "metadata": {},
   "source": [
    "### 3.3.1. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7bcace0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build Logistic Regression Model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def LogisticRegression_func(XTrain=X_train, XVal=X_val, XTest=X_FNA, yTrain=y_train, yVal=y_val, yTest=y_FNA):\n",
    "    model_lr = LogisticRegression(C=0.001, penalty='l1', solver=\"liblinear\", max_iter=5000, random_state=42, class_weight={0:0.9628, 1:1.0402})  # max_iter=100\n",
    "    model_lr.fit(XTrain,yTrain)\n",
    "    \n",
    "    # Training Set\n",
    "    #plt.rcParams[\"figure.figsize\"] = (3,3)\n",
    "    X_train_predictions = model_lr.predict(X_train)\n",
    "    print(\"Training Set F1:\", f1_score(y_train, model_lr.predict(X_train), sample_weight=sampleW))\n",
    "    print(\"Training Set MCC:\", matthews_corrcoef(y_train, model_lr.predict(X_train), sample_weight=sampleW))\n",
    "    print(\"Training Set Accuracy:\", metrics.accuracy_score(y_train, X_train_predictions))\n",
    "    print(classification_report(y_train, X_train_predictions))\n",
    "    print(confusion_matrix(y_train, X_train_predictions))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr, tpr, _ = metrics.roc_curve(y_train, X_train_predictions)\n",
    "    plt.plot(fpr,tpr)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_train.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    # Val set\n",
    "    predictions_val  = model_lr.predict(XVal)\n",
    "    print(\"Ext Val Set F1:\", f1_score(yVal, model_lr.predict(XVal), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set MCC:\", matthews_corrcoef(yVal, model_lr.predict(XVal), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set Accuracy:\", metrics.accuracy_score(yVal, predictions_val))\n",
    "    print(classification_report(yVal, predictions_val))\n",
    "    print(confusion_matrix(yVal, predictions_val))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_val, tpr_val, _ = metrics.roc_curve(yVal, predictions_val)\n",
    "    plt.plot(fpr_val,tpr_val)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_test.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    f1_5_train = cross_val_score(model_lr, XTrain, yTrain, cv = 5, scoring=\"f1\")\n",
    "    print(\"5F-CV:\", avgScore(f1_5_train, 5))\n",
    "    \n",
    "    # Test set\n",
    "    predictions_FNA = model_lr.predict(XTest)\n",
    "    print(\"FNA Set F1:\", f1_score(yTest, model_lr.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set MCC:\", matthews_corrcoef(yTest, model_lr.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set Recall:\", recall_score(yTest, model_lr.predict(XTest)))\n",
    "    print(\"FNA Test Set Accuracy:\", metrics.accuracy_score(yTest, predictions_FNA))\n",
    "    print(classification_report(yTest, predictions_FNA))\n",
    "    print(confusion_matrix(yTest, predictions_FNA))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_FNA, tpr_FNA, _ = metrics.roc_curve(yTest, predictions_FNA)\n",
    "    plt.plot(fpr_FNA,tpr_FNA)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"G:/raMSIn/XGB_Importance2/XGB2_ROC_FNAtest2.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    # Visualize the importantance of the features\n",
    "    feature_imp = pd.Series(model_lr.coef_[0], index=XTrain.columns).sort_values(ascending=False)\n",
    "    x=feature_imp\n",
    "    y=feature_imp.index\n",
    "    \n",
    "    plt.subplots(dpi = 300)\n",
    "    #plt.rcParams[\"figure.figsize\"] = [4, 6]\n",
    "    #plt.rcParams[\"font.family\"] = \"Arial\"\n",
    "    #plt.rcParams.update({'font.size': 6})\n",
    "    plt.xlabel('Feature Importance Score', fontproperties='Arial', fontsize=17)\n",
    "    plt.ylabel('Features', fontproperties='Arial', fontsize=17)\n",
    "    plt.xticks(fontsize=15)\n",
    "    plt.yticks(fontsize=15)\n",
    "    plt.title(\"Important Molecular Features\", fontproperties='Arial', fontsize=20)\n",
    "    sns.barplot(x=feature_imp, y=feature_imp.index)\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_TopFeatures.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    #feature_importances = model_lr.coef_[0]\n",
    "    #feature_df=pd.DataFrame({'m/z':XTrain.columns,'coef':feature_importances})\n",
    "\n",
    "    #fig = px.bar(feature_df, x='coef', y='m/z')\n",
    "    #fig.show()\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5d284fc7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set F1: 0.859050437745964\n",
      "Training Set MCC: 0.7146122915983197\n",
      "Training Set Accuracy: 0.8566072999120492\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.84      0.86     47449\n",
      "           1       0.84      0.87      0.85     43511\n",
      "\n",
      "    accuracy                           0.86     90960\n",
      "   macro avg       0.86      0.86      0.86     90960\n",
      "weighted avg       0.86      0.86      0.86     90960\n",
      "\n",
      "[[40044  7405]\n",
      " [ 5638 37873]]\n",
      "Ext Val Set F1: 0.7461016750410112\n",
      "Ext Val Set MCC: 0.4571267286244885\n",
      "Ext Val Set Accuracy: 0.7280658436213991\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.64      0.70      2943\n",
      "           1       0.71      0.81      0.75      3132\n",
      "\n",
      "    accuracy                           0.73      6075\n",
      "   macro avg       0.73      0.73      0.73      6075\n",
      "weighted avg       0.73      0.73      0.73      6075\n",
      "\n",
      "[[1897 1046]\n",
      " [ 606 2526]]\n",
      "5F-CV: 0.7508338046408912\n",
      "FNA Set F1: 0.5138786540927918\n",
      "FNA Set MCC: -0.004697186064931594\n",
      "FNA Set Recall: 0.5310115260071103\n",
      "FNA Test Set Accuracy: 0.497514120472148\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.46      0.48     44540\n",
      "           1       0.50      0.53      0.51     44161\n",
      "\n",
      "    accuracy                           0.50     88701\n",
      "   macro avg       0.50      0.50      0.50     88701\n",
      "weighted avg       0.50      0.50      0.50     88701\n",
      "\n",
      "[[20680 23860]\n",
      " [20711 23450]]\n"
     ]
    }
   ],
   "source": [
    "coeff_LogReg, TOPfeatures_LogReg = LogisticRegression_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e368acdd",
   "metadata": {},
   "source": [
    "### 3.3.2. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "88f68e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build LinearSVC Model\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "def LinearSVC_func(XTrain=X_train, XVal=X_val, XTest=X_FNA, yTrain=y_train, yVal=y_val, yTest=y_FNA):\n",
    "    model_svm = LinearSVC(penalty='l2', loss=\"squared_hinge\", C=461, random_state=42, class_weight={0:0.9628, 1:1.0402})\n",
    "    model_svm.fit(XTrain,yTrain)\n",
    "    \n",
    "    # Training Set\n",
    "    #plt.rcParams[\"figure.figsize\"] = (3,3)\n",
    "    X_train_predictions = model_svm.predict(X_train)\n",
    "    print(\"Training Set F1:\", f1_score(y_train, model_svm.predict(X_train), sample_weight=sampleW))\n",
    "    print(\"Training Set MCC:\", matthews_corrcoef(y_train, model_svm.predict(X_train), sample_weight=sampleW))\n",
    "    print(\"Training Set Accuracy:\", metrics.accuracy_score(y_train, X_train_predictions))\n",
    "    print(classification_report(y_train, X_train_predictions))\n",
    "    print(confusion_matrix(y_train, X_train_predictions))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr, tpr, _ = metrics.roc_curve(y_train, X_train_predictions)\n",
    "    plt.plot(fpr,tpr)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_train.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    # Val set\n",
    "    predictions_val  = model_svm.predict(XVal)\n",
    "    print(\"Ext Val Set F1:\", f1_score(yVal, model_svm.predict(XVal), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set MCC:\", matthews_corrcoef(yVal, model_svm.predict(XVal), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set Accuracy:\", metrics.accuracy_score(yVal, predictions_val))\n",
    "    print(classification_report(yVal, predictions_val))\n",
    "    print(confusion_matrix(yVal, predictions_val))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_val, tpr_val, _ = metrics.roc_curve(yVal, predictions_val)\n",
    "    plt.plot(fpr_val,tpr_val)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_test.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    f1_5_train = cross_val_score(model_svm, XTrain, yTrain, cv = 5, scoring=\"f1\")\n",
    "    print(\"5F-CV:\", avgScore(f1_5_train, 5))\n",
    "    \n",
    "    # Test set\n",
    "    predictions_FNA = model_svm.predict(XTest)\n",
    "    print(\"FNA Set F1:\", f1_score(yTest, model_svm.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set MCC:\", matthews_corrcoef(yTest, model_svm.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set Recall:\", recall_score(yTest, model_svm.predict(XTest)))\n",
    "    print(\"FNA Test Set Accuracy:\", metrics.accuracy_score(yTest, predictions_FNA))\n",
    "    print(classification_report(yTest, predictions_FNA))\n",
    "    print(confusion_matrix(yTest, predictions_FNA))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_FNA, tpr_FNA, _ = metrics.roc_curve(yTest, predictions_FNA)\n",
    "    plt.plot(fpr_FNA,tpr_FNA)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"G:/raMSIn/XGB_Importance2/XGB2_ROC_FNAtest2.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    # Visualize the importantance of the features\n",
    "    feature_imp = pd.Series(model_svm.coef_[0], index=XTrain.columns).sort_values(ascending=False)\n",
    "    x=feature_imp\n",
    "    y=feature_imp.index\n",
    "    \n",
    "    plt.subplots(dpi = 300)\n",
    "    #plt.rcParams[\"figure.figsize\"] = [4, 6]\n",
    "    #plt.rcParams[\"font.family\"] = \"Arial\"\n",
    "    #plt.rcParams.update({'font.size': 6})\n",
    "    plt.xlabel('Feature Importance Score', fontproperties='Arial', fontsize=17)\n",
    "    plt.ylabel('Features', fontproperties='Arial', fontsize=17)\n",
    "    plt.xticks(fontsize=15)\n",
    "    plt.yticks(fontsize=15)\n",
    "    plt.title(\"Important Molecular Features\", fontproperties='Arial', fontsize=20)\n",
    "    sns.barplot(x=feature_imp, y=feature_imp.index)\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_TopFeatures.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    #feature_importances = model_svm.coef_[0]\n",
    "    #feature_df=pd.DataFrame({'m/z':XTrain.columns,'coef':feature_importances})\n",
    "\n",
    "    #fig = px.bar(feature_df, x='coef', y='m/z')\n",
    "    #fig.show()\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "90420725",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set F1: 0.936826200403876\n",
      "Training Set MCC: 0.8786876453940262\n",
      "Training Set Accuracy: 0.9398636763412489\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.97      0.94     47449\n",
      "           1       0.96      0.91      0.94     43511\n",
      "\n",
      "    accuracy                           0.94     90960\n",
      "   macro avg       0.94      0.94      0.94     90960\n",
      "weighted avg       0.94      0.94      0.94     90960\n",
      "\n",
      "[[45891  1558]\n",
      " [ 3912 39599]]\n",
      "Ext Val Set F1: 0.5463637210755545\n",
      "Ext Val Set MCC: 0.1136442372665275\n",
      "Ext Val Set Accuracy: 0.5560493827160494\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.58      0.56      2943\n",
      "           1       0.57      0.53      0.55      3132\n",
      "\n",
      "    accuracy                           0.56      6075\n",
      "   macro avg       0.56      0.56      0.56      6075\n",
      "weighted avg       0.56      0.56      0.56      6075\n",
      "\n",
      "[[1706 1237]\n",
      " [1460 1672]]\n",
      "5F-CV: 0.8985142905056881\n",
      "FNA Set F1: 0.605895184096619\n",
      "FNA Set MCC: 0.24332754227055856\n",
      "FNA Set Recall: 0.5822105477683929\n",
      "FNA Test Set Accuracy: 0.621458608132941\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.66      0.64     44540\n",
      "           1       0.63      0.58      0.60     44161\n",
      "\n",
      "    accuracy                           0.62     88701\n",
      "   macro avg       0.62      0.62      0.62     88701\n",
      "weighted avg       0.62      0.62      0.62     88701\n",
      "\n",
      "[[29413 15127]\n",
      " [18450 25711]]\n"
     ]
    }
   ],
   "source": [
    "coeff_SVM, TOPfeatures_SVM = LinearSVC_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228ac6cd",
   "metadata": {},
   "source": [
    "### 3.3.3. GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7428a256",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build GBM Model\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "def GBM_func(XTrain=X_train, XVal=X_val, XTest=X_FNA, yTrain=y_train, yVal=y_val, yTest=y_FNA):\n",
    "    model_gbm = GradientBoostingClassifier(learning_rate=4, n_estimators=50, max_depth=7, min_samples_leaf=4, min_samples_split=30, n_iter_no_change=5, random_state=42)\n",
    "    model_gbm.fit(XTrain,yTrain)\n",
    "    \n",
    "    # Training Set\n",
    "    #plt.rcParams[\"figure.figsize\"] = (3,3)\n",
    "    X_train_predictions = model_gbm.predict(X_train)\n",
    "    print(\"Training Set F1:\", f1_score(y_train, model_gbm.predict(X_train), sample_weight=sampleW))\n",
    "    print(\"Training Set MCC:\", matthews_corrcoef(y_train, model_gbm.predict(X_train), sample_weight=sampleW))\n",
    "    print(\"Training Set Accuracy:\", metrics.accuracy_score(y_train, X_train_predictions))\n",
    "    print(classification_report(y_train, X_train_predictions))\n",
    "    print(confusion_matrix(y_train, X_train_predictions))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr, tpr, _ = metrics.roc_curve(y_train, X_train_predictions)\n",
    "    plt.plot(fpr,tpr)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_train.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    # Val set\n",
    "    predictions_val  = model_gbm.predict(XVal)\n",
    "    print(\"Ext Val Set F1:\", f1_score(yVal, model_gbm.predict(XVal), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set MCC:\", matthews_corrcoef(yVal, model_gbm.predict(XVal), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set Accuracy:\", metrics.accuracy_score(yVal, predictions_val))\n",
    "    print(classification_report(yVal, predictions_val))\n",
    "    print(confusion_matrix(yVal, predictions_val))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_val, tpr_val, _ = metrics.roc_curve(yVal, predictions_val)\n",
    "    plt.plot(fpr_val,tpr_val)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_test.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    f1_5_train = cross_val_score(model_gbm, XTrain, yTrain, cv = 5, scoring=\"f1\")\n",
    "    print(\"5F-CV:\", avgScore(f1_5_train, 5))\n",
    "    \n",
    "    # Test set\n",
    "    predictions_FNA = model_gbm.predict(XTest)\n",
    "    print(\"FNA Set F1:\", f1_score(yTest, model_gbm.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set MCC:\", matthews_corrcoef(yTest, model_gbm.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set Recall:\", recall_score(yTest, model_gbm.predict(XTest)))\n",
    "    print(\"FNA Test Set Accuracy:\", metrics.accuracy_score(yTest, predictions_FNA))\n",
    "    print(classification_report(yTest, predictions_FNA))\n",
    "    print(confusion_matrix(yTest, predictions_FNA))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_FNA, tpr_FNA, _ = metrics.roc_curve(yTest, predictions_FNA)\n",
    "    plt.plot(fpr_FNA,tpr_FNA)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"G:/raMSIn/XGB_Importance2/XGB2_ROC_FNAtest2.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    # Visualize the importantance of the features\n",
    "    feature_imp = pd.Series(model_gbm.feature_importances_, index=XTrain.columns).sort_values(ascending=False)\n",
    "    x=feature_imp\n",
    "    y=feature_imp.index\n",
    "    \n",
    "    plt.subplots(dpi = 300)\n",
    "    #plt.rcParams[\"figure.figsize\"] = [4, 6]\n",
    "    #plt.rcParams[\"font.family\"] = \"Arial\"\n",
    "    #plt.rcParams.update({'font.size': 6})\n",
    "    plt.xlabel('Feature Importance Score', fontproperties='Arial', fontsize=17)\n",
    "    plt.ylabel('Features', fontproperties='Arial', fontsize=17)\n",
    "    plt.xticks(fontsize=15)\n",
    "    plt.yticks(fontsize=15)\n",
    "    plt.title(\"Important Molecular Features\", fontproperties='Arial', fontsize=20)\n",
    "    sns.barplot(x=feature_imp, y=feature_imp.index)\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/XGB_TopFeatures.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    # Visualize the boxplot of the important features between the two groups\n",
    "    #fig = px.box(data_frame = df_ROI_for_ML_Opti, x = feature_imp[:10].index,color= 'type')\n",
    "    #fig.show()\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "02a72f17",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set F1: 0.7741684531291156\n",
      "Training Set MCC: 0.5971718001016285\n",
      "Training Set Accuracy: 0.7977572559366755\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.88      0.82     47449\n",
      "           1       0.85      0.71      0.77     43511\n",
      "\n",
      "    accuracy                           0.80     90960\n",
      "   macro avg       0.81      0.79      0.79     90960\n",
      "weighted avg       0.80      0.80      0.80     90960\n",
      "\n",
      "[[41832  5617]\n",
      " [12779 30732]]\n",
      "Ext Val Set F1: 0.5172605730534929\n",
      "Ext Val Set MCC: 0.06087729188052219\n",
      "Ext Val Set Accuracy: 0.5295473251028806\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.56      0.53      2943\n",
      "           1       0.55      0.50      0.52      3132\n",
      "\n",
      "    accuracy                           0.53      6075\n",
      "   macro avg       0.53      0.53      0.53      6075\n",
      "weighted avg       0.53      0.53      0.53      6075\n",
      "\n",
      "[[1641 1302]\n",
      " [1556 1576]]\n",
      "5F-CV: 0.7273904539489974\n",
      "FNA Set F1: 0.5601559761648502\n",
      "FNA Set MCC: 0.030178069495134508\n",
      "FNA Set Recall: 0.6179434342519418\n",
      "FNA Test Set Accuracy: 0.514323401089052\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.41      0.46     44540\n",
      "           1       0.51      0.62      0.56     44161\n",
      "\n",
      "    accuracy                           0.51     88701\n",
      "   macro avg       0.52      0.51      0.51     88701\n",
      "weighted avg       0.52      0.51      0.51     88701\n",
      "\n",
      "[[18332 26208]\n",
      " [16872 27289]]\n"
     ]
    }
   ],
   "source": [
    "coeff_GBM, TOPfeatures_GBM = GBM_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9edf4a32",
   "metadata": {},
   "source": [
    "### 3.3.4. Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9e7e60e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build stacking Model\n",
    "\n",
    "def Stacking_func(XTrain=X_train, XVal=X_val, XTest=X_FNA, XTest2=X_di, yTrain=y_train, yVal=y_val, yTest=y_FNA, yTest2=y_di):\n",
    "\n",
    "    base_learners = []\n",
    "\n",
    "    # Define models to use in stacking ensemble\n",
    "    m1 = LogisticRegression(C=0.001, penalty='l1', solver=\"liblinear\", max_iter=5000, random_state=42, class_weight={0:0.9628, 1:1.0402})\n",
    "    base_learners.append(m1)\n",
    "\n",
    "    m2 = LinearSVC(penalty='l2', loss=\"squared_hinge\", C=461, random_state=42, class_weight={0:0.9628, 1:1.0402})\n",
    "    base_learners.append(m2)\n",
    "\n",
    "    m3 = GradientBoostingClassifier(learning_rate=4, n_estimators=50, max_depth=7, min_samples_leaf=4, min_samples_split=30, n_iter_no_change=5, random_state=42)\n",
    "    base_learners.append(m3)\n",
    "\n",
    "    # Define the meta-classifier to use for stacking\n",
    "    meta_learner = LogisticRegression(C=0.0011, penalty='l1', solver=\"liblinear\", max_iter=5000, random_state=42)\n",
    "\n",
    "    model_sc = StackingRegressor([[m1, m2, m3], [meta_learner]])\n",
    "    model_sc.fit(XTrain, yTrain)\n",
    "    \n",
    "    #=======================================\n",
    "    \n",
    "    # Training Set\n",
    "    #plt.rcParams[\"figure.figsize\"] = (3,3)\n",
    "    X_train_predictions = model_sc.predict(X_train)[-1]\n",
    "    print(\"Training Set F1:\", f1_score(y_train, model_sc.predict(X_train)[-1], sample_weight=sampleW))\n",
    "    print(\"Training Set MCC:\", matthews_corrcoef(y_train, model_sc.predict(X_train)[-1], sample_weight=sampleW))\n",
    "    print(\"Training Set Accuracy:\", metrics.accuracy_score(y_train, X_train_predictions))\n",
    "    print(classification_report(y_train, X_train_predictions))\n",
    "    print(confusion_matrix(y_train, X_train_predictions))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr, tpr, _ = metrics.roc_curve(y_train, X_train_predictions)\n",
    "    plt.plot(fpr,tpr)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_train.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    # Val set\n",
    "    predictions_val  = model_sc.predict(XVal)[-1]\n",
    "    print(\"Ext Val Set F1:\", f1_score(yVal, model_sc.predict(XVal)[-1], sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set MCC:\", matthews_corrcoef(yVal, model_sc.predict(XVal)[-1], sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set Accuracy:\", metrics.accuracy_score(yVal, predictions_val))\n",
    "    print(classification_report(yVal, predictions_val))\n",
    "    print(confusion_matrix(yVal, predictions_val))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_val, tpr_val, _ = metrics.roc_curve(yVal, predictions_val)\n",
    "    plt.plot(fpr_val,tpr_val)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_test.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    #f1_5_train = cross_val_score(model_sc, XTrain, yTrain, cv = 5, scoring=\"f1\")\n",
    "    #print(\"5F-CV:\", avgScore(f1_5_train, 5))\n",
    "    \n",
    "    # Test set\n",
    "    predictions_FNA = model_sc.predict(XTest)[-1]\n",
    "    print(\"FNA Set F1:\", f1_score(yTest, model_sc.predict(XTest)[-1], sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set MCC:\", matthews_corrcoef(yTest, model_sc.predict(XTest)[-1], sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set Recall:\", recall_score(yTest, model_sc.predict(XTest)[-1]))\n",
    "    print(\"FNA Test Set Accuracy:\", metrics.accuracy_score(yTest, predictions_FNA))\n",
    "    print(classification_report(yTest, predictions_FNA))\n",
    "    print(confusion_matrix(yTest, predictions_FNA))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_FNA, tpr_FNA, _ = metrics.roc_curve(yTest, predictions_FNA)\n",
    "    plt.plot(fpr_FNA,tpr_FNA)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"G:/raMSIn/XGB_Importance2/XGB2_ROC_FNAtest2.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    # Test2 set\n",
    "    predictions_di = model_sc.predict(XTest2)[-1]\n",
    "    print(\"DirectIn Set F1:\", f1_score(yTest2, model_sc.predict(XTest2)[-1], sample_weight=sampleDiW))\n",
    "    print(\"DirectIn Set MCC:\", matthews_corrcoef(yTest2, model_sc.predict(XTest2)[-1], sample_weight=sampleDiW))\n",
    "    print(\"DirectIn Set Recall:\", recall_score(yTest2, model_sc.predict(XTest2)[-1]))\n",
    "    print(\"DirectIn Test Set Accuracy:\", metrics.accuracy_score(yTest2, predictions_di))\n",
    "    print(classification_report(yTest2, predictions_di))\n",
    "    print(confusion_matrix(yTest2, predictions_di))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_di, tpr_di, _ = metrics.roc_curve(yTest2, predictions_di)\n",
    "    plt.plot(fpr_di,tpr_di)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"G:/raMSIn/XGB_Importance2/XGB2_ROC_FNAtest2.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "53611a51",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set F1: 0.8662651830389484\n",
      "Training Set MCC: 0.7291963039236078\n",
      "Training Set Accuracy: 0.8638852242744063\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.85      0.87     47449\n",
      "           1       0.84      0.88      0.86     43511\n",
      "\n",
      "    accuracy                           0.86     90960\n",
      "   macro avg       0.86      0.86      0.86     90960\n",
      "weighted avg       0.86      0.86      0.86     90960\n",
      "\n",
      "[[40381  7068]\n",
      " [ 5313 38198]]\n",
      "Ext Val Set F1: 0.7507740699813095\n",
      "Ext Val Set MCC: 0.48543084825473565\n",
      "Ext Val Set Accuracy: 0.7432098765432099\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.71      0.73      2943\n",
      "           1       0.74      0.78      0.76      3132\n",
      "\n",
      "    accuracy                           0.74      6075\n",
      "   macro avg       0.74      0.74      0.74      6075\n",
      "weighted avg       0.74      0.74      0.74      6075\n",
      "\n",
      "[[2082  861]\n",
      " [ 699 2433]]\n",
      "FNA Set F1: 0.4948210434864645\n",
      "FNA Set MCC: -0.046115104901766193\n",
      "FNA Set Recall: 0.512261950589887\n",
      "FNA Test Set Accuracy: 0.47684918997531034\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.44      0.46     44540\n",
      "           1       0.48      0.51      0.49     44161\n",
      "\n",
      "    accuracy                           0.48     88701\n",
      "   macro avg       0.48      0.48      0.48     88701\n",
      "weighted avg       0.48      0.48      0.48     88701\n",
      "\n",
      "[[19675 24865]\n",
      " [21539 22622]]\n",
      "DirectIn Set F1: 0.604973436518509\n",
      "DirectIn Set MCC: 0.23098616898777202\n",
      "DirectIn Set Recall: 0.5891089108910891\n",
      "DirectIn Test Set Accuracy: 0.6153211160640581\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.64      0.63      3027\n",
      "           1       0.62      0.59      0.61      3030\n",
      "\n",
      "    accuracy                           0.62      6057\n",
      "   macro avg       0.62      0.62      0.62      6057\n",
      "weighted avg       0.62      0.62      0.62      6057\n",
      "\n",
      "[[1942 1085]\n",
      " [1245 1785]]\n"
     ]
    }
   ],
   "source": [
    "Stacking_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81113c91",
   "metadata": {},
   "source": [
    "### 3.3.5. Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3de1f12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Voting_func(XTrain=X_train, XVal=X_val, XTest=X_FNA, XTest2=X_di, yTrain=y_train, yVal=y_val, yTest=y_FNA, yTest2=y_di):\n",
    "\n",
    "    models = get_models()\n",
    "    \n",
    "    ensemble = models[\"hard_voting\"]\n",
    "    ensemble.fit(XTrain, yTrain)\n",
    "    #=======================================\n",
    "\n",
    "    # Training Set\n",
    "    #plt.rcParams[\"figure.figsize\"] = (3,3)\n",
    "    X_train_predictions = ensemble.predict(X_train)\n",
    "    print(\"Training Set F1:\", f1_score(y_train, ensemble.predict(X_train), sample_weight=sampleW))\n",
    "    print(\"Training Set MCC:\", matthews_corrcoef(y_train, ensemble.predict(X_train), sample_weight=sampleW))\n",
    "    print(\"Training Set Accuracy:\", metrics.accuracy_score(y_train, X_train_predictions))\n",
    "    print(classification_report(y_train, X_train_predictions))\n",
    "    print(confusion_matrix(y_train, X_train_predictions))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr, tpr, _ = metrics.roc_curve(y_train, X_train_predictions)\n",
    "    plt.plot(fpr,tpr)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_train.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    # Val set\n",
    "    predictions_val  = ensemble.predict(XVal)\n",
    "    print(\"Ext Val Set F1:\", f1_score(yVal, ensemble.predict(XVal), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set MCC:\", matthews_corrcoef(yVal, ensemble.predict(XVal), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set Accuracy:\", metrics.accuracy_score(yVal, predictions_val))\n",
    "    print(classification_report(yVal, predictions_val))\n",
    "    print(confusion_matrix(yVal, predictions_val))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_val, tpr_val, _ = metrics.roc_curve(yVal, predictions_val)\n",
    "    plt.plot(fpr_val,tpr_val)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_test.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    f1_5_train = cross_val_score(ensemble, XTrain, yTrain, cv = 5, scoring=\"f1\")\n",
    "    print(\"5F-CV:\", avgScore(f1_5_train, 5))\n",
    "\n",
    "    # Test set\n",
    "    predictions_FNA = ensemble.predict(XTest)\n",
    "    print(\"FNA Set F1:\", f1_score(yTest, ensemble.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set MCC:\", matthews_corrcoef(yTest, ensemble.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set Recall:\", recall_score(yTest, ensemble.predict(XTest)))\n",
    "    print(\"FNA Test Set Accuracy:\", metrics.accuracy_score(yTest, predictions_FNA))\n",
    "    print(classification_report(yTest, predictions_FNA))\n",
    "    print(confusion_matrix(yTest, predictions_FNA))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_FNA, tpr_FNA, _ = metrics.roc_curve(yTest, predictions_FNA)\n",
    "    plt.plot(fpr_FNA,tpr_FNA)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"G:/raMSIn/XGB_Importance2/XGB2_ROC_FNAtest2.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    # Test2 set\n",
    "    predictions_di = ensemble.predict(XTest2)\n",
    "    print(\"DirectIn Set F1:\", f1_score(yTest2, ensemble.predict(XTest2), sample_weight=sampleDiW))\n",
    "    print(\"DirectIn Set MCC:\", matthews_corrcoef(yTest2, ensemble.predict(XTest2), sample_weight=sampleDiW))\n",
    "    print(\"DirectIn Set Recall:\", recall_score(yTest2, ensemble.predict(XTest2)))\n",
    "    print(\"DirectIn Test Set Accuracy:\", metrics.accuracy_score(yTest2, predictions_di))\n",
    "    print(classification_report(yTest2, predictions_di))\n",
    "    print(confusion_matrix(yTest2, predictions_di))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_di, tpr_di, _ = metrics.roc_curve(yTest2, predictions_di)\n",
    "    plt.plot(fpr_di,tpr_di)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"G:/raMSIn/XGB_Importance2/XGB2_ROC_FNAtest2.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "becdb109",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set F1: 0.9290585732655074\n",
      "Training Set MCC: 0.8639791582334887\n",
      "Training Set Accuracy: 0.9325087950747581\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.96      0.94     47449\n",
      "           1       0.96      0.90      0.93     43511\n",
      "\n",
      "    accuracy                           0.93     90960\n",
      "   macro avg       0.93      0.93      0.93     90960\n",
      "weighted avg       0.93      0.93      0.93     90960\n",
      "\n",
      "[[45618  1831]\n",
      " [ 4308 39203]]\n",
      "Ext Val Set F1: 0.675045534099414\n",
      "Ext Val Set MCC: 0.3331311496465998\n",
      "Ext Val Set Accuracy: 0.6671604938271605\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.64      0.65      2943\n",
      "           1       0.67      0.69      0.68      3132\n",
      "\n",
      "    accuracy                           0.67      6075\n",
      "   macro avg       0.67      0.67      0.67      6075\n",
      "weighted avg       0.67      0.67      0.67      6075\n",
      "\n",
      "[[1882 1061]\n",
      " [ 961 2171]]\n",
      "5F-CV: 0.8796024401234556\n",
      "FNA Set F1: 0.5878371640587023\n",
      "FNA Set MCC: 0.17646130123091425\n",
      "FNA Set Recall: 0.5872602522587804\n",
      "FNA Test Set Accuracy: 0.588234630951173\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.59      0.59     44540\n",
      "           1       0.59      0.59      0.59     44161\n",
      "\n",
      "    accuracy                           0.59     88701\n",
      "   macro avg       0.59      0.59      0.59     88701\n",
      "weighted avg       0.59      0.59      0.59     88701\n",
      "\n",
      "[[26243 18297]\n",
      " [18227 25934]]\n",
      "DirectIn Set F1: 0.3776201507758243\n",
      "DirectIn Set MCC: -0.029932256663177094\n",
      "DirectIn Set Recall: 0.3118811881188119\n",
      "DirectIn Test Set Accuracy: 0.48588410104011887\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.66      0.56      3027\n",
      "           1       0.48      0.31      0.38      3030\n",
      "\n",
      "    accuracy                           0.49      6057\n",
      "   macro avg       0.48      0.49      0.47      6057\n",
      "weighted avg       0.48      0.49      0.47      6057\n",
      "\n",
      "[[1998 1029]\n",
      " [2085  945]]\n"
     ]
    }
   ],
   "source": [
    "Voting_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08fd62e",
   "metadata": {},
   "source": [
    "## 3.4 Machine Learning Modeling: Model 2 (Train 4:4, Val 6:6, Test 3:3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961246f0",
   "metadata": {},
   "source": [
    "### 3.4.1. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "99086aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build Logistic Regression Model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def LogisticRegression_func(XTrain=X_val, XVal=X_train, XTest=X_FNA, yTrain=y_val, yVal=y_train, yTest=y_FNA):\n",
    "    model_lr = LogisticRegression(C=0.001, penalty='l1', solver=\"liblinear\", max_iter=5000, random_state=42, class_weight={0:0.9628, 1:1.0402})  # max_iter=100\n",
    "    model_lr.fit(XTrain,yTrain)\n",
    "    \n",
    "    # Training Set\n",
    "    #plt.rcParams[\"figure.figsize\"] = (3,3)\n",
    "    X_train_predictions = model_lr.predict(XVal)\n",
    "    print(\"Training Set F1:\", f1_score(yVal, model_lr.predict(XVal), sample_weight=sampleW))\n",
    "    print(\"Training Set MCC:\", matthews_corrcoef(yVal, model_lr.predict(XVal), sample_weight=sampleW))\n",
    "    print(\"Training Set Accuracy:\", metrics.accuracy_score(yVal, X_train_predictions))\n",
    "    print(classification_report(yVal, X_train_predictions))\n",
    "    print(confusion_matrix(yVal, X_train_predictions))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr, tpr, _ = metrics.roc_curve(yVal, X_train_predictions)\n",
    "    plt.plot(fpr,tpr)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_train.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    # Val set\n",
    "    predictions_val  = model_lr.predict(XTrain)\n",
    "    print(\"Ext Val Set F1:\", f1_score(yTrain, model_lr.predict(XTrain), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set MCC:\", matthews_corrcoef(yTrain, model_lr.predict(XTrain), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set Accuracy:\", metrics.accuracy_score(yTrain, predictions_val))\n",
    "    print(classification_report(yTrain, predictions_val))\n",
    "    print(confusion_matrix(yTrain, predictions_val))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_val, tpr_val, _ = metrics.roc_curve(yTrain, predictions_val)\n",
    "    plt.plot(fpr_val,tpr_val)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_test.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    f1_5_train = cross_val_score(model_lr, XTrain, yTrain, cv = 5, scoring=\"f1\")\n",
    "    print(\"5F-CV:\", avgScore(f1_5_train, 5))\n",
    "    \n",
    "    # Test set\n",
    "    predictions_FNA = model_lr.predict(XTest)\n",
    "    print(\"FNA Set F1:\", f1_score(yTest, model_lr.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set MCC:\", matthews_corrcoef(yTest, model_lr.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set Recall:\", recall_score(yTest, model_lr.predict(XTest)))\n",
    "    print(\"FNA Test Set Accuracy:\", metrics.accuracy_score(yTest, predictions_FNA))\n",
    "    print(classification_report(yTest, predictions_FNA))\n",
    "    print(confusion_matrix(yTest, predictions_FNA))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_FNA, tpr_FNA, _ = metrics.roc_curve(yTest, predictions_FNA)\n",
    "    plt.plot(fpr_FNA,tpr_FNA)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"G:/raMSIn/XGB_Importance2/XGB2_ROC_FNAtest2.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    # Visualize the importantance of the features\n",
    "    feature_imp = pd.Series(model_lr.coef_[0], index=XTrain.columns).sort_values(ascending=False)\n",
    "    x=feature_imp\n",
    "    y=feature_imp.index\n",
    "    \n",
    "    plt.subplots(dpi = 300)\n",
    "    #plt.rcParams[\"figure.figsize\"] = [4, 6]\n",
    "    #plt.rcParams[\"font.family\"] = \"Arial\"\n",
    "    #plt.rcParams.update({'font.size': 6})\n",
    "    plt.xlabel('Feature Importance Score', fontproperties='Arial', fontsize=17)\n",
    "    plt.ylabel('Features', fontproperties='Arial', fontsize=17)\n",
    "    plt.xticks(fontsize=15)\n",
    "    plt.yticks(fontsize=15)\n",
    "    plt.title(\"Important Molecular Features\", fontproperties='Arial', fontsize=20)\n",
    "    sns.barplot(x=feature_imp, y=feature_imp.index)\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_TopFeatures.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    #feature_importances = model_lr.coef_[0]\n",
    "    #feature_df=pd.DataFrame({'m/z':XTrain.columns,'coef':feature_importances})\n",
    "\n",
    "    #fig = px.bar(feature_df, x='coef', y='m/z')\n",
    "    #fig.show()\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ff504fe8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set F1: 0.0\n",
      "Training Set MCC: 0.0\n",
      "Training Set Accuracy: 0.5216468777484609\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      1.00      0.69     47449\n",
      "           1       0.00      0.00      0.00     43511\n",
      "\n",
      "    accuracy                           0.52     90960\n",
      "   macro avg       0.26      0.50      0.34     90960\n",
      "weighted avg       0.27      0.52      0.36     90960\n",
      "\n",
      "[[47449     0]\n",
      " [43511     0]]\n",
      "Ext Val Set F1: 0.0\n",
      "Ext Val Set MCC: 0.0\n",
      "Ext Val Set Accuracy: 0.48444444444444446\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      1.00      0.65      2943\n",
      "           1       0.00      0.00      0.00      3132\n",
      "\n",
      "    accuracy                           0.48      6075\n",
      "   macro avg       0.24      0.50      0.33      6075\n",
      "weighted avg       0.23      0.48      0.32      6075\n",
      "\n",
      "[[2943    0]\n",
      " [3132    0]]\n",
      "5F-CV: 0.0\n",
      "FNA Set F1: 0.0\n",
      "FNA Set MCC: 0.0\n",
      "FNA Set Recall: 0.0\n",
      "FNA Test Set Accuracy: 0.5021363907960451\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67     44540\n",
      "           1       0.00      0.00      0.00     44161\n",
      "\n",
      "    accuracy                           0.50     88701\n",
      "   macro avg       0.25      0.50      0.33     88701\n",
      "weighted avg       0.25      0.50      0.34     88701\n",
      "\n",
      "[[44540     0]\n",
      " [44161     0]]\n"
     ]
    }
   ],
   "source": [
    "coeff_LogReg, TOPfeatures_LogReg = LogisticRegression_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a040e5",
   "metadata": {},
   "source": [
    "### 3.4.2. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ae3652ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build LinearSVC Model\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "def LinearSVC_func(XTrain=X_val, XVal=X_train, XTest=X_FNA, yTrain=y_val, yVal=y_train, yTest=y_FNA):\n",
    "    model_svm = LinearSVC(penalty='l2', loss=\"squared_hinge\", C=461, random_state=42, class_weight={0:0.9628, 1:1.0402})\n",
    "    model_svm.fit(XTrain,yTrain)\n",
    "    \n",
    "    # Training Set\n",
    "    #plt.rcParams[\"figure.figsize\"] = (3,3)\n",
    "    X_train_predictions = model_svm.predict(XVal)\n",
    "    print(\"Training Set F1:\", f1_score(yVal, model_svm.predict(XVal), sample_weight=sampleW))\n",
    "    print(\"Training Set MCC:\", matthews_corrcoef(yVal, model_svm.predict(XVal), sample_weight=sampleW))\n",
    "    print(\"Training Set Accuracy:\", metrics.accuracy_score(yVal, X_train_predictions))\n",
    "    print(classification_report(yVal, X_train_predictions))\n",
    "    print(confusion_matrix(yVal, X_train_predictions))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr, tpr, _ = metrics.roc_curve(yVal, X_train_predictions)\n",
    "    plt.plot(fpr,tpr)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_train.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    # Val set\n",
    "    predictions_val  = model_svm.predict(XTrain)\n",
    "    print(\"Ext Val Set F1:\", f1_score(yTrain, model_svm.predict(XTrain), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set MCC:\", matthews_corrcoef(yTrain, model_svm.predict(XTrain), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set Accuracy:\", metrics.accuracy_score(yTrain, predictions_val))\n",
    "    print(classification_report(yTrain, predictions_val))\n",
    "    print(confusion_matrix(yTrain, predictions_val))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_val, tpr_val, _ = metrics.roc_curve(yTrain, predictions_val)\n",
    "    plt.plot(fpr_val,tpr_val)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_test.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    f1_5_train = cross_val_score(model_svm, XTrain, yTrain, cv = 5, scoring=\"f1\")\n",
    "    print(\"5F-CV:\", avgScore(f1_5_train, 5))\n",
    "    \n",
    "    # Test set\n",
    "    predictions_FNA = model_svm.predict(XTest)\n",
    "    print(\"FNA Set F1:\", f1_score(yTest, model_svm.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set MCC:\", matthews_corrcoef(yTest, model_svm.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set Recall:\", recall_score(yTest, model_svm.predict(XTest)))\n",
    "    print(\"FNA Test Set Accuracy:\", metrics.accuracy_score(yTest, predictions_FNA))\n",
    "    print(classification_report(yTest, predictions_FNA))\n",
    "    print(confusion_matrix(yTest, predictions_FNA))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_FNA, tpr_FNA, _ = metrics.roc_curve(yTest, predictions_FNA)\n",
    "    plt.plot(fpr_FNA,tpr_FNA)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"G:/raMSIn/XGB_Importance2/XGB2_ROC_FNAtest2.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    # Visualize the importantance of the features\n",
    "    feature_imp = pd.Series(model_svm.coef_[0], index=XTrain.columns).sort_values(ascending=False)\n",
    "    x=feature_imp\n",
    "    y=feature_imp.index\n",
    "    \n",
    "    plt.subplots(dpi = 300)\n",
    "    #plt.rcParams[\"figure.figsize\"] = [4, 6]\n",
    "    #plt.rcParams[\"font.family\"] = \"Arial\"\n",
    "    #plt.rcParams.update({'font.size': 6})\n",
    "    plt.xlabel('Feature Importance Score', fontproperties='Arial', fontsize=17)\n",
    "    plt.ylabel('Features', fontproperties='Arial', fontsize=17)\n",
    "    plt.xticks(fontsize=15)\n",
    "    plt.yticks(fontsize=15)\n",
    "    plt.title(\"Important Molecular Features\", fontproperties='Arial', fontsize=20)\n",
    "    sns.barplot(x=feature_imp, y=feature_imp.index)\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_TopFeatures.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    #feature_importances = model_svm.coef_[0]\n",
    "    #feature_df=pd.DataFrame({'m/z':XTrain.columns,'coef':feature_importances})\n",
    "\n",
    "    #fig = px.bar(feature_df, x='coef', y='m/z')\n",
    "    #fig.show()\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8936e108",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set F1: 0.5361303550905401\n",
      "Training Set MCC: -0.009055524021052778\n",
      "Training Set Accuracy: 0.49175461741424803\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.41      0.46     47449\n",
      "           1       0.47      0.58      0.52     43511\n",
      "\n",
      "    accuracy                           0.49     90960\n",
      "   macro avg       0.50      0.50      0.49     90960\n",
      "weighted avg       0.50      0.49      0.49     90960\n",
      "\n",
      "[[19362 28087]\n",
      " [18143 25368]]\n",
      "Ext Val Set F1: 0.9527368264110506\n",
      "Ext Val Set MCC: 0.9103290940063884\n",
      "Ext Val Set Accuracy: 0.9532510288065844\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95      2943\n",
      "           1       0.99      0.92      0.95      3132\n",
      "\n",
      "    accuracy                           0.95      6075\n",
      "   macro avg       0.95      0.95      0.95      6075\n",
      "weighted avg       0.96      0.95      0.95      6075\n",
      "\n",
      "[[2902   41]\n",
      " [ 243 2889]]\n",
      "5F-CV: 0.8710870905637776\n",
      "FNA Set F1: 0.44731069235589443\n",
      "FNA Set MCC: -0.1440509068386531\n",
      "FNA Set Recall: 0.4628065487647472\n",
      "FNA Test Set Accuracy: 0.42799968433275837\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.39      0.41     44540\n",
      "           1       0.43      0.46      0.45     44161\n",
      "\n",
      "    accuracy                           0.43     88701\n",
      "   macro avg       0.43      0.43      0.43     88701\n",
      "weighted avg       0.43      0.43      0.43     88701\n",
      "\n",
      "[[17526 27014]\n",
      " [23723 20438]]\n"
     ]
    }
   ],
   "source": [
    "coeff_SVM, TOPfeatures_SVM = LinearSVC_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d25a8aa",
   "metadata": {},
   "source": [
    "### 3.4.3. GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0bf777fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build GBM Model\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "def GBM_func(XTrain=X_val, XVal=X_train, XTest=X_FNA, yTrain=y_val, yVal=y_train, yTest=y_FNA):\n",
    "    model_gbm = GradientBoostingClassifier(learning_rate=4, n_estimators=50, max_depth=7, min_samples_leaf=4, min_samples_split=30, n_iter_no_change=5, random_state=42)\n",
    "    model_gbm.fit(XTrain,yTrain)\n",
    "    \n",
    "    # Training Set\n",
    "    #plt.rcParams[\"figure.figsize\"] = (3,3)\n",
    "    X_train_predictions = model_gbm.predict(XVal)\n",
    "    print(\"Training Set F1:\", f1_score(yVal, model_gbm.predict(XVal), sample_weight=sampleW))\n",
    "    print(\"Training Set MCC:\", matthews_corrcoef(yVal, model_gbm.predict(XVal), sample_weight=sampleW))\n",
    "    print(\"Training Set Accuracy:\", metrics.accuracy_score(yVal, X_train_predictions))\n",
    "    print(classification_report(yVal, X_train_predictions))\n",
    "    print(confusion_matrix(yVal, X_train_predictions))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr, tpr, _ = metrics.roc_curve(yVal, X_train_predictions)\n",
    "    plt.plot(fpr,tpr)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_train.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    # Val set\n",
    "    predictions_val  = model_gbm.predict(XTrain)\n",
    "    print(\"Ext Val Set F1:\", f1_score(yTrain, model_gbm.predict(XTrain), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set MCC:\", matthews_corrcoef(yTrain, model_gbm.predict(XTrain), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set Accuracy:\", metrics.accuracy_score(yTrain, predictions_val))\n",
    "    print(classification_report(yTrain, predictions_val))\n",
    "    print(confusion_matrix(yTrain, predictions_val))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_val, tpr_val, _ = metrics.roc_curve(yTrain, predictions_val)\n",
    "    plt.plot(fpr_val,tpr_val)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_test.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    f1_5_train = cross_val_score(model_gbm, XTrain, yTrain, cv = 5, scoring=\"f1\")\n",
    "    print(\"5F-CV:\", avgScore(f1_5_train, 5))\n",
    "    \n",
    "    # Test set\n",
    "    predictions_FNA = model_gbm.predict(XTest)\n",
    "    print(\"FNA Set F1:\", f1_score(yTest, model_gbm.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set MCC:\", matthews_corrcoef(yTest, model_gbm.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set Recall:\", recall_score(yTest, model_gbm.predict(XTest)))\n",
    "    print(\"FNA Test Set Accuracy:\", metrics.accuracy_score(yTest, predictions_FNA))\n",
    "    print(classification_report(yTest, predictions_FNA))\n",
    "    print(confusion_matrix(yTest, predictions_FNA))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_FNA, tpr_FNA, _ = metrics.roc_curve(yTest, predictions_FNA)\n",
    "    plt.plot(fpr_FNA,tpr_FNA)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"G:/raMSIn/XGB_Importance2/XGB2_ROC_FNAtest2.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    # Visualize the importantance of the features\n",
    "    feature_imp = pd.Series(model_gbm.feature_importances_, index=XTrain.columns).sort_values(ascending=False)\n",
    "    x=feature_imp\n",
    "    y=feature_imp.index\n",
    "    \n",
    "    plt.subplots(dpi = 300)\n",
    "    #plt.rcParams[\"figure.figsize\"] = [4, 6]\n",
    "    #plt.rcParams[\"font.family\"] = \"Arial\"\n",
    "    #plt.rcParams.update({'font.size': 6})\n",
    "    plt.xlabel('Feature Importance Score', fontproperties='Arial', fontsize=17)\n",
    "    plt.ylabel('Features', fontproperties='Arial', fontsize=17)\n",
    "    plt.xticks(fontsize=15)\n",
    "    plt.yticks(fontsize=15)\n",
    "    plt.title(\"Important Molecular Features\", fontproperties='Arial', fontsize=20)\n",
    "    sns.barplot(x=feature_imp, y=feature_imp.index)\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/XGB_TopFeatures.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    # Visualize the boxplot of the important features between the two groups\n",
    "    #fig = px.box(data_frame = df_ROI_for_ML_Opti, x = feature_imp[:10].index,color= 'type')\n",
    "    #fig.show()\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "58c5dcd8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set F1: 0.5863644483618763\n",
      "Training Set MCC: 0.08615634286831296\n",
      "Training Set Accuracy: 0.5374450307827616\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.44      0.50     47449\n",
      "           1       0.51      0.65      0.57     43511\n",
      "\n",
      "    accuracy                           0.54     90960\n",
      "   macro avg       0.54      0.54      0.53     90960\n",
      "weighted avg       0.55      0.54      0.53     90960\n",
      "\n",
      "[[20642 26807]\n",
      " [15267 28244]]\n",
      "Ext Val Set F1: 0.8858235368847232\n",
      "Ext Val Set MCC: 0.7679336774159764\n",
      "Ext Val Set Accuracy: 0.8842798353909465\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.87      0.88      2943\n",
      "           1       0.88      0.90      0.89      3132\n",
      "\n",
      "    accuracy                           0.88      6075\n",
      "   macro avg       0.88      0.88      0.88      6075\n",
      "weighted avg       0.88      0.88      0.88      6075\n",
      "\n",
      "[[2546  397]\n",
      " [ 306 2826]]\n",
      "5F-CV: 0.7432621722756714\n",
      "FNA Set F1: 0.5866301920799357\n",
      "FNA Set MCC: 0.04374549576941435\n",
      "FNA Set Recall: 0.6801249971694482\n",
      "FNA Test Set Accuracy: 0.5200505067586612\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.36      0.43     44540\n",
      "           1       0.51      0.68      0.59     44161\n",
      "\n",
      "    accuracy                           0.52     88701\n",
      "   macro avg       0.52      0.52      0.51     88701\n",
      "weighted avg       0.52      0.52      0.51     88701\n",
      "\n",
      "[[16094 28446]\n",
      " [14126 30035]]\n"
     ]
    }
   ],
   "source": [
    "coeff_GBM, TOPfeatures_GBM = GBM_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c276f472",
   "metadata": {},
   "source": [
    "### 3.4.4. Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b940433a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build stacking Model\n",
    "\n",
    "def Stacking_func(XTrain=X_val, XVal=X_train, XTest=X_FNA, XTest2=X_di, yTrain=y_val, yVal=y_train, yTest=y_FNA, yTest2=y_di):\n",
    "\n",
    "    base_learners = []\n",
    "\n",
    "    # Define models to use in stacking ensemble\n",
    "    m1 = LogisticRegression(C=0.001, penalty='l1', solver=\"liblinear\", max_iter=5000, random_state=42, class_weight={0:0.9628, 1:1.0402})\n",
    "    base_learners.append(m1)\n",
    "\n",
    "    m2 = LinearSVC(penalty='l2', loss=\"squared_hinge\", C=461, random_state=42, class_weight={0:0.9628, 1:1.0402})\n",
    "    base_learners.append(m2)\n",
    "\n",
    "    m3 = GradientBoostingClassifier(learning_rate=4, n_estimators=50, max_depth=7, min_samples_leaf=4, min_samples_split=30, n_iter_no_change=5, random_state=42)\n",
    "    base_learners.append(m3)\n",
    "\n",
    "    # Define the meta-classifier to use for stacking\n",
    "    meta_learner = LogisticRegression(C=0.0011, penalty='l1', solver=\"liblinear\", max_iter=5000, random_state=42)\n",
    "\n",
    "    model_sc = StackingRegressor([[m1, m2, m3], [meta_learner]])\n",
    "    model_sc.fit(XTrain, yTrain)\n",
    "    \n",
    "    #=======================================\n",
    "    \n",
    "    # Training Set\n",
    "    #plt.rcParams[\"figure.figsize\"] = (3,3)\n",
    "    X_train_predictions = model_sc.predict(XVal)[-1]\n",
    "    print(\"Training Set F1:\", f1_score(yVal, model_sc.predict(XVal)[-1], sample_weight=sampleW))\n",
    "    print(\"Training Set MCC:\", matthews_corrcoef(yVal, model_sc.predict(XVal)[-1], sample_weight=sampleW))\n",
    "    print(\"Training Set Accuracy:\", metrics.accuracy_score(yVal, X_train_predictions))\n",
    "    print(classification_report(yVal, X_train_predictions))\n",
    "    print(confusion_matrix(yVal, X_train_predictions))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr, tpr, _ = metrics.roc_curve(yVal, X_train_predictions)\n",
    "    plt.plot(fpr,tpr)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_train.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    # Val set\n",
    "    predictions_val  = model_sc.predict(XTrain)[-1]\n",
    "    print(\"Ext Val Set F1:\", f1_score(yTrain, model_sc.predict(XTrain)[-1], sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set MCC:\", matthews_corrcoef(yTrain, model_sc.predict(XTrain)[-1], sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set Accuracy:\", metrics.accuracy_score(yTrain, predictions_val))\n",
    "    print(classification_report(yTrain, predictions_val))\n",
    "    print(confusion_matrix(yTrain, predictions_val))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_val, tpr_val, _ = metrics.roc_curve(yTrain, predictions_val)\n",
    "    plt.plot(fpr_val,tpr_val)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_test.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    #f1_5_train = cross_val_score(model_sc, XTrain, yTrain, cv = 5, scoring=\"f1\")\n",
    "    #print(\"5F-CV:\", avgScore(f1_5_train, 5))\n",
    "    \n",
    "    # Test set\n",
    "    predictions_FNA = model_sc.predict(XTest)[-1]\n",
    "    print(\"FNA Set F1:\", f1_score(yTest, model_sc.predict(XTest)[-1], sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set MCC:\", matthews_corrcoef(yTest, model_sc.predict(XTest)[-1], sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set Recall:\", recall_score(yTest, model_sc.predict(XTest)[-1]))\n",
    "    print(\"FNA Test Set Accuracy:\", metrics.accuracy_score(yTest, predictions_FNA))\n",
    "    print(classification_report(yTest, predictions_FNA))\n",
    "    print(confusion_matrix(yTest, predictions_FNA))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_FNA, tpr_FNA, _ = metrics.roc_curve(yTest, predictions_FNA)\n",
    "    plt.plot(fpr_FNA,tpr_FNA)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"G:/raMSIn/XGB_Importance2/XGB2_ROC_FNAtest2.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    # Test2 set\n",
    "    predictions_di = model_sc.predict(XTest2)[-1]\n",
    "    print(\"DirectIn Set F1:\", f1_score(yTest2, model_sc.predict(XTest2)[-1], sample_weight=sampleDiW))\n",
    "    print(\"DirectIn Set MCC:\", matthews_corrcoef(yTest2, model_sc.predict(XTest2)[-1], sample_weight=sampleDiW))\n",
    "    print(\"DirectIn Set Recall:\", recall_score(yTest2, model_sc.predict(XTest2)[-1]))\n",
    "    print(\"DirectIn Test Set Accuracy:\", metrics.accuracy_score(yTest2, predictions_di))\n",
    "    print(classification_report(yTest2, predictions_di))\n",
    "    print(confusion_matrix(yTest2, predictions_di))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_di, tpr_di, _ = metrics.roc_curve(yTest2, predictions_di)\n",
    "    plt.plot(fpr_di,tpr_di)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"G:/raMSIn/XGB_Importance2/XGB2_ROC_FNAtest2.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "74cbb345",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set F1: 0.0\n",
      "Training Set MCC: 0.0\n",
      "Training Set Accuracy: 0.5216468777484609\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      1.00      0.69     47449\n",
      "           1       0.00      0.00      0.00     43511\n",
      "\n",
      "    accuracy                           0.52     90960\n",
      "   macro avg       0.26      0.50      0.34     90960\n",
      "weighted avg       0.27      0.52      0.36     90960\n",
      "\n",
      "[[47449     0]\n",
      " [43511     0]]\n",
      "Ext Val Set F1: 0.0\n",
      "Ext Val Set MCC: 0.0\n",
      "Ext Val Set Accuracy: 0.48444444444444446\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      1.00      0.65      2943\n",
      "           1       0.00      0.00      0.00      3132\n",
      "\n",
      "    accuracy                           0.48      6075\n",
      "   macro avg       0.24      0.50      0.33      6075\n",
      "weighted avg       0.23      0.48      0.32      6075\n",
      "\n",
      "[[2943    0]\n",
      " [3132    0]]\n",
      "FNA Set F1: 0.0\n",
      "FNA Set MCC: 0.0\n",
      "FNA Set Recall: 0.0\n",
      "FNA Test Set Accuracy: 0.5021363907960451\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67     44540\n",
      "           1       0.00      0.00      0.00     44161\n",
      "\n",
      "    accuracy                           0.50     88701\n",
      "   macro avg       0.25      0.50      0.33     88701\n",
      "weighted avg       0.25      0.50      0.34     88701\n",
      "\n",
      "[[44540     0]\n",
      " [44161     0]]\n",
      "DirectIn Set F1: 0.0\n",
      "DirectIn Set MCC: 0.0\n",
      "DirectIn Set Recall: 0.0\n",
      "DirectIn Test Set Accuracy: 0.49975235264982665\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67      3027\n",
      "           1       0.00      0.00      0.00      3030\n",
      "\n",
      "    accuracy                           0.50      6057\n",
      "   macro avg       0.25      0.50      0.33      6057\n",
      "weighted avg       0.25      0.50      0.33      6057\n",
      "\n",
      "[[3027    0]\n",
      " [3030    0]]\n"
     ]
    }
   ],
   "source": [
    "Stacking_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b896917b",
   "metadata": {},
   "source": [
    "### 3.4.5. Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d03a0a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Voting_func(XTrain=X_val, XVal=X_train, XTest=X_FNA, XTest2=X_di, yTrain=y_val, yVal=y_train, yTest=y_FNA, yTest2=y_di):\n",
    "\n",
    "    models = get_models()\n",
    "    \n",
    "    ensemble = models[\"hard_voting\"]\n",
    "    ensemble.fit(XTrain, yTrain)\n",
    "    #=======================================\n",
    "\n",
    "    # Training Set\n",
    "    #plt.rcParams[\"figure.figsize\"] = (3,3)\n",
    "    X_train_predictions = ensemble.predict(XVal)\n",
    "    print(\"Training Set F1:\", f1_score(yVal, ensemble.predict(XVal), sample_weight=sampleW))\n",
    "    print(\"Training Set MCC:\", matthews_corrcoef(yVal, ensemble.predict(XVal), sample_weight=sampleW))\n",
    "    print(\"Training Set Accuracy:\", metrics.accuracy_score(yVal, X_train_predictions))\n",
    "    print(classification_report(yVal, X_train_predictions))\n",
    "    print(confusion_matrix(yVal, X_train_predictions))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr, tpr, _ = metrics.roc_curve(yVal, X_train_predictions)\n",
    "    plt.plot(fpr,tpr)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_train.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    # Val set\n",
    "    predictions_val  = ensemble.predict(XTrain)\n",
    "    print(\"Ext Val Set F1:\", f1_score(yTrain, ensemble.predict(XTrain), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set MCC:\", matthews_corrcoef(yTrain, ensemble.predict(XTrain), sample_weight=sampleExtW))\n",
    "    print(\"Ext Val Set Accuracy:\", metrics.accuracy_score(yTrain, predictions_val))\n",
    "    print(classification_report(yTrain, predictions_val))\n",
    "    print(confusion_matrix(yTrain, predictions_val))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_val, tpr_val, _ = metrics.roc_curve(yTrain, predictions_val)\n",
    "    plt.plot(fpr_val,tpr_val)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"H:/3_2_Output_raMSI_DataIngestion_DESIQE_12F/XGB_FNA/LogReg_ROC_test.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    f1_5_train = cross_val_score(ensemble, XTrain, yTrain, cv = 5, scoring=\"f1\")\n",
    "    print(\"5F-CV:\", avgScore(f1_5_train, 5))\n",
    "\n",
    "    # Test set\n",
    "    predictions_FNA = ensemble.predict(XTest)\n",
    "    print(\"FNA Set F1:\", f1_score(yTest, ensemble.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set MCC:\", matthews_corrcoef(yTest, ensemble.predict(XTest), sample_weight=sampleFNAW))\n",
    "    print(\"FNA Set Recall:\", recall_score(yTest, ensemble.predict(XTest)))\n",
    "    print(\"FNA Test Set Accuracy:\", metrics.accuracy_score(yTest, predictions_FNA))\n",
    "    print(classification_report(yTest, predictions_FNA))\n",
    "    print(confusion_matrix(yTest, predictions_FNA))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_FNA, tpr_FNA, _ = metrics.roc_curve(yTest, predictions_FNA)\n",
    "    plt.plot(fpr_FNA,tpr_FNA)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"G:/raMSIn/XGB_Importance2/XGB2_ROC_FNAtest2.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "    # Test2 set\n",
    "    predictions_di = ensemble.predict(XTest2)\n",
    "    print(\"DirectIn Set F1:\", f1_score(yTest2, ensemble.predict(XTest2), sample_weight=sampleDiW))\n",
    "    print(\"DirectIn Set MCC:\", matthews_corrcoef(yTest2, ensemble.predict(XTest2), sample_weight=sampleDiW))\n",
    "    print(\"DirectIn Set Recall:\", recall_score(yTest2, ensemble.predict(XTest2)))\n",
    "    print(\"DirectIn Test Set Accuracy:\", metrics.accuracy_score(yTest2, predictions_di))\n",
    "    print(classification_report(yTest2, predictions_di))\n",
    "    print(confusion_matrix(yTest2, predictions_di))\n",
    "\n",
    "    #create ROC curve\n",
    "    plt.subplots(dpi = 300)\n",
    "    fpr_di, tpr_di, _ = metrics.roc_curve(yTest2, predictions_di)\n",
    "    plt.plot(fpr_di,tpr_di)\n",
    "    plt.ylabel('True Positive Rate', fontsize=18)\n",
    "    plt.xlabel('False Positive Rate', fontsize=18)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    #plt.rcParams['figure.figsize'] = [2, 2]\n",
    "    #plt.savefig(r\"G:/raMSIn/XGB_Importance2/XGB2_ROC_FNAtest2.tif\", bbox_inches = 'tight')\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2e1865ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set F1: 0.40068780281187855\n",
      "Training Set MCC: -0.08164266841007049\n",
      "Training Set Accuracy: 0.46427000879507474\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.56      0.52     47449\n",
      "           1       0.43      0.36      0.39     43511\n",
      "\n",
      "    accuracy                           0.46     90960\n",
      "   macro avg       0.46      0.46      0.46     90960\n",
      "weighted avg       0.46      0.46      0.46     90960\n",
      "\n",
      "[[26521 20928]\n",
      " [27802 15709]]\n",
      "Ext Val Set F1: 0.9118366796605383\n",
      "Ext Val Set MCC: 0.8459695879583415\n",
      "Ext Val Set Accuracy: 0.9160493827160494\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.99      0.92      2943\n",
      "           1       0.99      0.84      0.91      3132\n",
      "\n",
      "    accuracy                           0.92      6075\n",
      "   macro avg       0.92      0.92      0.92      6075\n",
      "weighted avg       0.93      0.92      0.92      6075\n",
      "\n",
      "[[2920   23]\n",
      " [ 487 2645]]\n",
      "5F-CV: 0.7638403247393223\n",
      "FNA Set F1: 0.43991384396353395\n",
      "FNA Set MCC: -0.0265839290604983\n",
      "FNA Set Recall: 0.40300264939652636\n",
      "FNA Test Set Accuracy: 0.487254935119108\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.57      0.53     44540\n",
      "           1       0.48      0.40      0.44     44161\n",
      "\n",
      "    accuracy                           0.49     88701\n",
      "   macro avg       0.49      0.49      0.48     88701\n",
      "weighted avg       0.49      0.49      0.48     88701\n",
      "\n",
      "[[25423 19117]\n",
      " [26364 17797]]\n",
      "DirectIn Set F1: 0.4399314600150522\n",
      "DirectIn Set MCC: -0.005125685098704881\n",
      "DirectIn Set Recall: 0.3947194719471947\n",
      "DirectIn Test Set Accuracy: 0.497440977381542\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.60      0.54      3027\n",
      "           1       0.50      0.39      0.44      3030\n",
      "\n",
      "    accuracy                           0.50      6057\n",
      "   macro avg       0.50      0.50      0.49      6057\n",
      "weighted avg       0.50      0.50      0.49      6057\n",
      "\n",
      "[[1817 1210]\n",
      " [1834 1196]]\n"
     ]
    }
   ],
   "source": [
    "Voting_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a613c4",
   "metadata": {},
   "source": [
    "# 4. Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5cafba",
   "metadata": {},
   "source": [
    "## 4.1 Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0ab74741",
   "metadata": {},
   "outputs": [],
   "source": [
    "## deploy models for training set ##\n",
    "model_voting = jl.load(r\"H:\\3_output_raMSIn\\3_3_Output_raMSIn_HKU_Ingested4ALL\\XGB_ALL\\afterModelSelection\\cbMSIn_0d001\\model3to1Voting_cbMSIn0d001.joblib\")\n",
    "#\n",
    "## deploy model ##\n",
    "predicted0n1_train = model_voting.predict(X_train)\n",
    "#predicted0n1_trainProba = model_voting.predict_proba(X_train)         \n",
    "trainDEFSDf[\"predicted0n1\"] = predicted0n1_train\n",
    "T_ = []\n",
    "F_ = []\n",
    "for i in range(len(trainDEFSDf)):\n",
    "    if trainDEFSDf.iloc[i][\"predicted0n1\"] == 1:\n",
    "        T_.append(1)\n",
    "        F_.append(0)\n",
    "    elif trainDEFSDf.iloc[i][\"predicted0n1\"] == 0:\n",
    "        F_.append(1)\n",
    "        T_.append(0)\n",
    "trainDEFSDf[\"T\"] = T_\n",
    "trainDEFSDf[\"F\"] = F_\n",
    "#\n",
    "## save ##, ouputing trainSet df\n",
    "savePath = r\"H:\\3_output_raMSIn\\3_3_Output_raMSIn_HKU_Ingested4ALL\\XGB_ALL\\afterModelSelection\\cbMSIn_0d001\\df_train_cbMSIn0d001_norm_0n1.csv\"\n",
    "trainDEFSDf.to_csv(savePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "76d7c323",
   "metadata": {},
   "outputs": [],
   "source": [
    "## deploy models for Ext Val set ##\n",
    "model_voting = jl.load(r\"H:\\3_output_raMSIn\\3_3_Output_raMSIn_HKU_Ingested4ALL\\XGB_ALL\\afterModelSelection\\cbMSIn_0d001\\model3to1Voting_cbMSIn0d001.joblib\")\n",
    "#\n",
    "## deploy model ##\n",
    "predicted0n1_ext = model_voting.predict(X_val)\n",
    "extDEFSDf[\"predicted0n1\"] = predicted0n1_ext\n",
    "T_ = []\n",
    "F_ = []\n",
    "for i in range(len(extDEFSDf)):\n",
    "    if extDEFSDf.iloc[i][\"predicted0n1\"] == 1:\n",
    "        T_.append(1)\n",
    "        F_.append(0)\n",
    "    elif extDEFSDf.iloc[i][\"predicted0n1\"] == 0:\n",
    "        F_.append(1)\n",
    "        T_.append(0)\n",
    "extDEFSDf[\"T\"] = T_\n",
    "extDEFSDf[\"F\"] = F_\n",
    "#\n",
    "## save ##, ouputing extSet df\n",
    "savePath = r\"H:\\3_output_raMSIn\\3_3_Output_raMSIn_HKU_Ingested4ALL\\XGB_ALL\\afterModelSelection\\cbMSIn_0d001\\df_ext_cbMSIn0d001_norm_0n1.csv\"\n",
    "extDEFSDf.to_csv(savePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3a327944",
   "metadata": {},
   "outputs": [],
   "source": [
    "## deploy models for FNA set ##\n",
    "model_voting = jl.load(r\"H:\\3_output_raMSIn\\3_3_Output_raMSIn_HKU_Ingested4ALL\\XGB_ALL\\afterModelSelection\\cbMSIn_0d001\\model3to1Voting_cbMSIn0d001.joblib\")\n",
    "#\n",
    "## deploy model ##\n",
    "predicted0n1_FNA = model_voting.predict(X_FNA)\n",
    "fnaDEFSDf[\"predicted0n1\"] = predicted0n1_FNA\n",
    "T_ = []\n",
    "F_ = []\n",
    "for i in range(len(fnaDEFSDf)):\n",
    "    if fnaDEFSDf.iloc[i][\"predicted0n1\"] == 1:\n",
    "        T_.append(1)\n",
    "        F_.append(0)\n",
    "    elif fnaDEFSDf.iloc[i][\"predicted0n1\"] == 0:\n",
    "        F_.append(1)\n",
    "        T_.append(0)\n",
    "fnaDEFSDf[\"T\"] = T_\n",
    "fnaDEFSDf[\"F\"] = F_\n",
    "#\n",
    "## save ##, ouputing extSet df\n",
    "savePath = r\"H:\\3_output_raMSIn\\3_3_Output_raMSIn_HKU_Ingested4ALL\\XGB_ALL\\afterModelSelection\\cbMSIn_0d001\\df_FNA_cbMSIn0d001_norm_0n1.csv\"\n",
    "fnaDEFSDf.to_csv(savePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e771a1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "## deploy models for DirectInfusion set ##\n",
    "model_voting = jl.load(r\"H:\\3_output_raMSIn\\3_3_Output_raMSIn_HKU_Ingested4ALL\\XGB_ALL\\afterModelSelection\\cbMSIn_0d001\\model3to1Voting_cbMSIn0d001.joblib\")\n",
    "#\n",
    "## deploy model ##\n",
    "predicted0n1_Di = model_voting.predict(X_di)\n",
    "diDEFSDf[\"predicted0n1\"] = predicted0n1_Di\n",
    "T_ = []\n",
    "F_ = []\n",
    "for i in range(len(diDEFSDf)):\n",
    "    if diDEFSDf.iloc[i][\"predicted0n1\"] == 1:\n",
    "        T_.append(1)\n",
    "        F_.append(0)\n",
    "    elif diDEFSDf.iloc[i][\"predicted0n1\"] == 0:\n",
    "        F_.append(1)\n",
    "        T_.append(0)\n",
    "diDEFSDf[\"T\"] = T_\n",
    "diDEFSDf[\"F\"] = F_\n",
    "#\n",
    "## save ##, ouputing extSet df\n",
    "savePath = r\"H:\\3_output_raMSIn\\3_3_Output_raMSIn_HKU_Ingested4ALL\\XGB_ALL\\afterModelSelection\\cbMSIn_0d001\\df_Di_cbMSIn0d001_norm_0n1.csv\"\n",
    "diDEFSDf.to_csv(savePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3082152",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
